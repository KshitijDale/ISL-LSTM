{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVP2efUUNjn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c33cf54-ca8b-49cf-aaf4-c93f470aa4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, numpy, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 protobuf-4.25.7 sounddevice-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZIlJu7PbYbI",
        "outputId": "1f160bf3-a058-46d6-d44d-562cec2464da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZkkjD6oevmA"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "owOobpJ4NvzZ",
        "outputId": "1f8eea91-4ead-4660-ef1d-e5f977fcb8e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m32,768\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,857</span> (257.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,857\u001b[0m (257.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,857</span> (257.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,857\u001b[0m (257.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "SEQUENCE_LENGTH = 25\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(64, return_sequences=True, activation='relu', input_shape=(SEQUENCE_LENGTH, 63)),\n",
        "    LSTM(64, return_sequences=False, activation='relu'),  # Only last output is taken\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')  # Single output for the sequence\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrR99Su4Y8_o"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjY0A-b-gW-w",
        "outputId": "bbc30db0-d3d1-4d9c-a888-5897265e9c3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset saved! Shape: X=(54, 25, 126), Y=(54,)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Initialize MediaPipe Hands\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.1)\n",
        "\n",
        "# Paths\n",
        "FRAMES_DIR = \"/content/sample_data/frames\"\n",
        "OUTPUT_DIR = \"/content/sample_data/dataset\"\n",
        "SEQUENCE_LENGTH = 25\n",
        "NUM_LANDMARKS = 42 * 3  # 21 keypoints * 2 hands * (x, y, z)\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "gesture_labels = {\"Y\": 0, \"H\": 1, \"J\": 2}\n",
        "\n",
        "def extract_landmarks(image_path):\n",
        "    \"\"\"Extract hand landmarks relative to wrist midpoint.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(image_rgb)\n",
        "\n",
        "    left_hand, right_hand = None, None\n",
        "    all_landmarks = []\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        detected_hands = []\n",
        "\n",
        "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
        "            landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
        "            detected_hands.append((landmarks, handedness.classification[0].label))  # 'Left' or 'Right'\n",
        "\n",
        "        # Assign left and right hands correctly\n",
        "        left_hand = next((l for l, h in detected_hands if h == \"Left\"), None)\n",
        "        right_hand = next((l for l, h in detected_hands if h == \"Right\"), None)\n",
        "\n",
        "    # Find wrist midpoint\n",
        "    if left_hand is not None and right_hand is not None:\n",
        "        wrist_midpoint = (left_hand[0] + right_hand[0]) / 2  # Average of both wrists\n",
        "    elif left_hand is not None:\n",
        "        wrist_midpoint = left_hand[0]  # Use left wrist if only one hand\n",
        "    elif right_hand is not None:\n",
        "        wrist_midpoint = right_hand[0]  # Use right wrist if only one hand\n",
        "    else:\n",
        "        wrist_midpoint = np.zeros(3)  # No hand detected, use (0,0,0)\n",
        "\n",
        "    # Normalize landmarks relative to wrist midpoint\n",
        "    if left_hand is not None:\n",
        "        left_hand -= wrist_midpoint\n",
        "        all_landmarks.extend(left_hand.flatten())\n",
        "    if right_hand is not None:\n",
        "        right_hand -= wrist_midpoint\n",
        "        all_landmarks.extend(right_hand.flatten())\n",
        "\n",
        "    # Pad missing hand landmarks with zeros\n",
        "    while len(all_landmarks) < NUM_LANDMARKS:\n",
        "        all_landmarks.extend([0] * 3 * 21)\n",
        "\n",
        "    return all_landmarks\n",
        "\n",
        "\n",
        "def process_gesture_folder(gesture_folder, label):\n",
        "    \"\"\"Extract sequences from gesture folder.\"\"\"\n",
        "    frame_files = sorted(os.listdir(gesture_folder))\n",
        "    X_data, Y_data = [], []\n",
        "\n",
        "    if len(frame_files) < SEQUENCE_LENGTH:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    # Extract strictly non-overlapping sequences\n",
        "    for i in range(0, len(frame_files) - SEQUENCE_LENGTH + 1, SEQUENCE_LENGTH):\n",
        "        sequence = []\n",
        "        for j in range(SEQUENCE_LENGTH):\n",
        "            frame_path = os.path.join(gesture_folder, frame_files[i + j])\n",
        "            landmarks = extract_landmarks(frame_path)\n",
        "            sequence.append(landmarks)\n",
        "\n",
        "        X_data.append(sequence)\n",
        "        Y_data.append(label)\n",
        "\n",
        "    return np.array(X_data), np.array(Y_data)\n",
        "\n",
        "# Prepare dataset\n",
        "X_dataset, Y_dataset = [], []\n",
        "\n",
        "for gesture, label in gesture_labels.items():\n",
        "    gesture_folder = os.path.join(FRAMES_DIR, gesture)\n",
        "    X, Y = process_gesture_folder(gesture_folder, label)\n",
        "    if X.size > 0:\n",
        "        X_dataset.append(X)\n",
        "        Y_dataset.append(Y)\n",
        "\n",
        "X_dataset = np.concatenate(X_dataset, axis=0)\n",
        "Y_dataset = np.concatenate(Y_dataset, axis=0)\n",
        "\n",
        "np.save(os.path.join(OUTPUT_DIR, \"X_data.npy\"), X_dataset)\n",
        "np.save(os.path.join(OUTPUT_DIR, \"Y_data.npy\"), Y_dataset)\n",
        "\n",
        "print(f\"✅ Dataset saved! Shape: X={X_dataset.shape}, Y={Y_dataset.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbwm__Lfu7IK",
        "outputId": "18612afd-65ea-42ec-eb16-9eefe6df3449"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "Gtgvw_M5d8eU",
        "outputId": "0bba7fb6-d09f-4abb-9488-53f06b500167"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'core' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ca16d7352203>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Initialize MediaPipe drawing utilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/tasks/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/tasks/python/audio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mAudioEmbedderOptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioEmbedderOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mAudioEmbedderResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioEmbedderResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mRunningMode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_task_running_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioTaskRunningMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Remove unnecessary modules to avoid duplication in API docs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'core' is not defined"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize MediaPipe drawing utilities\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5)\n",
        "\n",
        "def draw_landmarks_on_image(image_path):\n",
        "    \"\"\"Detects hand landmarks and overlays them on the image.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for MediaPipe\n",
        "    results = hands.process(image_rgb)\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            # Draw landmarks and connections\n",
        "            mp_drawing.draw_landmarks(image_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
        "\n",
        "    # Display the image with landmarks\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Hand Landmarks Overlay\")\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "sample_image_path = \"/content/unnamed.jpg\"  # Update with actual path\n",
        "# image = cv2.resize(sample_image_path, (640, 480))\n",
        "draw_landmarks_on_image(sample_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# Initialize MediaPipe Hands\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Path to your image - replace with your image path\n",
        "IMAGE_PATH = '/content/unnamed.jpg'  # Replace with your image path\n",
        "\n",
        "# Process image with MediaPipe Hands\n",
        "with mp_hands.Hands(\n",
        "    static_image_mode=True,\n",
        "    max_num_hands=2,\n",
        "    min_detection_confidence=0.5) as hands:\n",
        "\n",
        "    # Read image\n",
        "    image = cv2.imread(IMAGE_PATH)\n",
        "    if image is None:\n",
        "        print(f\"Error: Could not read image at {IMAGE_PATH}\")\n",
        "    else:\n",
        "        # Convert to RGB\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Process image\n",
        "        results = hands.process(image_rgb)\n",
        "\n",
        "        # Make a copy for drawing\n",
        "        annotated_image = image_rgb.copy()\n",
        "\n",
        "        # Check if hands detected\n",
        "        if results.multi_hand_landmarks:\n",
        "            print(f\"Found {len(results.multi_hand_landmarks)} hand(s)\")\n",
        "\n",
        "            # Draw landmarks on image\n",
        "            for hand_landmarks in results.multi_hand_landmarks:\n",
        "                mp_drawing.draw_landmarks(\n",
        "                    annotated_image,\n",
        "                    hand_landmarks,\n",
        "                    mp_hands.HAND_CONNECTIONS,\n",
        "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                    mp_drawing_styles.get_default_hand_connections_style())\n",
        "\n",
        "            # Display original and processed images side by side\n",
        "            plt.figure(figsize=(15, 7))\n",
        "\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(image_rgb)\n",
        "            plt.title('Original Image')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(annotated_image)\n",
        "            plt.title('Hand Landmarks')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            # Save annotated image (optional)\n",
        "            output_path = 'annotated_hand.jpg'\n",
        "            cv2.imwrite(output_path, cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))\n",
        "            print(f\"Saved annotated image to {output_path}\")\n",
        "        else:\n",
        "            print(\"No hands detected in the image\")\n",
        "            plt.figure(figsize=(8, 8))\n",
        "            plt.imshow(image_rgb)\n",
        "            plt.title('No hands detected')\n",
        "            plt.axis('off')\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "5khR3rHqTVEz",
        "outputId": "1140605f-4ccb-4074-8687-3cf663c8e637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'audio_classifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-feef905f3c46>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/tasks/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"MediaPipe Tasks API.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/tasks/python/audio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_embedder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mAudioClassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mAudioClassifierOptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClassifierOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mAudioClassifierResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudioClassifierResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'audio_classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLlivfd9c_Ns",
        "outputId": "f4eb5d7b-4a1f-46f6-c038-1a98803a8ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Preprocessed Data Shapes -> X_train: (43, 25, 126), Y_train: (43, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "X = np.load(\"/content/sample_data/dataset/X_data.npy\")  # Shape: (20, 15, 126)\n",
        "Y = np.load(\"/content/sample_data/dataset/Y_data.npy\")  # Shape: (20,)\n",
        "\n",
        "# Normalize X (already between 0-1, but can standardize if needed)\n",
        "X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
        "\n",
        "# One-hot encode Y\n",
        "num_classes = len(set(Y))  # Number of unique gestures\n",
        "Y = to_categorical(Y, num_classes)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"✅ Preprocessed Data Shapes -> X_train: {X_train.shape}, Y_train: {Y_train.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "pp4coQarynnK",
        "outputId": "e8447e18-a572-497c-cd32-43d51094e8de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">48,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m48,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m99\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,611</span> (330.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,611\u001b[0m (330.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,355</span> (329.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,355\u001b[0m (329.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Model Parameters\n",
        "sequence_length = 25  # 15 frames per sequence\n",
        "num_features = 126    # 42 landmarks * 3 (x, y, z)\n",
        "hidden_units = 64     # LSTM hidden state size\n",
        "\n",
        "# Build LSTM Model\n",
        "model = Sequential([\n",
        "    LSTM(hidden_units, return_sequences=True, input_shape=(sequence_length, num_features)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    LSTM(hidden_units, return_sequences=False),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(num_classes, activation=\"softmax\")  # Output layer\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q0BEX1wskx0",
        "outputId": "1aeab2d3-9e85-484c-ed8a-25427848ba4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOAXAz-9yxD2",
        "outputId": "0ad69dfe-9d6d-4398-c09f-b72a14f37b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 727ms/step - accuracy: 0.3108 - loss: 1.8676 - val_accuracy: 0.3636 - val_loss: 1.0698\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6633 - loss: 0.6853 - val_accuracy: 0.3636 - val_loss: 1.0468\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8912 - loss: 0.2522 - val_accuracy: 0.3636 - val_loss: 1.0247\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.9482 - loss: 0.1805 - val_accuracy: 0.5455 - val_loss: 1.0084\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.9482 - loss: 0.1733 - val_accuracy: 0.5455 - val_loss: 0.9870\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9845 - loss: 0.0950 - val_accuracy: 0.5455 - val_loss: 0.9664\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9380 - loss: 0.1571 - val_accuracy: 0.7273 - val_loss: 0.9459\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0916 - val_accuracy: 0.9091 - val_loss: 0.9226\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.9845 - loss: 0.0594 - val_accuracy: 0.9091 - val_loss: 0.9052\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0491 - val_accuracy: 1.0000 - val_loss: 0.8900\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0241 - val_accuracy: 1.0000 - val_loss: 0.8786\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0497 - val_accuracy: 1.0000 - val_loss: 0.8715\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 1.0000 - val_loss: 0.8591\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0532 - val_accuracy: 0.9091 - val_loss: 0.8428\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.9091 - val_loss: 0.8291\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0598 - val_accuracy: 0.9091 - val_loss: 0.8148\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.9741 - loss: 0.0505 - val_accuracy: 1.0000 - val_loss: 0.8048\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.8007\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 1.0000 - val_loss: 0.7968\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.9741 - loss: 0.0461 - val_accuracy: 1.0000 - val_loss: 0.7917\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9845 - loss: 0.0396 - val_accuracy: 1.0000 - val_loss: 0.7861\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 0.7785\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 0.7711\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.7637\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.7539\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.7298\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 1.0000 - val_loss: 0.7067\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 0.6889\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 1.0000 - val_loss: 0.6728\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 1.0000 - val_loss: 0.6606\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6606\n",
            "Validation Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the Model\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    epochs=30,  # Number of training cycles\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "# Evaluate on validation set\n",
        "val_loss, val_acc = model.evaluate(X_val, Y_val)\n",
        "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyjAhERwsr2a",
        "outputId": "0b68ab6e-f68d-426e-e218-fe59c646db4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
          ]
        }
      ],
      "source": [
        "Y_predicted = np.argmax(model.predict(X_val), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lI3t2C1swX3",
        "outputId": "5b968498-6b8c-4ca8-8c25-2dabfa8074d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 2, 0, 2, 0, 0, 2, 0, 1, 0])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvzDeRW3zqjD"
      },
      "source": [
        "## Testing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--chUYvGzeEE",
        "outputId": "cf69e35e-fdb1-4323-d862-841dd43d7b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Prediction 1: J\n",
            "Prediction 2: J\n",
            "Prediction 3: J\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from tensorflow.keras.models import load_model\n",
        "from collections import deque\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load trained LSTM model\n",
        "\n",
        "\n",
        "# Initialize MediaPipe Hands\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
        "\n",
        "# Video path\n",
        "VIDEO_PATH = \"/content/sample_data/test/J_2.mp4\"\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "# Parameters\n",
        "SEQUENCE_LENGTH = 25  # Same as during training\n",
        "NUM_LANDMARKS = 42 * 3  # 42 keypoints (21 per hand) * 3 (x, y, z)\n",
        "\n",
        "# Class labels (update according to your dataset)\n",
        "gesture_labels = {0: \"Y\", 1: \"H\", 2: \"J\"}  # Update with actual labels\n",
        "\n",
        "# Define frame indices for the three sequences\n",
        "sequence_indices = [\n",
        "    0,                          # First sequence (frames 0-24)\n",
        "    (total_frames // 2) - 12,   # Middle sequence (centered around the middle)\n",
        "    total_frames - SEQUENCE_LENGTH  # Last sequence (frames at the end)\n",
        "]\n",
        "sequence_indices = [max(0, min(idx, total_frames - SEQUENCE_LENGTH)) for idx in sequence_indices]  # Ensure valid indices\n",
        "\n",
        "\n",
        "# Get total frame count\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Function to extract landmarks\n",
        "def extract_landmarks(frame):\n",
        "    \"\"\"Extracts hand landmarks relative to the wrist midpoint.\"\"\"\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(frame_rgb)\n",
        "\n",
        "    left_hand, right_hand = None, None\n",
        "    all_landmarks = []\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        detected_hands = []\n",
        "\n",
        "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
        "            landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
        "            detected_hands.append((landmarks, handedness.classification[0].label))  # 'Left' or 'Right'\n",
        "\n",
        "        # Assign left and right hands correctly\n",
        "        left_hand = next((l for l, h in detected_hands if h == \"Left\"), None)\n",
        "        right_hand = next((l for l, h in detected_hands if h == \"Right\"), None)\n",
        "\n",
        "    # Find wrist midpoint\n",
        "    if left_hand is not None and right_hand is not None:\n",
        "        wrist_midpoint = (left_hand[0] + right_hand[0]) / 2  # Average of both wrists\n",
        "    elif left_hand is not None:\n",
        "        wrist_midpoint = left_hand[0]  # Use left wrist if only one hand\n",
        "    elif right_hand is not None:\n",
        "        wrist_midpoint = right_hand[0]  # Use right wrist if only one hand\n",
        "    else:\n",
        "        wrist_midpoint = np.zeros(3)  # No hand detected, use (0,0,0)\n",
        "\n",
        "    # Normalize landmarks relative to wrist midpoint\n",
        "    if left_hand is not None:\n",
        "        left_hand -= wrist_midpoint\n",
        "        all_landmarks.extend(left_hand.flatten())\n",
        "    if right_hand is not None:\n",
        "        right_hand -= wrist_midpoint\n",
        "        all_landmarks.extend(right_hand.flatten())\n",
        "\n",
        "    # Pad missing hand landmarks with zeros\n",
        "    while len(all_landmarks) < NUM_LANDMARKS:\n",
        "        all_landmarks.extend([0] * 3 * 21)\n",
        "\n",
        "    return np.array(all_landmarks)\n",
        "\n",
        "# Store predictions\n",
        "predictions = []\n",
        "# Process video\n",
        "# Process video for the three sequences\n",
        "for seq_start in sequence_indices:\n",
        "    sequence_buffer = []\n",
        "\n",
        "    # Seek to the sequence start frame\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, seq_start)\n",
        "\n",
        "    # Read 25 frames\n",
        "    for _ in range(SEQUENCE_LENGTH):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        landmarks = extract_landmarks(frame)\n",
        "        sequence_buffer.append(landmarks)\n",
        "\n",
        "    # Convert to NumPy and predict\n",
        "    if len(sequence_buffer) == SEQUENCE_LENGTH:\n",
        "        input_sequence = np.expand_dims(np.array(sequence_buffer), axis=0)  # Shape: (1, 25, 126)\n",
        "        input_sequence = (input_sequence - np.min(input_sequence)) / (np.max(input_sequence) - np.min(input_sequence))\n",
        "        prediction = model.predict(input_sequence)\n",
        "        predicted_class = np.argmax(prediction)\n",
        "        predictions.append(gesture_labels.get(predicted_class, \"Unknown\"))\n",
        "\n",
        "# Release video\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Display final predictions\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(f\"Prediction {i+1}: {pred}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcrvwZwAoe8Y"
      },
      "source": [
        "# 26 Letters Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieSorALtoryF",
        "outputId": "92f1e6c9-4a82-4833-ff21-379037aed637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Preprocessed Data Shapes -> X_train: (228, 25, 126), Y_train: (228, 26)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "X = np.load(\"/content/X_data.npy\")  # Shape: (20, 15, 126)\n",
        "Y = np.load(\"/content/Y_data.npy\")  # Shape: (20,)\n",
        "\n",
        "# Normalize X (already between 0-1, but can standardize if needed)\n",
        "X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
        "\n",
        "# One-hot encode Y\n",
        "num_classes = len(set(Y))  # Number of unique gestures\n",
        "Y = to_categorical(Y, num_classes)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"✅ Preprocessed Data Shapes -> X_train: {X_train.shape}, Y_train: {Y_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnMmKS6cqIbF",
        "outputId": "dff0a44a-05de-4f2a-fefe-d6c772f53791"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0.37536773, 0.49811478, 0.50263583, ..., 0.64961891,\n",
              "         0.47170119, 0.46692846],\n",
              "        [0.37501746, 0.49783204, 0.50263583, ..., 0.65001245,\n",
              "         0.47117539, 0.46792102],\n",
              "        [0.3752563 , 0.49782602, 0.50263582, ..., 0.65211316,\n",
              "         0.47121818, 0.46765022],\n",
              "        ...,\n",
              "        [0.37465511, 0.49810867, 0.50263585, ..., 0.64783645,\n",
              "         0.47118497, 0.46464174],\n",
              "        [0.37439062, 0.49813885, 0.50263584, ..., 0.64774354,\n",
              "         0.47153428, 0.46416497],\n",
              "        [0.37350121, 0.49843268, 0.50263583, ..., 0.6477035 ,\n",
              "         0.47173651, 0.46421093]],\n",
              "\n",
              "       [[0.46293624, 0.41974403, 0.50263568, ..., 0.55127555,\n",
              "         0.57097059, 0.47885058],\n",
              "        [0.46290085, 0.42003788, 0.50263567, ..., 0.55159499,\n",
              "         0.56890942, 0.47891715],\n",
              "        [0.46311037, 0.41962012, 0.50263568, ..., 0.55136259,\n",
              "         0.57135966, 0.47735928],\n",
              "        ...,\n",
              "        [0.45842628, 0.37707532, 0.50263571, ..., 0.52992324,\n",
              "         0.62496248, 0.47077287],\n",
              "        [0.45732773, 0.3714621 , 0.5026357 , ..., 0.52950305,\n",
              "         0.63542575, 0.46565686],\n",
              "        [0.45778239, 0.37218405, 0.5026357 , ..., 0.52846954,\n",
              "         0.63617596, 0.46550431]],\n",
              "\n",
              "       [[0.42697987, 0.5400821 , 0.50263567, ..., 0.81610334,\n",
              "         0.41686565, 0.41712434],\n",
              "        [0.42974879, 0.53808717, 0.50263571, ..., 0.8197357 ,\n",
              "         0.41719315, 0.41821636],\n",
              "        [0.42905981, 0.53784073, 0.50263574, ..., 0.81976034,\n",
              "         0.41883623, 0.41400812],\n",
              "        ...,\n",
              "        [0.42837404, 0.5383272 , 0.50263569, ..., 0.81890843,\n",
              "         0.41225695, 0.40646639],\n",
              "        [0.4289824 , 0.53797568, 0.50263573, ..., 0.81878512,\n",
              "         0.4116584 , 0.40804421],\n",
              "        [0.42988853, 0.53861051, 0.50263567, ..., 0.81879606,\n",
              "         0.41197191, 0.40922985]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.43578866, 0.59222748, 0.50263565, ..., 0.58582552,\n",
              "         0.39495564, 0.46536833],\n",
              "        [0.43543439, 0.59177344, 0.50263566, ..., 0.58773599,\n",
              "         0.39396846, 0.46801181],\n",
              "        [0.50263566, 0.50263566, 0.50263566, ..., 0.50263566,\n",
              "         0.50263566, 0.50263566],\n",
              "        ...,\n",
              "        [0.50263566, 0.50263566, 0.50263566, ..., 0.50263566,\n",
              "         0.50263566, 0.50263566],\n",
              "        [0.50263566, 0.50263566, 0.50263566, ..., 0.50263566,\n",
              "         0.50263566, 0.50263566],\n",
              "        [0.50263566, 0.50263566, 0.50263566, ..., 0.50263566,\n",
              "         0.50263566, 0.50263566]],\n",
              "\n",
              "       [[0.50509633, 0.58387294, 0.50263514, ..., 0.75678503,\n",
              "         0.50943745, 0.37740221],\n",
              "        [0.50577319, 0.58487027, 0.50263515, ..., 0.75605882,\n",
              "         0.50987666, 0.38165493],\n",
              "        [0.50483848, 0.58407391, 0.50263524, ..., 0.75993441,\n",
              "         0.50909033, 0.38148981],\n",
              "        ...,\n",
              "        [0.50254213, 0.58451607, 0.50263512, ..., 0.76481111,\n",
              "         0.51368707, 0.3726535 ],\n",
              "        [0.49992598, 0.58355129, 0.50263531, ..., 0.76333834,\n",
              "         0.51219802, 0.37152533],\n",
              "        [0.50089628, 0.58518828, 0.50263512, ..., 0.76441884,\n",
              "         0.51472607, 0.3772058 ]],\n",
              "\n",
              "       [[0.29177718, 0.50889841, 0.50263579, ..., 0.64430198,\n",
              "         0.51854694, 0.39900688],\n",
              "        [0.28993119, 0.50886484, 0.5026358 , ..., 0.64660882,\n",
              "         0.5174096 , 0.39874381],\n",
              "        [0.29078832, 0.5081091 , 0.5026359 , ..., 0.64148587,\n",
              "         0.51741635, 0.41256614],\n",
              "        ...,\n",
              "        [0.29072113, 0.50723641, 0.50263589, ..., 0.64318544,\n",
              "         0.51599426, 0.41254755],\n",
              "        [0.2911972 , 0.50692025, 0.5026359 , ..., 0.64221016,\n",
              "         0.51593876, 0.4171418 ],\n",
              "        [0.29103853, 0.50772835, 0.50263589, ..., 0.64152732,\n",
              "         0.51541026, 0.41562448]]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "vZONfMVg1OOa",
        "outputId": "f337a5d9-3758-4c05-94e8-279136568bd8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">130,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,690</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m130,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m)                  │           \u001b[38;5;34m1,690\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">273,114</span> (1.04 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m273,114\u001b[0m (1.04 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">272,602</span> (1.04 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m272,602\u001b[0m (1.04 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Model Parameters\n",
        "sequence_length = 25  # Number of frames per sequence\n",
        "num_features = 126    # 42 landmarks * 3 (x, y, z)\n",
        "hidden_units = 128    # Increased hidden size for better feature extraction\n",
        "num_classes = 26      # A to Z\n",
        "l2_lambda = 0.001\n",
        "\n",
        "# Build LSTM Model\n",
        "model = Sequential([\n",
        "    LSTM(hidden_units, return_sequences=True, input_shape=(sequence_length, num_features), kernel_regularizer=l2(l2_lambda)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    LSTM(hidden_units, return_sequences=False, kernel_regularizer=l2(l2_lambda)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # LSTM(hidden_units, return_sequences=False, kernel_regularizer=l2(l2_lambda)),\n",
        "    # BatchNormalization(),\n",
        "    # Dropout(0.5),\n",
        "\n",
        "    Dense(64, activation=\"relu\", kernel_regularizer=l2(l2_lambda)),\n",
        "    # BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Dense(32, activation=\"relu\"),\n",
        "    # Dropout(0.3),\n",
        "\n",
        "    Dense(num_classes, activation=\"softmax\")  # Output layer\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IgDya-vSoqva",
        "outputId": "83f6e732-fdd5-4f13-8279-11cf93dc4672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 186ms/step - accuracy: 0.0578 - loss: 4.9670 - val_accuracy: 0.0517 - val_loss: 3.7273\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.0873 - loss: 4.0638 - val_accuracy: 0.0517 - val_loss: 3.7269\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.1845 - loss: 3.4525 - val_accuracy: 0.0345 - val_loss: 3.7268\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.2155 - loss: 3.1924 - val_accuracy: 0.0000e+00 - val_loss: 3.7274\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.3562 - loss: 2.8855 - val_accuracy: 0.0690 - val_loss: 3.7108\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.3835 - loss: 2.6078 - val_accuracy: 0.0345 - val_loss: 3.7225\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.4235 - loss: 2.4072 - val_accuracy: 0.0172 - val_loss: 3.7447\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.4347 - loss: 2.3365 - val_accuracy: 0.0690 - val_loss: 3.7377\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.4911 - loss: 2.1100 - val_accuracy: 0.1207 - val_loss: 3.6855\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.4478 - loss: 2.2832 - val_accuracy: 0.0517 - val_loss: 3.6428\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.5426 - loss: 1.9570 - val_accuracy: 0.0690 - val_loss: 3.6617\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.5354 - loss: 1.8719 - val_accuracy: 0.0862 - val_loss: 3.6627\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6217 - loss: 1.8412 - val_accuracy: 0.0862 - val_loss: 3.6442\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.5781 - loss: 1.7521 - val_accuracy: 0.0517 - val_loss: 3.6779\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.6334 - loss: 1.6829 - val_accuracy: 0.0172 - val_loss: 3.7397\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.6989 - loss: 1.5810 - val_accuracy: 0.1207 - val_loss: 3.5566\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.6786 - loss: 1.5961 - val_accuracy: 0.1207 - val_loss: 3.5142\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.7105 - loss: 1.4457 - val_accuracy: 0.0172 - val_loss: 3.5023\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.6874 - loss: 1.4446 - val_accuracy: 0.1207 - val_loss: 3.4691\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.6874 - loss: 1.4455 - val_accuracy: 0.2069 - val_loss: 3.4110\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.6871 - loss: 1.3936 - val_accuracy: 0.1207 - val_loss: 3.4509\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7590 - loss: 1.2924 - val_accuracy: 0.1552 - val_loss: 3.2686\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.7977 - loss: 1.1501 - val_accuracy: 0.0517 - val_loss: 3.3585\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7004 - loss: 1.3813 - val_accuracy: 0.0172 - val_loss: 3.6059\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.7376 - loss: 1.2455 - val_accuracy: 0.1207 - val_loss: 3.2840\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8088 - loss: 1.1617 - val_accuracy: 0.0862 - val_loss: 3.5687\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.7948 - loss: 1.1204 - val_accuracy: 0.1207 - val_loss: 3.2671\n",
            "Epoch 28/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.8567 - loss: 0.9970 - val_accuracy: 0.1379 - val_loss: 3.3779\n",
            "Epoch 29/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8031 - loss: 1.1260 - val_accuracy: 0.2759 - val_loss: 3.0899\n",
            "Epoch 30/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 170ms/step - accuracy: 0.8105 - loss: 1.0351 - val_accuracy: 0.3621 - val_loss: 2.8574\n",
            "Epoch 31/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.7884 - loss: 1.1456 - val_accuracy: 0.3103 - val_loss: 2.7941\n",
            "Epoch 32/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.8648 - loss: 0.9845 - val_accuracy: 0.2931 - val_loss: 2.7047\n",
            "Epoch 33/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.8481 - loss: 0.9675 - val_accuracy: 0.0000e+00 - val_loss: 4.4558\n",
            "Epoch 34/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.7869 - loss: 1.1727 - val_accuracy: 0.0000e+00 - val_loss: 4.3437\n",
            "Epoch 35/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.7681 - loss: 1.2395 - val_accuracy: 0.3276 - val_loss: 3.0403\n",
            "Epoch 36/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.7844 - loss: 1.0901 - val_accuracy: 0.0690 - val_loss: 3.3173\n",
            "Epoch 37/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.8164 - loss: 1.0124 - val_accuracy: 0.2931 - val_loss: 3.0985\n",
            "Epoch 38/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.8515 - loss: 0.9520 - val_accuracy: 0.3448 - val_loss: 2.6908\n",
            "Epoch 39/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.8654 - loss: 0.9381 - val_accuracy: 0.0862 - val_loss: 3.2963\n",
            "Epoch 40/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.7886 - loss: 1.0413 - val_accuracy: 0.1724 - val_loss: 4.1082\n",
            "Epoch 41/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.7208 - loss: 1.2516 - val_accuracy: 0.1379 - val_loss: 3.9399\n",
            "Epoch 42/100\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b9fede2a509b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Number of training cycles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the Model\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    epochs=100,  # Number of training cycles\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "# Evaluate on validation set\n",
        "val_loss, val_acc = model.evaluate(X_val, Y_val)\n",
        "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEMpXQ2RZG3f"
      },
      "source": [
        "# For Double handed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0frKxatrZGUS",
        "outputId": "9ed90487-becf-484b-bb40-5f7afb899d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (200, 25, 84)\n",
            "Y shape: (200,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_and_prepare_data(csv_path):\n",
        "    # Load data from CSV\n",
        "    data = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "    # Convert to NumPy array for efficient processing\n",
        "    data = data.values\n",
        "\n",
        "    # Separate X (features) and Y (first column as labels)\n",
        "    Y = data[:, 0]  # First column as labels\n",
        "    X = data[:, 1:]  # All other columns as features (shape: num_samples, 84)\n",
        "\n",
        "    # Define sequence length\n",
        "    sequence_length = 25\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_seq, Y_seq = [], []\n",
        "    num_sequences = len(X) // sequence_length\n",
        "\n",
        "    for i in range(num_sequences):\n",
        "        start_idx = i * sequence_length\n",
        "        X_seq.append(X[start_idx:start_idx + sequence_length])  # 25 rows of features\n",
        "        Y_seq.append(Y[start_idx])  # First column value corresponding to the sequence\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_seq = np.array(X_seq)  # Shape: (num_sequences, 25, 84)\n",
        "    Y_seq = np.array(Y_seq)  # Shape: (num_sequences,)\n",
        "\n",
        "    return X_seq, Y_seq\n",
        "\n",
        "# Example usage\n",
        "csv_path = \"/content/Double Handed Gestures 2nd April.csv\"  # Replace with actual path\n",
        "X_seq, Y_seq = load_and_prepare_data(csv_path)\n",
        "print(\"X shape:\", X_seq.shape)  # Expected: (num_sequences, 25, 84)\n",
        "print(\"Y shape:\", Y_seq.shape)  # Expected: (num_sequences,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hdupp37TpJVG",
        "outputId": "28d3bebc-a014-4b31-8894-5a79d76252f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B',\n",
              "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'D', 'D', 'D', 'D',\n",
              "       'D', 'D', 'D', 'D', 'D', 'D', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
              "       'E', 'E', 'E', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F', 'F',\n",
              "       'G', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'G', 'H', 'H', 'H',\n",
              "       'H', 'H', 'H', 'H', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J', 'J',\n",
              "       'J', 'J', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'M',\n",
              "       'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'N', 'N', 'N', 'N',\n",
              "       'N', 'N', 'N', 'N', 'N', 'N', 'P', 'P', 'P', 'P', 'P', 'P', 'P',\n",
              "       'P', 'P', 'P', 'Q', 'Q', 'Q', 'Q', 'Q', 'Q', 'Q', 'Q', 'Q', 'Q',\n",
              "       'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'S', 'S', 'S',\n",
              "       'S', 'S', 'S', 'S', 'S', 'S', 'S', 'T', 'T', 'T', 'T', 'T', 'T',\n",
              "       'T', 'T', 'T', 'T', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W',\n",
              "       'W', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'Y', 'Y',\n",
              "       'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Z', 'Z', 'Z', 'Z', 'Z',\n",
              "       'Z', 'Z', 'Z', 'Z', 'Z'], dtype='<U1')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzmCTtjmcddV",
        "outputId": "52ed9efe-09d3-4c68-82c9-5b99d92bf382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Preprocessed Data Shapes -> X_train: (160, 25, 84), Y_train: (160, 20)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Encode Y_seq (convert string labels to integers)\n",
        "label_encoder = LabelEncoder()\n",
        "Y_seq = label_encoder.fit_transform(Y_seq)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "Y_seq = to_categorical(Y_seq, num_classes)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_seq, Y_seq, test_size=0.2, random_state=42)\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "\n",
        "print(f\"✅ Preprocessed Data Shapes -> X_train: {X_train.shape}, Y_train: {Y_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "500tdfabwaAW",
        "outputId": "f6791c3d-fdf5-482c-c851-40a951f08a38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PL7Db5AdKbn",
        "outputId": "ce2a8392-187a-4382-d46c-c90fc8fdd9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Preprocessed Data Shapes -> X_test: (40, 25, 84), Y_test: (40, 20)\n"
          ]
        }
      ],
      "source": [
        "print(f\"✅ Preprocessed Data Shapes -> X_test: {X_val.shape}, Y_test: {Y_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "ptx6hBk5a4Fj",
        "outputId": "1798aa28-fbdf-4904-942e-3eeced650a2c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">109,056</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m109,056\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │           \u001b[38;5;34m1,300\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">251,220</span> (981.33 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m251,220\u001b[0m (981.33 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,708</span> (979.33 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m250,708\u001b[0m (979.33 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Model Parameters\n",
        "sequence_length = 25  # Number of frames per sequence\n",
        "num_features = 84    # 42 landmarks * 3 (x, y, z)\n",
        "hidden_units = 128    # Increased hidden size for better feature extraction\n",
        "num_classes = 20     # A to Z\n",
        "l2_lambda = 0.001\n",
        "\n",
        "# Build LSTM Model\n",
        "model = Sequential([\n",
        "    LSTM(hidden_units, return_sequences=True, input_shape=(sequence_length, num_features), kernel_regularizer=l2(l2_lambda)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    LSTM(hidden_units, return_sequences=False, kernel_regularizer=l2(l2_lambda)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # LSTM(hidden_units, return_sequences=False, kernel_regularizer=l2(l2_lambda)),\n",
        "    # BatchNormalization(),\n",
        "    # Dropout(0.5),\n",
        "\n",
        "    Dense(64, activation=\"relu\", kernel_regularizer=l2(l2_lambda)),\n",
        "    # BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # Dense(32, activation=\"relu\"),\n",
        "    # Dropout(0.3),\n",
        "\n",
        "    Dense(num_classes, activation=\"softmax\")  # Output layer\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abes5Fa8cXZm",
        "outputId": "c62b6309-b969-4488-e693-5c99cc9b605a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 254ms/step - accuracy: 0.0411 - loss: 4.2834 - val_accuracy: 0.2000 - val_loss: 3.3391\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1646 - loss: 3.3609 - val_accuracy: 0.1500 - val_loss: 3.2582\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.3514 - loss: 2.5708 - val_accuracy: 0.2750 - val_loss: 3.1789\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.4409 - loss: 2.3659 - val_accuracy: 0.3750 - val_loss: 3.0941\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5790 - loss: 1.8610 - val_accuracy: 0.4500 - val_loss: 2.9966\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.6318 - loss: 1.8089 - val_accuracy: 0.5500 - val_loss: 2.8929\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6214 - loss: 1.6738 - val_accuracy: 0.6250 - val_loss: 2.8018\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.7082 - loss: 1.4013 - val_accuracy: 0.6000 - val_loss: 2.7115\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7273 - loss: 1.2529 - val_accuracy: 0.6250 - val_loss: 2.6223\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.7916 - loss: 1.2099 - val_accuracy: 0.6750 - val_loss: 2.5190\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 0.7498 - loss: 1.2613 - val_accuracy: 0.7500 - val_loss: 2.4058\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.8124 - loss: 1.0956 - val_accuracy: 0.8000 - val_loss: 2.3209\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.8023 - loss: 1.0718 - val_accuracy: 0.8000 - val_loss: 2.2452\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.8858 - loss: 0.9372 - val_accuracy: 0.7750 - val_loss: 2.1676\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7832 - loss: 1.0565 - val_accuracy: 0.8250 - val_loss: 2.0728\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8352 - loss: 1.0357 - val_accuracy: 0.8250 - val_loss: 1.9850\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9146 - loss: 0.8147 - val_accuracy: 0.8500 - val_loss: 1.8809\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9111 - loss: 0.8648 - val_accuracy: 0.9000 - val_loss: 1.7894\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.9209 - loss: 0.7272 - val_accuracy: 0.9250 - val_loss: 1.7011\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9191 - loss: 0.7944 - val_accuracy: 0.9000 - val_loss: 1.6119\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8858 - loss: 0.7449 - val_accuracy: 0.9750 - val_loss: 1.4816\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9186 - loss: 0.7367 - val_accuracy: 0.9750 - val_loss: 1.3919\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9564 - loss: 0.6466 - val_accuracy: 0.9500 - val_loss: 1.3220\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9641 - loss: 0.6508 - val_accuracy: 0.9750 - val_loss: 1.2363\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.8998 - loss: 0.7669 - val_accuracy: 1.0000 - val_loss: 1.1480\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9469 - loss: 0.6987 - val_accuracy: 1.0000 - val_loss: 1.0999\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9579 - loss: 0.6370 - val_accuracy: 0.9750 - val_loss: 1.0580\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9698 - loss: 0.5948 - val_accuracy: 0.9500 - val_loss: 1.0040\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9752 - loss: 0.5906 - val_accuracy: 0.9500 - val_loss: 0.9492\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 162ms/step - accuracy: 0.9864 - loss: 0.5673 - val_accuracy: 0.9500 - val_loss: 0.8987\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.9740 - loss: 0.5438 - val_accuracy: 0.9750 - val_loss: 0.8515\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.9558 - loss: 0.5537 - val_accuracy: 0.9750 - val_loss: 0.7956\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9688 - loss: 0.5594 - val_accuracy: 1.0000 - val_loss: 0.7510\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9979 - loss: 0.5012 - val_accuracy: 1.0000 - val_loss: 0.7082\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9949 - loss: 0.5377 - val_accuracy: 1.0000 - val_loss: 0.6639\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9928 - loss: 0.5177 - val_accuracy: 0.9750 - val_loss: 0.6337\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9949 - loss: 0.5037 - val_accuracy: 0.9750 - val_loss: 0.6069\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.9706 - loss: 0.5177 - val_accuracy: 0.9750 - val_loss: 0.6067\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9949 - loss: 0.4993 - val_accuracy: 1.0000 - val_loss: 0.5562\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9561 - loss: 0.5543 - val_accuracy: 0.9750 - val_loss: 0.5414\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9786 - loss: 0.5097 - val_accuracy: 0.9500 - val_loss: 0.5891\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9524 - loss: 0.5960 - val_accuracy: 0.9750 - val_loss: 0.5371\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9898 - loss: 0.5304 - val_accuracy: 1.0000 - val_loss: 0.5043\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9838 - loss: 0.4821 - val_accuracy: 1.0000 - val_loss: 0.4866\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9877 - loss: 0.4818 - val_accuracy: 1.0000 - val_loss: 0.4778\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9881 - loss: 0.4763 - val_accuracy: 1.0000 - val_loss: 0.4954\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9928 - loss: 0.4811 - val_accuracy: 0.9750 - val_loss: 0.5025\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.4538 - val_accuracy: 1.0000 - val_loss: 0.4682\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9966 - loss: 0.4724 - val_accuracy: 1.0000 - val_loss: 0.4566\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9915 - loss: 0.4597 - val_accuracy: 1.0000 - val_loss: 0.4508\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.9966 - loss: 0.5069 - val_accuracy: 1.0000 - val_loss: 0.4470\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: 0.4240 - val_accuracy: 1.0000 - val_loss: 0.4349\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 0.4315 - val_accuracy: 1.0000 - val_loss: 0.4171\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9851 - loss: 0.4782 - val_accuracy: 1.0000 - val_loss: 0.4147\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9889 - loss: 0.4490 - val_accuracy: 1.0000 - val_loss: 0.4149\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.9889 - loss: 0.4567 - val_accuracy: 1.0000 - val_loss: 0.4086\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.4366 - val_accuracy: 1.0000 - val_loss: 0.4037\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9695 - loss: 0.4776 - val_accuracy: 1.0000 - val_loss: 0.4001\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9889 - loss: 0.4453 - val_accuracy: 1.0000 - val_loss: 0.3977\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.4263 - val_accuracy: 1.0000 - val_loss: 0.3956\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.4260 - val_accuracy: 1.0000 - val_loss: 0.3924\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9793 - loss: 0.4498 - val_accuracy: 0.9750 - val_loss: 0.4192\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.9747 - loss: 0.4592 - val_accuracy: 1.0000 - val_loss: 0.3954\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9852 - loss: 0.4259 - val_accuracy: 1.0000 - val_loss: 0.3923\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.9917 - loss: 0.4430 - val_accuracy: 0.9750 - val_loss: 0.5826\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9485 - loss: 0.5887 - val_accuracy: 1.0000 - val_loss: 0.3830\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9820 - loss: 0.4297 - val_accuracy: 1.0000 - val_loss: 0.3907\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9612 - loss: 0.5171 - val_accuracy: 1.0000 - val_loss: 0.3908\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.4385 - val_accuracy: 1.0000 - val_loss: 0.3886\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.3973 - val_accuracy: 1.0000 - val_loss: 0.3813\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9850 - loss: 0.4359 - val_accuracy: 1.0000 - val_loss: 0.3704\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 0.9958 - loss: 0.4009 - val_accuracy: 1.0000 - val_loss: 0.3674\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 0.9716 - loss: 0.4201 - val_accuracy: 1.0000 - val_loss: 0.3641\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9949 - loss: 0.4135 - val_accuracy: 1.0000 - val_loss: 0.3623\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.4037 - val_accuracy: 1.0000 - val_loss: 0.3606\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.9871 - loss: 0.4050 - val_accuracy: 1.0000 - val_loss: 0.3590\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.3828 - val_accuracy: 1.0000 - val_loss: 0.3575\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.3895 - val_accuracy: 1.0000 - val_loss: 0.3560\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.3818 - val_accuracy: 1.0000 - val_loss: 0.3544\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9949 - loss: 0.3877 - val_accuracy: 1.0000 - val_loss: 0.3529\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9850 - loss: 0.3961 - val_accuracy: 1.0000 - val_loss: 0.3512\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.3729 - val_accuracy: 1.0000 - val_loss: 0.3492\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.9949 - loss: 0.3811 - val_accuracy: 1.0000 - val_loss: 0.3475\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.3649 - val_accuracy: 1.0000 - val_loss: 0.3458\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.3674 - val_accuracy: 1.0000 - val_loss: 0.3443\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.3756 - val_accuracy: 1.0000 - val_loss: 0.3431\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.3630 - val_accuracy: 1.0000 - val_loss: 0.3417\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9902 - loss: 0.3693 - val_accuracy: 1.0000 - val_loss: 0.3404\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.3699 - val_accuracy: 1.0000 - val_loss: 0.3387\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.3637 - val_accuracy: 1.0000 - val_loss: 0.3371\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.3520 - val_accuracy: 1.0000 - val_loss: 0.3354\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 173ms/step - accuracy: 0.9923 - loss: 0.3599 - val_accuracy: 1.0000 - val_loss: 0.3336\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.9923 - loss: 0.3762 - val_accuracy: 1.0000 - val_loss: 0.3317\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.3556 - val_accuracy: 1.0000 - val_loss: 0.3301\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9872 - loss: 0.3806 - val_accuracy: 1.0000 - val_loss: 0.3287\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9898 - loss: 0.3633 - val_accuracy: 1.0000 - val_loss: 0.3275\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9966 - loss: 0.3526 - val_accuracy: 1.0000 - val_loss: 0.3288\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.9759 - loss: 0.4711 - val_accuracy: 0.9500 - val_loss: 0.7556\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9602 - loss: 0.4910 - val_accuracy: 1.0000 - val_loss: 0.3363\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9534 - loss: 0.4816 - val_accuracy: 0.9750 - val_loss: 0.3478\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9833 - loss: 0.3399\n",
            "Validation Accuracy: 97.50%\n"
          ]
        }
      ],
      "source": [
        "# Train the Model\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_val, Y_val),\n",
        "    epochs=100,  # Number of training cycles\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "# Evaluate on validation set\n",
        "val_loss, val_acc = model.evaluate(X_val, Y_val)\n",
        "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "upgZfsODegl0",
        "outputId": "d50961ee-82fa-4354-de81-89836bc9ea3d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract accuracy values from history\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Plot accuracy curves\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training & Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "4o4-7b2GfB6U",
        "outputId": "fb588f31-dbee-4d48-8ff5-1e1835dd77f9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract accuracy values from history\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Plot accuracy curves\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training & Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2b-l_CjtsDy",
        "outputId": "96c36333-982f-4d6a-d083-f7c220135c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(25,)\n",
            "(25, 84)\n",
            "X shape: (1, 25, 84)\n",
            "Y shape: (1,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_and_prepare_test_data(csv_le):\n",
        "    # Load data from CSV\n",
        "\n",
        "    data = pd.read_csv(csv_le, header=None)\n",
        "\n",
        "\n",
        "    # Convert to NumPy array for efficient processing\n",
        "    data = data.values\n",
        "    data.shape\n",
        "\n",
        "    # Separate X (features) and Y (first column as labels)\n",
        "    Y_test = data[:, 0]  # First column as labels\n",
        "    print(Y_test.shape)\n",
        "    X_test = data[:, 1:]\n",
        "    print(X_test.shape) # All other columns as features (shape: num_samples, 84)\n",
        "\n",
        "    # Define sequence length\n",
        "    sequence_length = 25\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_test_seq, Y_test_seq = [], []\n",
        "    num_sequences = len(X_test) // sequence_length\n",
        "\n",
        "    for i in range(num_sequences):\n",
        "        start_idx = i * sequence_length\n",
        "        X_test_seq.append(X_test[start_idx:start_idx + sequence_length])  # 25 rows of features\n",
        "        Y_test_seq.append(Y_test[start_idx])  # First column value corresponding to the sequence\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_test_seq = np.array(X_test_seq)  # Shape: (num_sequences, 25, 84)\n",
        "    Y_test_seq = np.array(Y_test_seq)  # Shape: (num_sequences,)\n",
        "\n",
        "    return X_test_seq, Y_test_seq\n",
        "\n",
        "# Example usage\n",
        "csv_le = \"/content/test.csv\"  # Replace with actual path\n",
        "X_test_seq, Y_test_seq = load_and_prepare_test_data(csv_le)\n",
        "print(\"X shape:\", X_test_seq.shape)  # Expected: (num_sequences, 25, 84)\n",
        "print(\"Y shape:\", Y_test_seq.shape)  # Expected: (num_sequences,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "2idUXe-UxDf7",
        "outputId": "cc0f00e2-71df-4719-808a-f8ef131cfc06"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-995d1c77-5bea-4e12-82be-eb361596d577\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y</th>\n",
              "      <th>0.1915422885572139</th>\n",
              "      <th>0.1815920398009950</th>\n",
              "      <th>0.0796019900497512</th>\n",
              "      <th>0.1343283582089552</th>\n",
              "      <th>-0.0174129353233831</th>\n",
              "      <th>0.0696517412935323</th>\n",
              "      <th>-0.0696517412935323</th>\n",
              "      <th>0.0273631840796020</th>\n",
              "      <th>-0.0497512437810945</th>\n",
              "      <th>...</th>\n",
              "      <th>-0.1766169154228856</th>\n",
              "      <th>-0.3805970149253731</th>\n",
              "      <th>-0.3855721393034826</th>\n",
              "      <th>-0.4203980099502487</th>\n",
              "      <th>-0.4004975124378110</th>\n",
              "      <th>-0.4676616915422885</th>\n",
              "      <th>-0.3159203980099503</th>\n",
              "      <th>-0.3880597014925373</th>\n",
              "      <th>-0.2512437810945274</th>\n",
              "      <th>-0.3333333333333333</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.189591</td>\n",
              "      <td>0.177200</td>\n",
              "      <td>0.080545</td>\n",
              "      <td>0.132590</td>\n",
              "      <td>-0.016109</td>\n",
              "      <td>0.068154</td>\n",
              "      <td>-0.065675</td>\n",
              "      <td>0.030979</td>\n",
              "      <td>-0.050805</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.177200</td>\n",
              "      <td>-0.382900</td>\n",
              "      <td>-0.382900</td>\n",
              "      <td>-0.420074</td>\n",
              "      <td>-0.400248</td>\n",
              "      <td>-0.472119</td>\n",
              "      <td>-0.315985</td>\n",
              "      <td>-0.390335</td>\n",
              "      <td>-0.251549</td>\n",
              "      <td>-0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.189591</td>\n",
              "      <td>0.182156</td>\n",
              "      <td>0.083024</td>\n",
              "      <td>0.135068</td>\n",
              "      <td>-0.013631</td>\n",
              "      <td>0.070632</td>\n",
              "      <td>-0.065675</td>\n",
              "      <td>0.030979</td>\n",
              "      <td>-0.053284</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.179678</td>\n",
              "      <td>-0.382900</td>\n",
              "      <td>-0.385378</td>\n",
              "      <td>-0.422553</td>\n",
              "      <td>-0.397770</td>\n",
              "      <td>-0.474597</td>\n",
              "      <td>-0.315985</td>\n",
              "      <td>-0.392813</td>\n",
              "      <td>-0.254027</td>\n",
              "      <td>-0.335812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.190594</td>\n",
              "      <td>0.188119</td>\n",
              "      <td>0.079208</td>\n",
              "      <td>0.141089</td>\n",
              "      <td>-0.019802</td>\n",
              "      <td>0.076733</td>\n",
              "      <td>-0.071782</td>\n",
              "      <td>0.034653</td>\n",
              "      <td>-0.061881</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.180693</td>\n",
              "      <td>-0.391089</td>\n",
              "      <td>-0.388614</td>\n",
              "      <td>-0.425743</td>\n",
              "      <td>-0.400990</td>\n",
              "      <td>-0.477723</td>\n",
              "      <td>-0.319307</td>\n",
              "      <td>-0.396040</td>\n",
              "      <td>-0.257426</td>\n",
              "      <td>-0.341584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.186104</td>\n",
              "      <td>0.186104</td>\n",
              "      <td>0.081886</td>\n",
              "      <td>0.146402</td>\n",
              "      <td>-0.009926</td>\n",
              "      <td>0.081886</td>\n",
              "      <td>-0.062035</td>\n",
              "      <td>0.044665</td>\n",
              "      <td>-0.049628</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.176179</td>\n",
              "      <td>-0.389578</td>\n",
              "      <td>-0.379653</td>\n",
              "      <td>-0.421836</td>\n",
              "      <td>-0.397022</td>\n",
              "      <td>-0.473945</td>\n",
              "      <td>-0.312655</td>\n",
              "      <td>-0.394541</td>\n",
              "      <td>-0.250620</td>\n",
              "      <td>-0.339950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.188656</td>\n",
              "      <td>0.188656</td>\n",
              "      <td>0.080148</td>\n",
              "      <td>0.144266</td>\n",
              "      <td>-0.016030</td>\n",
              "      <td>0.082614</td>\n",
              "      <td>-0.067818</td>\n",
              "      <td>0.045623</td>\n",
              "      <td>-0.055487</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.176326</td>\n",
              "      <td>-0.395808</td>\n",
              "      <td>-0.378545</td>\n",
              "      <td>-0.427867</td>\n",
              "      <td>-0.395808</td>\n",
              "      <td>-0.479655</td>\n",
              "      <td>-0.311961</td>\n",
              "      <td>-0.398274</td>\n",
              "      <td>-0.250308</td>\n",
              "      <td>-0.344020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.183395</td>\n",
              "      <td>0.189591</td>\n",
              "      <td>0.074349</td>\n",
              "      <td>0.149938</td>\n",
              "      <td>-0.017348</td>\n",
              "      <td>0.087980</td>\n",
              "      <td>-0.066914</td>\n",
              "      <td>0.048327</td>\n",
              "      <td>-0.052045</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.173482</td>\n",
              "      <td>-0.395291</td>\n",
              "      <td>-0.379182</td>\n",
              "      <td>-0.427509</td>\n",
              "      <td>-0.394052</td>\n",
              "      <td>-0.482032</td>\n",
              "      <td>-0.312268</td>\n",
              "      <td>-0.397770</td>\n",
              "      <td>-0.252788</td>\n",
              "      <td>-0.338290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.185049</td>\n",
              "      <td>0.193627</td>\n",
              "      <td>0.079657</td>\n",
              "      <td>0.147059</td>\n",
              "      <td>-0.013480</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>-0.064951</td>\n",
              "      <td>0.056373</td>\n",
              "      <td>-0.064951</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.177696</td>\n",
              "      <td>-0.397059</td>\n",
              "      <td>-0.378676</td>\n",
              "      <td>-0.431373</td>\n",
              "      <td>-0.390931</td>\n",
              "      <td>-0.482843</td>\n",
              "      <td>-0.307598</td>\n",
              "      <td>-0.401961</td>\n",
              "      <td>-0.248775</td>\n",
              "      <td>-0.348039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.184242</td>\n",
              "      <td>0.195152</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.151515</td>\n",
              "      <td>-0.012121</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>-0.060606</td>\n",
              "      <td>0.056970</td>\n",
              "      <td>-0.050909</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.172121</td>\n",
              "      <td>-0.401212</td>\n",
              "      <td>-0.370909</td>\n",
              "      <td>-0.435152</td>\n",
              "      <td>-0.387879</td>\n",
              "      <td>-0.488485</td>\n",
              "      <td>-0.305455</td>\n",
              "      <td>-0.408485</td>\n",
              "      <td>-0.247273</td>\n",
              "      <td>-0.352727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.188024</td>\n",
              "      <td>0.202395</td>\n",
              "      <td>0.073054</td>\n",
              "      <td>0.156886</td>\n",
              "      <td>-0.022754</td>\n",
              "      <td>0.092216</td>\n",
              "      <td>-0.073054</td>\n",
              "      <td>0.058683</td>\n",
              "      <td>-0.063473</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.176048</td>\n",
              "      <td>-0.415569</td>\n",
              "      <td>-0.372455</td>\n",
              "      <td>-0.441916</td>\n",
              "      <td>-0.389222</td>\n",
              "      <td>-0.499401</td>\n",
              "      <td>-0.307784</td>\n",
              "      <td>-0.420359</td>\n",
              "      <td>-0.247904</td>\n",
              "      <td>-0.362874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.187351</td>\n",
              "      <td>0.205251</td>\n",
              "      <td>0.075179</td>\n",
              "      <td>0.157518</td>\n",
              "      <td>-0.017900</td>\n",
              "      <td>0.095465</td>\n",
              "      <td>-0.075179</td>\n",
              "      <td>0.066826</td>\n",
              "      <td>-0.072792</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.177804</td>\n",
              "      <td>-0.415274</td>\n",
              "      <td>-0.371122</td>\n",
              "      <td>-0.448687</td>\n",
              "      <td>-0.387828</td>\n",
              "      <td>-0.503580</td>\n",
              "      <td>-0.309069</td>\n",
              "      <td>-0.424821</td>\n",
              "      <td>-0.249403</td>\n",
              "      <td>-0.367542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.185053</td>\n",
              "      <td>0.214709</td>\n",
              "      <td>0.071174</td>\n",
              "      <td>0.160142</td>\n",
              "      <td>-0.023725</td>\n",
              "      <td>0.096085</td>\n",
              "      <td>-0.075919</td>\n",
              "      <td>0.069988</td>\n",
              "      <td>-0.073547</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.175563</td>\n",
              "      <td>-0.425860</td>\n",
              "      <td>-0.377224</td>\n",
              "      <td>-0.454330</td>\n",
              "      <td>-0.391459</td>\n",
              "      <td>-0.516014</td>\n",
              "      <td>-0.310795</td>\n",
              "      <td>-0.437722</td>\n",
              "      <td>-0.251483</td>\n",
              "      <td>-0.378410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.187279</td>\n",
              "      <td>0.217903</td>\n",
              "      <td>0.071849</td>\n",
              "      <td>0.161366</td>\n",
              "      <td>-0.022379</td>\n",
              "      <td>0.100118</td>\n",
              "      <td>-0.078916</td>\n",
              "      <td>0.078916</td>\n",
              "      <td>-0.078916</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.177856</td>\n",
              "      <td>-0.427562</td>\n",
              "      <td>-0.375736</td>\n",
              "      <td>-0.455830</td>\n",
              "      <td>-0.389870</td>\n",
              "      <td>-0.519435</td>\n",
              "      <td>-0.309776</td>\n",
              "      <td>-0.439340</td>\n",
              "      <td>-0.253239</td>\n",
              "      <td>-0.380448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.175088</td>\n",
              "      <td>0.219741</td>\n",
              "      <td>0.069330</td>\n",
              "      <td>0.168038</td>\n",
              "      <td>-0.022327</td>\n",
              "      <td>0.106933</td>\n",
              "      <td>-0.071680</td>\n",
              "      <td>0.083431</td>\n",
              "      <td>-0.062280</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.165687</td>\n",
              "      <td>-0.433608</td>\n",
              "      <td>-0.365452</td>\n",
              "      <td>-0.452409</td>\n",
              "      <td>-0.379553</td>\n",
              "      <td>-0.518214</td>\n",
              "      <td>-0.297297</td>\n",
              "      <td>-0.440658</td>\n",
              "      <td>-0.240893</td>\n",
              "      <td>-0.381904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.181390</td>\n",
              "      <td>0.213192</td>\n",
              "      <td>0.075383</td>\n",
              "      <td>0.168433</td>\n",
              "      <td>-0.021201</td>\n",
              "      <td>0.104829</td>\n",
              "      <td>-0.068316</td>\n",
              "      <td>0.085984</td>\n",
              "      <td>-0.063604</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.167256</td>\n",
              "      <td>-0.422850</td>\n",
              "      <td>-0.362780</td>\n",
              "      <td>-0.458186</td>\n",
              "      <td>-0.379270</td>\n",
              "      <td>-0.517079</td>\n",
              "      <td>-0.299176</td>\n",
              "      <td>-0.439340</td>\n",
              "      <td>-0.240283</td>\n",
              "      <td>-0.380448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.179788</td>\n",
              "      <td>0.212691</td>\n",
              "      <td>0.081081</td>\n",
              "      <td>0.170388</td>\n",
              "      <td>-0.008226</td>\n",
              "      <td>0.109283</td>\n",
              "      <td>-0.057579</td>\n",
              "      <td>0.095182</td>\n",
              "      <td>-0.059929</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.163337</td>\n",
              "      <td>-0.428907</td>\n",
              "      <td>-0.353702</td>\n",
              "      <td>-0.464160</td>\n",
              "      <td>-0.372503</td>\n",
              "      <td>-0.520564</td>\n",
              "      <td>-0.294947</td>\n",
              "      <td>-0.443008</td>\n",
              "      <td>-0.231492</td>\n",
              "      <td>-0.386604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.190751</td>\n",
              "      <td>0.223121</td>\n",
              "      <td>0.075145</td>\n",
              "      <td>0.165318</td>\n",
              "      <td>-0.017341</td>\n",
              "      <td>0.102890</td>\n",
              "      <td>-0.065896</td>\n",
              "      <td>0.082081</td>\n",
              "      <td>-0.058960</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.172254</td>\n",
              "      <td>-0.435838</td>\n",
              "      <td>-0.357225</td>\n",
              "      <td>-0.472832</td>\n",
              "      <td>-0.378035</td>\n",
              "      <td>-0.528324</td>\n",
              "      <td>-0.301734</td>\n",
              "      <td>-0.452023</td>\n",
              "      <td>-0.239306</td>\n",
              "      <td>-0.396532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.194220</td>\n",
              "      <td>0.225434</td>\n",
              "      <td>0.073988</td>\n",
              "      <td>0.174566</td>\n",
              "      <td>-0.020809</td>\n",
              "      <td>0.114451</td>\n",
              "      <td>-0.073988</td>\n",
              "      <td>0.091329</td>\n",
              "      <td>-0.067052</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.175723</td>\n",
              "      <td>-0.435838</td>\n",
              "      <td>-0.367630</td>\n",
              "      <td>-0.468208</td>\n",
              "      <td>-0.386127</td>\n",
              "      <td>-0.523699</td>\n",
              "      <td>-0.307514</td>\n",
              "      <td>-0.449711</td>\n",
              "      <td>-0.247399</td>\n",
              "      <td>-0.391908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.196778</td>\n",
              "      <td>0.228999</td>\n",
              "      <td>0.074799</td>\n",
              "      <td>0.180667</td>\n",
              "      <td>-0.021864</td>\n",
              "      <td>0.123130</td>\n",
              "      <td>-0.072497</td>\n",
              "      <td>0.102417</td>\n",
              "      <td>-0.063291</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.176064</td>\n",
              "      <td>-0.438435</td>\n",
              "      <td>-0.369390</td>\n",
              "      <td>-0.466053</td>\n",
              "      <td>-0.387802</td>\n",
              "      <td>-0.525892</td>\n",
              "      <td>-0.309551</td>\n",
              "      <td>-0.449942</td>\n",
              "      <td>-0.249712</td>\n",
              "      <td>-0.394707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.177419</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.078341</td>\n",
              "      <td>0.182028</td>\n",
              "      <td>-0.011521</td>\n",
              "      <td>0.124424</td>\n",
              "      <td>-0.062212</td>\n",
              "      <td>0.112903</td>\n",
              "      <td>-0.057604</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.158986</td>\n",
              "      <td>-0.435484</td>\n",
              "      <td>-0.357143</td>\n",
              "      <td>-0.458525</td>\n",
              "      <td>-0.370968</td>\n",
              "      <td>-0.520737</td>\n",
              "      <td>-0.292627</td>\n",
              "      <td>-0.447005</td>\n",
              "      <td>-0.232719</td>\n",
              "      <td>-0.389401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.183603</td>\n",
              "      <td>0.230947</td>\n",
              "      <td>0.081986</td>\n",
              "      <td>0.184758</td>\n",
              "      <td>-0.010393</td>\n",
              "      <td>0.129330</td>\n",
              "      <td>-0.063510</td>\n",
              "      <td>0.120092</td>\n",
              "      <td>-0.065820</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.165127</td>\n",
              "      <td>-0.436490</td>\n",
              "      <td>-0.363741</td>\n",
              "      <td>-0.464203</td>\n",
              "      <td>-0.377598</td>\n",
              "      <td>-0.521940</td>\n",
              "      <td>-0.299076</td>\n",
              "      <td>-0.445727</td>\n",
              "      <td>-0.239030</td>\n",
              "      <td>-0.390300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.186207</td>\n",
              "      <td>0.232184</td>\n",
              "      <td>0.078161</td>\n",
              "      <td>0.188506</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>0.140230</td>\n",
              "      <td>-0.071264</td>\n",
              "      <td>0.135632</td>\n",
              "      <td>-0.071264</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.170115</td>\n",
              "      <td>-0.439080</td>\n",
              "      <td>-0.363218</td>\n",
              "      <td>-0.466667</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>-0.524138</td>\n",
              "      <td>-0.301149</td>\n",
              "      <td>-0.450575</td>\n",
              "      <td>-0.241379</td>\n",
              "      <td>-0.393103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.188422</td>\n",
              "      <td>0.237230</td>\n",
              "      <td>0.081725</td>\n",
              "      <td>0.191827</td>\n",
              "      <td>-0.013621</td>\n",
              "      <td>0.139614</td>\n",
              "      <td>-0.072645</td>\n",
              "      <td>0.132804</td>\n",
              "      <td>-0.077185</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.163451</td>\n",
              "      <td>-0.446084</td>\n",
              "      <td>-0.356413</td>\n",
              "      <td>-0.473326</td>\n",
              "      <td>-0.376844</td>\n",
              "      <td>-0.527809</td>\n",
              "      <td>-0.297389</td>\n",
              "      <td>-0.457435</td>\n",
              "      <td>-0.236095</td>\n",
              "      <td>-0.402951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.191562</td>\n",
              "      <td>0.231471</td>\n",
              "      <td>0.079818</td>\n",
              "      <td>0.194983</td>\n",
              "      <td>-0.013683</td>\n",
              "      <td>0.156214</td>\n",
              "      <td>-0.072976</td>\n",
              "      <td>0.156214</td>\n",
              "      <td>-0.086659</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.166477</td>\n",
              "      <td>-0.448119</td>\n",
              "      <td>-0.358039</td>\n",
              "      <td>-0.468643</td>\n",
              "      <td>-0.378563</td>\n",
              "      <td>-0.527936</td>\n",
              "      <td>-0.301026</td>\n",
              "      <td>-0.454960</td>\n",
              "      <td>-0.239453</td>\n",
              "      <td>-0.397948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Y</td>\n",
              "      <td>0.186576</td>\n",
              "      <td>0.230944</td>\n",
              "      <td>0.079636</td>\n",
              "      <td>0.192264</td>\n",
              "      <td>-0.011377</td>\n",
              "      <td>0.155859</td>\n",
              "      <td>-0.072810</td>\n",
              "      <td>0.164960</td>\n",
              "      <td>-0.088737</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.166098</td>\n",
              "      <td>-0.449374</td>\n",
              "      <td>-0.357224</td>\n",
              "      <td>-0.467577</td>\n",
              "      <td>-0.375427</td>\n",
              "      <td>-0.526735</td>\n",
              "      <td>-0.295791</td>\n",
              "      <td>-0.456200</td>\n",
              "      <td>-0.236633</td>\n",
              "      <td>-0.399317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24 rows × 85 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-995d1c77-5bea-4e12-82be-eb361596d577')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-995d1c77-5bea-4e12-82be-eb361596d577 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-995d1c77-5bea-4e12-82be-eb361596d577');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-16741b8e-aba1-412b-8faa-2f4e73f92389\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16741b8e-aba1-412b-8faa-2f4e73f92389')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-16741b8e-aba1-412b-8faa-2f4e73f92389 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7f9c6f6a-c5b9-42a0-80bf-1b5f1de78683\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7f9c6f6a-c5b9-42a0-80bf-1b5f1de78683 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Y  0.1915422885572139  0.1815920398009950  0.0796019900497512  \\\n",
              "0   Y            0.189591            0.177200            0.080545   \n",
              "1   Y            0.189591            0.182156            0.083024   \n",
              "2   Y            0.190594            0.188119            0.079208   \n",
              "3   Y            0.186104            0.186104            0.081886   \n",
              "4   Y            0.188656            0.188656            0.080148   \n",
              "5   Y            0.183395            0.189591            0.074349   \n",
              "6   Y            0.185049            0.193627            0.079657   \n",
              "7   Y            0.184242            0.195152            0.080000   \n",
              "8   Y            0.188024            0.202395            0.073054   \n",
              "9   Y            0.187351            0.205251            0.075179   \n",
              "10  Y            0.185053            0.214709            0.071174   \n",
              "11  Y            0.187279            0.217903            0.071849   \n",
              "12  Y            0.175088            0.219741            0.069330   \n",
              "13  Y            0.181390            0.213192            0.075383   \n",
              "14  Y            0.179788            0.212691            0.081081   \n",
              "15  Y            0.190751            0.223121            0.075145   \n",
              "16  Y            0.194220            0.225434            0.073988   \n",
              "17  Y            0.196778            0.228999            0.074799   \n",
              "18  Y            0.177419            0.225806            0.078341   \n",
              "19  Y            0.183603            0.230947            0.081986   \n",
              "20  Y            0.186207            0.232184            0.078161   \n",
              "21  Y            0.188422            0.237230            0.081725   \n",
              "22  Y            0.191562            0.231471            0.079818   \n",
              "23  Y            0.186576            0.230944            0.079636   \n",
              "\n",
              "    0.1343283582089552  -0.0174129353233831  0.0696517412935323  \\\n",
              "0             0.132590            -0.016109            0.068154   \n",
              "1             0.135068            -0.013631            0.070632   \n",
              "2             0.141089            -0.019802            0.076733   \n",
              "3             0.146402            -0.009926            0.081886   \n",
              "4             0.144266            -0.016030            0.082614   \n",
              "5             0.149938            -0.017348            0.087980   \n",
              "6             0.147059            -0.013480            0.083333   \n",
              "7             0.151515            -0.012121            0.086061   \n",
              "8             0.156886            -0.022754            0.092216   \n",
              "9             0.157518            -0.017900            0.095465   \n",
              "10            0.160142            -0.023725            0.096085   \n",
              "11            0.161366            -0.022379            0.100118   \n",
              "12            0.168038            -0.022327            0.106933   \n",
              "13            0.168433            -0.021201            0.104829   \n",
              "14            0.170388            -0.008226            0.109283   \n",
              "15            0.165318            -0.017341            0.102890   \n",
              "16            0.174566            -0.020809            0.114451   \n",
              "17            0.180667            -0.021864            0.123130   \n",
              "18            0.182028            -0.011521            0.124424   \n",
              "19            0.184758            -0.010393            0.129330   \n",
              "20            0.188506            -0.011494            0.140230   \n",
              "21            0.191827            -0.013621            0.139614   \n",
              "22            0.194983            -0.013683            0.156214   \n",
              "23            0.192264            -0.011377            0.155859   \n",
              "\n",
              "    -0.0696517412935323  0.0273631840796020  -0.0497512437810945  ...  \\\n",
              "0             -0.065675            0.030979            -0.050805  ...   \n",
              "1             -0.065675            0.030979            -0.053284  ...   \n",
              "2             -0.071782            0.034653            -0.061881  ...   \n",
              "3             -0.062035            0.044665            -0.049628  ...   \n",
              "4             -0.067818            0.045623            -0.055487  ...   \n",
              "5             -0.066914            0.048327            -0.052045  ...   \n",
              "6             -0.064951            0.056373            -0.064951  ...   \n",
              "7             -0.060606            0.056970            -0.050909  ...   \n",
              "8             -0.073054            0.058683            -0.063473  ...   \n",
              "9             -0.075179            0.066826            -0.072792  ...   \n",
              "10            -0.075919            0.069988            -0.073547  ...   \n",
              "11            -0.078916            0.078916            -0.078916  ...   \n",
              "12            -0.071680            0.083431            -0.062280  ...   \n",
              "13            -0.068316            0.085984            -0.063604  ...   \n",
              "14            -0.057579            0.095182            -0.059929  ...   \n",
              "15            -0.065896            0.082081            -0.058960  ...   \n",
              "16            -0.073988            0.091329            -0.067052  ...   \n",
              "17            -0.072497            0.102417            -0.063291  ...   \n",
              "18            -0.062212            0.112903            -0.057604  ...   \n",
              "19            -0.063510            0.120092            -0.065820  ...   \n",
              "20            -0.071264            0.135632            -0.071264  ...   \n",
              "21            -0.072645            0.132804            -0.077185  ...   \n",
              "22            -0.072976            0.156214            -0.086659  ...   \n",
              "23            -0.072810            0.164960            -0.088737  ...   \n",
              "\n",
              "    -0.1766169154228856  -0.3805970149253731  -0.3855721393034826  \\\n",
              "0             -0.177200            -0.382900            -0.382900   \n",
              "1             -0.179678            -0.382900            -0.385378   \n",
              "2             -0.180693            -0.391089            -0.388614   \n",
              "3             -0.176179            -0.389578            -0.379653   \n",
              "4             -0.176326            -0.395808            -0.378545   \n",
              "5             -0.173482            -0.395291            -0.379182   \n",
              "6             -0.177696            -0.397059            -0.378676   \n",
              "7             -0.172121            -0.401212            -0.370909   \n",
              "8             -0.176048            -0.415569            -0.372455   \n",
              "9             -0.177804            -0.415274            -0.371122   \n",
              "10            -0.175563            -0.425860            -0.377224   \n",
              "11            -0.177856            -0.427562            -0.375736   \n",
              "12            -0.165687            -0.433608            -0.365452   \n",
              "13            -0.167256            -0.422850            -0.362780   \n",
              "14            -0.163337            -0.428907            -0.353702   \n",
              "15            -0.172254            -0.435838            -0.357225   \n",
              "16            -0.175723            -0.435838            -0.367630   \n",
              "17            -0.176064            -0.438435            -0.369390   \n",
              "18            -0.158986            -0.435484            -0.357143   \n",
              "19            -0.165127            -0.436490            -0.363741   \n",
              "20            -0.170115            -0.439080            -0.363218   \n",
              "21            -0.163451            -0.446084            -0.356413   \n",
              "22            -0.166477            -0.448119            -0.358039   \n",
              "23            -0.166098            -0.449374            -0.357224   \n",
              "\n",
              "    -0.4203980099502487  -0.4004975124378110  -0.4676616915422885  \\\n",
              "0             -0.420074            -0.400248            -0.472119   \n",
              "1             -0.422553            -0.397770            -0.474597   \n",
              "2             -0.425743            -0.400990            -0.477723   \n",
              "3             -0.421836            -0.397022            -0.473945   \n",
              "4             -0.427867            -0.395808            -0.479655   \n",
              "5             -0.427509            -0.394052            -0.482032   \n",
              "6             -0.431373            -0.390931            -0.482843   \n",
              "7             -0.435152            -0.387879            -0.488485   \n",
              "8             -0.441916            -0.389222            -0.499401   \n",
              "9             -0.448687            -0.387828            -0.503580   \n",
              "10            -0.454330            -0.391459            -0.516014   \n",
              "11            -0.455830            -0.389870            -0.519435   \n",
              "12            -0.452409            -0.379553            -0.518214   \n",
              "13            -0.458186            -0.379270            -0.517079   \n",
              "14            -0.464160            -0.372503            -0.520564   \n",
              "15            -0.472832            -0.378035            -0.528324   \n",
              "16            -0.468208            -0.386127            -0.523699   \n",
              "17            -0.466053            -0.387802            -0.525892   \n",
              "18            -0.458525            -0.370968            -0.520737   \n",
              "19            -0.464203            -0.377598            -0.521940   \n",
              "20            -0.466667            -0.379310            -0.524138   \n",
              "21            -0.473326            -0.376844            -0.527809   \n",
              "22            -0.468643            -0.378563            -0.527936   \n",
              "23            -0.467577            -0.375427            -0.526735   \n",
              "\n",
              "    -0.3159203980099503  -0.3880597014925373  -0.2512437810945274  \\\n",
              "0             -0.315985            -0.390335            -0.251549   \n",
              "1             -0.315985            -0.392813            -0.254027   \n",
              "2             -0.319307            -0.396040            -0.257426   \n",
              "3             -0.312655            -0.394541            -0.250620   \n",
              "4             -0.311961            -0.398274            -0.250308   \n",
              "5             -0.312268            -0.397770            -0.252788   \n",
              "6             -0.307598            -0.401961            -0.248775   \n",
              "7             -0.305455            -0.408485            -0.247273   \n",
              "8             -0.307784            -0.420359            -0.247904   \n",
              "9             -0.309069            -0.424821            -0.249403   \n",
              "10            -0.310795            -0.437722            -0.251483   \n",
              "11            -0.309776            -0.439340            -0.253239   \n",
              "12            -0.297297            -0.440658            -0.240893   \n",
              "13            -0.299176            -0.439340            -0.240283   \n",
              "14            -0.294947            -0.443008            -0.231492   \n",
              "15            -0.301734            -0.452023            -0.239306   \n",
              "16            -0.307514            -0.449711            -0.247399   \n",
              "17            -0.309551            -0.449942            -0.249712   \n",
              "18            -0.292627            -0.447005            -0.232719   \n",
              "19            -0.299076            -0.445727            -0.239030   \n",
              "20            -0.301149            -0.450575            -0.241379   \n",
              "21            -0.297389            -0.457435            -0.236095   \n",
              "22            -0.301026            -0.454960            -0.239453   \n",
              "23            -0.295791            -0.456200            -0.236633   \n",
              "\n",
              "    -0.3333333333333333  \n",
              "0             -0.333333  \n",
              "1             -0.335812  \n",
              "2             -0.341584  \n",
              "3             -0.339950  \n",
              "4             -0.344020  \n",
              "5             -0.338290  \n",
              "6             -0.348039  \n",
              "7             -0.352727  \n",
              "8             -0.362874  \n",
              "9             -0.367542  \n",
              "10            -0.378410  \n",
              "11            -0.380448  \n",
              "12            -0.381904  \n",
              "13            -0.380448  \n",
              "14            -0.386604  \n",
              "15            -0.396532  \n",
              "16            -0.391908  \n",
              "17            -0.394707  \n",
              "18            -0.389401  \n",
              "19            -0.390300  \n",
              "20            -0.393103  \n",
              "21            -0.402951  \n",
              "22            -0.397948  \n",
              "23            -0.399317  \n",
              "\n",
              "[24 rows x 85 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Encode Y_seq (convert string labels to integers)\n",
        "label_encoder = LabelEncoder()\n",
        "Y_seq = label_encoder.fit_transform(Y_seq)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "Y_seq = to_categorical(Y_seq, num_classes)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_seq, Y_seq, test_size=0.2, random_state=42)\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "\n",
        "print(f\"✅ Preprocessed Data Shapes -> X_train: {X_train.shape}, Y_train: {Y_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJO3yzt19YL0"
      },
      "source": [
        "# KFolds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ-3EsK2062E",
        "outputId": "712658c8-3883-4881-f0af-fb47fe038f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (260, 25, 84)\n",
            "Y shape: (260,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[ 0.6868327 , -0.07117438,  0.42348754, ..., -0.27046263,\n",
              "         -0.64768684, -0.25622776],\n",
              "        [ 0.6684303 , -0.0670194 ,  0.4144621 , ..., -0.26455027,\n",
              "         -0.64021164, -0.24691358],\n",
              "        [ 0.6804309 , -0.07001796,  0.41113105, ..., -0.27109516,\n",
              "         -0.6337522 , -0.25314182],\n",
              "        ...,\n",
              "        [ 0.66785717, -0.075     ,  0.39642859, ..., -0.26785713,\n",
              "         -0.61071426, -0.23928571],\n",
              "        [ 0.6642599 , -0.07220217,  0.41516244, ..., -0.27436823,\n",
              "         -0.58844763, -0.23826715],\n",
              "        [ 0.6642599 , -0.07039711,  0.41155234, ..., -0.2761733 ,\n",
              "         -0.599278  , -0.24729241]],\n",
              "\n",
              "       [[ 0.68345326, -0.07014389,  0.41007194, ..., -0.28597122,\n",
              "         -0.58633095, -0.2535971 ],\n",
              "        [ 0.6768402 , -0.06104129,  0.40394974, ..., -0.28007182,\n",
              "         -0.61220825, -0.25852782],\n",
              "        [ 0.681736  , -0.06509946,  0.403255  , ..., -0.27486438,\n",
              "         -0.59855336, -0.25316456],\n",
              "        ...,\n",
              "        [ 0.6906475 , -0.04856115,  0.39928058, ..., -0.2967626 ,\n",
              "         -0.60071945, -0.2643885 ],\n",
              "        [ 0.6925859 , -0.05424955,  0.40687162, ..., -0.2965642 ,\n",
              "         -0.60217   , -0.26401445],\n",
              "        [ 0.69454545, -0.05272727,  0.40727273, ..., -0.29636362,\n",
              "         -0.6036364 , -0.26727274]],\n",
              "\n",
              "       [[ 0.5295056 , -0.01435407,  0.37001595, ..., -0.42264754,\n",
              "         -0.57735246, -0.34290272],\n",
              "        [ 0.53451043, -0.0176565 ,  0.37078652, ..., -0.4189406 ,\n",
              "         -0.56982344, -0.33868378],\n",
              "        [ 0.53536975, -0.01286174,  0.3681672 , ..., -0.41157556,\n",
              "         -0.5868167 , -0.33440515],\n",
              "        ...,\n",
              "        [ 0.56393445, -0.02622951,  0.40655738, ..., -0.40983605,\n",
              "         -0.5967213 , -0.32786885],\n",
              "        [ 0.56978655, -0.02463054,  0.40558293, ..., -0.41543514,\n",
              "         -0.6059113 , -0.33333334],\n",
              "        [ 0.5633117 , -0.01948052,  0.39123377, ..., -0.41883117,\n",
              "         -0.58928573, -0.33766234]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        , ...,  0.02352941,\n",
              "          0.26352942,  0.02588235],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.01728395,\n",
              "          0.31851852,  0.07901235],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.00943396,\n",
              "          0.29245284,  0.0259434 ],\n",
              "        ...,\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.07808565,\n",
              "          0.38035265,  0.13602015],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.04555809,\n",
              "          0.35307518,  0.11161731]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        , ..., -0.2005277 ,\n",
              "          0.10817942, -0.12664908],\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.19788918,\n",
              "          0.10554089, -0.12664908],\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.19422573,\n",
              "          0.10236221, -0.12598425],\n",
              "        ...,\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.19729729,\n",
              "          0.11081081, -0.12702702],\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.19293478,\n",
              "          0.10326087, -0.12228261],\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.19086021,\n",
              "          0.09946237, -0.12365592]],\n",
              "\n",
              "       [[ 0.        ,  0.        ,  0.        , ..., -0.19680852,\n",
              "          0.0930851 , -0.12765957],\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.19680852,\n",
              "          0.0930851 , -0.13031915],\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.19518717,\n",
              "          0.09893048, -0.12834224],\n",
              "        ...,\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.16991644,\n",
              "          0.10306407, -0.10306407],\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.17403315,\n",
              "          0.11878453, -0.09944751],\n",
              "        [ 0.        ,  0.        ,  0.        , ..., -0.17451523,\n",
              "          0.12188365, -0.09972299]]], dtype=float32)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def load_and_prepare_data(csv_path):\n",
        "    # Load data from CSV\n",
        "    data = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "    # Convert to NumPy array for efficient processing\n",
        "    data = data.values\n",
        "\n",
        "    # Separate X (features) and Y (first column as labels)\n",
        "    Y = data[:, 0]  # First column as labels\n",
        "    X = data[:, 1:]  # All other columns as features (shape: num_samples, 84)\n",
        "\n",
        "    # Define sequence length\n",
        "    sequence_length = 25\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_seq, Y_seq = [], []\n",
        "    num_sequences = len(X) // sequence_length\n",
        "\n",
        "    for i in range(num_sequences):\n",
        "        start_idx = i * sequence_length\n",
        "        X_seq.append(X[start_idx:start_idx + sequence_length])  # 25 rows of features\n",
        "        Y_seq.append(Y[start_idx])  # First column value corresponding to the sequence\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_seq = np.array(X_seq)  # Shape: (num_sequences, 25, 84)\n",
        "    Y_seq = np.array(Y_seq)  # Shape: (num_sequences,)\n",
        "\n",
        "    return X_seq, Y_seq\n",
        "\n",
        "# Example usage\n",
        "csv_path = \"/content/Double Handed Gestures 2nd April.csv\"  # Replace with actual path\n",
        "X_seq, Y_seq = load_and_prepare_data(csv_path)\n",
        "print(\"X shape:\", X_seq.shape)  # Expected: (num_sequences, 25, 84)\n",
        "print(\"Y shape:\", Y_seq.shape)  # Expected: (num_sequences,)\n",
        "\n",
        "# Encode Y_seq (convert string labels to integers)\n",
        "label_encoder = LabelEncoder()\n",
        "Y_seq = label_encoder.fit_transform(Y_seq)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "Y_seq = to_categorical(Y_seq, num_classes)\n",
        "\n",
        "X_seq.astype('float32')\n",
        "# Y_seq.dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttQsXzK21EWv",
        "outputId": "7426d4b4-9443-4d88-c389-6b7becbb6bd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(189, 18)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1RWoKB_1AHS",
        "outputId": "4ab8ceac-a09f-4474-a1b9-5c6cef750649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1 / 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.0452 - loss: 3.5964 - val_accuracy: 0.0769 - val_loss: 3.5182\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0882 - loss: 3.4659 - val_accuracy: 0.1538 - val_loss: 3.4317\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1874 - loss: 3.3483 - val_accuracy: 0.1538 - val_loss: 3.3198\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2304 - loss: 3.2368 - val_accuracy: 0.2308 - val_loss: 3.1731\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3226 - loss: 3.0534 - val_accuracy: 0.3077 - val_loss: 3.0181\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3067 - loss: 2.8897 - val_accuracy: 0.3077 - val_loss: 2.8492\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4289 - loss: 2.6967 - val_accuracy: 0.4231 - val_loss: 2.6240\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4051 - loss: 2.5261 - val_accuracy: 0.3846 - val_loss: 2.4430\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4420 - loss: 2.3745 - val_accuracy: 0.4615 - val_loss: 2.2442\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5299 - loss: 2.2425 - val_accuracy: 0.5769 - val_loss: 2.0813\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4976 - loss: 2.0805 - val_accuracy: 0.6538 - val_loss: 1.9155\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6362 - loss: 1.9112 - val_accuracy: 0.6154 - val_loss: 1.8185\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6559 - loss: 1.8173 - val_accuracy: 0.8077 - val_loss: 1.6534\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6903 - loss: 1.7231 - val_accuracy: 0.7692 - val_loss: 1.5467\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6905 - loss: 1.6015 - val_accuracy: 0.7692 - val_loss: 1.4444\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6988 - loss: 1.5620 - val_accuracy: 0.8077 - val_loss: 1.3444\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7404 - loss: 1.4633 - val_accuracy: 0.7692 - val_loss: 1.2509\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7089 - loss: 1.3797 - val_accuracy: 0.8077 - val_loss: 1.1606\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7793 - loss: 1.2833 - val_accuracy: 0.8077 - val_loss: 1.1101\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7989 - loss: 1.2363 - val_accuracy: 0.8846 - val_loss: 1.0352\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8306 - loss: 1.1407 - val_accuracy: 0.8846 - val_loss: 0.9853\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8190 - loss: 1.1225 - val_accuracy: 0.8077 - val_loss: 0.9713\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8414 - loss: 1.0528 - val_accuracy: 0.8077 - val_loss: 0.9195\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8747 - loss: 0.9921 - val_accuracy: 0.7692 - val_loss: 0.9324\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8449 - loss: 1.0164 - val_accuracy: 0.7692 - val_loss: 0.9409\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8967 - loss: 0.9436 - val_accuracy: 0.8077 - val_loss: 0.9433\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7878 - loss: 1.0730 - val_accuracy: 0.8077 - val_loss: 0.9872\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7796 - loss: 1.0846 - val_accuracy: 0.8462 - val_loss: 0.8174\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8928 - loss: 0.8840 - val_accuracy: 0.8462 - val_loss: 0.8437\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8602 - loss: 0.9333 - val_accuracy: 0.8462 - val_loss: 0.7512\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9073 - loss: 0.8225 - val_accuracy: 0.8462 - val_loss: 0.7535\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8660 - loss: 0.8514 - val_accuracy: 0.8077 - val_loss: 0.7544\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9171 - loss: 0.7836 - val_accuracy: 0.8462 - val_loss: 0.7083\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9107 - loss: 0.8021 - val_accuracy: 0.8462 - val_loss: 0.7090\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9022 - loss: 0.7260 - val_accuracy: 0.9615 - val_loss: 0.6542\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9364 - loss: 0.7185 - val_accuracy: 0.9615 - val_loss: 0.6417\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9008 - loss: 0.7522 - val_accuracy: 0.8462 - val_loss: 0.6672\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9179 - loss: 0.7257 - val_accuracy: 0.9231 - val_loss: 0.6272\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9037 - loss: 0.7695 - val_accuracy: 0.8846 - val_loss: 0.6694\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9005 - loss: 0.7084 - val_accuracy: 0.9231 - val_loss: 0.6419\n",
            "\n",
            "Fold 2 / 10\n",
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - accuracy: 0.0484 - loss: 3.6082 - val_accuracy: 0.3462 - val_loss: 3.4573\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.1649 - loss: 3.4596 - val_accuracy: 0.2692 - val_loss: 3.3046\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2328 - loss: 3.2869 - val_accuracy: 0.3077 - val_loss: 3.1352\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.1783 - loss: 3.1724 - val_accuracy: 0.3462 - val_loss: 2.9869\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.2560 - loss: 3.0393 - val_accuracy: 0.3462 - val_loss: 2.8247\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3382 - loss: 2.8112 - val_accuracy: 0.4231 - val_loss: 2.6497\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4162 - loss: 2.6127 - val_accuracy: 0.5385 - val_loss: 2.5106\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4336 - loss: 2.4836 - val_accuracy: 0.5000 - val_loss: 2.2715\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5563 - loss: 2.2278 - val_accuracy: 0.5385 - val_loss: 2.0952\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5850 - loss: 2.1434 - val_accuracy: 0.6154 - val_loss: 2.0603\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6310 - loss: 1.9556 - val_accuracy: 0.6154 - val_loss: 1.9575\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6449 - loss: 1.8629 - val_accuracy: 0.6154 - val_loss: 1.9145\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6865 - loss: 1.7364 - val_accuracy: 0.6538 - val_loss: 1.5633\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6726 - loss: 1.6172 - val_accuracy: 0.6923 - val_loss: 1.5771\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7398 - loss: 1.5261 - val_accuracy: 0.7692 - val_loss: 1.3786\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7610 - loss: 1.4006 - val_accuracy: 0.7692 - val_loss: 1.4383\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8022 - loss: 1.3130 - val_accuracy: 0.7692 - val_loss: 1.2382\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7899 - loss: 1.2546 - val_accuracy: 0.8077 - val_loss: 1.1581\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8384 - loss: 1.1314 - val_accuracy: 0.7308 - val_loss: 1.2811\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7968 - loss: 1.1348 - val_accuracy: 0.7692 - val_loss: 1.4707\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7925 - loss: 1.0911 - val_accuracy: 0.8077 - val_loss: 1.0721\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8426 - loss: 1.0082 - val_accuracy: 0.7308 - val_loss: 1.2456\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8164 - loss: 1.0293 - val_accuracy: 0.6538 - val_loss: 1.2291\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8447 - loss: 1.0215 - val_accuracy: 0.6923 - val_loss: 1.0570\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8037 - loss: 0.9930 - val_accuracy: 0.8846 - val_loss: 0.9316\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8834 - loss: 0.9004 - val_accuracy: 0.8846 - val_loss: 0.8647\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8909 - loss: 0.8881 - val_accuracy: 0.8077 - val_loss: 0.8343\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9073 - loss: 0.7882 - val_accuracy: 0.8846 - val_loss: 0.7929\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8224 - loss: 0.8306 - val_accuracy: 0.8846 - val_loss: 0.7829\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8910 - loss: 0.7869 - val_accuracy: 0.7308 - val_loss: 0.9118\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8739 - loss: 0.8078 - val_accuracy: 0.7308 - val_loss: 0.7783\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8962 - loss: 0.7636 - val_accuracy: 0.8077 - val_loss: 0.8037\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8975 - loss: 0.7492 - val_accuracy: 0.7692 - val_loss: 1.0220\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8796 - loss: 0.7705 - val_accuracy: 0.8077 - val_loss: 0.7604\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8918 - loss: 0.7314 - val_accuracy: 0.9231 - val_loss: 0.6716\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8888 - loss: 0.6803 - val_accuracy: 0.9231 - val_loss: 0.6826\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8738 - loss: 0.7007 - val_accuracy: 0.7692 - val_loss: 0.8646\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8635 - loss: 0.7421 - val_accuracy: 0.8077 - val_loss: 0.9608\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8770 - loss: 0.6941 - val_accuracy: 0.8846 - val_loss: 0.6580\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9211 - loss: 0.6372 - val_accuracy: 0.8077 - val_loss: 1.0355\n",
            "\n",
            "Fold 3 / 10\n",
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.0353 - loss: 3.5998 - val_accuracy: 0.0385 - val_loss: 3.5717\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0443 - loss: 3.4656 - val_accuracy: 0.0000e+00 - val_loss: 3.4907\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1301 - loss: 3.3521 - val_accuracy: 0.0385 - val_loss: 3.4012\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2161 - loss: 3.2094 - val_accuracy: 0.0769 - val_loss: 3.2879\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2504 - loss: 3.0819 - val_accuracy: 0.2308 - val_loss: 3.1655\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3158 - loss: 2.9154 - val_accuracy: 0.0769 - val_loss: 3.0123\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3134 - loss: 2.7672 - val_accuracy: 0.3077 - val_loss: 2.8717\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3953 - loss: 2.6010 - val_accuracy: 0.3462 - val_loss: 2.7128\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4234 - loss: 2.4124 - val_accuracy: 0.3462 - val_loss: 2.5399\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4390 - loss: 2.2862 - val_accuracy: 0.4231 - val_loss: 2.3400\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5367 - loss: 2.1287 - val_accuracy: 0.5000 - val_loss: 2.1855\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5957 - loss: 1.9234 - val_accuracy: 0.5769 - val_loss: 2.0263\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6582 - loss: 1.7657 - val_accuracy: 0.6538 - val_loss: 1.8840\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6861 - loss: 1.6927 - val_accuracy: 0.5769 - val_loss: 1.8154\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6764 - loss: 1.5853 - val_accuracy: 0.7308 - val_loss: 1.6133\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7777 - loss: 1.4686 - val_accuracy: 0.6923 - val_loss: 1.5057\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7187 - loss: 1.4225 - val_accuracy: 0.7692 - val_loss: 1.4894\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6445 - loss: 1.4824 - val_accuracy: 0.7692 - val_loss: 1.4118\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7564 - loss: 1.2761 - val_accuracy: 0.7308 - val_loss: 1.3158\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7586 - loss: 1.1919 - val_accuracy: 0.8077 - val_loss: 1.2038\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7747 - loss: 1.2403 - val_accuracy: 0.7692 - val_loss: 1.1811\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8473 - loss: 1.0730 - val_accuracy: 0.8077 - val_loss: 1.1004\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.7695 - loss: 1.1266 - val_accuracy: 0.8462 - val_loss: 1.0101\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8331 - loss: 1.0237 - val_accuracy: 0.8462 - val_loss: 0.9413\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7908 - loss: 1.0093 - val_accuracy: 0.8462 - val_loss: 0.9193\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7580 - loss: 1.1158 - val_accuracy: 0.8462 - val_loss: 0.9107\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8539 - loss: 0.9683 - val_accuracy: 0.8077 - val_loss: 0.8669\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8550 - loss: 0.9344 - val_accuracy: 0.8077 - val_loss: 0.8373\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8329 - loss: 0.9439 - val_accuracy: 0.8462 - val_loss: 0.8515\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8088 - loss: 0.9451 - val_accuracy: 0.8077 - val_loss: 0.8067\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8570 - loss: 0.9163 - val_accuracy: 0.8077 - val_loss: 0.8335\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8315 - loss: 0.9166 - val_accuracy: 0.9615 - val_loss: 0.7097\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9008 - loss: 0.8596 - val_accuracy: 0.9615 - val_loss: 0.6765\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8492 - loss: 0.8331 - val_accuracy: 0.9231 - val_loss: 0.6932\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8441 - loss: 0.8472 - val_accuracy: 0.9615 - val_loss: 0.6588\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9075 - loss: 0.7434 - val_accuracy: 0.9615 - val_loss: 0.6370\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9198 - loss: 0.7152 - val_accuracy: 0.9231 - val_loss: 0.5914\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8745 - loss: 0.7512 - val_accuracy: 0.9231 - val_loss: 0.5794\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9178 - loss: 0.6900 - val_accuracy: 0.9615 - val_loss: 0.5765\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8835 - loss: 0.7045 - val_accuracy: 0.9615 - val_loss: 0.5596\n",
            "\n",
            "Fold 4 / 10\n",
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.0890 - loss: 3.6058 - val_accuracy: 0.2308 - val_loss: 3.5144\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1228 - loss: 3.5225 - val_accuracy: 0.2308 - val_loss: 3.4345\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1491 - loss: 3.4531 - val_accuracy: 0.2692 - val_loss: 3.3564\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.1749 - loss: 3.3607 - val_accuracy: 0.3077 - val_loss: 3.2402\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2724 - loss: 3.2600 - val_accuracy: 0.5000 - val_loss: 3.1009\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2561 - loss: 3.1382 - val_accuracy: 0.5000 - val_loss: 2.9703\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3583 - loss: 2.9953 - val_accuracy: 0.4615 - val_loss: 2.8292\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3604 - loss: 2.8242 - val_accuracy: 0.5769 - val_loss: 2.6694\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3485 - loss: 2.7482 - val_accuracy: 0.4615 - val_loss: 2.5384\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4069 - loss: 2.5224 - val_accuracy: 0.5769 - val_loss: 2.2909\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4594 - loss: 2.3204 - val_accuracy: 0.6154 - val_loss: 2.1653\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4907 - loss: 2.2410 - val_accuracy: 0.6538 - val_loss: 1.9929\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4874 - loss: 2.0581 - val_accuracy: 0.6538 - val_loss: 1.7962\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6103 - loss: 1.8634 - val_accuracy: 0.7308 - val_loss: 1.7349\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6218 - loss: 1.8177 - val_accuracy: 0.5769 - val_loss: 1.8560\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5922 - loss: 1.8080 - val_accuracy: 0.6538 - val_loss: 1.7181\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6417 - loss: 1.7172 - val_accuracy: 0.6923 - val_loss: 1.5325\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6813 - loss: 1.5627 - val_accuracy: 0.6538 - val_loss: 1.4187\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6655 - loss: 1.5580 - val_accuracy: 0.6923 - val_loss: 1.3799\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7232 - loss: 1.4554 - val_accuracy: 0.7692 - val_loss: 1.2198\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7297 - loss: 1.3593 - val_accuracy: 0.7692 - val_loss: 1.1757\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6982 - loss: 1.3410 - val_accuracy: 0.6538 - val_loss: 1.3619\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6948 - loss: 1.4439 - val_accuracy: 0.6923 - val_loss: 1.1345\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7434 - loss: 1.2770 - val_accuracy: 0.7308 - val_loss: 1.1017\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7925 - loss: 1.2138 - val_accuracy: 0.6538 - val_loss: 1.0804\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7574 - loss: 1.1110 - val_accuracy: 0.8846 - val_loss: 0.9532\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8181 - loss: 1.0696 - val_accuracy: 0.8077 - val_loss: 0.9817\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7997 - loss: 1.0252 - val_accuracy: 0.8462 - val_loss: 0.8920\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8478 - loss: 0.9816 - val_accuracy: 0.8077 - val_loss: 0.8692\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8417 - loss: 1.0014 - val_accuracy: 0.8462 - val_loss: 0.7901\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8266 - loss: 0.9482 - val_accuracy: 0.8462 - val_loss: 0.7789\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8307 - loss: 0.9441 - val_accuracy: 0.8462 - val_loss: 0.7610\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8759 - loss: 0.8853 - val_accuracy: 0.8846 - val_loss: 0.7265\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8606 - loss: 0.8431 - val_accuracy: 0.8846 - val_loss: 0.7455\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8663 - loss: 0.8555 - val_accuracy: 0.8462 - val_loss: 0.7645\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8716 - loss: 0.7983 - val_accuracy: 0.8846 - val_loss: 0.7092\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8884 - loss: 0.8041 - val_accuracy: 0.8846 - val_loss: 0.6870\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8742 - loss: 0.7776 - val_accuracy: 0.9615 - val_loss: 0.6504\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8989 - loss: 0.7515 - val_accuracy: 0.8462 - val_loss: 0.7587\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8733 - loss: 0.7771 - val_accuracy: 0.8846 - val_loss: 0.7608\n",
            "\n",
            "Fold 5 / 10\n",
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.0544 - loss: 3.5872 - val_accuracy: 0.1538 - val_loss: 3.4915\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1534 - loss: 3.4678 - val_accuracy: 0.1538 - val_loss: 3.4020\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1585 - loss: 3.3868 - val_accuracy: 0.1923 - val_loss: 3.3147\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2782 - loss: 3.2514 - val_accuracy: 0.2308 - val_loss: 3.2049\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3634 - loss: 3.0717 - val_accuracy: 0.3077 - val_loss: 3.0678\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3067 - loss: 2.9852 - val_accuracy: 0.2308 - val_loss: 2.9539\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3849 - loss: 2.8099 - val_accuracy: 0.3077 - val_loss: 2.7908\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4379 - loss: 2.6718 - val_accuracy: 0.4231 - val_loss: 2.6088\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4850 - loss: 2.4459 - val_accuracy: 0.5000 - val_loss: 2.4784\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4983 - loss: 2.3053 - val_accuracy: 0.5385 - val_loss: 2.3115\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5161 - loss: 2.1211 - val_accuracy: 0.5769 - val_loss: 2.1633\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5785 - loss: 2.0337 - val_accuracy: 0.3846 - val_loss: 2.3708\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5220 - loss: 2.0487 - val_accuracy: 0.4615 - val_loss: 2.0517\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5584 - loss: 1.9153 - val_accuracy: 0.5769 - val_loss: 1.9258\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6317 - loss: 1.7549 - val_accuracy: 0.6154 - val_loss: 1.8242\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6545 - loss: 1.6176 - val_accuracy: 0.6538 - val_loss: 1.6686\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6759 - loss: 1.5019 - val_accuracy: 0.6538 - val_loss: 1.5474\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6528 - loss: 1.4699 - val_accuracy: 0.6538 - val_loss: 1.5236\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6605 - loss: 1.4512 - val_accuracy: 0.6538 - val_loss: 1.4790\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7989 - loss: 1.2832 - val_accuracy: 0.7692 - val_loss: 1.4440\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7678 - loss: 1.2681 - val_accuracy: 0.6154 - val_loss: 1.4719\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7115 - loss: 1.2539 - val_accuracy: 0.6923 - val_loss: 1.3115\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7478 - loss: 1.1674 - val_accuracy: 0.7308 - val_loss: 1.2130\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7601 - loss: 1.0592 - val_accuracy: 0.8077 - val_loss: 1.1742\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8264 - loss: 1.0289 - val_accuracy: 0.7692 - val_loss: 1.1407\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8154 - loss: 1.0160 - val_accuracy: 0.7308 - val_loss: 1.2233\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7607 - loss: 1.0753 - val_accuracy: 0.6154 - val_loss: 1.2913\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8172 - loss: 0.9473 - val_accuracy: 0.6923 - val_loss: 1.2261\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7832 - loss: 0.9806 - val_accuracy: 0.6538 - val_loss: 1.2232\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7566 - loss: 1.0025 - val_accuracy: 0.7308 - val_loss: 1.1290\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8440 - loss: 0.9308 - val_accuracy: 0.6923 - val_loss: 1.1118\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7771 - loss: 0.9525 - val_accuracy: 0.8462 - val_loss: 0.9628\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8563 - loss: 0.8473 - val_accuracy: 0.8462 - val_loss: 0.9449\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8687 - loss: 0.8308 - val_accuracy: 0.8077 - val_loss: 0.9873\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8474 - loss: 0.8092 - val_accuracy: 0.7692 - val_loss: 0.9861\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9015 - loss: 0.7572 - val_accuracy: 0.7692 - val_loss: 1.0115\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9035 - loss: 0.7736 - val_accuracy: 0.8846 - val_loss: 0.8369\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9009 - loss: 0.7491 - val_accuracy: 0.8462 - val_loss: 0.8074\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8982 - loss: 0.7257 - val_accuracy: 0.9231 - val_loss: 0.7517\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8708 - loss: 0.7453 - val_accuracy: 0.8846 - val_loss: 0.7611\n",
            "\n",
            "Fold 6 / 10\n",
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - accuracy: 0.0295 - loss: 3.6210 - val_accuracy: 0.0769 - val_loss: 3.5001\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0659 - loss: 3.4899 - val_accuracy: 0.2308 - val_loss: 3.4250\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1469 - loss: 3.4004 - val_accuracy: 0.1538 - val_loss: 3.3462\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2322 - loss: 3.2628 - val_accuracy: 0.1923 - val_loss: 3.2334\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2680 - loss: 3.1595 - val_accuracy: 0.2692 - val_loss: 3.0936\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3384 - loss: 3.0042 - val_accuracy: 0.2692 - val_loss: 2.9500\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3538 - loss: 2.8364 - val_accuracy: 0.2308 - val_loss: 2.8069\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3759 - loss: 2.6459 - val_accuracy: 0.3077 - val_loss: 2.6827\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4752 - loss: 2.4935 - val_accuracy: 0.3462 - val_loss: 2.5504\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4725 - loss: 2.3151 - val_accuracy: 0.3846 - val_loss: 2.4495\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5614 - loss: 2.1240 - val_accuracy: 0.4615 - val_loss: 2.3495\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6190 - loss: 1.9760 - val_accuracy: 0.5000 - val_loss: 2.2866\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5589 - loss: 1.8526 - val_accuracy: 0.5769 - val_loss: 2.1390\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7114 - loss: 1.7252 - val_accuracy: 0.5769 - val_loss: 2.0594\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6708 - loss: 1.6859 - val_accuracy: 0.5385 - val_loss: 2.0138\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6850 - loss: 1.5558 - val_accuracy: 0.6154 - val_loss: 1.9239\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7196 - loss: 1.4372 - val_accuracy: 0.6154 - val_loss: 1.7919\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7509 - loss: 1.3392 - val_accuracy: 0.6923 - val_loss: 1.7068\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8299 - loss: 1.2589 - val_accuracy: 0.6923 - val_loss: 1.5706\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8071 - loss: 1.2432 - val_accuracy: 0.7308 - val_loss: 1.5328\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7994 - loss: 1.2158 - val_accuracy: 0.7692 - val_loss: 1.4618\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7939 - loss: 1.1654 - val_accuracy: 0.7692 - val_loss: 1.3989\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7946 - loss: 1.1884 - val_accuracy: 0.7692 - val_loss: 1.4074\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8324 - loss: 1.0754 - val_accuracy: 0.7692 - val_loss: 1.4323\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8676 - loss: 1.0054 - val_accuracy: 0.8077 - val_loss: 1.3885\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9013 - loss: 0.8895 - val_accuracy: 0.8077 - val_loss: 1.3617\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8874 - loss: 0.9558 - val_accuracy: 0.7692 - val_loss: 1.3330\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8477 - loss: 0.8914 - val_accuracy: 0.7692 - val_loss: 1.2676\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9425 - loss: 0.7891 - val_accuracy: 0.7692 - val_loss: 1.2366\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9470 - loss: 0.7270 - val_accuracy: 0.7692 - val_loss: 1.2129\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9290 - loss: 0.7886 - val_accuracy: 0.7692 - val_loss: 1.1813\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9359 - loss: 0.6926 - val_accuracy: 0.8077 - val_loss: 1.1932\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9141 - loss: 0.7297 - val_accuracy: 0.7692 - val_loss: 1.2176\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9154 - loss: 0.7196 - val_accuracy: 0.7692 - val_loss: 1.1978\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9252 - loss: 0.6818 - val_accuracy: 0.8077 - val_loss: 1.1633\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9432 - loss: 0.6920 - val_accuracy: 0.7692 - val_loss: 1.2536\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9117 - loss: 0.7192 - val_accuracy: 0.7692 - val_loss: 1.2517\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9105 - loss: 0.6652 - val_accuracy: 0.8462 - val_loss: 1.0043\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9455 - loss: 0.6330 - val_accuracy: 0.8077 - val_loss: 1.0913\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9290 - loss: 0.6033 - val_accuracy: 0.8846 - val_loss: 0.9737\n",
            "\n",
            "Fold 7 / 10\n",
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - accuracy: 0.0890 - loss: 3.6089 - val_accuracy: 0.3462 - val_loss: 3.5046\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1747 - loss: 3.4929 - val_accuracy: 0.1923 - val_loss: 3.3779\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1796 - loss: 3.3656 - val_accuracy: 0.2692 - val_loss: 3.2434\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2891 - loss: 3.2079 - val_accuracy: 0.3077 - val_loss: 3.0729\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3267 - loss: 3.0430 - val_accuracy: 0.4231 - val_loss: 2.8923\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3132 - loss: 2.8715 - val_accuracy: 0.4231 - val_loss: 2.7052\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4025 - loss: 2.6678 - val_accuracy: 0.4615 - val_loss: 2.5183\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4158 - loss: 2.4820 - val_accuracy: 0.5385 - val_loss: 2.3577\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4449 - loss: 2.3700 - val_accuracy: 0.5000 - val_loss: 2.1782\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4473 - loss: 2.2218 - val_accuracy: 0.5769 - val_loss: 2.0757\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.4479 - loss: 2.0865 - val_accuracy: 0.5769 - val_loss: 1.9213\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5888 - loss: 1.8893 - val_accuracy: 0.6923 - val_loss: 1.7526\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5229 - loss: 1.8090 - val_accuracy: 0.6538 - val_loss: 1.6516\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.6392 - loss: 1.7026 - val_accuracy: 0.7308 - val_loss: 1.6989\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6294 - loss: 1.6131 - val_accuracy: 0.7692 - val_loss: 1.5443\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6260 - loss: 1.5846 - val_accuracy: 0.7308 - val_loss: 1.5059\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7253 - loss: 1.4485 - val_accuracy: 0.8077 - val_loss: 1.3616\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6453 - loss: 1.3735 - val_accuracy: 0.8077 - val_loss: 1.2423\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7716 - loss: 1.3341 - val_accuracy: 0.7692 - val_loss: 1.2713\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7733 - loss: 1.2443 - val_accuracy: 0.8462 - val_loss: 1.1354\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7598 - loss: 1.1808 - val_accuracy: 0.8462 - val_loss: 1.1203\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7487 - loss: 1.1567 - val_accuracy: 0.8846 - val_loss: 1.0256\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8396 - loss: 1.0821 - val_accuracy: 0.8462 - val_loss: 0.9614\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8082 - loss: 1.0501 - val_accuracy: 0.8077 - val_loss: 0.9967\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8104 - loss: 0.9989 - val_accuracy: 0.8846 - val_loss: 0.8755\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8085 - loss: 1.0187 - val_accuracy: 0.9231 - val_loss: 0.8496\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8079 - loss: 0.9773 - val_accuracy: 0.9231 - val_loss: 0.8399\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8514 - loss: 0.8806 - val_accuracy: 0.8077 - val_loss: 1.0947\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8250 - loss: 0.9232 - val_accuracy: 0.8846 - val_loss: 0.8220\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8190 - loss: 0.9021 - val_accuracy: 0.8846 - val_loss: 0.8123\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7955 - loss: 0.8851 - val_accuracy: 0.8846 - val_loss: 0.7639\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8193 - loss: 0.8730 - val_accuracy: 0.9231 - val_loss: 0.7287\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8055 - loss: 0.8756 - val_accuracy: 0.8462 - val_loss: 0.7657\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8497 - loss: 0.8299 - val_accuracy: 0.8846 - val_loss: 0.7112\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8640 - loss: 0.8044 - val_accuracy: 0.9231 - val_loss: 0.6795\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8960 - loss: 0.7460 - val_accuracy: 0.8846 - val_loss: 0.6371\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8755 - loss: 0.7451 - val_accuracy: 0.9231 - val_loss: 0.6144\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8947 - loss: 0.7428 - val_accuracy: 0.9231 - val_loss: 0.6238\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8998 - loss: 0.7112 - val_accuracy: 0.8846 - val_loss: 0.6206\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8405 - loss: 0.7650 - val_accuracy: 0.9231 - val_loss: 0.5894\n",
            "\n",
            "Fold 8 / 10\n",
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.0417 - loss: 3.6181 - val_accuracy: 0.0769 - val_loss: 3.5221\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1265 - loss: 3.4676 - val_accuracy: 0.1538 - val_loss: 3.4101\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1942 - loss: 3.3310 - val_accuracy: 0.1154 - val_loss: 3.2940\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2154 - loss: 3.1994 - val_accuracy: 0.1538 - val_loss: 3.1412\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2564 - loss: 3.0585 - val_accuracy: 0.3077 - val_loss: 2.9888\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3152 - loss: 2.9175 - val_accuracy: 0.3462 - val_loss: 2.8426\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3745 - loss: 2.7235 - val_accuracy: 0.3846 - val_loss: 2.6707\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3531 - loss: 2.5367 - val_accuracy: 0.3846 - val_loss: 2.4975\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3899 - loss: 2.4113 - val_accuracy: 0.4231 - val_loss: 2.3414\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4899 - loss: 2.2113 - val_accuracy: 0.4615 - val_loss: 2.2047\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5556 - loss: 2.0999 - val_accuracy: 0.4615 - val_loss: 2.0153\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5005 - loss: 1.9769 - val_accuracy: 0.5000 - val_loss: 1.8645\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5365 - loss: 1.9421 - val_accuracy: 0.5000 - val_loss: 1.9813\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5108 - loss: 1.9106 - val_accuracy: 0.6154 - val_loss: 1.6403\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6342 - loss: 1.7070 - val_accuracy: 0.6538 - val_loss: 1.6369\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5336 - loss: 1.6907 - val_accuracy: 0.7308 - val_loss: 1.5023\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6317 - loss: 1.5829 - val_accuracy: 0.6923 - val_loss: 1.4281\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6864 - loss: 1.4937 - val_accuracy: 0.8462 - val_loss: 1.2905\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7222 - loss: 1.4215 - val_accuracy: 0.8462 - val_loss: 1.2692\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7476 - loss: 1.3696 - val_accuracy: 0.6923 - val_loss: 1.3139\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7532 - loss: 1.2851 - val_accuracy: 0.8846 - val_loss: 1.0697\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7934 - loss: 1.2050 - val_accuracy: 0.8077 - val_loss: 1.0812\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7330 - loss: 1.2128 - val_accuracy: 0.7692 - val_loss: 1.0484\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7738 - loss: 1.1106 - val_accuracy: 0.8846 - val_loss: 0.9274\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.7767 - loss: 1.1381 - val_accuracy: 0.8846 - val_loss: 0.8756\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8133 - loss: 1.0178 - val_accuracy: 0.8077 - val_loss: 0.8627\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8030 - loss: 1.0696 - val_accuracy: 0.8846 - val_loss: 0.7765\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8482 - loss: 1.0000 - val_accuracy: 0.8077 - val_loss: 0.8589\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8220 - loss: 1.0005 - val_accuracy: 0.8462 - val_loss: 0.8070\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7997 - loss: 0.9436 - val_accuracy: 0.8462 - val_loss: 0.7369\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8479 - loss: 0.9734 - val_accuracy: 0.8462 - val_loss: 0.7037\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8784 - loss: 0.8728 - val_accuracy: 0.9615 - val_loss: 0.6308\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8831 - loss: 0.8865 - val_accuracy: 0.9231 - val_loss: 0.6669\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8845 - loss: 0.8674 - val_accuracy: 0.9615 - val_loss: 0.5979\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8842 - loss: 0.7993 - val_accuracy: 0.8846 - val_loss: 0.6436\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9290 - loss: 0.7697 - val_accuracy: 0.9231 - val_loss: 0.6353\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8680 - loss: 0.7782 - val_accuracy: 0.9615 - val_loss: 0.5625\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9368 - loss: 0.7186 - val_accuracy: 0.9231 - val_loss: 0.5919\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9060 - loss: 0.7336 - val_accuracy: 0.9615 - val_loss: 0.5125\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9383 - loss: 0.6855 - val_accuracy: 0.8846 - val_loss: 0.6066\n",
            "\n",
            "Fold 9 / 10\n",
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.0181 - loss: 3.6318 - val_accuracy: 0.1154 - val_loss: 3.4636\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.0895 - loss: 3.4934 - val_accuracy: 0.1538 - val_loss: 3.3678\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.0774 - loss: 3.3991 - val_accuracy: 0.2308 - val_loss: 3.2608\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.1434 - loss: 3.2937 - val_accuracy: 0.1923 - val_loss: 3.1530\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2331 - loss: 3.1678 - val_accuracy: 0.1923 - val_loss: 3.0336\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2403 - loss: 3.0351 - val_accuracy: 0.3077 - val_loss: 2.8641\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.2888 - loss: 2.9255 - val_accuracy: 0.3846 - val_loss: 2.6962\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4190 - loss: 2.6603 - val_accuracy: 0.3846 - val_loss: 2.5296\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.3741 - loss: 2.5780 - val_accuracy: 0.5000 - val_loss: 2.3746\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4165 - loss: 2.3628 - val_accuracy: 0.5385 - val_loss: 2.1914\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4462 - loss: 2.2313 - val_accuracy: 0.5000 - val_loss: 2.1272\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5301 - loss: 2.1158 - val_accuracy: 0.5769 - val_loss: 1.9219\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5954 - loss: 1.9401 - val_accuracy: 0.6923 - val_loss: 1.8015\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6128 - loss: 1.8336 - val_accuracy: 0.6154 - val_loss: 1.6828\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6800 - loss: 1.7047 - val_accuracy: 0.6923 - val_loss: 1.5686\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6636 - loss: 1.6395 - val_accuracy: 0.8462 - val_loss: 1.4372\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7063 - loss: 1.4989 - val_accuracy: 0.7692 - val_loss: 1.4131\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7318 - loss: 1.4941 - val_accuracy: 0.8077 - val_loss: 1.2912\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7518 - loss: 1.3948 - val_accuracy: 0.7692 - val_loss: 1.2197\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7763 - loss: 1.3635 - val_accuracy: 0.7692 - val_loss: 1.1745\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7718 - loss: 1.2654 - val_accuracy: 0.7692 - val_loss: 1.1509\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8103 - loss: 1.1379 - val_accuracy: 0.8077 - val_loss: 1.1337\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7248 - loss: 1.2866 - val_accuracy: 0.8462 - val_loss: 1.0556\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8836 - loss: 1.0457 - val_accuracy: 0.8462 - val_loss: 0.9689\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8188 - loss: 1.0528 - val_accuracy: 0.8462 - val_loss: 0.9199\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8353 - loss: 1.0269 - val_accuracy: 0.8077 - val_loss: 0.8958\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8532 - loss: 1.0401 - val_accuracy: 0.8462 - val_loss: 0.8849\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8525 - loss: 0.9580 - val_accuracy: 0.8462 - val_loss: 0.9048\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8582 - loss: 0.9395 - val_accuracy: 0.8077 - val_loss: 0.9055\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8856 - loss: 0.8737 - val_accuracy: 0.8462 - val_loss: 0.8276\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8881 - loss: 0.8550 - val_accuracy: 0.8846 - val_loss: 0.7664\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8983 - loss: 0.8823 - val_accuracy: 0.8846 - val_loss: 0.7394\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9205 - loss: 0.7890 - val_accuracy: 0.8846 - val_loss: 0.7115\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8956 - loss: 0.7384 - val_accuracy: 0.8462 - val_loss: 0.6858\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8727 - loss: 0.7483 - val_accuracy: 0.8462 - val_loss: 0.6676\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8990 - loss: 0.7339 - val_accuracy: 0.8077 - val_loss: 0.6618\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9360 - loss: 0.6720 - val_accuracy: 0.8077 - val_loss: 0.6665\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9322 - loss: 0.6415 - val_accuracy: 0.8077 - val_loss: 0.6624\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8781 - loss: 0.6757 - val_accuracy: 0.8077 - val_loss: 0.6370\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9196 - loss: 0.6594 - val_accuracy: 0.7308 - val_loss: 0.7359\n",
            "\n",
            "Fold 10 / 10\n",
            "Epoch 1/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.0420 - loss: 3.5974 - val_accuracy: 0.0769 - val_loss: 3.4943\n",
            "Epoch 2/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0897 - loss: 3.4909 - val_accuracy: 0.1923 - val_loss: 3.3799\n",
            "Epoch 3/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1477 - loss: 3.3405 - val_accuracy: 0.1923 - val_loss: 3.2615\n",
            "Epoch 4/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1994 - loss: 3.2076 - val_accuracy: 0.2692 - val_loss: 3.1410\n",
            "Epoch 5/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2493 - loss: 3.0806 - val_accuracy: 0.3462 - val_loss: 2.9890\n",
            "Epoch 6/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2732 - loss: 2.9792 - val_accuracy: 0.3846 - val_loss: 2.8177\n",
            "Epoch 7/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3673 - loss: 2.7661 - val_accuracy: 0.4231 - val_loss: 2.6706\n",
            "Epoch 8/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4323 - loss: 2.5599 - val_accuracy: 0.5769 - val_loss: 2.5002\n",
            "Epoch 9/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4665 - loss: 2.4353 - val_accuracy: 0.5769 - val_loss: 2.2964\n",
            "Epoch 10/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5608 - loss: 2.2196 - val_accuracy: 0.5769 - val_loss: 2.1315\n",
            "Epoch 11/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5975 - loss: 2.0916 - val_accuracy: 0.5769 - val_loss: 1.9936\n",
            "Epoch 12/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5618 - loss: 2.0447 - val_accuracy: 0.6538 - val_loss: 2.0104\n",
            "Epoch 13/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6182 - loss: 1.8756 - val_accuracy: 0.6538 - val_loss: 2.0143\n",
            "Epoch 14/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6543 - loss: 1.7663 - val_accuracy: 0.6923 - val_loss: 1.7210\n",
            "Epoch 15/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6492 - loss: 1.7449 - val_accuracy: 0.7308 - val_loss: 1.7038\n",
            "Epoch 16/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7083 - loss: 1.6468 - val_accuracy: 0.6923 - val_loss: 1.6154\n",
            "Epoch 17/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6431 - loss: 1.6420 - val_accuracy: 0.6538 - val_loss: 1.5002\n",
            "Epoch 18/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7543 - loss: 1.3822 - val_accuracy: 0.6923 - val_loss: 1.3557\n",
            "Epoch 19/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6756 - loss: 1.4105 - val_accuracy: 0.8077 - val_loss: 1.2245\n",
            "Epoch 20/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7736 - loss: 1.3232 - val_accuracy: 0.6923 - val_loss: 1.3844\n",
            "Epoch 21/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7532 - loss: 1.2759 - val_accuracy: 0.7692 - val_loss: 1.1858\n",
            "Epoch 22/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8051 - loss: 1.2397 - val_accuracy: 0.9231 - val_loss: 1.0787\n",
            "Epoch 23/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7981 - loss: 1.2145 - val_accuracy: 0.8462 - val_loss: 1.0995\n",
            "Epoch 24/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8049 - loss: 1.0966 - val_accuracy: 0.9231 - val_loss: 0.9517\n",
            "Epoch 25/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8537 - loss: 1.0383 - val_accuracy: 0.9231 - val_loss: 0.9315\n",
            "Epoch 26/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8867 - loss: 1.0249 - val_accuracy: 0.9615 - val_loss: 0.8254\n",
            "Epoch 27/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8065 - loss: 1.0844 - val_accuracy: 0.9615 - val_loss: 0.7971\n",
            "Epoch 28/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8449 - loss: 1.0262 - val_accuracy: 0.9615 - val_loss: 0.8026\n",
            "Epoch 29/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8895 - loss: 0.9232 - val_accuracy: 0.9231 - val_loss: 0.7298\n",
            "Epoch 30/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8542 - loss: 0.9655 - val_accuracy: 1.0000 - val_loss: 0.6885\n",
            "Epoch 31/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8398 - loss: 0.9539 - val_accuracy: 0.9615 - val_loss: 0.7032\n",
            "Epoch 32/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8613 - loss: 0.8946 - val_accuracy: 0.8846 - val_loss: 0.7711\n",
            "Epoch 33/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8381 - loss: 0.9585 - val_accuracy: 0.8846 - val_loss: 0.6653\n",
            "Epoch 34/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8973 - loss: 0.7827 - val_accuracy: 0.9231 - val_loss: 0.6840\n",
            "Epoch 35/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8903 - loss: 0.8327 - val_accuracy: 0.9231 - val_loss: 0.6622\n",
            "Epoch 36/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8768 - loss: 0.8122 - val_accuracy: 0.8846 - val_loss: 0.7654\n",
            "Epoch 37/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8565 - loss: 0.8489 - val_accuracy: 0.8846 - val_loss: 0.7156\n",
            "Epoch 38/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8760 - loss: 0.8065 - val_accuracy: 0.8846 - val_loss: 0.6686\n",
            "Epoch 39/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9026 - loss: 0.7705 - val_accuracy: 1.0000 - val_loss: 0.5958\n",
            "Epoch 40/40\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8940 - loss: 0.7509 - val_accuracy: 0.9615 - val_loss: 0.6012\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define LSTM model with regularization\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(25, 84), kernel_regularizer=l2(0.001)),\n",
        "        Dropout(0.4),  # Dropout added to prevent overfitting\n",
        "        LSTM(32, return_sequences=False, kernel_regularizer=l2(0.002)),\n",
        "        Dropout(0.4),\n",
        "        Dense(32, activation='relu', kernel_regularizer=l2(0.002)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 10-Fold Cross-Validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "accuracy_scores = []\n",
        "val_losses = []  # Store validation losses\n",
        "val_accuracies = []  # Store validation accuracies\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X_seq)):\n",
        "    print(f\"\\nFold {fold+1} / {kf.get_n_splits()}\")\n",
        "\n",
        "    X_train, X_test = X_seq[train_index], X_seq[test_index]\n",
        "    y_train, y_test = Y_seq[train_index], Y_seq[test_index]\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    model = create_model()\n",
        "    history = model.fit(X_train, y_train, epochs=40, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    val_losses.append(history.history['val_loss'])\n",
        "    val_accuracies.append(history.history['val_accuracy'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "gzrfFWISBTYo",
        "outputId": "ba1b69f5-478c-43b5-e02a-942a6f1ed4bc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mean Accuracy: 0.8846\n"
          ]
        }
      ],
      "source": [
        "# Plot Validation Loss and Accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "for i in range(5):\n",
        "    plt.plot(val_losses[i], label=f'Fold {i+1}')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.title(\"Validation Loss per Fold\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot Validation Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "for i in range(5):\n",
        "    plt.plot(val_accuracies[i], label=f'Fold {i+1}')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Validation Accuracy per Fold\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nMean Accuracy: {np.mean(accuracy_scores):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8zlnPxxBwxe"
      },
      "source": [
        "#LOOCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qlj01GXTBweq",
        "outputId": "362092b8-5648-45f5-f696-bb661b700103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0380 - loss: 3.0192\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1486 - loss: 2.8608\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2633 - loss: 2.7359\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3079 - loss: 2.5831\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3488 - loss: 2.4417\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3864 - loss: 2.2476\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4806 - loss: 2.1009\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5401 - loss: 1.8940\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5721 - loss: 1.7262\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6615 - loss: 1.4738\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6552 - loss: 1.3872\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6901 - loss: 1.2534\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7781 - loss: 1.1292\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8051 - loss: 0.9515\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8942 - loss: 0.7961\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8191 - loss: 0.8439\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8668 - loss: 0.7007\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8690 - loss: 0.6702\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8877 - loss: 0.5662\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9191 - loss: 0.5680\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.0602 - loss: 2.9643\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1798 - loss: 2.8340\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1798 - loss: 2.6885\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2381 - loss: 2.5458\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3682 - loss: 2.3406\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4120 - loss: 2.1953\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4746 - loss: 2.0366\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6207 - loss: 1.7712\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6667 - loss: 1.6165\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7260 - loss: 1.4377\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7621 - loss: 1.3074\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7688 - loss: 1.1930\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8543 - loss: 1.0856\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8067 - loss: 0.9786\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8060 - loss: 0.9132\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8209 - loss: 0.8838\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8399 - loss: 0.8171\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8645 - loss: 0.7130\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8941 - loss: 0.5937\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8820 - loss: 0.6093\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1131 - loss: 2.9924\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1910 - loss: 2.8305\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3038 - loss: 2.6996\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2845 - loss: 2.5518\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3609 - loss: 2.3680\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3926 - loss: 2.2102\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4188 - loss: 2.0495\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5518 - loss: 1.8524\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5533 - loss: 1.7418\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6283 - loss: 1.5389\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6964 - loss: 1.4427\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7392 - loss: 1.2827\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7853 - loss: 1.0938\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7319 - loss: 1.0841\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8090 - loss: 0.9645\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8340 - loss: 0.9398\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7715 - loss: 0.9455\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7604 - loss: 0.8473\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7979 - loss: 0.7562\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8678 - loss: 0.6277\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0418 - loss: 2.9760\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1201 - loss: 2.8207\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1647 - loss: 2.7399\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2500 - loss: 2.5933\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3579 - loss: 2.4054\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3828 - loss: 2.2359\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3893 - loss: 2.0786\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4980 - loss: 1.9666\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6116 - loss: 1.7214\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7243 - loss: 1.5426\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7743 - loss: 1.3805\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7733 - loss: 1.2310\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7853 - loss: 1.1031\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8578 - loss: 0.9837\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8744 - loss: 0.8333\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8796 - loss: 0.7393\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9185 - loss: 0.6666\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9140 - loss: 0.5867\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8732 - loss: 0.6872\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8734 - loss: 0.5792\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0703 - loss: 2.9464\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1016 - loss: 2.7950\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2352 - loss: 2.6411\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2299 - loss: 2.5302\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3885 - loss: 2.3438\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4287 - loss: 2.1680\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4222 - loss: 2.0397\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4781 - loss: 1.8845\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5691 - loss: 1.7280\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6027 - loss: 1.5460\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7034 - loss: 1.4000\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7276 - loss: 1.2946\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7545 - loss: 1.1965\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7873 - loss: 1.0621\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7812 - loss: 0.9441\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8258 - loss: 0.9123\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9194 - loss: 0.7456\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9334 - loss: 0.6718\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8656 - loss: 0.6460\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9469 - loss: 0.5851\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0530 - loss: 3.0025\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1507 - loss: 2.8983\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2533 - loss: 2.7752\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3010 - loss: 2.6148\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3216 - loss: 2.4719\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3743 - loss: 2.3174\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4424 - loss: 2.0865\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5295 - loss: 1.9052\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5133 - loss: 1.7824\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6155 - loss: 1.6214\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6663 - loss: 1.4084\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6433 - loss: 1.3460\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7324 - loss: 1.2035\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6999 - loss: 1.2437\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7678 - loss: 1.0051\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8289 - loss: 0.9610\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8263 - loss: 0.8506\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8657 - loss: 0.7811\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8789 - loss: 0.7001\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8092 - loss: 0.7212\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0541 - loss: 2.9794\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1271 - loss: 2.8571\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2557 - loss: 2.7294\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2613 - loss: 2.6028\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2793 - loss: 2.3893\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4209 - loss: 2.2479\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5074 - loss: 2.0417\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4429 - loss: 1.9133\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6349 - loss: 1.6991\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6663 - loss: 1.4951\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7033 - loss: 1.3320\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7743 - loss: 1.2203\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8154 - loss: 1.0977\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8099 - loss: 1.0804\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8401 - loss: 0.9188\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8404 - loss: 0.8646\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8509 - loss: 0.7728\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8460 - loss: 0.7222\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8224 - loss: 0.7006\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8694 - loss: 0.6305\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0672 - loss: 2.9866\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2028 - loss: 2.8622\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3051 - loss: 2.7401\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2601 - loss: 2.6275\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4115 - loss: 2.4277\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4370 - loss: 2.2579\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4744 - loss: 2.1302\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5154 - loss: 1.8487\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5799 - loss: 1.7299\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6122 - loss: 1.5449\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6746 - loss: 1.4009\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7348 - loss: 1.2111\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6681 - loss: 1.2454\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7937 - loss: 1.0780\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8493 - loss: 0.8980\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8704 - loss: 0.8545\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8196 - loss: 0.8647\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8464 - loss: 0.7459\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9235 - loss: 0.5900\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9523 - loss: 0.5687\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0943 - loss: 2.9517\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1447 - loss: 2.8191\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2153 - loss: 2.6714\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3486 - loss: 2.4653\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3763 - loss: 2.3107\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4946 - loss: 2.1249\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5527 - loss: 1.9045\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6039 - loss: 1.7140\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6748 - loss: 1.4904\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7103 - loss: 1.3180\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7798 - loss: 1.1584\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7893 - loss: 1.0828\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8350 - loss: 0.8947\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8187 - loss: 0.8691\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8699 - loss: 0.7175\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8882 - loss: 0.6701\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9118 - loss: 0.5924\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8998 - loss: 0.5658\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9057 - loss: 0.5243\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9086 - loss: 0.5138\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0357 - loss: 2.9759\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1477 - loss: 2.8054\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2512 - loss: 2.7116\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2895 - loss: 2.5547\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4132 - loss: 2.3877\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5193 - loss: 2.2133\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6028 - loss: 2.0076\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5915 - loss: 1.8636\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6407 - loss: 1.7005\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6934 - loss: 1.5362\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6634 - loss: 1.3907\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7371 - loss: 1.1569\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7799 - loss: 1.1024\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7140 - loss: 1.0863\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7872 - loss: 0.9752\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7814 - loss: 0.8806\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8517 - loss: 0.7898\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8236 - loss: 0.7897\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8602 - loss: 0.7187\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8785 - loss: 0.6878\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1203 - loss: 2.9534\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1676 - loss: 2.7980\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2399 - loss: 2.6715\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3262 - loss: 2.5218\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4547 - loss: 2.3303\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4737 - loss: 2.1570\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5201 - loss: 2.0203\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6350 - loss: 1.7690\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6056 - loss: 1.6784\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7191 - loss: 1.4234\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7309 - loss: 1.3061\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7777 - loss: 1.2136\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8235 - loss: 1.0321\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8411 - loss: 0.9186\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8691 - loss: 0.8217\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8861 - loss: 0.7403\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8785 - loss: 0.7027\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8784 - loss: 0.6748\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8307 - loss: 0.7100\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8580 - loss: 0.6444\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0779 - loss: 3.0013\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2333 - loss: 2.8080\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2352 - loss: 2.6728\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3718 - loss: 2.4862\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3972 - loss: 2.3291\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4825 - loss: 2.1884\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5166 - loss: 1.9435\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5473 - loss: 1.8293\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5746 - loss: 1.6733\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6260 - loss: 1.5227\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6300 - loss: 1.3325\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6779 - loss: 1.2457\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6994 - loss: 1.2217\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7569 - loss: 1.0414\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7141 - loss: 0.9400\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8838 - loss: 0.7789\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8444 - loss: 0.7240\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8749 - loss: 0.6376\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9278 - loss: 0.5194\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9146 - loss: 0.4950\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.0622 - loss: 2.9852\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1154 - loss: 2.8576\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2191 - loss: 2.7080\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3490 - loss: 2.5238\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3464 - loss: 2.3918\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4530 - loss: 2.2134\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4766 - loss: 2.0688\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4971 - loss: 1.9200\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5773 - loss: 1.6918\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5888 - loss: 1.6067\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6386 - loss: 1.4689\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6786 - loss: 1.2891\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7764 - loss: 1.1381\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7874 - loss: 1.0138\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8493 - loss: 0.9082\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8338 - loss: 0.8693\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8957 - loss: 0.7518\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8853 - loss: 0.6576\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9204 - loss: 0.6263\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9242 - loss: 0.6043\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0946 - loss: 2.9658\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2030 - loss: 2.8301\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2537 - loss: 2.7010\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3088 - loss: 2.5685\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4268 - loss: 2.3683\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4763 - loss: 2.2194\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5271 - loss: 1.9567\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6239 - loss: 1.8635\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6178 - loss: 1.6635\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6899 - loss: 1.4579\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7446 - loss: 1.2423\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8284 - loss: 1.1681\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8482 - loss: 0.9918\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8999 - loss: 0.8339\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8788 - loss: 0.7747\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8799 - loss: 0.6962\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8900 - loss: 0.6479\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8976 - loss: 0.6066\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9106 - loss: 0.5517\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9256 - loss: 0.5060\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.0836 - loss: 3.0062\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1692 - loss: 2.8526\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2510 - loss: 2.7114\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3547 - loss: 2.5972\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3670 - loss: 2.4360\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4888 - loss: 2.2240\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4879 - loss: 2.0328\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5466 - loss: 1.8293\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6553 - loss: 1.6918\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6187 - loss: 1.5169\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6962 - loss: 1.3514\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6860 - loss: 1.2267\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7848 - loss: 1.0552\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8200 - loss: 0.9407\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8574 - loss: 0.8216\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8351 - loss: 0.8071\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8577 - loss: 0.7199\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8727 - loss: 0.7095\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8750 - loss: 0.6551\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8604 - loss: 0.6027\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1069 - loss: 2.9642\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1669 - loss: 2.8178\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3348 - loss: 2.6669\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3671 - loss: 2.5172\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4288 - loss: 2.3441\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4893 - loss: 2.1815\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5335 - loss: 2.0090\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6297 - loss: 1.7474\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6616 - loss: 1.5841\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6984 - loss: 1.4336\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7355 - loss: 1.3124\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7475 - loss: 1.1953\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8203 - loss: 0.9997\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 0.9689\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8273 - loss: 0.8617\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8789 - loss: 0.7540\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8827 - loss: 0.6901\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9034 - loss: 0.6476\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9286 - loss: 0.5754\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9201 - loss: 0.5295\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.0388 - loss: 2.9658\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1242 - loss: 2.8638\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2299 - loss: 2.7476\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3296 - loss: 2.6094\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4549 - loss: 2.4507\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5615 - loss: 2.2329\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5604 - loss: 2.1013\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6200 - loss: 1.8452\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6344 - loss: 1.6736\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7020 - loss: 1.4872\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6690 - loss: 1.3125\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7305 - loss: 1.2447\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7957 - loss: 1.0359\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8247 - loss: 0.9467\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8574 - loss: 0.7688\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9042 - loss: 0.6747\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7868 - loss: 0.8227\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9053 - loss: 0.6831\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9262 - loss: 0.5852\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9245 - loss: 0.5848\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0432 - loss: 2.9549\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0973 - loss: 2.8002\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1510 - loss: 2.6332\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2701 - loss: 2.4430\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3507 - loss: 2.3101\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4472 - loss: 2.1098\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4582 - loss: 1.9414\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5151 - loss: 1.8060\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5990 - loss: 1.6477\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6775 - loss: 1.3818\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7271 - loss: 1.2772\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7802 - loss: 1.2685\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7480 - loss: 1.1762\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8178 - loss: 1.0062\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7939 - loss: 0.9245\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8307 - loss: 0.8703\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8153 - loss: 0.7482\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8641 - loss: 0.6736\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8626 - loss: 0.6514\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9437 - loss: 0.5277\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0542 - loss: 2.9935\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1555 - loss: 2.8421\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2448 - loss: 2.6768\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3089 - loss: 2.5110\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3354 - loss: 2.3718\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3866 - loss: 2.1805\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4673 - loss: 1.9816\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4848 - loss: 1.8683\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5457 - loss: 1.6663\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6209 - loss: 1.4982\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6378 - loss: 1.4221\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7133 - loss: 1.2711\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7694 - loss: 1.1676\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8039 - loss: 1.0621\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7871 - loss: 0.9755\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8112 - loss: 0.9385\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8565 - loss: 0.8761\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7850 - loss: 0.8247\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8666 - loss: 0.6797\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8605 - loss: 0.6670\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0805 - loss: 2.9776\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1903 - loss: 2.8035\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2556 - loss: 2.6666\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3409 - loss: 2.4949\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3978 - loss: 2.2980\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4256 - loss: 2.1192\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5337 - loss: 1.8889\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5634 - loss: 1.7608\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5494 - loss: 1.6191\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6978 - loss: 1.4481\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6605 - loss: 1.3352\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8198 - loss: 1.0819\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7522 - loss: 1.0378\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7906 - loss: 0.9901\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8217 - loss: 0.8638\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8444 - loss: 0.8459\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8248 - loss: 0.7541\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8843 - loss: 0.6777\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8654 - loss: 0.5754\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8918 - loss: 0.5543\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.0864 - loss: 2.9520\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1586 - loss: 2.8369\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2839 - loss: 2.6835\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3160 - loss: 2.5914\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4728 - loss: 2.3743\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5284 - loss: 2.2102\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6126 - loss: 2.0130\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5948 - loss: 1.8247\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6779 - loss: 1.5752\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7065 - loss: 1.4669\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6916 - loss: 1.3462\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7784 - loss: 1.1551\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7515 - loss: 1.2050\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7264 - loss: 1.3811\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6708 - loss: 1.2819\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7829 - loss: 1.1103\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7956 - loss: 0.9233\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8532 - loss: 0.8723\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7998 - loss: 0.8186\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8299 - loss: 0.7726\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0521 - loss: 2.9971\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1987 - loss: 2.8363\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2418 - loss: 2.6993\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2900 - loss: 2.5850\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3807 - loss: 2.3996\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3809 - loss: 2.2818\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5359 - loss: 2.0556\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6099 - loss: 1.8758\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5662 - loss: 1.7087\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6022 - loss: 1.5451\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7000 - loss: 1.3583\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7251 - loss: 1.2355\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7584 - loss: 1.1170\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8267 - loss: 1.0053\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8527 - loss: 0.9016\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8121 - loss: 0.8740\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8117 - loss: 0.7878\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8353 - loss: 0.8039\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8500 - loss: 0.7239\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8607 - loss: 0.7143\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.0977 - loss: 2.9583\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1728 - loss: 2.7769\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2274 - loss: 2.6402\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3018 - loss: 2.4924\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3955 - loss: 2.3257\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4469 - loss: 2.1462\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5523 - loss: 1.9400\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4753 - loss: 1.8039\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6223 - loss: 1.6896\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6253 - loss: 1.5025\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7100 - loss: 1.2872\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7093 - loss: 1.2275\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7676 - loss: 1.1136\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8217 - loss: 0.9960\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8262 - loss: 0.9358\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8327 - loss: 0.8281\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8774 - loss: 0.7445\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8598 - loss: 0.7234\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9081 - loss: 0.5771\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8448 - loss: 0.6545\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0986 - loss: 2.9668\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2014 - loss: 2.8425\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2024 - loss: 2.7289\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2182 - loss: 2.5810\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2766 - loss: 2.4726\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3325 - loss: 2.2221\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4065 - loss: 2.0970\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4795 - loss: 1.9776\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5363 - loss: 1.8174\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6475 - loss: 1.6063\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6547 - loss: 1.4862\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6589 - loss: 1.4055\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7445 - loss: 1.2398\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7599 - loss: 1.1247\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7010 - loss: 1.1405\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7865 - loss: 1.0149\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7613 - loss: 0.9467\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8401 - loss: 0.7961\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8314 - loss: 0.7823\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8882 - loss: 0.6215\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0497 - loss: 2.9973\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1030 - loss: 2.8529\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2211 - loss: 2.7232\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2507 - loss: 2.5763\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3560 - loss: 2.4287\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3558 - loss: 2.2623\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5367 - loss: 2.0410\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5396 - loss: 1.9455\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5420 - loss: 1.7856\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7050 - loss: 1.5829\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7542 - loss: 1.4497\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7199 - loss: 1.3680\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8310 - loss: 1.1586\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 1.0999\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8070 - loss: 1.0348\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7757 - loss: 0.9893\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8028 - loss: 0.9568\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8756 - loss: 0.8126\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8563 - loss: 0.6838\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9036 - loss: 0.6141\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0667 - loss: 2.9825\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2014 - loss: 2.8242\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3785 - loss: 2.6455\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3435 - loss: 2.5338\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3877 - loss: 2.3490\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4428 - loss: 2.1772\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5215 - loss: 1.9533\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5495 - loss: 1.8166\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6392 - loss: 1.5450\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6826 - loss: 1.4467\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7465 - loss: 1.2094\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7145 - loss: 1.1859\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7586 - loss: 0.9738\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7780 - loss: 0.9689\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8081 - loss: 0.8347\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8517 - loss: 0.7710\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8430 - loss: 0.7270\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8858 - loss: 0.6306\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8756 - loss: 0.5864\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8740 - loss: 0.5590\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0855 - loss: 2.9971\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1073 - loss: 2.9035\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1497 - loss: 2.7885\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2173 - loss: 2.6795\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2408 - loss: 2.5516\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3260 - loss: 2.3929\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3544 - loss: 2.2761\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4167 - loss: 2.1451\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5486 - loss: 1.9012\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6749 - loss: 1.7120\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6138 - loss: 1.5871\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7088 - loss: 1.4151\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6821 - loss: 1.2975\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7654 - loss: 1.1723\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7651 - loss: 1.0761\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6507 - loss: 1.1252\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7824 - loss: 0.9919\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8264 - loss: 0.8761\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8498 - loss: 0.7840\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8186 - loss: 0.7504\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0210 - loss: 3.0112\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1415 - loss: 2.8988\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2622 - loss: 2.7724\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3187 - loss: 2.6445\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4213 - loss: 2.4863\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4446 - loss: 2.2814\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5295 - loss: 2.0633\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6070 - loss: 1.8703\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5719 - loss: 1.6845\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6716 - loss: 1.5015\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7013 - loss: 1.3322\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7646 - loss: 1.1683\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8512 - loss: 1.0358\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7550 - loss: 1.0876\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8197 - loss: 0.9137\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7842 - loss: 0.9065\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8650 - loss: 0.7474\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8811 - loss: 0.7023\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9200 - loss: 0.6050\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9391 - loss: 0.5252\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0469 - loss: 2.9879\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1875 - loss: 2.8277\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2887 - loss: 2.6937\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3301 - loss: 2.5004\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3604 - loss: 2.3299\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4356 - loss: 2.1839\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5126 - loss: 1.9712\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5597 - loss: 1.7599\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6029 - loss: 1.5597\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7015 - loss: 1.4869\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7071 - loss: 1.2790\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7295 - loss: 1.1612\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7248 - loss: 1.1252\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7513 - loss: 1.0361\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7887 - loss: 0.8856\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8173 - loss: 0.8301\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8918 - loss: 0.7390\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8831 - loss: 0.6233\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8708 - loss: 0.5919\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9181 - loss: 0.5576\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0975 - loss: 2.9699\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1983 - loss: 2.8219\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2055 - loss: 2.6930\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2796 - loss: 2.5046\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2835 - loss: 2.3971\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3720 - loss: 2.2287\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4536 - loss: 2.1091\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4441 - loss: 1.9332\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5139 - loss: 1.7696\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4862 - loss: 1.6991\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5941 - loss: 1.4857\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6063 - loss: 1.3638\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6953 - loss: 1.2137\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6860 - loss: 1.1519\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7047 - loss: 1.0540\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7850 - loss: 0.9375\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8438 - loss: 0.8134\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8119 - loss: 0.7954\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8228 - loss: 0.7019\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8372 - loss: 0.6570\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0825 - loss: 2.9518\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1657 - loss: 2.8169\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2254 - loss: 2.6861\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2755 - loss: 2.5788\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3739 - loss: 2.3725\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3937 - loss: 2.2619\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5021 - loss: 2.0774\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5736 - loss: 1.8675\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5473 - loss: 1.7697\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6762 - loss: 1.5565\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7216 - loss: 1.4486\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7194 - loss: 1.2801\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7376 - loss: 1.1467\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8224 - loss: 1.0402\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8113 - loss: 0.9721\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8082 - loss: 0.9141\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8552 - loss: 0.8043\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8493 - loss: 0.7262\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8684 - loss: 0.7029\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8571 - loss: 0.6355\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0653 - loss: 2.9750\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1461 - loss: 2.8765\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2341 - loss: 2.7449\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3758 - loss: 2.6260\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3722 - loss: 2.4607\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5037 - loss: 2.2678\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5699 - loss: 2.0890\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6300 - loss: 1.8816\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6917 - loss: 1.7173\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6822 - loss: 1.5402\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7475 - loss: 1.3947\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8373 - loss: 1.2002\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8026 - loss: 1.1129\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8496 - loss: 1.0114\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8781 - loss: 0.8790\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8971 - loss: 0.8319\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9310 - loss: 0.7164\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9414 - loss: 0.6076\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9609 - loss: 0.5487\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9503 - loss: 0.5170\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0978 - loss: 2.9830\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2097 - loss: 2.8231\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2610 - loss: 2.7261\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3660 - loss: 2.5570\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3870 - loss: 2.3630\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4588 - loss: 2.1522\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5189 - loss: 2.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6210 - loss: 1.7501\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6602 - loss: 1.5503\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7143 - loss: 1.4403\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7320 - loss: 1.3073\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7911 - loss: 1.1926\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8368 - loss: 1.0848\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8114 - loss: 0.9918\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8694 - loss: 0.9258\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8630 - loss: 0.8231\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8882 - loss: 0.7595\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9115 - loss: 0.6935\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8951 - loss: 0.6579\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8900 - loss: 0.6100\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1295 - loss: 2.9755\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1141 - loss: 2.8778\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2183 - loss: 2.7314\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3303 - loss: 2.5778\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3967 - loss: 2.3930\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4279 - loss: 2.2143\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5331 - loss: 2.0261\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5388 - loss: 1.8432\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5858 - loss: 1.6249\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6079 - loss: 1.4685\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7167 - loss: 1.2759\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7268 - loss: 1.2124\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7319 - loss: 1.0976\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7590 - loss: 1.0136\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7931 - loss: 0.8689\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8083 - loss: 0.8353\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8535 - loss: 0.7001\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8382 - loss: 0.7292\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8536 - loss: 0.5941\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8472 - loss: 0.6095\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0910 - loss: 2.9811\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1753 - loss: 2.8260\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2168 - loss: 2.6684\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2573 - loss: 2.5739\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2362 - loss: 2.4707\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3721 - loss: 2.2610\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4121 - loss: 2.1293\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4685 - loss: 1.9876\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6229 - loss: 1.7643\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6433 - loss: 1.6230\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7120 - loss: 1.4284\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7900 - loss: 1.2726\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8692 - loss: 1.1348\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8685 - loss: 1.0062\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8999 - loss: 0.8711\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8851 - loss: 0.8396\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8586 - loss: 0.8309\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9099 - loss: 0.7135\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9318 - loss: 0.6226\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8515 - loss: 0.7506\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.0392 - loss: 2.9920\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1389 - loss: 2.8856\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2494 - loss: 2.7501\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3375 - loss: 2.6083\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3403 - loss: 2.4893\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4656 - loss: 2.2955\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4866 - loss: 2.0938\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5551 - loss: 1.8998\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5906 - loss: 1.7374\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6384 - loss: 1.5721\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6561 - loss: 1.4588\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6671 - loss: 1.2993\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7409 - loss: 1.2044\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7916 - loss: 1.0432\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7916 - loss: 0.9852\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8277 - loss: 0.8605\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8603 - loss: 0.7556\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8839 - loss: 0.6998\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9319 - loss: 0.6304\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8669 - loss: 0.6042\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1129 - loss: 2.9341\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2696 - loss: 2.7682\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3104 - loss: 2.6086\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2891 - loss: 2.4480\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3274 - loss: 2.2965\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3952 - loss: 2.0873\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4398 - loss: 1.9395\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5376 - loss: 1.7312\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5709 - loss: 1.6028\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5943 - loss: 1.4645\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6121 - loss: 1.3580\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6747 - loss: 1.2226\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6884 - loss: 1.1485\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7713 - loss: 1.0202\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8114 - loss: 0.8723\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8709 - loss: 0.8410\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8320 - loss: 0.7698\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8252 - loss: 0.7503\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8728 - loss: 0.6251\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7922 - loss: 0.7261\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.0768 - loss: 2.9982\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1248 - loss: 2.8748\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2079 - loss: 2.7528\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3024 - loss: 2.6620\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3367 - loss: 2.4653\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4170 - loss: 2.3052\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3473 - loss: 2.2441\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4383 - loss: 2.0193\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4449 - loss: 1.9054\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5366 - loss: 1.7353\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5389 - loss: 1.6493\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6147 - loss: 1.4750\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5861 - loss: 1.4538\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6590 - loss: 1.2859\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6834 - loss: 1.1313\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7610 - loss: 1.0267\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7557 - loss: 1.0133\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7741 - loss: 0.9811\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8288 - loss: 0.7875\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7681 - loss: 0.7964\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0540 - loss: 3.0026\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1931 - loss: 2.8662\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1921 - loss: 2.7311\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2812 - loss: 2.5717\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3522 - loss: 2.3798\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3463 - loss: 2.2630\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4897 - loss: 2.0698\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6052 - loss: 1.8514\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5549 - loss: 1.7158\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6768 - loss: 1.5347\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7604 - loss: 1.3538\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6769 - loss: 1.2179\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7861 - loss: 1.0944\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7747 - loss: 1.0493\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8338 - loss: 0.9085\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8576 - loss: 0.7610\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8414 - loss: 0.7329\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8520 - loss: 0.6396\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8889 - loss: 0.6211\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8996 - loss: 0.5593\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.1001 - loss: 2.9491\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1535 - loss: 2.8283\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2213 - loss: 2.6782\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3195 - loss: 2.5538\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3406 - loss: 2.4160\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4635 - loss: 2.2381\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4333 - loss: 2.1068\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5637 - loss: 1.9354\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6149 - loss: 1.7687\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6296 - loss: 1.5987\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7406 - loss: 1.3528\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7784 - loss: 1.2891\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7680 - loss: 1.1819\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7387 - loss: 1.1650\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7709 - loss: 1.0317\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8297 - loss: 0.9140\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7370 - loss: 1.0386\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7766 - loss: 0.8344\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7995 - loss: 0.7892\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8650 - loss: 0.6742\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.0620 - loss: 2.9817\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1919 - loss: 2.8455\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3274 - loss: 2.7001\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3333 - loss: 2.5574\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3973 - loss: 2.3887\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4464 - loss: 2.1947\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 1.9697\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6050 - loss: 1.7691\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6602 - loss: 1.5285\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6490 - loss: 1.4491\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7461 - loss: 1.2837\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7640 - loss: 1.1793\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7681 - loss: 1.0974\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8386 - loss: 0.9808\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8080 - loss: 0.8322\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8230 - loss: 0.8141\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8834 - loss: 0.7128\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9318 - loss: 0.5921\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9028 - loss: 0.5548\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9241 - loss: 0.5382\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.1121 - loss: 2.9639\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2067 - loss: 2.8283\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2845 - loss: 2.6971\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3789 - loss: 2.5474\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4091 - loss: 2.3963\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4121 - loss: 2.1867\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5368 - loss: 1.9501\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6734 - loss: 1.7075\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6679 - loss: 1.4918\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7028 - loss: 1.2953\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6997 - loss: 1.2364\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7160 - loss: 1.1263\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8147 - loss: 0.9602\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8226 - loss: 0.8767\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7863 - loss: 0.8564\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8306 - loss: 0.7855\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8204 - loss: 0.7463\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8264 - loss: 0.6671\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9191 - loss: 0.5703\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8754 - loss: 0.5906\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.0936 - loss: 2.9430\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2027 - loss: 2.7751\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1845 - loss: 2.6339\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2137 - loss: 2.4921\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2804 - loss: 2.3453\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4565 - loss: 2.1412\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5783 - loss: 1.9936\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6037 - loss: 1.7689\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6176 - loss: 1.6433\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6384 - loss: 1.4860\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6656 - loss: 1.3982\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7872 - loss: 1.1832\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7856 - loss: 1.0548\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7497 - loss: 1.0003\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8032 - loss: 0.9233\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7906 - loss: 0.8812\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7985 - loss: 0.8778\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8229 - loss: 0.7657\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8318 - loss: 0.6930\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8598 - loss: 0.5946\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.0625 - loss: 2.9708\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1410 - loss: 2.8565\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1959 - loss: 2.7447\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3177 - loss: 2.5798\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3307 - loss: 2.4526\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3549 - loss: 2.2757\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4889 - loss: 2.1308\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5485 - loss: 1.9321\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6418 - loss: 1.7870\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6612 - loss: 1.6089\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6836 - loss: 1.4583\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7445 - loss: 1.2856\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7142 - loss: 1.2196\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8450 - loss: 1.0593\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7966 - loss: 0.9669\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7952 - loss: 0.8876\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8850 - loss: 0.7064\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8669 - loss: 0.7076\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8938 - loss: 0.5879\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9133 - loss: 0.5574\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1218 - loss: 2.9688\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1452 - loss: 2.8460\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3124 - loss: 2.7410\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3285 - loss: 2.5817\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4711 - loss: 2.4139\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4681 - loss: 2.2484\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4930 - loss: 2.1191\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5052 - loss: 1.9250\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5582 - loss: 1.7811\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6081 - loss: 1.6213\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6527 - loss: 1.4633\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6773 - loss: 1.3039\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8014 - loss: 1.1381\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8078 - loss: 1.0143\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8442 - loss: 0.9557\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8554 - loss: 0.8106\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8866 - loss: 0.7591\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8664 - loss: 0.7120\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8856 - loss: 0.6514\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8566 - loss: 0.6455\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0476 - loss: 3.0127\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1968 - loss: 2.8623\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2349 - loss: 2.7394\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2608 - loss: 2.5923\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4065 - loss: 2.4214\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4445 - loss: 2.2498\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4833 - loss: 2.0850\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6003 - loss: 1.8173\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6516 - loss: 1.6384\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6609 - loss: 1.5231\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7034 - loss: 1.3472\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7442 - loss: 1.2261\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7538 - loss: 1.1127\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7331 - loss: 1.0307\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7945 - loss: 0.9119\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8378 - loss: 0.8197\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7569 - loss: 0.8078\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8025 - loss: 0.6989\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8022 - loss: 0.7211\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7848 - loss: 0.8379\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0791 - loss: 2.9676\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1440 - loss: 2.8139\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2306 - loss: 2.6673\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3023 - loss: 2.5152\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3790 - loss: 2.3509\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4289 - loss: 2.0947\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4504 - loss: 2.0086\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5376 - loss: 1.7529\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6180 - loss: 1.6685\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6290 - loss: 1.4542\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7014 - loss: 1.3130\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6973 - loss: 1.1991\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7715 - loss: 1.0330\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7678 - loss: 1.0589\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7957 - loss: 0.9247\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8093 - loss: 0.8900\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8464 - loss: 0.8469\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8660 - loss: 0.7471\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8733 - loss: 0.6668\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9397 - loss: 0.5815\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0581 - loss: 2.9790\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1542 - loss: 2.8124\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2524 - loss: 2.6868\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3346 - loss: 2.4902\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4453 - loss: 2.3214\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4771 - loss: 2.1665\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4976 - loss: 1.9647\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5922 - loss: 1.7526\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6175 - loss: 1.6038\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6554 - loss: 1.4165\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7081 - loss: 1.2985\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7783 - loss: 1.2339\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7626 - loss: 1.0530\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8633 - loss: 0.9341\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8818 - loss: 0.7585\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8489 - loss: 0.7930\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9084 - loss: 0.6252\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9558 - loss: 0.5987\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9183 - loss: 0.5856\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9010 - loss: 0.5383\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0417 - loss: 2.9808\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2483 - loss: 2.8408\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2457 - loss: 2.7545\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4112 - loss: 2.5944\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3684 - loss: 2.4586\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4822 - loss: 2.2879\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5746 - loss: 2.0811\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5758 - loss: 1.8469\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6529 - loss: 1.6703\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7171 - loss: 1.4817\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7682 - loss: 1.3093\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7977 - loss: 1.1450\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8438 - loss: 0.9796\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8768 - loss: 0.8135\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8377 - loss: 0.8537\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8626 - loss: 0.8085\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8768 - loss: 0.6522\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8819 - loss: 0.6284\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9425 - loss: 0.5321\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9157 - loss: 0.4466\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0779 - loss: 2.9648\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1921 - loss: 2.7899\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2486 - loss: 2.6529\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3060 - loss: 2.4923\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3537 - loss: 2.3274\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3937 - loss: 2.2060\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4812 - loss: 1.9616\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5780 - loss: 1.8218\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6088 - loss: 1.6772\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6855 - loss: 1.4936\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6813 - loss: 1.2878\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7488 - loss: 1.1648\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7306 - loss: 1.1119\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8265 - loss: 0.9116\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8873 - loss: 0.7881\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8088 - loss: 0.8126\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8194 - loss: 0.7671\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8422 - loss: 0.6708\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8752 - loss: 0.6196\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9399 - loss: 0.5474\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0220 - loss: 3.0078\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0860 - loss: 2.8620\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1775 - loss: 2.7436\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2715 - loss: 2.6171\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3086 - loss: 2.4859\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2917 - loss: 2.3602\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3273 - loss: 2.1795\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3768 - loss: 2.0429\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4870 - loss: 1.8258\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5252 - loss: 1.7207\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6886 - loss: 1.4884\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7474 - loss: 1.3510\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7471 - loss: 1.2295\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8278 - loss: 1.0643\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7947 - loss: 1.0581\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8870 - loss: 0.8813\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8571 - loss: 0.9049\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9028 - loss: 0.7049\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8719 - loss: 0.6766\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9370 - loss: 0.6316\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.0603 - loss: 2.9722\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1266 - loss: 2.8613\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2514 - loss: 2.7501\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3388 - loss: 2.5855\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3586 - loss: 2.4350\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4715 - loss: 2.2377\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4579 - loss: 2.1089\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5772 - loss: 1.8923\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6283 - loss: 1.7144\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7916 - loss: 1.5244\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7768 - loss: 1.3825\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8292 - loss: 1.1344\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7789 - loss: 1.1130\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7716 - loss: 1.0896\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8441 - loss: 0.8886\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8114 - loss: 0.8322\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8312 - loss: 0.8363\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7781 - loss: 0.8573\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8005 - loss: 0.8434\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8566 - loss: 0.6765\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0567 - loss: 2.9893\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1726 - loss: 2.8535\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2333 - loss: 2.7377\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2259 - loss: 2.6324\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3068 - loss: 2.5023\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3289 - loss: 2.3622\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4051 - loss: 2.1606\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4807 - loss: 2.0152\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5736 - loss: 1.7640\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6809 - loss: 1.5814\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6708 - loss: 1.4403\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7923 - loss: 1.2462\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7361 - loss: 1.1980\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8011 - loss: 0.9915\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8141 - loss: 0.9396\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8530 - loss: 0.8317\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8704 - loss: 0.8092\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8604 - loss: 0.7592\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8802 - loss: 0.6328\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8997 - loss: 0.5802\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.0595 - loss: 2.9615\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1600 - loss: 2.8489\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2495 - loss: 2.6542\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3233 - loss: 2.5189\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2952 - loss: 2.3931\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4536 - loss: 2.1003\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5351 - loss: 1.9535\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4950 - loss: 1.8218\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6712 - loss: 1.6504\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6932 - loss: 1.4676\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7484 - loss: 1.2891\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8121 - loss: 1.1751\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7871 - loss: 1.0719\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8549 - loss: 0.9825\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8562 - loss: 0.8309\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8517 - loss: 0.7784\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8975 - loss: 0.6891\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9007 - loss: 0.5925\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9255 - loss: 0.5678\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9460 - loss: 0.4785\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0893 - loss: 2.9729\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1786 - loss: 2.7994\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2116 - loss: 2.7017\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4204 - loss: 2.4895\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3497 - loss: 2.3712\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4326 - loss: 2.2308\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5122 - loss: 2.0307\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5448 - loss: 1.9301\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5972 - loss: 1.7524\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5851 - loss: 1.5946\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7074 - loss: 1.4497\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6905 - loss: 1.3044\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7064 - loss: 1.2102\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7167 - loss: 1.1205\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7561 - loss: 0.9525\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8277 - loss: 0.8884\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8389 - loss: 0.8134\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9185 - loss: 0.7137\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9223 - loss: 0.6180\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9102 - loss: 0.5593\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.0741 - loss: 2.9858\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2213 - loss: 2.8493\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2850 - loss: 2.7438\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3429 - loss: 2.5801\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3765 - loss: 2.4465\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4376 - loss: 2.2772\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5668 - loss: 2.0110\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6130 - loss: 1.9054\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6421 - loss: 1.7087\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6895 - loss: 1.5345\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6663 - loss: 1.3692\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7423 - loss: 1.2286\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8142 - loss: 1.0545\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7979 - loss: 0.9991\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7734 - loss: 0.9344\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8047 - loss: 0.8106\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7650 - loss: 0.8217\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8287 - loss: 0.7855\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7959 - loss: 0.7849\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7699 - loss: 0.7723\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.0746 - loss: 2.9808\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1950 - loss: 2.8089\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2473 - loss: 2.7145\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3041 - loss: 2.5957\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4407 - loss: 2.4282\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5109 - loss: 2.2525\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5750 - loss: 2.0861\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5421 - loss: 1.9452\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6714 - loss: 1.7141\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7251 - loss: 1.5102\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7996 - loss: 1.2851\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7882 - loss: 1.2227\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8561 - loss: 1.0522\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8951 - loss: 0.8656\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8849 - loss: 0.7307\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8653 - loss: 0.7189\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9021 - loss: 0.5703\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9421 - loss: 0.5253\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9578 - loss: 0.4427\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9103 - loss: 0.4818\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.0503 - loss: 2.9921\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2040 - loss: 2.8111\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2093 - loss: 2.7097\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3537 - loss: 2.5117\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3713 - loss: 2.3686\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4429 - loss: 2.1826\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5135 - loss: 2.0517\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5557 - loss: 1.8078\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5975 - loss: 1.6165\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6308 - loss: 1.4770\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7001 - loss: 1.2860\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7098 - loss: 1.2177\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7192 - loss: 1.1017\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7740 - loss: 1.0077\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7522 - loss: 1.0018\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7745 - loss: 0.9172\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8342 - loss: 0.7673\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8107 - loss: 0.8108\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8569 - loss: 0.6298\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8865 - loss: 0.6212\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0426 - loss: 2.9895\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1552 - loss: 2.8604\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2886 - loss: 2.7009\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3558 - loss: 2.5807\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3629 - loss: 2.4134\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4367 - loss: 2.2300\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5144 - loss: 1.9969\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5640 - loss: 1.8370\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7009 - loss: 1.6080\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6845 - loss: 1.4280\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7359 - loss: 1.2663\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7534 - loss: 1.1785\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7390 - loss: 1.0826\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7605 - loss: 1.0149\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7714 - loss: 0.9347\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8300 - loss: 0.8161\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7935 - loss: 0.8117\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8232 - loss: 0.7681\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8614 - loss: 0.6357\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8511 - loss: 0.6597\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0891 - loss: 3.0018\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1624 - loss: 2.8494\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2709 - loss: 2.7120\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2844 - loss: 2.5598\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2844 - loss: 2.4232\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3577 - loss: 2.2893\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4689 - loss: 2.1007\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5719 - loss: 1.8866\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5962 - loss: 1.7605\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6800 - loss: 1.5682\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7296 - loss: 1.3729\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7338 - loss: 1.3176\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7506 - loss: 1.1407\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8568 - loss: 1.0340\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8031 - loss: 0.9926\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8387 - loss: 0.8967\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8474 - loss: 0.8382\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8228 - loss: 0.8362\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8822 - loss: 0.6951\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8397 - loss: 0.8003\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0670 - loss: 2.9901\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0759 - loss: 2.8673\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1919 - loss: 2.7714\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2947 - loss: 2.6123\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3634 - loss: 2.4645\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4442 - loss: 2.3186\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5166 - loss: 2.1188\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5296 - loss: 1.9418\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5718 - loss: 1.7410\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6295 - loss: 1.5830\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6784 - loss: 1.3811\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7005 - loss: 1.3248\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7173 - loss: 1.2480\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8204 - loss: 1.0856\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8422 - loss: 0.9318\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8456 - loss: 0.8748\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8197 - loss: 0.8824\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8215 - loss: 0.8135\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8345 - loss: 0.8224\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8224 - loss: 0.7148\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.0558 - loss: 2.9825\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1494 - loss: 2.8347\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3415 - loss: 2.6863\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4625 - loss: 2.5398\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4158 - loss: 2.4052\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4593 - loss: 2.2003\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5289 - loss: 1.9937\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6341 - loss: 1.8005\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6511 - loss: 1.6617\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5985 - loss: 1.4823\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6510 - loss: 1.4280\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7281 - loss: 1.2234\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7628 - loss: 1.0689\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7503 - loss: 1.0133\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7936 - loss: 0.9567\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7970 - loss: 0.8464\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8383 - loss: 0.7528\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8853 - loss: 0.7183\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8286 - loss: 0.6571\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8813 - loss: 0.6283\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0551 - loss: 3.0036\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1506 - loss: 2.8633\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3215 - loss: 2.7146\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3855 - loss: 2.5433\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3577 - loss: 2.4438\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3572 - loss: 2.2906\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5275 - loss: 2.0394\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5091 - loss: 1.9089\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6425 - loss: 1.6705\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6488 - loss: 1.5606\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6564 - loss: 1.5119\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7622 - loss: 1.3175\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8366 - loss: 1.0822\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7358 - loss: 1.0328\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7822 - loss: 1.1025\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8833 - loss: 0.8054\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9081 - loss: 0.7212\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9253 - loss: 0.6557\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8374 - loss: 0.7995\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7603 - loss: 0.9574\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0755 - loss: 2.9941\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1780 - loss: 2.8583\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1533 - loss: 2.7497\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2154 - loss: 2.6300\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3483 - loss: 2.4109\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4236 - loss: 2.2925\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4462 - loss: 2.1163\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4782 - loss: 1.9409\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5214 - loss: 1.8358\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5963 - loss: 1.6119\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6485 - loss: 1.4803\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6556 - loss: 1.4205\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7143 - loss: 1.2664\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7304 - loss: 1.1146\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7519 - loss: 1.1130\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7644 - loss: 0.9580\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7654 - loss: 0.8820\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8227 - loss: 0.8485\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8587 - loss: 0.7120\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8577 - loss: 0.7200\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0847 - loss: 2.9902\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2079 - loss: 2.8457\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3236 - loss: 2.6701\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3244 - loss: 2.5350\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4345 - loss: 2.3440\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4880 - loss: 2.1760\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6017 - loss: 1.9428\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5609 - loss: 1.8093\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6306 - loss: 1.6105\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6698 - loss: 1.5202\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7343 - loss: 1.3319\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7977 - loss: 1.1332\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7884 - loss: 1.1115\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8994 - loss: 0.9099\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8446 - loss: 0.8236\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8790 - loss: 0.8149\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8276 - loss: 0.7848\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8264 - loss: 0.7576\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8328 - loss: 0.7267\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8978 - loss: 0.6053\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0930 - loss: 2.9677\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2004 - loss: 2.8212\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1987 - loss: 2.6885\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3284 - loss: 2.5618\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3240 - loss: 2.3962\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3634 - loss: 2.2279\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4265 - loss: 2.0269\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5316 - loss: 1.8474\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6177 - loss: 1.6632\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6343 - loss: 1.5280\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6990 - loss: 1.3472\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7912 - loss: 1.0877\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7829 - loss: 1.0283\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8215 - loss: 0.8978\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8885 - loss: 0.8266\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9127 - loss: 0.7194\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9055 - loss: 0.6430\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9387 - loss: 0.5512\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8409 - loss: 0.7536\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8229 - loss: 0.7896\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1133 - loss: 2.9735\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2531 - loss: 2.7952\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2413 - loss: 2.6875\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3542 - loss: 2.4971\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3198 - loss: 2.3566\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4296 - loss: 2.1734\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5277 - loss: 2.0291\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5667 - loss: 1.8025\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5924 - loss: 1.7313\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6717 - loss: 1.5244\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6344 - loss: 1.4353\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7340 - loss: 1.2487\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7515 - loss: 1.1939\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7880 - loss: 1.0437\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8016 - loss: 0.9594\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7968 - loss: 0.9204\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8008 - loss: 0.8869\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8389 - loss: 0.7877\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8212 - loss: 0.7444\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8650 - loss: 0.6532\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0599 - loss: 2.9924\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2147 - loss: 2.8557\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2442 - loss: 2.7242\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3394 - loss: 2.5732\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4561 - loss: 2.4158\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4956 - loss: 2.2243\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4972 - loss: 2.0483\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5576 - loss: 1.9321\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6705 - loss: 1.6949\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7187 - loss: 1.5215\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6811 - loss: 1.3725\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7731 - loss: 1.1800\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7162 - loss: 1.1390\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7953 - loss: 0.9790\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8408 - loss: 0.8311\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9077 - loss: 0.7234\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8805 - loss: 0.7111\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8834 - loss: 0.6299\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9086 - loss: 0.5808\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9240 - loss: 0.4903\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0964 - loss: 2.9519\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3094 - loss: 2.8062\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3351 - loss: 2.6536\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4267 - loss: 2.4697\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4734 - loss: 2.3415\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5699 - loss: 2.1508\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5850 - loss: 1.9749\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6360 - loss: 1.7929\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6217 - loss: 1.6929\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6724 - loss: 1.4469\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7035 - loss: 1.3571\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8161 - loss: 1.1697\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8046 - loss: 1.0970\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7664 - loss: 0.9950\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8234 - loss: 0.9401\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8602 - loss: 0.7712\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8810 - loss: 0.7221\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9352 - loss: 0.6214\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9095 - loss: 0.5907\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9219 - loss: 0.5468\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.0494 - loss: 2.9785\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1168 - loss: 2.8250\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1860 - loss: 2.7051\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2791 - loss: 2.5338\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3010 - loss: 2.3878\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4459 - loss: 2.2151\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4817 - loss: 2.0260\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4977 - loss: 1.8854\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5703 - loss: 1.7742\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6374 - loss: 1.5850\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7070 - loss: 1.4113\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6955 - loss: 1.3051\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7668 - loss: 1.2179\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7963 - loss: 1.0961\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7404 - loss: 1.0235\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8502 - loss: 0.8494\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8357 - loss: 0.7949\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8508 - loss: 0.7311\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8892 - loss: 0.6070\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8932 - loss: 0.5700\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0872 - loss: 2.9616\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1572 - loss: 2.8521\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2677 - loss: 2.7336\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2699 - loss: 2.6194\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3436 - loss: 2.5013\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4000 - loss: 2.3036\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5217 - loss: 2.1240\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5501 - loss: 1.9187\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6407 - loss: 1.7385\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7610 - loss: 1.5053\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8112 - loss: 1.3307\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8179 - loss: 1.2005\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8896 - loss: 0.9870\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8577 - loss: 0.9245\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8733 - loss: 0.9402\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8833 - loss: 0.8154\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9018 - loss: 0.7179\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9085 - loss: 0.6518\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9597 - loss: 0.5120\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9326 - loss: 0.4692\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.0462 - loss: 3.0295\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1347 - loss: 2.8952\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2122 - loss: 2.7878\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3000 - loss: 2.6515\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3330 - loss: 2.5608\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3777 - loss: 2.3825\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3845 - loss: 2.2257\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5193 - loss: 2.0452\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6024 - loss: 1.8524\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6786 - loss: 1.6565\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6248 - loss: 1.5662\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7581 - loss: 1.3220\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7910 - loss: 1.2484\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8347 - loss: 1.0892\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8342 - loss: 0.9547\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8369 - loss: 0.8777\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9042 - loss: 0.7820\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9095 - loss: 0.6956\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9249 - loss: 0.6291\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9225 - loss: 0.5697\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1085 - loss: 2.9627\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2243 - loss: 2.8055\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3540 - loss: 2.6508\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4170 - loss: 2.4621\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4002 - loss: 2.3453\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4942 - loss: 2.1230\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4741 - loss: 1.9850\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6379 - loss: 1.7313\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6674 - loss: 1.5862\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7538 - loss: 1.4129\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7887 - loss: 1.2209\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8144 - loss: 1.1170\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8257 - loss: 1.0782\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8189 - loss: 0.9690\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8593 - loss: 0.8394\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8933 - loss: 0.7215\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8886 - loss: 0.7114\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9170 - loss: 0.6152\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9340 - loss: 0.5604\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9442 - loss: 0.5099\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.1074 - loss: 2.9478\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2550 - loss: 2.7747\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3956 - loss: 2.5923\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2989 - loss: 2.5379\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4279 - loss: 2.3427\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5480 - loss: 2.1281\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5109 - loss: 1.9498\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6333 - loss: 1.7104\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7353 - loss: 1.4550\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7371 - loss: 1.3247\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7690 - loss: 1.1783\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7738 - loss: 1.0222\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8698 - loss: 0.9449\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8464 - loss: 0.8016\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8430 - loss: 0.7978\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8421 - loss: 0.8102\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8752 - loss: 0.6689\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8993 - loss: 0.5591\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8860 - loss: 0.5547\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8452 - loss: 0.6332\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0409 - loss: 2.9678\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1920 - loss: 2.8462\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2142 - loss: 2.7239\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2709 - loss: 2.5668\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4029 - loss: 2.3646\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4666 - loss: 2.1717\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5800 - loss: 1.9188\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6240 - loss: 1.7540\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6185 - loss: 1.6305\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6494 - loss: 1.4232\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6751 - loss: 1.3641\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8039 - loss: 1.1404\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7597 - loss: 1.1097\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8067 - loss: 0.9781\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7594 - loss: 0.9272\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8058 - loss: 0.8532\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8250 - loss: 0.7742\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8750 - loss: 0.6406\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8889 - loss: 0.6185\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8621 - loss: 0.6231\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.1038 - loss: 3.0160\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2316 - loss: 2.8683\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3085 - loss: 2.7561\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3692 - loss: 2.6040\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3540 - loss: 2.4655\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4170 - loss: 2.2431\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4420 - loss: 2.0958\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4962 - loss: 1.8936\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6544 - loss: 1.7032\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6671 - loss: 1.5253\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7576 - loss: 1.3351\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7778 - loss: 1.1719\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8422 - loss: 1.0615\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8259 - loss: 0.9872\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8865 - loss: 0.8423\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8698 - loss: 0.7844\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8446 - loss: 0.7431\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9136 - loss: 0.6225\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9260 - loss: 0.5627\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9358 - loss: 0.5852\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0909 - loss: 2.9544\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2291 - loss: 2.8339\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2678 - loss: 2.7185\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3728 - loss: 2.5559\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3909 - loss: 2.3706\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5064 - loss: 2.1592\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5872 - loss: 1.9091\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6192 - loss: 1.7684\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6876 - loss: 1.5500\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7094 - loss: 1.3620\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8253 - loss: 1.2711\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8250 - loss: 1.0788\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8286 - loss: 1.0215\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8553 - loss: 0.9489\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8604 - loss: 0.7967\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9036 - loss: 0.7454\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8921 - loss: 0.7694\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8783 - loss: 0.7601\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8246 - loss: 0.7808\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7902 - loss: 0.7638\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.0439 - loss: 2.9681\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1828 - loss: 2.8239\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2613 - loss: 2.6941\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3042 - loss: 2.5485\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3805 - loss: 2.4077\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4073 - loss: 2.1855\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5047 - loss: 2.0083\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5305 - loss: 1.8376\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5500 - loss: 1.6928\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6668 - loss: 1.5030\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6802 - loss: 1.4045\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7606 - loss: 1.1895\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7687 - loss: 1.1195\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8354 - loss: 0.9166\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8205 - loss: 0.9071\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8627 - loss: 0.7528\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8447 - loss: 0.7163\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8065 - loss: 0.6843\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8591 - loss: 0.6137\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8525 - loss: 0.5913\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0396 - loss: 2.9723\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1396 - loss: 2.8512\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3143 - loss: 2.6936\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4088 - loss: 2.5246\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4568 - loss: 2.3196\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5378 - loss: 2.1026\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6674 - loss: 1.8415\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6521 - loss: 1.7551\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6467 - loss: 1.5777\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6653 - loss: 1.4503\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7219 - loss: 1.2507\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7552 - loss: 1.1106\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8304 - loss: 0.9354\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7873 - loss: 0.8693\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7381 - loss: 0.8750\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7756 - loss: 0.8442\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7787 - loss: 0.8192\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7620 - loss: 0.8169\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8212 - loss: 0.6752\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8196 - loss: 0.6817\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.1017 - loss: 2.9694\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2106 - loss: 2.8375\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3303 - loss: 2.7340\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3333 - loss: 2.6071\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3943 - loss: 2.4622\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4928 - loss: 2.2773\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5300 - loss: 2.0999\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6248 - loss: 1.8752\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6872 - loss: 1.6494\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7346 - loss: 1.4735\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7294 - loss: 1.3843\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7652 - loss: 1.1886\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7953 - loss: 1.0744\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8665 - loss: 0.9800\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8544 - loss: 0.8960\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8652 - loss: 0.7768\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8672 - loss: 0.7739\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8980 - loss: 0.6889\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9345 - loss: 0.5800\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8986 - loss: 0.5660\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0887 - loss: 2.9764\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1760 - loss: 2.7937\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2471 - loss: 2.6288\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3544 - loss: 2.4774\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3543 - loss: 2.3090\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4403 - loss: 2.1050\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5838 - loss: 1.8645\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5390 - loss: 1.7693\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6147 - loss: 1.6130\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7069 - loss: 1.4362\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7193 - loss: 1.3234\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7997 - loss: 1.1752\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6945 - loss: 1.1756\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7618 - loss: 1.0548\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8177 - loss: 0.9509\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8140 - loss: 0.8858\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8071 - loss: 0.7866\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7690 - loss: 0.8213\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7849 - loss: 0.8152\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8627 - loss: 0.7066\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0224 - loss: 3.0521\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1417 - loss: 2.8720\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1714 - loss: 2.8107\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2491 - loss: 2.6554\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3029 - loss: 2.5347\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3117 - loss: 2.4284\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4398 - loss: 2.2537\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4373 - loss: 2.0940\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5024 - loss: 1.9218\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5484 - loss: 1.6846\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5664 - loss: 1.5795\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6539 - loss: 1.4029\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6660 - loss: 1.2743\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7277 - loss: 1.1226\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7677 - loss: 0.9959\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7673 - loss: 0.9301\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8360 - loss: 0.8414\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9014 - loss: 0.6354\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8574 - loss: 0.5767\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9064 - loss: 0.5682\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0819 - loss: 2.9779\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1819 - loss: 2.8433\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2318 - loss: 2.6832\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2339 - loss: 2.5670\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3772 - loss: 2.4228\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4536 - loss: 2.2295\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5194 - loss: 2.1084\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5703 - loss: 1.8811\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6606 - loss: 1.7458\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6405 - loss: 1.6327\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6919 - loss: 1.4704\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7620 - loss: 1.2887\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7838 - loss: 1.1300\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7671 - loss: 1.1381\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8067 - loss: 0.9248\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8620 - loss: 0.7728\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8976 - loss: 0.6906\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9274 - loss: 0.6226\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8736 - loss: 0.7065\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8971 - loss: 0.5974\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1040 - loss: 2.9378\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2080 - loss: 2.7980\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2915 - loss: 2.6641\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4142 - loss: 2.5250\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4827 - loss: 2.3263\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5126 - loss: 2.1659\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5858 - loss: 1.9890\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6286 - loss: 1.7416\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6614 - loss: 1.6304\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7461 - loss: 1.4629\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7253 - loss: 1.3379\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7743 - loss: 1.2414\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8226 - loss: 1.0719\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7561 - loss: 1.0192\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7867 - loss: 1.0469\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8594 - loss: 0.8282\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8987 - loss: 0.7617\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8870 - loss: 0.6893\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9080 - loss: 0.6112\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9194 - loss: 0.5823\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0605 - loss: 2.9893\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1436 - loss: 2.8384\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2377 - loss: 2.7217\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2920 - loss: 2.5861\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3941 - loss: 2.4146\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4448 - loss: 2.2415\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5025 - loss: 2.0374\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5629 - loss: 1.8723\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5449 - loss: 1.7547\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6392 - loss: 1.4634\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6168 - loss: 1.4005\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7040 - loss: 1.2433\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7571 - loss: 1.0751\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7396 - loss: 1.0135\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7685 - loss: 0.9102\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7086 - loss: 0.9483\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7306 - loss: 0.9818\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7681 - loss: 0.8544\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8373 - loss: 0.7410\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8255 - loss: 0.7105\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0609 - loss: 2.9768\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1517 - loss: 2.8469\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2360 - loss: 2.6999\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2899 - loss: 2.5447\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4177 - loss: 2.3681\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3981 - loss: 2.1754\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5148 - loss: 1.9304\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5556 - loss: 1.7341\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5664 - loss: 1.5885\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6947 - loss: 1.3820\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6907 - loss: 1.2994\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6781 - loss: 1.3256\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7172 - loss: 1.1700\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7062 - loss: 1.1377\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7963 - loss: 0.9526\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8307 - loss: 0.8990\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7618 - loss: 0.8344\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8723 - loss: 0.7438\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8656 - loss: 0.6351\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9159 - loss: 0.6133\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0405 - loss: 3.0017\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2057 - loss: 2.8696\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3141 - loss: 2.7396\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3288 - loss: 2.6295\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3654 - loss: 2.4436\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4402 - loss: 2.1926\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3927 - loss: 2.1077\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4916 - loss: 1.8684\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5726 - loss: 1.7235\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5620 - loss: 1.5282\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6278 - loss: 1.4421\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6656 - loss: 1.2939\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6409 - loss: 1.2298\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6873 - loss: 1.1730\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7447 - loss: 1.0713\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7007 - loss: 1.0927\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7541 - loss: 0.9831\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7822 - loss: 0.8877\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7824 - loss: 0.8301\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8262 - loss: 0.7377\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0510 - loss: 2.9649\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1705 - loss: 2.8061\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2254 - loss: 2.6889\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3832 - loss: 2.5249\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3982 - loss: 2.3189\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4815 - loss: 2.1135\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5646 - loss: 1.9256\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5813 - loss: 1.7158\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6504 - loss: 1.5671\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6330 - loss: 1.4802\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7513 - loss: 1.2202\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7763 - loss: 1.1495\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7969 - loss: 1.1247\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8426 - loss: 0.9478\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8426 - loss: 0.8726\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7983 - loss: 0.9160\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8205 - loss: 0.8537\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8630 - loss: 0.7578\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8881 - loss: 0.6379\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8229 - loss: 0.6511\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1305 - loss: 2.9695\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1815 - loss: 2.8282\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1731 - loss: 2.7136\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2703 - loss: 2.5810\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3507 - loss: 2.4245\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3964 - loss: 2.2850\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4915 - loss: 2.1371\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5282 - loss: 1.9021\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6231 - loss: 1.7092\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5884 - loss: 1.5918\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6574 - loss: 1.4360\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7590 - loss: 1.3031\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7678 - loss: 1.1591\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8044 - loss: 1.0373\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8065 - loss: 0.9773\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8421 - loss: 0.8895\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8919 - loss: 0.7516\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8416 - loss: 0.7425\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9210 - loss: 0.6632\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9679 - loss: 0.5377\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0730 - loss: 2.9948\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1668 - loss: 2.8350\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3097 - loss: 2.7035\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3665 - loss: 2.5635\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4036 - loss: 2.4212\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5008 - loss: 2.2391\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5589 - loss: 2.0772\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6459 - loss: 1.8543\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6898 - loss: 1.6997\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7653 - loss: 1.4872\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7879 - loss: 1.3083\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8041 - loss: 1.2026\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8072 - loss: 1.1233\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7876 - loss: 1.0706\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8209 - loss: 1.0144\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9120 - loss: 0.8157\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8959 - loss: 0.7037\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8709 - loss: 0.7326\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8316 - loss: 0.7115\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8354 - loss: 0.6449\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.0370 - loss: 3.0045\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1512 - loss: 2.8898\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2642 - loss: 2.7909\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3346 - loss: 2.6644\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3880 - loss: 2.4935\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4686 - loss: 2.3513\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5272 - loss: 2.1431\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5697 - loss: 1.9121\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6517 - loss: 1.7117\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6524 - loss: 1.5628\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7200 - loss: 1.3309\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7562 - loss: 1.1640\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7601 - loss: 1.1105\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7695 - loss: 0.9883\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7662 - loss: 0.9174\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7589 - loss: 0.9207\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8481 - loss: 0.7530\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8647 - loss: 0.7026\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8572 - loss: 0.6404\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8777 - loss: 0.6175\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0821 - loss: 2.9897\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1969 - loss: 2.8497\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2384 - loss: 2.7118\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2743 - loss: 2.5709\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2735 - loss: 2.4464\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4079 - loss: 2.2304\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5087 - loss: 2.0226\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5584 - loss: 1.8486\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5414 - loss: 1.6356\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6219 - loss: 1.4675\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7318 - loss: 1.2555\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7656 - loss: 1.1763\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8109 - loss: 1.0350\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7551 - loss: 0.9629\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7891 - loss: 0.9110\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7915 - loss: 0.8160\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8375 - loss: 0.7493\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8999 - loss: 0.6683\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8844 - loss: 0.5860\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9059 - loss: 0.5468\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.0779 - loss: 2.9832\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1671 - loss: 2.8906\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1715 - loss: 2.7936\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2581 - loss: 2.6331\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3179 - loss: 2.4784\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3937 - loss: 2.3457\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5028 - loss: 2.0902\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5451 - loss: 1.9329\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6020 - loss: 1.7346\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6941 - loss: 1.6067\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7255 - loss: 1.4293\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7233 - loss: 1.3660\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6901 - loss: 1.3592\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7877 - loss: 1.1061\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7908 - loss: 0.9969\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7980 - loss: 0.8924\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8458 - loss: 0.8256\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8472 - loss: 0.7677\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9044 - loss: 0.6499\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9184 - loss: 0.6121\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0514 - loss: 2.9607\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1377 - loss: 2.7590\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1672 - loss: 2.5807\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2680 - loss: 2.4206\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3319 - loss: 2.2870\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4400 - loss: 2.0904\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4452 - loss: 1.9594\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5435 - loss: 1.7377\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5262 - loss: 1.6103\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6920 - loss: 1.4575\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7392 - loss: 1.3042\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7247 - loss: 1.1520\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7454 - loss: 1.1460\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7573 - loss: 1.0550\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7430 - loss: 0.9990\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7891 - loss: 0.8525\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8763 - loss: 0.7517\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8473 - loss: 0.6941\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9152 - loss: 0.5925\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9221 - loss: 0.5424\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.0961 - loss: 2.9603\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1887 - loss: 2.8004\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2174 - loss: 2.6730\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2702 - loss: 2.5672\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2693 - loss: 2.4012\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4803 - loss: 2.2081\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5277 - loss: 2.0358\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5019 - loss: 1.9039\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6622 - loss: 1.6969\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6006 - loss: 1.5746\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7314 - loss: 1.4326\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6997 - loss: 1.3392\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7706 - loss: 1.1915\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8367 - loss: 1.1217\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8051 - loss: 1.0009\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8178 - loss: 1.0102\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8082 - loss: 0.9435\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8654 - loss: 0.8457\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8355 - loss: 0.8775\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8664 - loss: 0.7602\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0487 - loss: 2.9747\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1772 - loss: 2.8518\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2181 - loss: 2.7418\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3104 - loss: 2.6077\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3205 - loss: 2.4375\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3619 - loss: 2.2744\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3827 - loss: 2.1023\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4912 - loss: 1.9070\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5353 - loss: 1.7683\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5907 - loss: 1.5539\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6445 - loss: 1.4191\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6620 - loss: 1.3125\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6136 - loss: 1.2141\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7402 - loss: 1.0566\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8185 - loss: 0.8819\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8060 - loss: 0.8583\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8579 - loss: 0.7624\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8388 - loss: 0.6964\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8207 - loss: 0.6909\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8923 - loss: 0.5731\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.0553 - loss: 2.9794\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1195 - loss: 2.8562\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2203 - loss: 2.7248\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2543 - loss: 2.6008\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3701 - loss: 2.4234\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4245 - loss: 2.2330\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4156 - loss: 2.0834\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4559 - loss: 1.9070\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5683 - loss: 1.7241\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6627 - loss: 1.5465\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7020 - loss: 1.3904\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7337 - loss: 1.2700\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7919 - loss: 1.0527\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8472 - loss: 0.9260\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8056 - loss: 0.8859\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8557 - loss: 0.7837\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8399 - loss: 0.7074\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8675 - loss: 0.5968\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8836 - loss: 0.5878\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8628 - loss: 0.6110\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0684 - loss: 2.9734\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2081 - loss: 2.8158\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2184 - loss: 2.6774\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2972 - loss: 2.5396\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3484 - loss: 2.3635\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3993 - loss: 2.2374\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4799 - loss: 2.0627\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4973 - loss: 1.8734\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5931 - loss: 1.6765\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6161 - loss: 1.5980\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6364 - loss: 1.4568\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6607 - loss: 1.3700\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7089 - loss: 1.2280\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7894 - loss: 1.0446\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7778 - loss: 1.0048\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8663 - loss: 0.8076\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8732 - loss: 0.7442\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8206 - loss: 0.7219\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8625 - loss: 0.6577\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8815 - loss: 0.5692\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.0705 - loss: 2.9871\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1781 - loss: 2.8370\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3069 - loss: 2.6932\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3677 - loss: 2.5248\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3854 - loss: 2.3109\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4663 - loss: 2.1553\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4908 - loss: 1.9562\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5689 - loss: 1.7429\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7024 - loss: 1.5813\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7671 - loss: 1.3952\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7454 - loss: 1.2418\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8853 - loss: 1.0492\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8707 - loss: 0.9411\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8967 - loss: 0.8391\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8435 - loss: 0.8097\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9140 - loss: 0.6854\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9296 - loss: 0.6478\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9521 - loss: 0.5901\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9399 - loss: 0.5153\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9597 - loss: 0.4412\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0520 - loss: 2.9852\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1232 - loss: 2.8319\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2816 - loss: 2.6702\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3512 - loss: 2.5245\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3971 - loss: 2.3327\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5329 - loss: 2.1063\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5924 - loss: 1.9251\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6843 - loss: 1.7541\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7168 - loss: 1.5339\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7801 - loss: 1.3819\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8418 - loss: 1.1739\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8465 - loss: 1.1030\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8054 - loss: 1.0020\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8159 - loss: 0.9509\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8217 - loss: 0.8380\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8762 - loss: 0.7018\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8887 - loss: 0.6834\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8820 - loss: 0.5999\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9180 - loss: 0.5309\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9067 - loss: 0.4958\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.0416 - loss: 2.9823\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1621 - loss: 2.8566\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1730 - loss: 2.7344\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2608 - loss: 2.6072\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2757 - loss: 2.4682\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3772 - loss: 2.2973\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4336 - loss: 2.0896\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5029 - loss: 1.9507\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4394 - loss: 1.8784\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5854 - loss: 1.6167\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6565 - loss: 1.5348\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6100 - loss: 1.4304\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7187 - loss: 1.2205\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7536 - loss: 1.0932\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8028 - loss: 0.9606\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8931 - loss: 0.7850\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8629 - loss: 0.7502\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8524 - loss: 0.7990\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7906 - loss: 0.8350\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8030 - loss: 0.7578\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0533 - loss: 2.9580\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1720 - loss: 2.8385\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2293 - loss: 2.6882\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2718 - loss: 2.5531\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3375 - loss: 2.4278\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4339 - loss: 2.2707\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4341 - loss: 2.0793\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5788 - loss: 1.8526\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6192 - loss: 1.7358\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7557 - loss: 1.4541\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8036 - loss: 1.2949\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7055 - loss: 1.2158\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8233 - loss: 1.1194\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8362 - loss: 0.9584\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8164 - loss: 0.8938\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8674 - loss: 0.7671\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8697 - loss: 0.6796\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8893 - loss: 0.5954\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9354 - loss: 0.5126\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9078 - loss: 0.4831\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0425 - loss: 2.9827\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1436 - loss: 2.8532\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2779 - loss: 2.7028\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2794 - loss: 2.5863\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3355 - loss: 2.4204\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4824 - loss: 2.2138\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5077 - loss: 2.0380\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4986 - loss: 1.8530\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6039 - loss: 1.6978\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6471 - loss: 1.5485\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7358 - loss: 1.3436\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7174 - loss: 1.2717\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8298 - loss: 1.0896\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8386 - loss: 0.9671\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8733 - loss: 0.8346\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8647 - loss: 0.7682\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8469 - loss: 0.8072\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9161 - loss: 0.6772\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8746 - loss: 0.6917\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8511 - loss: 0.5951\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0826 - loss: 2.9825\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1770 - loss: 2.8227\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2910 - loss: 2.7057\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3690 - loss: 2.5100\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4199 - loss: 2.3430\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4801 - loss: 2.1626\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5943 - loss: 1.9619\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6308 - loss: 1.7202\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6521 - loss: 1.5863\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6626 - loss: 1.3726\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6999 - loss: 1.1972\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7439 - loss: 1.0783\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7415 - loss: 0.9682\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7487 - loss: 0.9134\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8814 - loss: 0.7330\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8222 - loss: 0.7390\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8787 - loss: 0.6203\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8648 - loss: 0.6063\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9133 - loss: 0.5152\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8845 - loss: 0.4984\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0339 - loss: 2.9946\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1361 - loss: 2.8446\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1909 - loss: 2.7214\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2780 - loss: 2.5732\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2824 - loss: 2.4104\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3766 - loss: 2.2874\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4729 - loss: 2.1380\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4821 - loss: 1.9758\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5767 - loss: 1.8105\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6519 - loss: 1.6136\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6948 - loss: 1.4476\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7659 - loss: 1.3102\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8316 - loss: 1.1753\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8224 - loss: 1.0168\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8480 - loss: 0.9746\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8977 - loss: 0.8424\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9108 - loss: 0.7395\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8636 - loss: 0.7982\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9095 - loss: 0.6651\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8910 - loss: 0.6133\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0408 - loss: 2.9975\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1214 - loss: 2.8838\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2706 - loss: 2.7192\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3276 - loss: 2.5688\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3190 - loss: 2.4472\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4435 - loss: 2.2623\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4111 - loss: 2.1199\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5213 - loss: 1.8780\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5940 - loss: 1.7314\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6585 - loss: 1.5962\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6534 - loss: 1.4408\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6736 - loss: 1.3827\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7472 - loss: 1.1722\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7066 - loss: 1.1407\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6993 - loss: 1.0805\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8006 - loss: 0.9190\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7418 - loss: 0.9012\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8453 - loss: 0.7627\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8900 - loss: 0.6524\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9001 - loss: 0.6762\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.0672 - loss: 2.9799\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2234 - loss: 2.8465\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2777 - loss: 2.7196\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3747 - loss: 2.5217\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4598 - loss: 2.3709\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4431 - loss: 2.1646\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5752 - loss: 1.9449\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6121 - loss: 1.6904\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6493 - loss: 1.4898\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6665 - loss: 1.3869\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8020 - loss: 1.1506\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8323 - loss: 1.0136\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8590 - loss: 0.8859\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8728 - loss: 0.7946\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9275 - loss: 0.7036\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9059 - loss: 0.6870\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8642 - loss: 0.6486\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8970 - loss: 0.5993\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9573 - loss: 0.4918\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9526 - loss: 0.4772\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1648 - loss: 2.9481\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2484 - loss: 2.7816\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2887 - loss: 2.6352\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3367 - loss: 2.4734\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3647 - loss: 2.3831\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4103 - loss: 2.1727\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3947 - loss: 2.0874\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5568 - loss: 1.8264\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5944 - loss: 1.7496\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6213 - loss: 1.6128\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6074 - loss: 1.5200\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6044 - loss: 1.4485\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6859 - loss: 1.3317\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7120 - loss: 1.2094\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7822 - loss: 1.0748\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8243 - loss: 0.9695\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8430 - loss: 0.9580\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8317 - loss: 0.8881\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8963 - loss: 0.7098\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8724 - loss: 0.6953\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.0766 - loss: 2.9873\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1327 - loss: 2.8580\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2211 - loss: 2.7303\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2710 - loss: 2.5739\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3360 - loss: 2.4789\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4032 - loss: 2.2609\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4743 - loss: 2.0846\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5934 - loss: 1.9186\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6346 - loss: 1.7770\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6054 - loss: 1.6801\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6345 - loss: 1.4888\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6123 - loss: 1.4737\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6651 - loss: 1.2821\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7395 - loss: 1.1208\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7286 - loss: 1.0348\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8048 - loss: 0.8857\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8271 - loss: 0.8628\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8030 - loss: 0.8650\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7188 - loss: 0.8713\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7757 - loss: 0.8192\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0519 - loss: 2.9848\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2530 - loss: 2.8226\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2729 - loss: 2.7025\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2816 - loss: 2.5544\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4116 - loss: 2.3902\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4655 - loss: 2.2381\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5321 - loss: 2.0375\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5680 - loss: 1.8784\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6474 - loss: 1.6229\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7216 - loss: 1.4678\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7316 - loss: 1.2621\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7254 - loss: 1.1677\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7708 - loss: 1.0211\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7170 - loss: 1.0128\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8559 - loss: 0.7971\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8520 - loss: 0.7413\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9113 - loss: 0.6548\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9135 - loss: 0.5757\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9163 - loss: 0.5482\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9290 - loss: 0.5419\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.0319 - loss: 2.9774\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1328 - loss: 2.8538\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0958 - loss: 2.7745\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2387 - loss: 2.6177\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2986 - loss: 2.4841\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4061 - loss: 2.3365\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4602 - loss: 2.0906\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5809 - loss: 1.9032\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6205 - loss: 1.7095\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7119 - loss: 1.5010\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7407 - loss: 1.3013\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8351 - loss: 1.2040\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8712 - loss: 1.0954\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8491 - loss: 1.0093\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9118 - loss: 0.7820\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9201 - loss: 0.7670\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9071 - loss: 0.7264\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9254 - loss: 0.6042\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8441 - loss: 0.7447\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8868 - loss: 0.5822\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.0608 - loss: 3.0094\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1147 - loss: 2.8616\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2088 - loss: 2.6936\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2766 - loss: 2.5707\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3197 - loss: 2.4161\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3762 - loss: 2.2662\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4284 - loss: 2.1305\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5085 - loss: 1.9265\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5625 - loss: 1.7601\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6171 - loss: 1.6361\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6496 - loss: 1.4393\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6866 - loss: 1.3236\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7221 - loss: 1.2406\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7386 - loss: 1.0536\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8045 - loss: 1.0511\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7917 - loss: 0.8924\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8609 - loss: 0.8196\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8021 - loss: 0.8694\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8688 - loss: 0.7109\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8642 - loss: 0.6601\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.0293 - loss: 2.9878\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0968 - loss: 2.8835\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1858 - loss: 2.7503\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2625 - loss: 2.6329\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4144 - loss: 2.4672\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3464 - loss: 2.3360\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4722 - loss: 2.1246\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5510 - loss: 1.9696\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6363 - loss: 1.7256\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6238 - loss: 1.6529\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7665 - loss: 1.4769\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7840 - loss: 1.2613\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7805 - loss: 1.1234\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8327 - loss: 1.0065\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8068 - loss: 0.9708\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8214 - loss: 0.8157\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8497 - loss: 0.7929\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7853 - loss: 0.8476\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8519 - loss: 0.7581\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8361 - loss: 0.6778\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0155 - loss: 2.9669\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1174 - loss: 2.8339\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2053 - loss: 2.6963\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2548 - loss: 2.5837\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3077 - loss: 2.4603\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4216 - loss: 2.2775\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5368 - loss: 2.0936\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6148 - loss: 1.9529\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6685 - loss: 1.8098\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7146 - loss: 1.5647\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7445 - loss: 1.4899\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7553 - loss: 1.3454\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8070 - loss: 1.1937\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8487 - loss: 1.0626\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8951 - loss: 0.9916\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8818 - loss: 0.8803\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9325 - loss: 0.7380\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9331 - loss: 0.6970\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8432 - loss: 0.8416\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8895 - loss: 0.6500\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.0407 - loss: 2.9854\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1681 - loss: 2.8540\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2028 - loss: 2.7279\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2221 - loss: 2.5978\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3434 - loss: 2.3984\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4104 - loss: 2.2676\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4499 - loss: 2.0798\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5347 - loss: 1.9234\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6223 - loss: 1.7295\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6366 - loss: 1.6008\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6523 - loss: 1.4934\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7490 - loss: 1.3805\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7218 - loss: 1.3742\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8020 - loss: 1.1124\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8258 - loss: 1.0913\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7869 - loss: 0.9880\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8537 - loss: 0.9152\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8558 - loss: 0.8424\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8539 - loss: 0.7924\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9163 - loss: 0.6044\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0998 - loss: 2.9508\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2142 - loss: 2.7782\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2774 - loss: 2.6286\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2832 - loss: 2.4701\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3813 - loss: 2.3676\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4391 - loss: 2.1312\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5277 - loss: 2.0015\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5550 - loss: 1.8145\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6648 - loss: 1.6764\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6659 - loss: 1.5015\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7392 - loss: 1.3443\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7789 - loss: 1.2297\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8012 - loss: 1.0708\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8243 - loss: 0.9641\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8286 - loss: 0.8704\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8526 - loss: 0.8133\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8289 - loss: 0.7950\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8758 - loss: 0.6669\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8905 - loss: 0.6051\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9465 - loss: 0.5051\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.0693 - loss: 2.9942\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1584 - loss: 2.8279\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2331 - loss: 2.7026\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2826 - loss: 2.5218\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4088 - loss: 2.3529\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5145 - loss: 2.1445\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5945 - loss: 1.9684\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6451 - loss: 1.7842\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6418 - loss: 1.6656\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6930 - loss: 1.4614\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6640 - loss: 1.3754\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7287 - loss: 1.2752\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7274 - loss: 1.1656\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7515 - loss: 1.1299\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8008 - loss: 0.9455\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8165 - loss: 0.9185\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8018 - loss: 0.8269\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8398 - loss: 0.7839\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8676 - loss: 0.6629\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8557 - loss: 0.6502\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0686 - loss: 2.9641\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1218 - loss: 2.8551\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2041 - loss: 2.7299\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2365 - loss: 2.6013\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3319 - loss: 2.4645\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4423 - loss: 2.3211\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4246 - loss: 2.1688\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4820 - loss: 1.9549\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5734 - loss: 1.7220\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5917 - loss: 1.6779\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6081 - loss: 1.4687\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7473 - loss: 1.3123\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7768 - loss: 1.1911\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7684 - loss: 1.1013\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8027 - loss: 0.9671\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7913 - loss: 0.8479\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8093 - loss: 0.8801\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8464 - loss: 0.7088\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8636 - loss: 0.6368\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7820 - loss: 0.6761\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.0573 - loss: 2.9996\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1492 - loss: 2.8922\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2913 - loss: 2.7475\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3552 - loss: 2.5756\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3549 - loss: 2.4885\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5225 - loss: 2.2451\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5653 - loss: 2.0513\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6324 - loss: 1.8591\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6747 - loss: 1.7052\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7505 - loss: 1.5024\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7124 - loss: 1.3854\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8119 - loss: 1.2029\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8093 - loss: 1.0730\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8281 - loss: 0.9784\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8500 - loss: 0.8551\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8426 - loss: 0.8240\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8345 - loss: 0.8647\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8420 - loss: 0.7574\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8797 - loss: 0.6728\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8804 - loss: 0.6881\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0663 - loss: 2.9708\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1971 - loss: 2.8371\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2661 - loss: 2.6870\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3629 - loss: 2.6000\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5105 - loss: 2.3768\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5185 - loss: 2.1796\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5335 - loss: 2.0167\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6200 - loss: 1.7465\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6378 - loss: 1.5748\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7179 - loss: 1.3995\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7309 - loss: 1.2956\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7301 - loss: 1.1506\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8137 - loss: 1.0134\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7543 - loss: 0.9743\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8294 - loss: 0.9097\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8177 - loss: 0.8863\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7896 - loss: 0.8469\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8111 - loss: 0.8308\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7687 - loss: 0.7480\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8759 - loss: 0.6277\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.1138 - loss: 2.9558\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1890 - loss: 2.8445\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2252 - loss: 2.7059\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2731 - loss: 2.5356\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3514 - loss: 2.3826\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5202 - loss: 2.1532\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5673 - loss: 2.0498\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5733 - loss: 1.8403\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7032 - loss: 1.6520\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7145 - loss: 1.5441\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7858 - loss: 1.3523\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8044 - loss: 1.2826\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8620 - loss: 1.1286\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8579 - loss: 0.9411\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7824 - loss: 1.0349\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8606 - loss: 0.8565\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8340 - loss: 0.7922\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8719 - loss: 0.7316\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8883 - loss: 0.6314\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9073 - loss: 0.5380\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.1414 - loss: 2.9448\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2376 - loss: 2.8085\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3176 - loss: 2.6413\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3186 - loss: 2.4915\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3905 - loss: 2.2965\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4730 - loss: 2.1517\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5219 - loss: 1.9670\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6251 - loss: 1.7627\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5927 - loss: 1.6943\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7053 - loss: 1.4907\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7542 - loss: 1.3120\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7087 - loss: 1.1951\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7782 - loss: 1.0863\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8066 - loss: 0.9606\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8078 - loss: 0.8632\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8754 - loss: 0.7468\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8324 - loss: 0.7544\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8839 - loss: 0.6159\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8847 - loss: 0.6411\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9442 - loss: 0.5200\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0679 - loss: 2.9686\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1706 - loss: 2.8261\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2176 - loss: 2.6804\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2692 - loss: 2.5320\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3817 - loss: 2.3683\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4089 - loss: 2.2029\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4904 - loss: 2.0050\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5092 - loss: 1.8402\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5667 - loss: 1.6742\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6495 - loss: 1.5019\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6367 - loss: 1.3299\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6884 - loss: 1.2506\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7393 - loss: 1.1210\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7766 - loss: 0.9876\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8353 - loss: 0.9241\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7461 - loss: 0.9149\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7337 - loss: 1.0079\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7285 - loss: 0.9132\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7995 - loss: 0.7796\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7965 - loss: 0.7258\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0427 - loss: 3.0002\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1261 - loss: 2.8509\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2012 - loss: 2.6603\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2993 - loss: 2.5351\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3902 - loss: 2.3478\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3610 - loss: 2.2269\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4618 - loss: 2.0842\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5304 - loss: 1.8801\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5730 - loss: 1.7004\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6817 - loss: 1.5068\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6210 - loss: 1.4903\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6592 - loss: 1.3176\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7310 - loss: 1.1564\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8527 - loss: 0.9933\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8152 - loss: 0.9573\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8594 - loss: 0.8328\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8511 - loss: 0.8261\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8544 - loss: 0.7704\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9018 - loss: 0.6857\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8964 - loss: 0.6505\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.1618 - loss: 2.9495\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2027 - loss: 2.8154\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2785 - loss: 2.6574\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3973 - loss: 2.4676\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3627 - loss: 2.3454\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4642 - loss: 2.1343\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5004 - loss: 1.9572\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5209 - loss: 1.7892\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5875 - loss: 1.5661\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6436 - loss: 1.4468\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7283 - loss: 1.2266\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7546 - loss: 1.1843\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8396 - loss: 0.9686\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8380 - loss: 0.9097\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8503 - loss: 0.7403\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8372 - loss: 0.7784\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8118 - loss: 0.7434\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7821 - loss: 0.7733\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8192 - loss: 0.7921\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8182 - loss: 0.6736\n",
            "Mean Accuracy (LOOCV): 0.8250\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "# Define your LSTM model\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(25, 84)),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# LOOCV setup\n",
        "loo = LeaveOneOut()\n",
        "accuracy_scores = []\n",
        "\n",
        "for train_index, test_index in loo.split(X_seq):\n",
        "    # Splitting the data\n",
        "    X_train, X_test = X_seq[train_index], X_seq[test_index]\n",
        "    y_train, y_test = Y_seq[train_index], Y_seq[test_index]\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    # Create and train a new model for each iteration\n",
        "    model = create_model()\n",
        "    model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)  # Set verbose=1 to see progress\n",
        "\n",
        "    # Evaluate on the single test sample\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "# Compute mean accuracy across all LOOCV iterations\n",
        "print(f\"Mean Accuracy (LOOCV): {np.mean(accuracy_scores):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9rEqiov2Vkp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from tensorflow.keras.models import load_model\n",
        "from collections import deque\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load trained LSTM model\n",
        "\n",
        "\n",
        "# Initialize MediaPipe Hands\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)\n",
        "\n",
        "# Video path\n",
        "VIDEO_PATH = \"/content/sample_data/test/J_2.mp4\"\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "# Parameters\n",
        "SEQUENCE_LENGTH = 25  # Same as during training\n",
        "NUM_LANDMARKS = 42 * 3  # 42 keypoints (21 per hand) * 3 (x, y, z)\n",
        "\n",
        "# Class labels (update according to your dataset)\n",
        "gesture_labels = {0: \"Y\", 1: \"H\", 2: \"J\"}  # Update with actual labels\n",
        "\n",
        "# Define frame indices for the three sequences\n",
        "sequence_indices = [\n",
        "    0,                          # First sequence (frames 0-24)\n",
        "    (total_frames // 2) - 12,   # Middle sequence (centered around the middle)\n",
        "    total_frames - SEQUENCE_LENGTH  # Last sequence (frames at the end)\n",
        "]\n",
        "sequence_indices = [max(0, min(idx, total_frames - SEQUENCE_LENGTH)) for idx in sequence_indices]  # Ensure valid indices\n",
        "\n",
        "\n",
        "# Get total frame count\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Function to extract landmarks\n",
        "def extract_landmarks(frame):\n",
        "    \"\"\"Extracts hand landmarks relative to the wrist midpoint.\"\"\"\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(frame_rgb)\n",
        "\n",
        "    left_hand, right_hand = None, None\n",
        "    all_landmarks = []\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        detected_hands = []\n",
        "\n",
        "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
        "            landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark])\n",
        "            detected_hands.append((landmarks, handedness.classification[0].label))  # 'Left' or 'Right'\n",
        "\n",
        "        # Assign left and right hands correctly\n",
        "        left_hand = next((l for l, h in detected_hands if h == \"Left\"), None)\n",
        "        right_hand = next((l for l, h in detected_hands if h == \"Right\"), None)\n",
        "\n",
        "    # Find wrist midpoint\n",
        "    if left_hand is not None and right_hand is not None:\n",
        "        wrist_midpoint = (left_hand[0] + right_hand[0]) / 2  # Average of both wrists\n",
        "    elif left_hand is not None:\n",
        "        wrist_midpoint = left_hand[0]  # Use left wrist if only one hand\n",
        "    elif right_hand is not None:\n",
        "        wrist_midpoint = right_hand[0]  # Use right wrist if only one hand\n",
        "    else:\n",
        "        wrist_midpoint = np.zeros(3)  # No hand detected, use (0,0,0)\n",
        "\n",
        "    # Normalize landmarks relative to wrist midpoint\n",
        "    if left_hand is not None:\n",
        "        left_hand -= wrist_midpoint\n",
        "        all_landmarks.extend(left_hand.flatten())\n",
        "    if right_hand is not None:\n",
        "        right_hand -= wrist_midpoint\n",
        "        all_landmarks.extend(right_hand.flatten())\n",
        "\n",
        "    # Pad missing hand landmarks with zeros\n",
        "    while len(all_landmarks) < NUM_LANDMARKS:\n",
        "        all_landmarks.extend([0] * 3 * 21)\n",
        "\n",
        "    return np.array(all_landmarks)\n",
        "\n",
        "# Store predictions\n",
        "predictions = []\n",
        "# Process video\n",
        "# Process video for the three sequences\n",
        "for seq_start in sequence_indices:\n",
        "    sequence_buffer = []\n",
        "\n",
        "    # Seek to the sequence start frame\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, seq_start)\n",
        "\n",
        "    # Read 25 frames\n",
        "    for _ in range(SEQUENCE_LENGTH):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        landmarks = extract_landmarks(frame)\n",
        "        sequence_buffer.append(landmarks)\n",
        "\n",
        "    # Convert to NumPy and predict\n",
        "    if len(sequence_buffer) == SEQUENCE_LENGTH:\n",
        "        input_sequence = np.expand_dims(np.array(sequence_buffer), axis=0)  # Shape: (1, 25, 126)\n",
        "        input_sequence = (input_sequence - np.min(input_sequence)) / (np.max(input_sequence) - np.min(input_sequence))\n",
        "        prediction = model.predict(input_sequence)\n",
        "        predicted_class = np.argmax(prediction)\n",
        "        predictions.append(gesture_labels.get(predicted_class, \"Unknown\"))\n",
        "\n",
        "# Release video\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Display final predictions\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(f\"Prediction {i+1}: {pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2qXZenGvs00"
      },
      "source": [
        "# KFolds on Updated data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xEgm2M9v0CE",
        "outputId": "a69cfad4-04a3-4992-a30f-050525c5e182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (879, 25, 84)\n",
            "Y shape: (879,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[ 0.73493975, -0.03614458,  0.48364887, ..., -0.28055078,\n",
              "         -0.72805506, -0.28743544],\n",
              "        [ 0.73402417, -0.04490501,  0.48531953, ..., -0.28324696,\n",
              "         -0.7202073 , -0.29360968],\n",
              "        [ 0.7241379 , -0.04827586,  0.4827586 , ..., -0.2724138 ,\n",
              "         -0.7137931 , -0.28275862],\n",
              "        ...,\n",
              "        [ 0.694859  , -0.03482587,  0.45605308, ..., -0.26699835,\n",
              "         -0.73134327, -0.28026533],\n",
              "        [ 0.70715475, -0.03494176,  0.4608985 , ..., -0.27454242,\n",
              "         -0.7237937 , -0.28785357],\n",
              "        [ 0.6981758 , -0.03980099,  0.45273632, ..., -0.2620232 ,\n",
              "         -0.7280265 , -0.27860695]],\n",
              "\n",
              "       [[ 0.69175625, -0.0609319 ,  0.41218638, ..., -0.28315413,\n",
              "         -0.60573477, -0.25448027],\n",
              "        [ 0.6802842 , -0.05861456,  0.39964476, ..., -0.28596804,\n",
              "         -0.61634105, -0.26110125],\n",
              "        [ 0.68817204, -0.05734767,  0.41218638, ..., -0.28673837,\n",
              "         -0.6236559 , -0.26523298],\n",
              "        ...,\n",
              "        [ 0.69174314, -0.07339449,  0.42018348, ..., -0.2825688 ,\n",
              "         -0.5963303 , -0.25321102],\n",
              "        [ 0.6886447 , -0.06959707,  0.41758242, ..., -0.2820513 ,\n",
              "         -0.6007326 , -0.25274727],\n",
              "        [ 0.6886447 , -0.06410256,  0.41391942, ..., -0.2838828 ,\n",
              "         -0.60805863, -0.25091577]],\n",
              "\n",
              "       [[ 0.7653061 , -0.04081633,  0.5136054 , ..., -0.26530612,\n",
              "         -0.6904762 , -0.24489796],\n",
              "        [ 0.74453783, -0.04201681,  0.49579832, ..., -0.26386556,\n",
              "         -0.687395  , -0.24369748],\n",
              "        [ 0.7483221 , -0.0352349 ,  0.4966443 , ..., -0.26677853,\n",
              "         -0.7013423 , -0.23993288],\n",
              "        ...,\n",
              "        [ 0.75972927, -0.04060914,  0.5025381 , ..., -0.26395938,\n",
              "         -0.69204736, -0.23688664],\n",
              "        [ 0.7631134 , -0.04060914,  0.5025381 , ..., -0.26395938,\n",
              "         -0.69204736, -0.23688664],\n",
              "        [ 0.75634515, -0.04060914,  0.49915397, ..., -0.2605753 ,\n",
              "         -0.6988156 , -0.23011844]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.32814372, -0.05868264,  0.1988024 , ..., -0.26946107,\n",
              "          0.23473054, -0.24311377],\n",
              "        [ 0.32806805, -0.05710814,  0.19684082, ..., -0.2636695 ,\n",
              "          0.2381531 , -0.23936817],\n",
              "        [ 0.32971016, -0.04830918,  0.19202898, ..., -0.2753623 ,\n",
              "          0.23309179, -0.25603864],\n",
              "        ...,\n",
              "        [ 0.3271028 , -0.03504673,  0.17523365, ..., -0.28738317,\n",
              "          0.20560747, -0.29205608],\n",
              "        [ 0.3278302 , -0.04245283,  0.18160377, ..., -0.28537735,\n",
              "          0.19339623, -0.29245284],\n",
              "        [ 0.33450294, -0.03391813,  0.18245614, ..., -0.29122806,\n",
              "          0.21052632, -0.29356724]],\n",
              "\n",
              "       [[ 0.33411214, -0.03037383,  0.17523365, ..., -0.29672897,\n",
              "          0.21962617, -0.30140188],\n",
              "        [ 0.34      , -0.03058824,  0.18      , ..., -0.29647058,\n",
              "          0.21529412, -0.29882354],\n",
              "        [ 0.32827103, -0.02570093,  0.18341121, ..., -0.29439253,\n",
              "          0.20443925, -0.29439253],\n",
              "        ...,\n",
              "        [ 0.40880504,  0.01383648,  0.27044025, ..., -0.22012578,\n",
              "          0.27295598, -0.23018868],\n",
              "        [ 0.4118388 ,  0.01259446,  0.27581865, ..., -0.21914358,\n",
              "          0.28085643, -0.22921914],\n",
              "        [ 0.40948814,  0.01123596,  0.27715355, ..., -0.22846442,\n",
              "          0.28214732, -0.23595506]],\n",
              "\n",
              "       [[ 0.40717822,  0.01732673,  0.27351484, ..., -0.23019803,\n",
              "          0.27351484, -0.24009901],\n",
              "        [ 0.41044775,  0.0199005 ,  0.27860695, ..., -0.22636816,\n",
              "          0.2761194 , -0.23383084],\n",
              "        [ 0.41016108,  0.02106567,  0.28376704, ..., -0.22428748,\n",
              "          0.27137548, -0.23172243],\n",
              "        ...,\n",
              "        [ 0.477208  ,  0.07692308,  0.32905984, ..., -0.21937323,\n",
              "          0.2777778 , -0.2022792 ],\n",
              "        [ 0.477208  ,  0.07692308,  0.33760685, ..., -0.22222222,\n",
              "          0.28917378, -0.2079772 ],\n",
              "        [ 0.47857141,  0.07714286,  0.34428573, ..., -0.22      ,\n",
              "          0.2957143 , -0.20857143]]], dtype=float32)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def load_and_prepare_data(csv_path):\n",
        "    # Load data from CSV\n",
        "    data = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "    # Convert to NumPy array for efficient processing\n",
        "    data = data.values\n",
        "\n",
        "    # Separate X (features) and Y (first column as labels)\n",
        "    Y = data[:, 0]  # First column as labels\n",
        "    X = data[:, 2:]  # All other columns as features (shape: num_samples, 84)\n",
        "\n",
        "    # Define sequence length\n",
        "    sequence_length = 25\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_seq, Y_seq = [], []\n",
        "    num_sequences = len(X) // sequence_length\n",
        "\n",
        "    for i in range(num_sequences):\n",
        "        start_idx = i * sequence_length\n",
        "        X_seq.append(X[start_idx:start_idx + sequence_length])  # 25 rows of features\n",
        "        Y_seq.append(Y[start_idx])  # First column value corresponding to the sequence\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_seq = np.array(X_seq)  # Shape: (num_sequences, 25, 84)\n",
        "    Y_seq = np.array(Y_seq)  # Shape: (num_sequences,)\n",
        "\n",
        "    return X_seq, Y_seq\n",
        "\n",
        "# Example usage\n",
        "csv_path = \"/content/Double Handed Keypoints 8th April-LSTM.csv\"  # Replace with actual path\n",
        "X_seq, Y_seq = load_and_prepare_data(csv_path)\n",
        "print(\"X shape:\", X_seq.shape)  # Expected: (num_sequences, 25, 84)\n",
        "print(\"Y shape:\", Y_seq.shape)  # Expected: (num_sequences,)\n",
        "\n",
        "# Encode Y_seq (convert string labels to integers)\n",
        "label_encoder = LabelEncoder()\n",
        "Y_seq = label_encoder.fit_transform(Y_seq)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "Y_seq = to_categorical(Y_seq, num_classes)\n",
        "\n",
        "X_seq.astype('float32')\n",
        "# Y_seq.dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StHsdrmbxJSK",
        "outputId": "37429e3b-07c7-48ee-8d32-abfac948e4f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(879, 26)\n"
          ]
        }
      ],
      "source": [
        "print(Y_seq.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxUejKCWv8JR",
        "outputId": "d3eaf051-82f1-469c-db67-9c75104d2a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1 / 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.0762 - loss: 3.5243 - val_accuracy: 0.2614 - val_loss: 3.1668\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.2185 - loss: 3.1421 - val_accuracy: 0.3977 - val_loss: 2.5640\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3434 - loss: 2.5867 - val_accuracy: 0.5227 - val_loss: 2.0826\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5276 - loss: 2.1607 - val_accuracy: 0.7045 - val_loss: 1.6388\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6659 - loss: 1.7637 - val_accuracy: 0.7500 - val_loss: 1.4353\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7208 - loss: 1.5080 - val_accuracy: 0.8295 - val_loss: 1.1932\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7223 - loss: 1.3847 - val_accuracy: 0.8409 - val_loss: 1.0565\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8014 - loss: 1.1271 - val_accuracy: 0.7727 - val_loss: 0.9486\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7984 - loss: 1.0351 - val_accuracy: 0.8864 - val_loss: 0.8214\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8478 - loss: 0.9398 - val_accuracy: 0.9318 - val_loss: 0.7417\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8159 - loss: 0.9038 - val_accuracy: 0.8864 - val_loss: 0.7587\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8618 - loss: 0.8374 - val_accuracy: 0.8182 - val_loss: 0.7632\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8746 - loss: 0.7822 - val_accuracy: 0.8750 - val_loss: 0.6825\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8894 - loss: 0.7436 - val_accuracy: 0.8977 - val_loss: 0.6090\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8768 - loss: 0.7008 - val_accuracy: 0.8409 - val_loss: 0.8199\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8720 - loss: 0.7047 - val_accuracy: 0.8750 - val_loss: 0.6043\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9096 - loss: 0.6253 - val_accuracy: 0.8295 - val_loss: 0.7523\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8401 - loss: 0.8214 - val_accuracy: 0.8864 - val_loss: 0.5571\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8747 - loss: 0.6512 - val_accuracy: 0.8977 - val_loss: 0.6101\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9030 - loss: 0.6172 - val_accuracy: 0.9091 - val_loss: 0.6220\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8661 - loss: 0.6704 - val_accuracy: 0.8295 - val_loss: 0.6845\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8655 - loss: 0.6147 - val_accuracy: 0.9091 - val_loss: 0.5464\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8874 - loss: 0.6262 - val_accuracy: 0.9205 - val_loss: 0.5163\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9418 - loss: 0.5238 - val_accuracy: 0.9205 - val_loss: 0.5739\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9103 - loss: 0.5530 - val_accuracy: 0.8977 - val_loss: 0.5491\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9069 - loss: 0.5388 - val_accuracy: 0.9659 - val_loss: 0.4779\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9186 - loss: 0.4958 - val_accuracy: 0.9318 - val_loss: 0.5070\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9143 - loss: 0.4829 - val_accuracy: 0.9205 - val_loss: 0.4817\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9273 - loss: 0.4933 - val_accuracy: 0.8750 - val_loss: 0.5423\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9303 - loss: 0.4628 - val_accuracy: 0.8750 - val_loss: 0.6257\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9350 - loss: 0.4679 - val_accuracy: 0.8864 - val_loss: 0.7369\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9004 - loss: 0.6280 - val_accuracy: 0.9091 - val_loss: 0.6249\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9408 - loss: 0.4526 - val_accuracy: 0.9091 - val_loss: 0.5226\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9372 - loss: 0.4271 - val_accuracy: 0.9659 - val_loss: 0.4785\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9267 - loss: 0.4659 - val_accuracy: 0.9318 - val_loss: 0.4510\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9286 - loss: 0.4799 - val_accuracy: 0.8977 - val_loss: 0.5257\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9367 - loss: 0.4341 - val_accuracy: 0.9432 - val_loss: 0.4481\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.5226 - val_accuracy: 0.8864 - val_loss: 0.6268\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9303 - loss: 0.5023 - val_accuracy: 0.9318 - val_loss: 0.4895\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9464 - loss: 0.4065 - val_accuracy: 0.9205 - val_loss: 0.5116\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9456 - loss: 0.4078 - val_accuracy: 0.9205 - val_loss: 0.6399\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9510 - loss: 0.3953 - val_accuracy: 0.9659 - val_loss: 0.4430\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9472 - loss: 0.3913 - val_accuracy: 0.9659 - val_loss: 0.4251\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9349 - loss: 0.3959 - val_accuracy: 0.9432 - val_loss: 0.4414\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9265 - loss: 0.4230 - val_accuracy: 0.9545 - val_loss: 0.4875\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9428 - loss: 0.4252 - val_accuracy: 0.8750 - val_loss: 0.6214\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9248 - loss: 0.4915 - val_accuracy: 0.9432 - val_loss: 0.5630\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9383 - loss: 0.5082 - val_accuracy: 0.9659 - val_loss: 0.4564\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9556 - loss: 0.3952 - val_accuracy: 0.9659 - val_loss: 0.3842\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9707 - loss: 0.3508 - val_accuracy: 0.9773 - val_loss: 0.3689\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9729 - loss: 0.3467 - val_accuracy: 0.9773 - val_loss: 0.3606\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9720 - loss: 0.3481 - val_accuracy: 0.9545 - val_loss: 0.3952\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9542 - loss: 0.3540 - val_accuracy: 0.9205 - val_loss: 0.6468\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9516 - loss: 0.3749 - val_accuracy: 0.9432 - val_loss: 0.5253\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9531 - loss: 0.3445 - val_accuracy: 0.9545 - val_loss: 0.4404\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9753 - loss: 0.3326 - val_accuracy: 0.9773 - val_loss: 0.3650\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9694 - loss: 0.3244 - val_accuracy: 0.9659 - val_loss: 0.4052\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9566 - loss: 0.3362 - val_accuracy: 0.9659 - val_loss: 0.3737\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9432 - loss: 0.3736 - val_accuracy: 0.8750 - val_loss: 0.7048\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8976 - loss: 0.5686 - val_accuracy: 0.9318 - val_loss: 0.5019\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9341 - loss: 0.4268 - val_accuracy: 0.9659 - val_loss: 0.3703\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9621 - loss: 0.3575 - val_accuracy: 0.9432 - val_loss: 0.5314\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9009 - loss: 0.5280 - val_accuracy: 0.9205 - val_loss: 0.5215\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8759 - loss: 0.5620 - val_accuracy: 0.8409 - val_loss: 0.5320\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9126 - loss: 0.4449 - val_accuracy: 0.9318 - val_loss: 0.4578\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9302 - loss: 0.4594 - val_accuracy: 0.9205 - val_loss: 0.3887\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9464 - loss: 0.3652 - val_accuracy: 0.9318 - val_loss: 0.4661\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9583 - loss: 0.3738 - val_accuracy: 0.9545 - val_loss: 0.3839\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9784 - loss: 0.3335 - val_accuracy: 0.9659 - val_loss: 0.3656\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9621 - loss: 0.3581 - val_accuracy: 0.9659 - val_loss: 0.3581\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9733 - loss: 0.3118 - val_accuracy: 0.9773 - val_loss: 0.3323\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9776 - loss: 0.3127 - val_accuracy: 0.9545 - val_loss: 0.3440\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9715 - loss: 0.3172 - val_accuracy: 0.9205 - val_loss: 0.4306\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9276 - loss: 0.4378 - val_accuracy: 0.9318 - val_loss: 0.4615\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9709 - loss: 0.3488 - val_accuracy: 0.9659 - val_loss: 0.3823\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9862 - loss: 0.2889 - val_accuracy: 0.9432 - val_loss: 0.3667\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9848 - loss: 0.2835 - val_accuracy: 0.9545 - val_loss: 0.3975\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9753 - loss: 0.3130 - val_accuracy: 0.9659 - val_loss: 0.3578\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9736 - loss: 0.2959 - val_accuracy: 0.9545 - val_loss: 0.3773\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9832 - loss: 0.2808 - val_accuracy: 0.9545 - val_loss: 0.3772\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9842 - loss: 0.2919 - val_accuracy: 0.9659 - val_loss: 0.3513\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9776 - loss: 0.2853 - val_accuracy: 0.9659 - val_loss: 0.4089\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9753 - loss: 0.3094 - val_accuracy: 0.9091 - val_loss: 0.4788\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9327 - loss: 0.3877 - val_accuracy: 0.9545 - val_loss: 0.4480\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.3076 - val_accuracy: 0.9545 - val_loss: 0.4219\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.2469 - val_accuracy: 0.9432 - val_loss: 0.4604\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9691 - loss: 0.3210 - val_accuracy: 0.9659 - val_loss: 0.3726\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9627 - loss: 0.3255 - val_accuracy: 0.9545 - val_loss: 0.3204\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9698 - loss: 0.2805 - val_accuracy: 0.9773 - val_loss: 0.3004\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9847 - loss: 0.2651 - val_accuracy: 0.9773 - val_loss: 0.3037\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9788 - loss: 0.2500 - val_accuracy: 0.9773 - val_loss: 0.3022\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9884 - loss: 0.2358 - val_accuracy: 0.9659 - val_loss: 0.3154\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9877 - loss: 0.2317 - val_accuracy: 0.9659 - val_loss: 0.3523\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.2102 - val_accuracy: 0.9659 - val_loss: 0.3379\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9910 - loss: 0.2370 - val_accuracy: 0.9659 - val_loss: 0.3339\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9924 - loss: 0.2161 - val_accuracy: 0.9659 - val_loss: 0.3337\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9900 - loss: 0.2154 - val_accuracy: 0.9659 - val_loss: 0.3237\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.2087 - val_accuracy: 0.9659 - val_loss: 0.3300\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.2200 - val_accuracy: 0.9659 - val_loss: 0.3252\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.2065 - val_accuracy: 0.9659 - val_loss: 0.3385\n",
            "\n",
            "Fold 2 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.0848 - loss: 3.5709 - val_accuracy: 0.2955 - val_loss: 3.2241\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1785 - loss: 3.1878 - val_accuracy: 0.3523 - val_loss: 2.7189\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3481 - loss: 2.7290 - val_accuracy: 0.5000 - val_loss: 2.2315\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4339 - loss: 2.3191 - val_accuracy: 0.6136 - val_loss: 1.7815\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5779 - loss: 1.8462 - val_accuracy: 0.7273 - val_loss: 1.5102\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6687 - loss: 1.5890 - val_accuracy: 0.7841 - val_loss: 1.3472\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6825 - loss: 1.5110 - val_accuracy: 0.7955 - val_loss: 1.1461\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7271 - loss: 1.2206 - val_accuracy: 0.8068 - val_loss: 1.0276\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7653 - loss: 1.1468 - val_accuracy: 0.8750 - val_loss: 0.8673\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7877 - loss: 1.0582 - val_accuracy: 0.8750 - val_loss: 0.8804\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8058 - loss: 1.0228 - val_accuracy: 0.8750 - val_loss: 0.8227\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7991 - loss: 0.9591 - val_accuracy: 0.9091 - val_loss: 0.7340\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8387 - loss: 0.8941 - val_accuracy: 0.8864 - val_loss: 0.7059\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8762 - loss: 0.7932 - val_accuracy: 0.8636 - val_loss: 0.8110\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8380 - loss: 0.8685 - val_accuracy: 0.8977 - val_loss: 0.6974\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8368 - loss: 0.8233 - val_accuracy: 0.9545 - val_loss: 0.5948\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8939 - loss: 0.7169 - val_accuracy: 0.9545 - val_loss: 0.5832\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8788 - loss: 0.7011 - val_accuracy: 0.9545 - val_loss: 0.5745\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8820 - loss: 0.7155 - val_accuracy: 0.9432 - val_loss: 0.5687\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8850 - loss: 0.6777 - val_accuracy: 0.9432 - val_loss: 0.5641\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8987 - loss: 0.6306 - val_accuracy: 0.9318 - val_loss: 0.5638\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9216 - loss: 0.6110 - val_accuracy: 0.9432 - val_loss: 0.5377\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9190 - loss: 0.5677 - val_accuracy: 0.9318 - val_loss: 0.5276\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9290 - loss: 0.5800 - val_accuracy: 0.8068 - val_loss: 1.0077\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8630 - loss: 0.7833 - val_accuracy: 0.9318 - val_loss: 0.5329\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9050 - loss: 0.5978 - val_accuracy: 0.9091 - val_loss: 0.5257\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9276 - loss: 0.5247 - val_accuracy: 0.9091 - val_loss: 0.5073\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9416 - loss: 0.5050 - val_accuracy: 0.9091 - val_loss: 0.5479\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9502 - loss: 0.5230 - val_accuracy: 0.9545 - val_loss: 0.4507\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9556 - loss: 0.4577 - val_accuracy: 0.9432 - val_loss: 0.4658\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9478 - loss: 0.4490 - val_accuracy: 0.9318 - val_loss: 0.5036\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9499 - loss: 0.4760 - val_accuracy: 0.9545 - val_loss: 0.4250\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9670 - loss: 0.4375 - val_accuracy: 0.9545 - val_loss: 0.3949\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.4334 - val_accuracy: 0.9318 - val_loss: 0.4491\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9536 - loss: 0.4342 - val_accuracy: 0.9318 - val_loss: 0.4512\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.4572 - val_accuracy: 0.9432 - val_loss: 0.4339\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9451 - loss: 0.4702 - val_accuracy: 0.9205 - val_loss: 0.5698\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9233 - loss: 0.5267 - val_accuracy: 0.9205 - val_loss: 0.4794\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9299 - loss: 0.4880 - val_accuracy: 0.9091 - val_loss: 0.5826\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9275 - loss: 0.4541 - val_accuracy: 0.9091 - val_loss: 0.5324\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9548 - loss: 0.4457 - val_accuracy: 0.9318 - val_loss: 0.4515\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9624 - loss: 0.4046 - val_accuracy: 0.9318 - val_loss: 0.4739\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9561 - loss: 0.3896 - val_accuracy: 0.9432 - val_loss: 0.4439\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9802 - loss: 0.3563 - val_accuracy: 0.9318 - val_loss: 0.4738\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9705 - loss: 0.4017 - val_accuracy: 0.9205 - val_loss: 0.5231\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9775 - loss: 0.3594 - val_accuracy: 0.9545 - val_loss: 0.4603\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9818 - loss: 0.3294 - val_accuracy: 0.9659 - val_loss: 0.4135\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.3451 - val_accuracy: 0.9205 - val_loss: 0.5567\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9460 - loss: 0.4762 - val_accuracy: 0.8182 - val_loss: 0.7960\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9182 - loss: 0.5415 - val_accuracy: 0.9659 - val_loss: 0.4463\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9652 - loss: 0.4112 - val_accuracy: 0.9659 - val_loss: 0.4185\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9717 - loss: 0.3601 - val_accuracy: 0.9432 - val_loss: 0.4310\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.3535 - val_accuracy: 0.9659 - val_loss: 0.4005\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9728 - loss: 0.3571 - val_accuracy: 0.9659 - val_loss: 0.3992\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9776 - loss: 0.3205 - val_accuracy: 0.9659 - val_loss: 0.4021\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9716 - loss: 0.3302 - val_accuracy: 0.9659 - val_loss: 0.3755\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9891 - loss: 0.2976 - val_accuracy: 0.9659 - val_loss: 0.3779\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.2801 - val_accuracy: 0.9205 - val_loss: 0.5604\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9622 - loss: 0.3671 - val_accuracy: 0.9659 - val_loss: 0.3782\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9830 - loss: 0.3151 - val_accuracy: 0.9659 - val_loss: 0.3810\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8679 - loss: 0.7767 - val_accuracy: 0.8864 - val_loss: 0.5448\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9029 - loss: 0.5446 - val_accuracy: 0.8636 - val_loss: 0.6723\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9105 - loss: 0.5004 - val_accuracy: 0.9318 - val_loss: 0.4754\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9540 - loss: 0.4120 - val_accuracy: 0.9318 - val_loss: 0.4854\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.3918 - val_accuracy: 0.9091 - val_loss: 0.5005\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9460 - loss: 0.3818 - val_accuracy: 0.9545 - val_loss: 0.4304\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9583 - loss: 0.3792 - val_accuracy: 0.8977 - val_loss: 0.5182\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9658 - loss: 0.3587 - val_accuracy: 0.9545 - val_loss: 0.4372\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9754 - loss: 0.3253 - val_accuracy: 0.9318 - val_loss: 0.4767\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9688 - loss: 0.3210 - val_accuracy: 0.9545 - val_loss: 0.4191\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9762 - loss: 0.3101 - val_accuracy: 0.9659 - val_loss: 0.4128\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9743 - loss: 0.3390 - val_accuracy: 0.9659 - val_loss: 0.4342\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9430 - loss: 0.4639 - val_accuracy: 0.9545 - val_loss: 0.4068\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9664 - loss: 0.3441 - val_accuracy: 0.9432 - val_loss: 0.4296\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9583 - loss: 0.3574 - val_accuracy: 0.9659 - val_loss: 0.3722\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9754 - loss: 0.3237 - val_accuracy: 0.9659 - val_loss: 0.3563\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: 0.3544 - val_accuracy: 0.9318 - val_loss: 0.3851\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9682 - loss: 0.3508 - val_accuracy: 0.9545 - val_loss: 0.3632\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9768 - loss: 0.3088 - val_accuracy: 0.9545 - val_loss: 0.3889\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9782 - loss: 0.3066 - val_accuracy: 0.9659 - val_loss: 0.3678\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.2646 - val_accuracy: 0.9659 - val_loss: 0.3620\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.2771 - val_accuracy: 0.9659 - val_loss: 0.3499\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9936 - loss: 0.2452 - val_accuracy: 0.9545 - val_loss: 0.3829\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9881 - loss: 0.2601 - val_accuracy: 0.9545 - val_loss: 0.4344\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.3018 - val_accuracy: 0.9545 - val_loss: 0.3554\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9815 - loss: 0.2945 - val_accuracy: 0.9545 - val_loss: 0.3472\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9770 - loss: 0.2851 - val_accuracy: 0.9432 - val_loss: 0.3716\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9669 - loss: 0.3264 - val_accuracy: 0.9545 - val_loss: 0.3488\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9709 - loss: 0.3021 - val_accuracy: 0.9545 - val_loss: 0.4062\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9806 - loss: 0.2697 - val_accuracy: 0.9545 - val_loss: 0.3981\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.2645 - val_accuracy: 0.9432 - val_loss: 0.4001\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9706 - loss: 0.3058 - val_accuracy: 0.9205 - val_loss: 0.4679\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9768 - loss: 0.2729 - val_accuracy: 0.9318 - val_loss: 0.4447\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9864 - loss: 0.2666 - val_accuracy: 0.9432 - val_loss: 0.4225\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9694 - loss: 0.3110 - val_accuracy: 0.9659 - val_loss: 0.3570\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.2721 - val_accuracy: 0.9432 - val_loss: 0.3858\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9517 - loss: 0.3708 - val_accuracy: 0.9545 - val_loss: 0.2768\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9598 - loss: 0.3796 - val_accuracy: 0.8636 - val_loss: 0.6298\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9563 - loss: 0.3520 - val_accuracy: 0.9318 - val_loss: 0.4670\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9602 - loss: 0.3440 - val_accuracy: 0.9205 - val_loss: 0.5048\n",
            "\n",
            "Fold 3 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.0937 - loss: 3.5175 - val_accuracy: 0.2386 - val_loss: 3.2285\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2610 - loss: 3.1317 - val_accuracy: 0.4091 - val_loss: 2.7630\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3629 - loss: 2.6588 - val_accuracy: 0.5682 - val_loss: 2.1681\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4999 - loss: 2.1487 - val_accuracy: 0.7386 - val_loss: 1.6796\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6595 - loss: 1.7211 - val_accuracy: 0.8068 - val_loss: 1.3346\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7360 - loss: 1.3993 - val_accuracy: 0.8182 - val_loss: 1.1464\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7544 - loss: 1.2647 - val_accuracy: 0.8409 - val_loss: 1.0683\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7795 - loss: 1.1143 - val_accuracy: 0.7273 - val_loss: 1.1219\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7786 - loss: 1.0950 - val_accuracy: 0.8182 - val_loss: 0.9111\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8338 - loss: 0.9324 - val_accuracy: 0.8409 - val_loss: 0.8486\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8646 - loss: 0.8360 - val_accuracy: 0.8409 - val_loss: 0.8098\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8582 - loss: 0.8143 - val_accuracy: 0.8409 - val_loss: 0.8441\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8624 - loss: 0.7916 - val_accuracy: 0.9091 - val_loss: 0.7538\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8671 - loss: 0.7451 - val_accuracy: 0.8295 - val_loss: 0.7617\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8444 - loss: 0.7706 - val_accuracy: 0.8864 - val_loss: 0.7399\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8914 - loss: 0.6778 - val_accuracy: 0.9318 - val_loss: 0.7502\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8566 - loss: 0.7381 - val_accuracy: 0.9091 - val_loss: 0.7577\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8883 - loss: 0.6695 - val_accuracy: 0.8977 - val_loss: 0.7246\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8957 - loss: 0.6610 - val_accuracy: 0.9545 - val_loss: 0.7342\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9222 - loss: 0.5816 - val_accuracy: 0.8864 - val_loss: 0.6934\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9139 - loss: 0.5753 - val_accuracy: 0.8977 - val_loss: 0.6636\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9305 - loss: 0.5267 - val_accuracy: 0.8750 - val_loss: 0.6974\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9168 - loss: 0.5409 - val_accuracy: 0.8636 - val_loss: 0.6889\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8972 - loss: 0.6561 - val_accuracy: 0.8523 - val_loss: 0.7146\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9153 - loss: 0.5943 - val_accuracy: 0.8409 - val_loss: 0.7101\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8647 - loss: 0.6995 - val_accuracy: 0.8523 - val_loss: 0.6749\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9073 - loss: 0.5936 - val_accuracy: 0.9545 - val_loss: 0.6374\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8796 - loss: 0.5861 - val_accuracy: 0.9205 - val_loss: 0.6681\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9184 - loss: 0.5192 - val_accuracy: 0.8636 - val_loss: 0.7203\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9246 - loss: 0.5339 - val_accuracy: 0.8636 - val_loss: 0.7531\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8987 - loss: 0.6270 - val_accuracy: 0.8295 - val_loss: 0.7800\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8912 - loss: 0.5927 - val_accuracy: 0.8409 - val_loss: 0.8002\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9038 - loss: 0.5686 - val_accuracy: 0.8750 - val_loss: 0.7120\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9341 - loss: 0.5216 - val_accuracy: 0.8636 - val_loss: 0.7120\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9155 - loss: 0.5301 - val_accuracy: 0.8750 - val_loss: 0.6794\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9282 - loss: 0.4601 - val_accuracy: 0.8750 - val_loss: 0.6545\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9472 - loss: 0.4512 - val_accuracy: 0.9318 - val_loss: 0.6096\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9598 - loss: 0.4219 - val_accuracy: 0.9318 - val_loss: 0.6472\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9839 - loss: 0.3850 - val_accuracy: 0.9545 - val_loss: 0.6189\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9567 - loss: 0.4179 - val_accuracy: 0.9318 - val_loss: 0.6638\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9586 - loss: 0.3906 - val_accuracy: 0.9545 - val_loss: 0.5996\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9751 - loss: 0.3638 - val_accuracy: 0.9432 - val_loss: 0.5749\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.3407 - val_accuracy: 0.9432 - val_loss: 0.5853\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9861 - loss: 0.3594 - val_accuracy: 0.9432 - val_loss: 0.5971\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.3284 - val_accuracy: 0.9432 - val_loss: 0.6318\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9828 - loss: 0.3468 - val_accuracy: 0.8977 - val_loss: 0.7411\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.4323 - val_accuracy: 0.9545 - val_loss: 0.6206\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9254 - loss: 0.4540 - val_accuracy: 0.9318 - val_loss: 0.6267\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9530 - loss: 0.3885 - val_accuracy: 0.9432 - val_loss: 0.5344\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9630 - loss: 0.3520 - val_accuracy: 0.9545 - val_loss: 0.5369\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9698 - loss: 0.3634 - val_accuracy: 0.9318 - val_loss: 0.6363\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9655 - loss: 0.3573 - val_accuracy: 0.9432 - val_loss: 0.5495\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9800 - loss: 0.3279 - val_accuracy: 0.9545 - val_loss: 0.5932\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.3075 - val_accuracy: 0.9545 - val_loss: 0.5603\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9722 - loss: 0.3309 - val_accuracy: 0.9432 - val_loss: 0.5526\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9841 - loss: 0.3109 - val_accuracy: 0.9545 - val_loss: 0.5530\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9510 - loss: 0.3329 - val_accuracy: 0.9659 - val_loss: 0.5211\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9803 - loss: 0.2952 - val_accuracy: 0.9659 - val_loss: 0.5084\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9823 - loss: 0.2975 - val_accuracy: 0.9659 - val_loss: 0.5018\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9699 - loss: 0.3145 - val_accuracy: 0.9545 - val_loss: 0.5358\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9838 - loss: 0.2803 - val_accuracy: 0.9659 - val_loss: 0.5226\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9828 - loss: 0.2763 - val_accuracy: 0.9659 - val_loss: 0.4928\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9839 - loss: 0.2936 - val_accuracy: 0.9659 - val_loss: 0.5022\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.2706 - val_accuracy: 0.9659 - val_loss: 0.4956\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9881 - loss: 0.2598 - val_accuracy: 0.9659 - val_loss: 0.5128\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.2620 - val_accuracy: 0.9545 - val_loss: 0.5761\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.2648 - val_accuracy: 0.9659 - val_loss: 0.5515\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9862 - loss: 0.2611 - val_accuracy: 0.9545 - val_loss: 0.5288\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9852 - loss: 0.2729 - val_accuracy: 0.9432 - val_loss: 0.5350\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.2392 - val_accuracy: 0.9545 - val_loss: 0.5187\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9890 - loss: 0.2395 - val_accuracy: 0.9545 - val_loss: 0.5274\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.2260 - val_accuracy: 0.9432 - val_loss: 0.5490\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9948 - loss: 0.2326 - val_accuracy: 0.9545 - val_loss: 0.5188\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9911 - loss: 0.2314 - val_accuracy: 0.9545 - val_loss: 0.5691\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9915 - loss: 0.2400 - val_accuracy: 0.9545 - val_loss: 0.5653\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9825 - loss: 0.2636 - val_accuracy: 0.9545 - val_loss: 0.5886\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9942 - loss: 0.2220 - val_accuracy: 0.9659 - val_loss: 0.5404\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9942 - loss: 0.2286 - val_accuracy: 0.9659 - val_loss: 0.5473\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9671 - loss: 0.3576 - val_accuracy: 0.8750 - val_loss: 0.8464\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8718 - loss: 0.6368 - val_accuracy: 0.8977 - val_loss: 0.8010\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9208 - loss: 0.4451 - val_accuracy: 0.9318 - val_loss: 0.5751\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9469 - loss: 0.3348 - val_accuracy: 0.9318 - val_loss: 0.5849\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9589 - loss: 0.3197 - val_accuracy: 0.9545 - val_loss: 0.5844\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.2672 - val_accuracy: 0.9545 - val_loss: 0.5174\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.2628 - val_accuracy: 0.9545 - val_loss: 0.5615\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.2447 - val_accuracy: 0.9545 - val_loss: 0.5190\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.2685 - val_accuracy: 0.9545 - val_loss: 0.5554\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9868 - loss: 0.2499 - val_accuracy: 0.9545 - val_loss: 0.5806\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9889 - loss: 0.2477 - val_accuracy: 0.9545 - val_loss: 0.5742\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9830 - loss: 0.2458 - val_accuracy: 0.9545 - val_loss: 0.5240\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.2554 - val_accuracy: 0.9545 - val_loss: 0.5335\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9853 - loss: 0.2356 - val_accuracy: 0.9545 - val_loss: 0.5688\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.2552 - val_accuracy: 0.9432 - val_loss: 0.5946\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9834 - loss: 0.2450 - val_accuracy: 0.9545 - val_loss: 0.5431\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.2153 - val_accuracy: 0.9545 - val_loss: 0.5776\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9838 - loss: 0.2422 - val_accuracy: 0.9545 - val_loss: 0.5165\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.2105 - val_accuracy: 0.9545 - val_loss: 0.4804\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.2853 - val_accuracy: 0.9545 - val_loss: 0.5388\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9586 - loss: 0.2492 - val_accuracy: 0.9432 - val_loss: 0.4989\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9543 - loss: 0.3158 - val_accuracy: 0.9545 - val_loss: 0.4855\n",
            "\n",
            "Fold 4 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.1356 - loss: 3.5320 - val_accuracy: 0.2727 - val_loss: 3.2078\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2623 - loss: 3.1180 - val_accuracy: 0.3977 - val_loss: 2.7768\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3761 - loss: 2.7120 - val_accuracy: 0.5455 - val_loss: 2.2578\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5690 - loss: 2.1626 - val_accuracy: 0.6591 - val_loss: 1.8132\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6754 - loss: 1.7642 - val_accuracy: 0.7045 - val_loss: 1.4777\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7101 - loss: 1.5428 - val_accuracy: 0.7614 - val_loss: 1.2121\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7359 - loss: 1.3183 - val_accuracy: 0.7955 - val_loss: 1.0553\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7511 - loss: 1.1672 - val_accuracy: 0.7273 - val_loss: 1.1007\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7483 - loss: 1.1570 - val_accuracy: 0.7841 - val_loss: 0.9813\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7692 - loss: 1.0520 - val_accuracy: 0.7727 - val_loss: 0.9483\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7904 - loss: 1.0043 - val_accuracy: 0.8523 - val_loss: 0.8133\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8286 - loss: 0.8811 - val_accuracy: 0.8523 - val_loss: 0.7966\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8603 - loss: 0.8097 - val_accuracy: 0.8409 - val_loss: 0.7330\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8257 - loss: 0.8368 - val_accuracy: 0.8409 - val_loss: 0.7159\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8381 - loss: 0.7922 - val_accuracy: 0.9091 - val_loss: 0.6101\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8861 - loss: 0.7388 - val_accuracy: 0.9318 - val_loss: 0.5924\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8670 - loss: 0.7049 - val_accuracy: 0.9091 - val_loss: 0.5846\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9114 - loss: 0.6501 - val_accuracy: 0.9318 - val_loss: 0.5959\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8789 - loss: 0.6869 - val_accuracy: 0.8977 - val_loss: 0.6429\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8926 - loss: 0.6470 - val_accuracy: 0.9205 - val_loss: 0.5674\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9168 - loss: 0.5829 - val_accuracy: 0.8636 - val_loss: 0.5828\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8994 - loss: 0.6140 - val_accuracy: 0.9205 - val_loss: 0.4882\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9263 - loss: 0.5390 - val_accuracy: 0.8750 - val_loss: 0.5993\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9243 - loss: 0.6061 - val_accuracy: 0.9318 - val_loss: 0.4970\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8941 - loss: 0.6179 - val_accuracy: 0.9205 - val_loss: 0.5834\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8962 - loss: 0.6169 - val_accuracy: 0.9659 - val_loss: 0.4374\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9474 - loss: 0.5451 - val_accuracy: 0.9091 - val_loss: 0.4576\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9629 - loss: 0.4392 - val_accuracy: 0.9773 - val_loss: 0.4030\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9669 - loss: 0.4482 - val_accuracy: 0.9432 - val_loss: 0.3619\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9629 - loss: 0.4339 - val_accuracy: 0.9659 - val_loss: 0.3345\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9627 - loss: 0.4684 - val_accuracy: 0.9773 - val_loss: 0.3600\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9493 - loss: 0.4424 - val_accuracy: 0.9545 - val_loss: 0.3260\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9722 - loss: 0.3974 - val_accuracy: 0.9886 - val_loss: 0.3187\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9658 - loss: 0.3990 - val_accuracy: 0.9659 - val_loss: 0.3694\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9656 - loss: 0.3921 - val_accuracy: 0.9545 - val_loss: 0.4240\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9699 - loss: 0.4235 - val_accuracy: 0.9545 - val_loss: 0.4041\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9504 - loss: 0.4476 - val_accuracy: 0.9545 - val_loss: 0.3563\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9333 - loss: 0.4614 - val_accuracy: 0.9886 - val_loss: 0.3615\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9298 - loss: 0.4337 - val_accuracy: 0.8977 - val_loss: 0.5331\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9132 - loss: 0.4939 - val_accuracy: 0.8977 - val_loss: 0.4155\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9161 - loss: 0.4733 - val_accuracy: 0.9545 - val_loss: 0.3712\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9589 - loss: 0.3962 - val_accuracy: 0.9886 - val_loss: 0.3390\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9771 - loss: 0.3299 - val_accuracy: 0.9886 - val_loss: 0.3334\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9752 - loss: 0.3824 - val_accuracy: 0.9773 - val_loss: 0.3566\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9792 - loss: 0.3478 - val_accuracy: 0.9659 - val_loss: 0.3441\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9741 - loss: 0.3436 - val_accuracy: 0.9091 - val_loss: 0.4844\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9272 - loss: 0.4481 - val_accuracy: 0.9545 - val_loss: 0.3160\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9504 - loss: 0.4098 - val_accuracy: 0.9545 - val_loss: 0.4524\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9032 - loss: 0.5796 - val_accuracy: 0.8182 - val_loss: 0.6118\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8781 - loss: 0.5625 - val_accuracy: 0.9318 - val_loss: 0.4325\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9292 - loss: 0.4439 - val_accuracy: 0.9886 - val_loss: 0.3413\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9588 - loss: 0.3948 - val_accuracy: 0.9545 - val_loss: 0.3549\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9578 - loss: 0.3784 - val_accuracy: 0.9773 - val_loss: 0.3420\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9734 - loss: 0.3341 - val_accuracy: 0.9659 - val_loss: 0.3099\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9744 - loss: 0.3503 - val_accuracy: 0.9659 - val_loss: 0.3151\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.3133 - val_accuracy: 0.9886 - val_loss: 0.2478\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9688 - loss: 0.3257 - val_accuracy: 0.9886 - val_loss: 0.2420\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9655 - loss: 0.3338 - val_accuracy: 0.9886 - val_loss: 0.2558\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9547 - loss: 0.3787 - val_accuracy: 0.9318 - val_loss: 0.4475\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9100 - loss: 0.5532 - val_accuracy: 0.9773 - val_loss: 0.2839\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9639 - loss: 0.3543 - val_accuracy: 1.0000 - val_loss: 0.2476\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9794 - loss: 0.3344 - val_accuracy: 0.9886 - val_loss: 0.2559\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9855 - loss: 0.3053 - val_accuracy: 1.0000 - val_loss: 0.2405\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9798 - loss: 0.2990 - val_accuracy: 0.9886 - val_loss: 0.2410\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.3118 - val_accuracy: 0.9773 - val_loss: 0.2547\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.3122 - val_accuracy: 0.9773 - val_loss: 0.2656\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9709 - loss: 0.3319 - val_accuracy: 0.9886 - val_loss: 0.2598\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.2871 - val_accuracy: 0.9886 - val_loss: 0.2483\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9858 - loss: 0.2806 - val_accuracy: 0.9773 - val_loss: 0.2584\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9634 - loss: 0.3124 - val_accuracy: 0.9886 - val_loss: 0.2599\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.2701 - val_accuracy: 1.0000 - val_loss: 0.2164\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9920 - loss: 0.2529 - val_accuracy: 0.9886 - val_loss: 0.2403\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9881 - loss: 0.2792 - val_accuracy: 0.9886 - val_loss: 0.2322\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9743 - loss: 0.2968 - val_accuracy: 0.8750 - val_loss: 0.5626\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9014 - loss: 0.5433 - val_accuracy: 0.9318 - val_loss: 0.3737\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9553 - loss: 0.3641 - val_accuracy: 0.9773 - val_loss: 0.3219\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9722 - loss: 0.3244 - val_accuracy: 0.9205 - val_loss: 0.3801\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9587 - loss: 0.3080 - val_accuracy: 0.9886 - val_loss: 0.2150\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9810 - loss: 0.2726 - val_accuracy: 0.9773 - val_loss: 0.2629\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9707 - loss: 0.3171 - val_accuracy: 0.9886 - val_loss: 0.2173\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9725 - loss: 0.3046 - val_accuracy: 0.9318 - val_loss: 0.3255\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9610 - loss: 0.3483 - val_accuracy: 0.9886 - val_loss: 0.2371\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.2986 - val_accuracy: 0.9773 - val_loss: 0.2232\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.3028 - val_accuracy: 0.9659 - val_loss: 0.2791\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9660 - loss: 0.2848 - val_accuracy: 0.9545 - val_loss: 0.2854\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9659 - loss: 0.3025 - val_accuracy: 0.9545 - val_loss: 0.3526\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9709 - loss: 0.2887 - val_accuracy: 0.9545 - val_loss: 0.3173\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9402 - loss: 0.3863 - val_accuracy: 0.9773 - val_loss: 0.2744\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9618 - loss: 0.3516 - val_accuracy: 0.9886 - val_loss: 0.2455\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9670 - loss: 0.3043 - val_accuracy: 1.0000 - val_loss: 0.1948\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9830 - loss: 0.2635 - val_accuracy: 1.0000 - val_loss: 0.1920\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.2366 - val_accuracy: 1.0000 - val_loss: 0.1889\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.2423 - val_accuracy: 1.0000 - val_loss: 0.1878\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9921 - loss: 0.2389 - val_accuracy: 1.0000 - val_loss: 0.1797\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9945 - loss: 0.2207 - val_accuracy: 1.0000 - val_loss: 0.1794\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9837 - loss: 0.2582 - val_accuracy: 0.9886 - val_loss: 0.1873\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9817 - loss: 0.2284 - val_accuracy: 0.9886 - val_loss: 0.2108\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.2445 - val_accuracy: 1.0000 - val_loss: 0.1742\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9848 - loss: 0.2511 - val_accuracy: 1.0000 - val_loss: 0.1694\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.2145 - val_accuracy: 1.0000 - val_loss: 0.1681\n",
            "\n",
            "Fold 5 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.0627 - loss: 3.5454 - val_accuracy: 0.1932 - val_loss: 3.3027\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1763 - loss: 3.1616 - val_accuracy: 0.4659 - val_loss: 2.8427\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3005 - loss: 2.7208 - val_accuracy: 0.5682 - val_loss: 2.3664\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4841 - loss: 2.2729 - val_accuracy: 0.5455 - val_loss: 1.8928\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6414 - loss: 1.7967 - val_accuracy: 0.8068 - val_loss: 1.5574\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7143 - loss: 1.5406 - val_accuracy: 0.7273 - val_loss: 1.3578\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7139 - loss: 1.4532 - val_accuracy: 0.7500 - val_loss: 1.1616\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7707 - loss: 1.2719 - val_accuracy: 0.8068 - val_loss: 1.0021\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8101 - loss: 1.0610 - val_accuracy: 0.8750 - val_loss: 0.8771\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8718 - loss: 0.9848 - val_accuracy: 0.8977 - val_loss: 0.7790\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8493 - loss: 0.9328 - val_accuracy: 0.9091 - val_loss: 0.7830\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8972 - loss: 0.8472 - val_accuracy: 0.9091 - val_loss: 0.7360\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9148 - loss: 0.7640 - val_accuracy: 0.9205 - val_loss: 0.6953\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9202 - loss: 0.7345 - val_accuracy: 0.9318 - val_loss: 0.6738\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9256 - loss: 0.7125 - val_accuracy: 0.9545 - val_loss: 0.6095\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9427 - loss: 0.6618 - val_accuracy: 0.9545 - val_loss: 0.5503\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9666 - loss: 0.6118 - val_accuracy: 0.9545 - val_loss: 0.4875\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9690 - loss: 0.5238 - val_accuracy: 0.9545 - val_loss: 0.4816\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9660 - loss: 0.5053 - val_accuracy: 0.9205 - val_loss: 0.5901\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9222 - loss: 0.6017 - val_accuracy: 0.9432 - val_loss: 0.5223\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9295 - loss: 0.5738 - val_accuracy: 0.8636 - val_loss: 0.6686\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9083 - loss: 0.6443 - val_accuracy: 0.9091 - val_loss: 0.5105\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9325 - loss: 0.5331 - val_accuracy: 0.9545 - val_loss: 0.4693\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9591 - loss: 0.5002 - val_accuracy: 0.9545 - val_loss: 0.4853\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9665 - loss: 0.4967 - val_accuracy: 0.9432 - val_loss: 0.4584\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9751 - loss: 0.4425 - val_accuracy: 0.9205 - val_loss: 0.5586\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9231 - loss: 0.5852 - val_accuracy: 0.8068 - val_loss: 0.7905\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9004 - loss: 0.6174 - val_accuracy: 0.9545 - val_loss: 0.4552\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9497 - loss: 0.5084 - val_accuracy: 0.9432 - val_loss: 0.4908\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9552 - loss: 0.4859 - val_accuracy: 0.9432 - val_loss: 0.4912\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9336 - loss: 0.5092 - val_accuracy: 0.9659 - val_loss: 0.4657\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9798 - loss: 0.4085 - val_accuracy: 0.9205 - val_loss: 0.5213\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9799 - loss: 0.3978 - val_accuracy: 0.9545 - val_loss: 0.4533\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9864 - loss: 0.3589 - val_accuracy: 0.9545 - val_loss: 0.4473\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9818 - loss: 0.3851 - val_accuracy: 0.9545 - val_loss: 0.4041\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.3420 - val_accuracy: 0.9545 - val_loss: 0.4305\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9891 - loss: 0.3695 - val_accuracy: 0.9318 - val_loss: 0.4668\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9876 - loss: 0.3302 - val_accuracy: 0.9432 - val_loss: 0.5216\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9838 - loss: 0.3428 - val_accuracy: 0.9545 - val_loss: 0.4474\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9937 - loss: 0.3039 - val_accuracy: 0.9773 - val_loss: 0.3662\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9741 - loss: 0.3471 - val_accuracy: 0.9432 - val_loss: 0.5203\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9432 - loss: 0.4302 - val_accuracy: 0.8977 - val_loss: 0.6419\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9198 - loss: 0.5005 - val_accuracy: 0.8977 - val_loss: 0.6302\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8929 - loss: 0.4887 - val_accuracy: 0.9205 - val_loss: 0.4804\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9111 - loss: 0.4889 - val_accuracy: 0.9545 - val_loss: 0.3907\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9539 - loss: 0.3811 - val_accuracy: 0.9545 - val_loss: 0.3698\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9706 - loss: 0.3722 - val_accuracy: 0.9773 - val_loss: 0.4163\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9632 - loss: 0.3749 - val_accuracy: 0.9432 - val_loss: 0.4394\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9602 - loss: 0.3811 - val_accuracy: 0.9432 - val_loss: 0.4293\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9662 - loss: 0.3542 - val_accuracy: 0.9318 - val_loss: 0.5632\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9672 - loss: 0.3704 - val_accuracy: 0.9545 - val_loss: 0.4821\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9759 - loss: 0.3256 - val_accuracy: 0.9091 - val_loss: 0.5245\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9576 - loss: 0.3378 - val_accuracy: 0.9545 - val_loss: 0.4689\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9633 - loss: 0.3588 - val_accuracy: 0.9205 - val_loss: 0.4430\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9728 - loss: 0.3432 - val_accuracy: 0.9659 - val_loss: 0.3609\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: 0.3472 - val_accuracy: 0.9432 - val_loss: 0.3946\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9570 - loss: 0.3761 - val_accuracy: 0.9432 - val_loss: 0.3350\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9798 - loss: 0.3092 - val_accuracy: 0.9091 - val_loss: 0.4789\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9262 - loss: 0.5473 - val_accuracy: 0.9318 - val_loss: 0.4352\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9453 - loss: 0.3922 - val_accuracy: 0.9432 - val_loss: 0.4387\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9620 - loss: 0.3383 - val_accuracy: 0.9545 - val_loss: 0.4242\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9728 - loss: 0.3139 - val_accuracy: 0.9432 - val_loss: 0.4158\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9745 - loss: 0.3028 - val_accuracy: 0.9545 - val_loss: 0.3771\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.2790 - val_accuracy: 0.9545 - val_loss: 0.3393\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9825 - loss: 0.3030 - val_accuracy: 0.9432 - val_loss: 0.3988\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9810 - loss: 0.2947 - val_accuracy: 0.9659 - val_loss: 0.3134\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9881 - loss: 0.2881 - val_accuracy: 0.9773 - val_loss: 0.2859\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9701 - loss: 0.3152 - val_accuracy: 0.9545 - val_loss: 0.3722\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9761 - loss: 0.3057 - val_accuracy: 0.9659 - val_loss: 0.3275\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.2661 - val_accuracy: 0.9545 - val_loss: 0.3108\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9809 - loss: 0.2801 - val_accuracy: 0.9659 - val_loss: 0.3082\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.2720 - val_accuracy: 0.9659 - val_loss: 0.2568\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9967 - loss: 0.2486 - val_accuracy: 0.9659 - val_loss: 0.2911\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.2669 - val_accuracy: 0.9659 - val_loss: 0.2829\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.2422 - val_accuracy: 0.9659 - val_loss: 0.2863\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.2412 - val_accuracy: 0.9773 - val_loss: 0.2787\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.2346 - val_accuracy: 0.9659 - val_loss: 0.3475\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9954 - loss: 0.2314 - val_accuracy: 0.9659 - val_loss: 0.4404\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.2413 - val_accuracy: 0.9205 - val_loss: 0.5251\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9793 - loss: 0.2644 - val_accuracy: 0.9318 - val_loss: 0.4420\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9718 - loss: 0.3149 - val_accuracy: 0.9205 - val_loss: 0.4461\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9092 - loss: 0.4455 - val_accuracy: 0.9205 - val_loss: 0.5162\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9339 - loss: 0.3533 - val_accuracy: 0.9659 - val_loss: 0.2773\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9664 - loss: 0.3072 - val_accuracy: 0.9773 - val_loss: 0.3149\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9688 - loss: 0.3079 - val_accuracy: 0.9205 - val_loss: 0.4774\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9676 - loss: 0.3057 - val_accuracy: 0.9432 - val_loss: 0.4020\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9837 - loss: 0.2774 - val_accuracy: 0.9545 - val_loss: 0.3715\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9911 - loss: 0.2490 - val_accuracy: 0.9318 - val_loss: 0.4833\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9850 - loss: 0.2595 - val_accuracy: 0.9318 - val_loss: 0.4256\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9931 - loss: 0.2233 - val_accuracy: 0.9545 - val_loss: 0.4153\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9950 - loss: 0.2243 - val_accuracy: 0.9545 - val_loss: 0.3942\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9919 - loss: 0.2159 - val_accuracy: 0.9545 - val_loss: 0.3937\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9963 - loss: 0.2178 - val_accuracy: 0.9545 - val_loss: 0.3784\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.2150 - val_accuracy: 0.9432 - val_loss: 0.3940\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9774 - loss: 0.2732 - val_accuracy: 0.9545 - val_loss: 0.3585\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9889 - loss: 0.2422 - val_accuracy: 0.9432 - val_loss: 0.3577\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9913 - loss: 0.2178 - val_accuracy: 0.9659 - val_loss: 0.3234\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9896 - loss: 0.2247 - val_accuracy: 0.9432 - val_loss: 0.4321\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9324 - loss: 0.3639 - val_accuracy: 0.8977 - val_loss: 0.3954\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9342 - loss: 0.4420 - val_accuracy: 0.8864 - val_loss: 0.5613\n",
            "\n",
            "Fold 6 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.0772 - loss: 3.5085 - val_accuracy: 0.3295 - val_loss: 3.2204\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2093 - loss: 3.1229 - val_accuracy: 0.4773 - val_loss: 2.7756\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3473 - loss: 2.6824 - val_accuracy: 0.6364 - val_loss: 2.3055\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4913 - loss: 2.2678 - val_accuracy: 0.6705 - val_loss: 1.8950\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5962 - loss: 1.8426 - val_accuracy: 0.7159 - val_loss: 1.6086\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6652 - loss: 1.5948 - val_accuracy: 0.8182 - val_loss: 1.3051\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7093 - loss: 1.4072 - val_accuracy: 0.7500 - val_loss: 1.4384\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6815 - loss: 1.3929 - val_accuracy: 0.8864 - val_loss: 0.9388\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8090 - loss: 1.1171 - val_accuracy: 0.9091 - val_loss: 0.8493\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8321 - loss: 0.9831 - val_accuracy: 0.8864 - val_loss: 0.7667\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8486 - loss: 0.9649 - val_accuracy: 0.8977 - val_loss: 0.7353\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8548 - loss: 0.9054 - val_accuracy: 0.9091 - val_loss: 0.7226\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8599 - loss: 0.8734 - val_accuracy: 0.9091 - val_loss: 0.6765\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8218 - loss: 0.9279 - val_accuracy: 0.9091 - val_loss: 0.6463\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8582 - loss: 0.8370 - val_accuracy: 0.9773 - val_loss: 0.5833\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9008 - loss: 0.7483 - val_accuracy: 0.9545 - val_loss: 0.5913\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9050 - loss: 0.6807 - val_accuracy: 0.9545 - val_loss: 0.5353\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9178 - loss: 0.6215 - val_accuracy: 0.9886 - val_loss: 0.4932\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9002 - loss: 0.6409 - val_accuracy: 0.9659 - val_loss: 0.5016\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9150 - loss: 0.6025 - val_accuracy: 0.9659 - val_loss: 0.4955\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9246 - loss: 0.5558 - val_accuracy: 0.9886 - val_loss: 0.4713\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9376 - loss: 0.5470 - val_accuracy: 0.9773 - val_loss: 0.4674\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9463 - loss: 0.4955 - val_accuracy: 0.9886 - val_loss: 0.4604\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9250 - loss: 0.5355 - val_accuracy: 0.9659 - val_loss: 0.4719\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9493 - loss: 0.4999 - val_accuracy: 0.9659 - val_loss: 0.4587\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9166 - loss: 0.5821 - val_accuracy: 0.7614 - val_loss: 1.1653\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8108 - loss: 0.9716 - val_accuracy: 0.8977 - val_loss: 0.6027\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8872 - loss: 0.6760 - val_accuracy: 0.8523 - val_loss: 0.6785\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8699 - loss: 0.6651 - val_accuracy: 0.9773 - val_loss: 0.4304\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8699 - loss: 0.6001 - val_accuracy: 0.9659 - val_loss: 0.4637\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9371 - loss: 0.4849 - val_accuracy: 0.9432 - val_loss: 0.4718\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9352 - loss: 0.4820 - val_accuracy: 0.9659 - val_loss: 0.4562\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9156 - loss: 0.4855 - val_accuracy: 0.9545 - val_loss: 0.4498\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9533 - loss: 0.4447 - val_accuracy: 0.9545 - val_loss: 0.4415\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9617 - loss: 0.4326 - val_accuracy: 0.9545 - val_loss: 0.4175\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9656 - loss: 0.4130 - val_accuracy: 0.9659 - val_loss: 0.4370\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9745 - loss: 0.4120 - val_accuracy: 0.9545 - val_loss: 0.4771\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.4035 - val_accuracy: 0.9659 - val_loss: 0.4422\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9728 - loss: 0.3855 - val_accuracy: 0.9318 - val_loss: 0.4891\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9246 - loss: 0.4997 - val_accuracy: 0.9432 - val_loss: 0.5029\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9675 - loss: 0.4374 - val_accuracy: 0.9773 - val_loss: 0.3575\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9603 - loss: 0.4112 - val_accuracy: 0.9773 - val_loss: 0.5041\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9650 - loss: 0.3762 - val_accuracy: 0.9545 - val_loss: 0.4970\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9503 - loss: 0.4163 - val_accuracy: 0.9545 - val_loss: 0.4853\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9446 - loss: 0.4333 - val_accuracy: 0.9545 - val_loss: 0.5037\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.3649 - val_accuracy: 0.9545 - val_loss: 0.4531\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9697 - loss: 0.3545 - val_accuracy: 0.9659 - val_loss: 0.4417\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9618 - loss: 0.3918 - val_accuracy: 0.9659 - val_loss: 0.4461\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9633 - loss: 0.3729 - val_accuracy: 0.9773 - val_loss: 0.4784\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9581 - loss: 0.3584 - val_accuracy: 0.9659 - val_loss: 0.5233\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9769 - loss: 0.3701 - val_accuracy: 0.9545 - val_loss: 0.5621\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9619 - loss: 0.3884 - val_accuracy: 0.9545 - val_loss: 0.5714\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9598 - loss: 0.3946 - val_accuracy: 0.9773 - val_loss: 0.4062\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9268 - loss: 0.5125 - val_accuracy: 0.9773 - val_loss: 0.4069\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9349 - loss: 0.3923 - val_accuracy: 0.9886 - val_loss: 0.4015\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9447 - loss: 0.3644 - val_accuracy: 0.9886 - val_loss: 0.3856\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9422 - loss: 0.4231 - val_accuracy: 0.9545 - val_loss: 0.4875\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9713 - loss: 0.3627 - val_accuracy: 0.9318 - val_loss: 0.5027\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9451 - loss: 0.4274 - val_accuracy: 0.9318 - val_loss: 0.5483\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9655 - loss: 0.3889 - val_accuracy: 0.9432 - val_loss: 0.4807\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9581 - loss: 0.4010 - val_accuracy: 0.9886 - val_loss: 0.3853\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9493 - loss: 0.4747 - val_accuracy: 0.9432 - val_loss: 0.5319\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9467 - loss: 0.4820 - val_accuracy: 0.9318 - val_loss: 0.4137\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9336 - loss: 0.4240 - val_accuracy: 0.9886 - val_loss: 0.3224\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9746 - loss: 0.3436 - val_accuracy: 0.9432 - val_loss: 0.4179\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9495 - loss: 0.3975 - val_accuracy: 0.9886 - val_loss: 0.3703\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9890 - loss: 0.2936 - val_accuracy: 0.9886 - val_loss: 0.3630\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9867 - loss: 0.2922 - val_accuracy: 0.9773 - val_loss: 0.3830\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9432 - loss: 0.3779 - val_accuracy: 0.9886 - val_loss: 0.3412\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9628 - loss: 0.3410 - val_accuracy: 0.9886 - val_loss: 0.3671\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9640 - loss: 0.3778 - val_accuracy: 0.9432 - val_loss: 0.3867\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9399 - loss: 0.3917 - val_accuracy: 0.9432 - val_loss: 0.3763\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9276 - loss: 0.3929 - val_accuracy: 0.9432 - val_loss: 0.3579\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9415 - loss: 0.3766 - val_accuracy: 0.9432 - val_loss: 0.3976\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9509 - loss: 0.3452 - val_accuracy: 0.9545 - val_loss: 0.4257\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.3269 - val_accuracy: 0.9773 - val_loss: 0.4193\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9522 - loss: 0.3643 - val_accuracy: 0.9773 - val_loss: 0.3738\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9378 - loss: 0.4647 - val_accuracy: 0.9432 - val_loss: 0.5196\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9570 - loss: 0.4048 - val_accuracy: 0.9659 - val_loss: 0.4129\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9333 - loss: 0.4756 - val_accuracy: 0.9432 - val_loss: 0.4923\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9033 - loss: 0.5823 - val_accuracy: 0.9659 - val_loss: 0.3818\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9540 - loss: 0.3651 - val_accuracy: 0.9886 - val_loss: 0.3835\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9703 - loss: 0.3380 - val_accuracy: 0.9545 - val_loss: 0.4141\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9495 - loss: 0.3525 - val_accuracy: 0.9318 - val_loss: 0.5551\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9528 - loss: 0.3984 - val_accuracy: 0.9886 - val_loss: 0.3728\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9658 - loss: 0.3035 - val_accuracy: 0.9886 - val_loss: 0.3612\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9824 - loss: 0.2890 - val_accuracy: 0.9886 - val_loss: 0.3582\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.2588 - val_accuracy: 0.9773 - val_loss: 0.3626\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9944 - loss: 0.2536 - val_accuracy: 0.9773 - val_loss: 0.3611\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9968 - loss: 0.2451 - val_accuracy: 0.9773 - val_loss: 0.3572\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9866 - loss: 0.2605 - val_accuracy: 0.9773 - val_loss: 0.3521\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9928 - loss: 0.2403 - val_accuracy: 0.9886 - val_loss: 0.3479\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.2281 - val_accuracy: 0.9886 - val_loss: 0.3472\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9936 - loss: 0.2490 - val_accuracy: 0.9773 - val_loss: 0.3625\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9933 - loss: 0.2348 - val_accuracy: 0.9773 - val_loss: 0.3509\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.2405 - val_accuracy: 0.9773 - val_loss: 0.3583\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.2292 - val_accuracy: 0.9773 - val_loss: 0.3508\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9928 - loss: 0.2154 - val_accuracy: 0.9773 - val_loss: 0.3497\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.2194 - val_accuracy: 0.9773 - val_loss: 0.3498\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9960 - loss: 0.2156 - val_accuracy: 0.9773 - val_loss: 0.3463\n",
            "\n",
            "Fold 7 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.1120 - loss: 3.5318 - val_accuracy: 0.2159 - val_loss: 3.2374\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2931 - loss: 3.0889 - val_accuracy: 0.3750 - val_loss: 2.6374\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4486 - loss: 2.5228 - val_accuracy: 0.5568 - val_loss: 2.0871\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5745 - loss: 2.0331 - val_accuracy: 0.7841 - val_loss: 1.5946\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6373 - loss: 1.6837 - val_accuracy: 0.7273 - val_loss: 1.3026\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7031 - loss: 1.4807 - val_accuracy: 0.7955 - val_loss: 1.1100\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7759 - loss: 1.2549 - val_accuracy: 0.7841 - val_loss: 0.9749\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7883 - loss: 1.1439 - val_accuracy: 0.8750 - val_loss: 0.8708\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8383 - loss: 1.0222 - val_accuracy: 0.7955 - val_loss: 0.9080\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8394 - loss: 0.9768 - val_accuracy: 0.9205 - val_loss: 0.7076\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8077 - loss: 0.9541 - val_accuracy: 0.8864 - val_loss: 0.7462\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8188 - loss: 0.8809 - val_accuracy: 0.9205 - val_loss: 0.6748\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8704 - loss: 0.7515 - val_accuracy: 0.8750 - val_loss: 0.6740\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8802 - loss: 0.7820 - val_accuracy: 0.9318 - val_loss: 0.6480\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8904 - loss: 0.7152 - val_accuracy: 0.9318 - val_loss: 0.5913\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8799 - loss: 0.6905 - val_accuracy: 0.8750 - val_loss: 0.5785\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9034 - loss: 0.6808 - val_accuracy: 0.9318 - val_loss: 0.5747\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8954 - loss: 0.6531 - val_accuracy: 0.9545 - val_loss: 0.5481\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9254 - loss: 0.6375 - val_accuracy: 0.8977 - val_loss: 0.6347\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9145 - loss: 0.5845 - val_accuracy: 0.9205 - val_loss: 0.5846\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8965 - loss: 0.6357 - val_accuracy: 0.9205 - val_loss: 0.6839\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9161 - loss: 0.6172 - val_accuracy: 0.9318 - val_loss: 0.5073\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9231 - loss: 0.5933 - val_accuracy: 0.9659 - val_loss: 0.4503\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9226 - loss: 0.5731 - val_accuracy: 0.9545 - val_loss: 0.5096\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8598 - loss: 0.6912 - val_accuracy: 0.8864 - val_loss: 0.5786\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8841 - loss: 0.6403 - val_accuracy: 0.9545 - val_loss: 0.5031\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8893 - loss: 0.6212 - val_accuracy: 0.9773 - val_loss: 0.4184\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9496 - loss: 0.5038 - val_accuracy: 0.9773 - val_loss: 0.3796\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9412 - loss: 0.5056 - val_accuracy: 0.8864 - val_loss: 0.5975\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8888 - loss: 0.6172 - val_accuracy: 0.8864 - val_loss: 0.5981\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8795 - loss: 0.6266 - val_accuracy: 0.9545 - val_loss: 0.4733\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8831 - loss: 0.6006 - val_accuracy: 0.9773 - val_loss: 0.4257\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9091 - loss: 0.5408 - val_accuracy: 0.9886 - val_loss: 0.3398\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9464 - loss: 0.4900 - val_accuracy: 0.9886 - val_loss: 0.3940\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9539 - loss: 0.4397 - val_accuracy: 0.9432 - val_loss: 0.3911\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9621 - loss: 0.4424 - val_accuracy: 0.9886 - val_loss: 0.3688\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9595 - loss: 0.4336 - val_accuracy: 0.9886 - val_loss: 0.3615\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9588 - loss: 0.4310 - val_accuracy: 0.9659 - val_loss: 0.3949\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9600 - loss: 0.4325 - val_accuracy: 0.9886 - val_loss: 0.3488\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9769 - loss: 0.3824 - val_accuracy: 0.9659 - val_loss: 0.3662\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9510 - loss: 0.4536 - val_accuracy: 0.9545 - val_loss: 0.3638\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8975 - loss: 0.6177 - val_accuracy: 0.9318 - val_loss: 0.4039\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9323 - loss: 0.4558 - val_accuracy: 0.9886 - val_loss: 0.3483\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9685 - loss: 0.3969 - val_accuracy: 0.9886 - val_loss: 0.3266\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9642 - loss: 0.4197 - val_accuracy: 0.9886 - val_loss: 0.3107\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9827 - loss: 0.3365 - val_accuracy: 0.9886 - val_loss: 0.3024\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9746 - loss: 0.3396 - val_accuracy: 0.9773 - val_loss: 0.3047\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9922 - loss: 0.3165 - val_accuracy: 0.9432 - val_loss: 0.3513\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: 0.3778 - val_accuracy: 0.9659 - val_loss: 0.3634\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9474 - loss: 0.4250 - val_accuracy: 0.9432 - val_loss: 0.5142\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9444 - loss: 0.4395 - val_accuracy: 0.9545 - val_loss: 0.3713\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.3734 - val_accuracy: 0.9773 - val_loss: 0.3473\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9647 - loss: 0.3820 - val_accuracy: 0.9659 - val_loss: 0.4433\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.3174 - val_accuracy: 0.9773 - val_loss: 0.3583\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9889 - loss: 0.3112 - val_accuracy: 0.9773 - val_loss: 0.3172\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9887 - loss: 0.3005 - val_accuracy: 0.9773 - val_loss: 0.3239\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9815 - loss: 0.3024 - val_accuracy: 0.9773 - val_loss: 0.3401\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9876 - loss: 0.3067 - val_accuracy: 0.9886 - val_loss: 0.2660\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9864 - loss: 0.3019 - val_accuracy: 0.9773 - val_loss: 0.3352\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9707 - loss: 0.3392 - val_accuracy: 0.8864 - val_loss: 0.4865\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9321 - loss: 0.4124 - val_accuracy: 0.9432 - val_loss: 0.4179\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9528 - loss: 0.3717 - val_accuracy: 0.9773 - val_loss: 0.3365\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9708 - loss: 0.3495 - val_accuracy: 0.9773 - val_loss: 0.3410\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9832 - loss: 0.3046 - val_accuracy: 0.9886 - val_loss: 0.2644\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9758 - loss: 0.3318 - val_accuracy: 0.9432 - val_loss: 0.3443\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9512 - loss: 0.4037 - val_accuracy: 0.9318 - val_loss: 0.3065\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9682 - loss: 0.3358 - val_accuracy: 0.9545 - val_loss: 0.3239\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9767 - loss: 0.3206 - val_accuracy: 0.9886 - val_loss: 0.2670\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9897 - loss: 0.2769 - val_accuracy: 0.9773 - val_loss: 0.2667\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9795 - loss: 0.2866 - val_accuracy: 0.9773 - val_loss: 0.3185\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9932 - loss: 0.2582 - val_accuracy: 0.9773 - val_loss: 0.2833\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9928 - loss: 0.2661 - val_accuracy: 0.9886 - val_loss: 0.2423\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9846 - loss: 0.2768 - val_accuracy: 0.9773 - val_loss: 0.2816\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.2461 - val_accuracy: 0.9886 - val_loss: 0.2904\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.2422 - val_accuracy: 0.9886 - val_loss: 0.2663\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9921 - loss: 0.2420 - val_accuracy: 0.9773 - val_loss: 0.2858\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9926 - loss: 0.2429 - val_accuracy: 0.9773 - val_loss: 0.2617\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9904 - loss: 0.2472 - val_accuracy: 0.9773 - val_loss: 0.2688\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9813 - loss: 0.2617 - val_accuracy: 0.9886 - val_loss: 0.2533\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.2346 - val_accuracy: 0.9886 - val_loss: 0.2229\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.2224 - val_accuracy: 0.9886 - val_loss: 0.2455\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9943 - loss: 0.2298 - val_accuracy: 0.9886 - val_loss: 0.2485\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9878 - loss: 0.2364 - val_accuracy: 0.9659 - val_loss: 0.3489\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9929 - loss: 0.2394 - val_accuracy: 0.9773 - val_loss: 0.3246\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9811 - loss: 0.2500 - val_accuracy: 0.9773 - val_loss: 0.2420\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9830 - loss: 0.2702 - val_accuracy: 0.9773 - val_loss: 0.3396\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9599 - loss: 0.3347 - val_accuracy: 0.9886 - val_loss: 0.2768\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.2531 - val_accuracy: 0.9773 - val_loss: 0.3079\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9902 - loss: 0.2562 - val_accuracy: 0.9773 - val_loss: 0.3101\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9708 - loss: 0.3129 - val_accuracy: 0.9773 - val_loss: 0.3127\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.2639 - val_accuracy: 0.9886 - val_loss: 0.2135\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9581 - loss: 0.3724 - val_accuracy: 0.9659 - val_loss: 0.3427\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9547 - loss: 0.3723 - val_accuracy: 0.9773 - val_loss: 0.2789\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9776 - loss: 0.2847 - val_accuracy: 0.9091 - val_loss: 0.7181\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9380 - loss: 0.4966 - val_accuracy: 0.9091 - val_loss: 0.3827\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9672 - loss: 0.2988 - val_accuracy: 0.9886 - val_loss: 0.2537\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9860 - loss: 0.2461 - val_accuracy: 0.9659 - val_loss: 0.3414\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9888 - loss: 0.2260 - val_accuracy: 0.9773 - val_loss: 0.3002\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.2302 - val_accuracy: 0.9773 - val_loss: 0.3158\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.2332 - val_accuracy: 0.9773 - val_loss: 0.3131\n",
            "\n",
            "Fold 8 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.0423 - loss: 3.5812 - val_accuracy: 0.2841 - val_loss: 3.3263\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1998 - loss: 3.2089 - val_accuracy: 0.3523 - val_loss: 2.8296\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3656 - loss: 2.6898 - val_accuracy: 0.4318 - val_loss: 2.2891\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4061 - loss: 2.3138 - val_accuracy: 0.5682 - val_loss: 1.9883\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5375 - loss: 1.8976 - val_accuracy: 0.5568 - val_loss: 1.7031\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5869 - loss: 1.6534 - val_accuracy: 0.6250 - val_loss: 1.5359\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6134 - loss: 1.4891 - val_accuracy: 0.7159 - val_loss: 1.3142\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6864 - loss: 1.3474 - val_accuracy: 0.7500 - val_loss: 1.1873\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7326 - loss: 1.2298 - val_accuracy: 0.8068 - val_loss: 1.0190\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7252 - loss: 1.1526 - val_accuracy: 0.8409 - val_loss: 0.9755\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7673 - loss: 1.0683 - val_accuracy: 0.8523 - val_loss: 0.9319\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7622 - loss: 0.9910 - val_accuracy: 0.8750 - val_loss: 0.8390\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7975 - loss: 0.9461 - val_accuracy: 0.8409 - val_loss: 0.8170\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7968 - loss: 0.9134 - val_accuracy: 0.8068 - val_loss: 0.8847\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8414 - loss: 0.8345 - val_accuracy: 0.7955 - val_loss: 0.9048\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7832 - loss: 0.9844 - val_accuracy: 0.7955 - val_loss: 0.8636\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8306 - loss: 0.8349 - val_accuracy: 0.8523 - val_loss: 0.7078\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8445 - loss: 0.7369 - val_accuracy: 0.8864 - val_loss: 0.6389\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8626 - loss: 0.7243 - val_accuracy: 0.8523 - val_loss: 0.6950\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8322 - loss: 0.7628 - val_accuracy: 0.8182 - val_loss: 0.7633\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8731 - loss: 0.6832 - val_accuracy: 0.8068 - val_loss: 0.8074\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8450 - loss: 0.7103 - val_accuracy: 0.8523 - val_loss: 0.6263\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8590 - loss: 0.6721 - val_accuracy: 0.8523 - val_loss: 0.6338\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8857 - loss: 0.6461 - val_accuracy: 0.8068 - val_loss: 0.7969\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8473 - loss: 0.6572 - val_accuracy: 0.8864 - val_loss: 0.6108\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8764 - loss: 0.6599 - val_accuracy: 0.8750 - val_loss: 0.6570\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8795 - loss: 0.6388 - val_accuracy: 0.8750 - val_loss: 0.5609\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8665 - loss: 0.6462 - val_accuracy: 0.9432 - val_loss: 0.5569\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8880 - loss: 0.5593 - val_accuracy: 0.9659 - val_loss: 0.5102\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9259 - loss: 0.5248 - val_accuracy: 0.9318 - val_loss: 0.5184\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8891 - loss: 0.5753 - val_accuracy: 0.8977 - val_loss: 0.6675\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9090 - loss: 0.5271 - val_accuracy: 0.9091 - val_loss: 0.6529\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9226 - loss: 0.5085 - val_accuracy: 0.9205 - val_loss: 0.5757\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9140 - loss: 0.5182 - val_accuracy: 0.8864 - val_loss: 0.5607\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9049 - loss: 0.5067 - val_accuracy: 0.9545 - val_loss: 0.4958\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9622 - loss: 0.4438 - val_accuracy: 0.9545 - val_loss: 0.5516\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9591 - loss: 0.4478 - val_accuracy: 0.9205 - val_loss: 0.5101\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9393 - loss: 0.4678 - val_accuracy: 0.8977 - val_loss: 0.4986\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9371 - loss: 0.4457 - val_accuracy: 0.9773 - val_loss: 0.4278\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9359 - loss: 0.4874 - val_accuracy: 0.8409 - val_loss: 0.6624\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8863 - loss: 0.5633 - val_accuracy: 0.9091 - val_loss: 0.5602\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9110 - loss: 0.4898 - val_accuracy: 0.8977 - val_loss: 0.7525\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9374 - loss: 0.4684 - val_accuracy: 0.9205 - val_loss: 0.4568\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9624 - loss: 0.4006 - val_accuracy: 0.9432 - val_loss: 0.5238\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9654 - loss: 0.4104 - val_accuracy: 0.9659 - val_loss: 0.4697\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9735 - loss: 0.3733 - val_accuracy: 0.9545 - val_loss: 0.4905\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9831 - loss: 0.3637 - val_accuracy: 0.9432 - val_loss: 0.4817\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9575 - loss: 0.4008 - val_accuracy: 0.8977 - val_loss: 0.5772\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9469 - loss: 0.4568 - val_accuracy: 0.9432 - val_loss: 0.4683\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9617 - loss: 0.3888 - val_accuracy: 0.9545 - val_loss: 0.4846\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9640 - loss: 0.3949 - val_accuracy: 0.9545 - val_loss: 0.4497\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9563 - loss: 0.4098 - val_accuracy: 0.9432 - val_loss: 0.4619\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9234 - loss: 0.4830 - val_accuracy: 0.9091 - val_loss: 0.6411\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9471 - loss: 0.4722 - val_accuracy: 0.9432 - val_loss: 0.4810\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.3492 - val_accuracy: 0.9545 - val_loss: 0.4256\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9693 - loss: 0.3992 - val_accuracy: 0.9545 - val_loss: 0.3780\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.3256 - val_accuracy: 0.9545 - val_loss: 0.4102\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9641 - loss: 0.3516 - val_accuracy: 0.9318 - val_loss: 0.4429\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9915 - loss: 0.3138 - val_accuracy: 0.9545 - val_loss: 0.4000\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9754 - loss: 0.3351 - val_accuracy: 0.9545 - val_loss: 0.3881\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.2943 - val_accuracy: 0.9545 - val_loss: 0.4770\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9832 - loss: 0.2986 - val_accuracy: 0.9432 - val_loss: 0.4557\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9818 - loss: 0.3314 - val_accuracy: 0.9205 - val_loss: 0.5316\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9124 - loss: 0.5268 - val_accuracy: 0.9091 - val_loss: 0.5609\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9202 - loss: 0.4288 - val_accuracy: 0.8636 - val_loss: 0.9949\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8805 - loss: 0.5760 - val_accuracy: 0.9545 - val_loss: 0.5011\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9413 - loss: 0.4154 - val_accuracy: 0.9091 - val_loss: 0.6072\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8947 - loss: 0.5892 - val_accuracy: 0.9091 - val_loss: 0.4662\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9076 - loss: 0.4524 - val_accuracy: 0.9432 - val_loss: 0.4964\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9460 - loss: 0.3731 - val_accuracy: 0.9432 - val_loss: 0.4345\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9643 - loss: 0.3737 - val_accuracy: 0.9545 - val_loss: 0.3864\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9720 - loss: 0.3296 - val_accuracy: 0.9545 - val_loss: 0.3763\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9732 - loss: 0.3274 - val_accuracy: 0.9545 - val_loss: 0.3664\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9713 - loss: 0.3452 - val_accuracy: 0.9432 - val_loss: 0.4963\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9537 - loss: 0.3919 - val_accuracy: 0.9205 - val_loss: 0.5611\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9585 - loss: 0.3514 - val_accuracy: 0.9659 - val_loss: 0.4064\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9951 - loss: 0.2791 - val_accuracy: 0.9659 - val_loss: 0.3769\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9767 - loss: 0.3357 - val_accuracy: 0.9545 - val_loss: 0.4184\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9754 - loss: 0.3106 - val_accuracy: 0.9545 - val_loss: 0.4558\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9881 - loss: 0.2668 - val_accuracy: 0.9659 - val_loss: 0.4231\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.2717 - val_accuracy: 0.9545 - val_loss: 0.5231\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.2803 - val_accuracy: 0.9545 - val_loss: 0.5007\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.2582 - val_accuracy: 0.9659 - val_loss: 0.3763\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9899 - loss: 0.2557 - val_accuracy: 0.9091 - val_loss: 0.6213\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9580 - loss: 0.3556 - val_accuracy: 0.9659 - val_loss: 0.3864\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9895 - loss: 0.2652 - val_accuracy: 0.9773 - val_loss: 0.3554\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9532 - loss: 0.3753 - val_accuracy: 0.9545 - val_loss: 0.4643\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9674 - loss: 0.3227 - val_accuracy: 0.9773 - val_loss: 0.3599\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9831 - loss: 0.2943 - val_accuracy: 0.9659 - val_loss: 0.3711\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9918 - loss: 0.2617 - val_accuracy: 0.9773 - val_loss: 0.3465\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.2638 - val_accuracy: 0.9773 - val_loss: 0.3301\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.2442 - val_accuracy: 0.9773 - val_loss: 0.3303\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9914 - loss: 0.2392 - val_accuracy: 0.9773 - val_loss: 0.3652\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9917 - loss: 0.2313 - val_accuracy: 0.9773 - val_loss: 0.3628\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9908 - loss: 0.2396 - val_accuracy: 0.9773 - val_loss: 0.3550\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9958 - loss: 0.2301 - val_accuracy: 0.9659 - val_loss: 0.3717\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9920 - loss: 0.2390 - val_accuracy: 0.9659 - val_loss: 0.3754\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.2453 - val_accuracy: 0.9659 - val_loss: 0.3791\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.2552 - val_accuracy: 0.9659 - val_loss: 0.3753\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.2095 - val_accuracy: 0.9659 - val_loss: 0.3706\n",
            "\n",
            "Fold 9 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.0605 - loss: 3.5566 - val_accuracy: 0.1932 - val_loss: 3.3464\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2077 - loss: 3.2303 - val_accuracy: 0.2273 - val_loss: 2.9344\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.2969 - loss: 2.7956 - val_accuracy: 0.4091 - val_loss: 2.2951\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4733 - loss: 2.2472 - val_accuracy: 0.7159 - val_loss: 1.7217\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6684 - loss: 1.8073 - val_accuracy: 0.8409 - val_loss: 1.3400\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7589 - loss: 1.4861 - val_accuracy: 0.8977 - val_loss: 1.0710\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8110 - loss: 1.2425 - val_accuracy: 0.9091 - val_loss: 0.9164\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8783 - loss: 1.0599 - val_accuracy: 0.9659 - val_loss: 0.7292\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9016 - loss: 0.9202 - val_accuracy: 0.9545 - val_loss: 0.6445\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9234 - loss: 0.8281 - val_accuracy: 0.9091 - val_loss: 0.8428\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8653 - loss: 0.9203 - val_accuracy: 0.9318 - val_loss: 0.6565\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8827 - loss: 0.8317 - val_accuracy: 0.9545 - val_loss: 0.5825\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9011 - loss: 0.8011 - val_accuracy: 0.8864 - val_loss: 0.7045\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8700 - loss: 0.8632 - val_accuracy: 0.9318 - val_loss: 0.6186\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8846 - loss: 0.7156 - val_accuracy: 0.8750 - val_loss: 0.6295\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9226 - loss: 0.6390 - val_accuracy: 0.9318 - val_loss: 0.5643\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9144 - loss: 0.6203 - val_accuracy: 0.9432 - val_loss: 0.5105\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9156 - loss: 0.6454 - val_accuracy: 0.9773 - val_loss: 0.4672\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9397 - loss: 0.5647 - val_accuracy: 0.8977 - val_loss: 0.7317\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8862 - loss: 0.7371 - val_accuracy: 0.9432 - val_loss: 0.5492\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8982 - loss: 0.6333 - val_accuracy: 0.9545 - val_loss: 0.4875\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9476 - loss: 0.5229 - val_accuracy: 0.9545 - val_loss: 0.4618\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9593 - loss: 0.5105 - val_accuracy: 0.9205 - val_loss: 0.4866\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9413 - loss: 0.5466 - val_accuracy: 0.9205 - val_loss: 0.5219\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9363 - loss: 0.5053 - val_accuracy: 0.9318 - val_loss: 0.4990\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9564 - loss: 0.4708 - val_accuracy: 0.9432 - val_loss: 0.4651\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9562 - loss: 0.4800 - val_accuracy: 0.9432 - val_loss: 0.4177\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9547 - loss: 0.4535 - val_accuracy: 0.9659 - val_loss: 0.3853\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9499 - loss: 0.5017 - val_accuracy: 0.9205 - val_loss: 0.5730\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9510 - loss: 0.4727 - val_accuracy: 0.9545 - val_loss: 0.4339\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9183 - loss: 0.5444 - val_accuracy: 0.9773 - val_loss: 0.3993\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9653 - loss: 0.4535 - val_accuracy: 0.9773 - val_loss: 0.3644\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9765 - loss: 0.3917 - val_accuracy: 0.9659 - val_loss: 0.3786\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9715 - loss: 0.3969 - val_accuracy: 0.9659 - val_loss: 0.3719\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9721 - loss: 0.4015 - val_accuracy: 0.9318 - val_loss: 0.4367\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9467 - loss: 0.4430 - val_accuracy: 0.9659 - val_loss: 0.4242\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9539 - loss: 0.4196 - val_accuracy: 0.9318 - val_loss: 0.5325\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9540 - loss: 0.4618 - val_accuracy: 0.9773 - val_loss: 0.3640\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9736 - loss: 0.3797 - val_accuracy: 0.9659 - val_loss: 0.3792\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9664 - loss: 0.4012 - val_accuracy: 0.9318 - val_loss: 0.4346\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9332 - loss: 0.4374 - val_accuracy: 0.9318 - val_loss: 0.4222\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9232 - loss: 0.4643 - val_accuracy: 0.9545 - val_loss: 0.4442\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9561 - loss: 0.4075 - val_accuracy: 0.9432 - val_loss: 0.4111\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9638 - loss: 0.3850 - val_accuracy: 0.9432 - val_loss: 0.4506\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9369 - loss: 0.4836 - val_accuracy: 0.9318 - val_loss: 0.4699\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9427 - loss: 0.4242 - val_accuracy: 0.9432 - val_loss: 0.4678\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9521 - loss: 0.4271 - val_accuracy: 0.9091 - val_loss: 0.5220\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9457 - loss: 0.4295 - val_accuracy: 0.9545 - val_loss: 0.4164\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9697 - loss: 0.3395 - val_accuracy: 0.9432 - val_loss: 0.4182\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9825 - loss: 0.3599 - val_accuracy: 0.9545 - val_loss: 0.4250\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9703 - loss: 0.3754 - val_accuracy: 0.9432 - val_loss: 0.4417\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9617 - loss: 0.3670 - val_accuracy: 0.9091 - val_loss: 0.5167\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9778 - loss: 0.3664 - val_accuracy: 0.9318 - val_loss: 0.3573\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9754 - loss: 0.3503 - val_accuracy: 0.9545 - val_loss: 0.3680\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9791 - loss: 0.3114 - val_accuracy: 0.9318 - val_loss: 0.4295\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: 0.3604 - val_accuracy: 0.9432 - val_loss: 0.3652\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9670 - loss: 0.3575 - val_accuracy: 0.9205 - val_loss: 0.4241\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9725 - loss: 0.3415 - val_accuracy: 0.9545 - val_loss: 0.3856\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9851 - loss: 0.3038 - val_accuracy: 0.9545 - val_loss: 0.3839\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9928 - loss: 0.2754 - val_accuracy: 0.9545 - val_loss: 0.3692\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9803 - loss: 0.3181 - val_accuracy: 0.9432 - val_loss: 0.4212\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9969 - loss: 0.2572 - val_accuracy: 0.9545 - val_loss: 0.3823\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9777 - loss: 0.2974 - val_accuracy: 0.9545 - val_loss: 0.4015\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9876 - loss: 0.2784 - val_accuracy: 0.9545 - val_loss: 0.3831\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9853 - loss: 0.2913 - val_accuracy: 0.9659 - val_loss: 0.3645\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9862 - loss: 0.2990 - val_accuracy: 0.9545 - val_loss: 0.3496\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.2903 - val_accuracy: 0.9659 - val_loss: 0.3409\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9886 - loss: 0.2743 - val_accuracy: 0.9659 - val_loss: 0.3395\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9878 - loss: 0.2568 - val_accuracy: 0.9659 - val_loss: 0.3306\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.2600 - val_accuracy: 0.9659 - val_loss: 0.3252\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9944 - loss: 0.2338 - val_accuracy: 0.9659 - val_loss: 0.3156\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9910 - loss: 0.2330 - val_accuracy: 0.9659 - val_loss: 0.3288\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9915 - loss: 0.2555 - val_accuracy: 0.9659 - val_loss: 0.3106\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9771 - loss: 0.2898 - val_accuracy: 0.9773 - val_loss: 0.2855\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9960 - loss: 0.2345 - val_accuracy: 0.9773 - val_loss: 0.2849\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9821 - loss: 0.2647 - val_accuracy: 0.9773 - val_loss: 0.2847\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9880 - loss: 0.2605 - val_accuracy: 0.9773 - val_loss: 0.2799\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9943 - loss: 0.2264 - val_accuracy: 0.9545 - val_loss: 0.4199\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9282 - loss: 0.4854 - val_accuracy: 0.8864 - val_loss: 0.5788\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8998 - loss: 0.4401 - val_accuracy: 0.9205 - val_loss: 0.5182\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9482 - loss: 0.3541 - val_accuracy: 0.9432 - val_loss: 0.4098\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9505 - loss: 0.3470 - val_accuracy: 0.9091 - val_loss: 0.4363\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9684 - loss: 0.3184 - val_accuracy: 0.9205 - val_loss: 0.4269\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9164 - loss: 0.5638 - val_accuracy: 0.8977 - val_loss: 0.4110\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9291 - loss: 0.3827 - val_accuracy: 0.9432 - val_loss: 0.3525\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9578 - loss: 0.3257 - val_accuracy: 0.9545 - val_loss: 0.3080\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9441 - loss: 0.3997 - val_accuracy: 0.8977 - val_loss: 0.6415\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9105 - loss: 0.4256 - val_accuracy: 0.9318 - val_loss: 0.4261\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9144 - loss: 0.4707 - val_accuracy: 0.9318 - val_loss: 0.3782\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9357 - loss: 0.3652 - val_accuracy: 0.9545 - val_loss: 0.3412\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9516 - loss: 0.3243 - val_accuracy: 0.9545 - val_loss: 0.3098\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9659 - loss: 0.3148 - val_accuracy: 0.9659 - val_loss: 0.2644\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9788 - loss: 0.2787 - val_accuracy: 0.9773 - val_loss: 0.2318\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9886 - loss: 0.2505 - val_accuracy: 0.9773 - val_loss: 0.2499\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9922 - loss: 0.2444 - val_accuracy: 0.9773 - val_loss: 0.2616\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9904 - loss: 0.2285 - val_accuracy: 0.9773 - val_loss: 0.2559\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9839 - loss: 0.2342 - val_accuracy: 0.9773 - val_loss: 0.2564\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9932 - loss: 0.2272 - val_accuracy: 0.9773 - val_loss: 0.2588\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9961 - loss: 0.2138 - val_accuracy: 0.9773 - val_loss: 0.2655\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9924 - loss: 0.2145 - val_accuracy: 0.9773 - val_loss: 0.2645\n",
            "\n",
            "Fold 10 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.1303 - loss: 3.5198 - val_accuracy: 0.2989 - val_loss: 3.1117\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2671 - loss: 3.1222 - val_accuracy: 0.3103 - val_loss: 2.5474\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3247 - loss: 2.6555 - val_accuracy: 0.5977 - val_loss: 2.0302\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5341 - loss: 2.2043 - val_accuracy: 0.6897 - val_loss: 1.6681\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6289 - loss: 1.8044 - val_accuracy: 0.7586 - val_loss: 1.3735\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7121 - loss: 1.4989 - val_accuracy: 0.7816 - val_loss: 1.2303\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7702 - loss: 1.3366 - val_accuracy: 0.7816 - val_loss: 1.1170\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8159 - loss: 1.1769 - val_accuracy: 0.8161 - val_loss: 1.0352\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8119 - loss: 1.0539 - val_accuracy: 0.7586 - val_loss: 0.9846\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8450 - loss: 0.9509 - val_accuracy: 0.8621 - val_loss: 0.9863\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8183 - loss: 0.9738 - val_accuracy: 0.8621 - val_loss: 0.8733\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8544 - loss: 0.8978 - val_accuracy: 0.9195 - val_loss: 0.7837\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8806 - loss: 0.8263 - val_accuracy: 0.9195 - val_loss: 0.7058\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9382 - loss: 0.6704 - val_accuracy: 0.9080 - val_loss: 0.7500\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9061 - loss: 0.7109 - val_accuracy: 0.8391 - val_loss: 0.8863\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9057 - loss: 0.6751 - val_accuracy: 0.9080 - val_loss: 0.6855\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9197 - loss: 0.6836 - val_accuracy: 0.9425 - val_loss: 0.6798\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9237 - loss: 0.6662 - val_accuracy: 0.9310 - val_loss: 0.6959\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9077 - loss: 0.6623 - val_accuracy: 0.9310 - val_loss: 0.6934\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9237 - loss: 0.6287 - val_accuracy: 0.9080 - val_loss: 0.6566\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9351 - loss: 0.5291 - val_accuracy: 0.9540 - val_loss: 0.6352\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9463 - loss: 0.5660 - val_accuracy: 0.9195 - val_loss: 0.6679\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9421 - loss: 0.5389 - val_accuracy: 0.8851 - val_loss: 0.6722\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9233 - loss: 0.5691 - val_accuracy: 0.8391 - val_loss: 0.9395\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9085 - loss: 0.6374 - val_accuracy: 0.8851 - val_loss: 0.7046\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9085 - loss: 0.5951 - val_accuracy: 0.9655 - val_loss: 0.5488\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9174 - loss: 0.5580 - val_accuracy: 0.9655 - val_loss: 0.5635\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9413 - loss: 0.5498 - val_accuracy: 0.9310 - val_loss: 0.6344\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9482 - loss: 0.5015 - val_accuracy: 0.9310 - val_loss: 0.6127\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9492 - loss: 0.4737 - val_accuracy: 0.8161 - val_loss: 0.8485\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8625 - loss: 0.8013 - val_accuracy: 0.8161 - val_loss: 0.9973\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8360 - loss: 0.7732 - val_accuracy: 0.8621 - val_loss: 0.7485\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9009 - loss: 0.6050 - val_accuracy: 0.9310 - val_loss: 0.6573\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9363 - loss: 0.4767 - val_accuracy: 0.9770 - val_loss: 0.5733\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9328 - loss: 0.5484 - val_accuracy: 0.9770 - val_loss: 0.5542\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9430 - loss: 0.5046 - val_accuracy: 0.9655 - val_loss: 0.5730\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9700 - loss: 0.4582 - val_accuracy: 0.9310 - val_loss: 0.6147\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9465 - loss: 0.4444 - val_accuracy: 0.9770 - val_loss: 0.5473\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.3737 - val_accuracy: 0.9655 - val_loss: 0.5292\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9741 - loss: 0.4190 - val_accuracy: 0.9655 - val_loss: 0.5327\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9605 - loss: 0.4564 - val_accuracy: 0.9310 - val_loss: 0.6173\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9651 - loss: 0.4100 - val_accuracy: 0.9425 - val_loss: 0.5971\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9798 - loss: 0.3651 - val_accuracy: 0.9540 - val_loss: 0.5572\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9732 - loss: 0.4033 - val_accuracy: 0.8966 - val_loss: 0.6934\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9535 - loss: 0.4283 - val_accuracy: 0.9655 - val_loss: 0.5438\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.3690 - val_accuracy: 0.9425 - val_loss: 0.5507\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9573 - loss: 0.4215 - val_accuracy: 0.9425 - val_loss: 0.5669\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9642 - loss: 0.4099 - val_accuracy: 0.9540 - val_loss: 0.5687\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9650 - loss: 0.3993 - val_accuracy: 0.9770 - val_loss: 0.5198\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9617 - loss: 0.4141 - val_accuracy: 0.9540 - val_loss: 0.5985\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9501 - loss: 0.4256 - val_accuracy: 0.9540 - val_loss: 0.6069\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9651 - loss: 0.3764 - val_accuracy: 0.9425 - val_loss: 0.6072\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.3525 - val_accuracy: 0.9655 - val_loss: 0.5329\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9928 - loss: 0.3228 - val_accuracy: 0.9655 - val_loss: 0.4996\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9868 - loss: 0.3183 - val_accuracy: 0.9655 - val_loss: 0.5063\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9710 - loss: 0.3477 - val_accuracy: 0.9195 - val_loss: 0.6582\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9657 - loss: 0.3589 - val_accuracy: 0.9655 - val_loss: 0.5100\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.3353 - val_accuracy: 0.9655 - val_loss: 0.4957\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9852 - loss: 0.3047 - val_accuracy: 0.9540 - val_loss: 0.5281\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9864 - loss: 0.3221 - val_accuracy: 0.9655 - val_loss: 0.5004\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9894 - loss: 0.2861 - val_accuracy: 0.9080 - val_loss: 0.6461\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9843 - loss: 0.3140 - val_accuracy: 0.9540 - val_loss: 0.5218\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9642 - loss: 0.3402 - val_accuracy: 0.9655 - val_loss: 0.5139\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.2903 - val_accuracy: 0.9540 - val_loss: 0.5304\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.2781 - val_accuracy: 0.9310 - val_loss: 0.5586\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9895 - loss: 0.2850 - val_accuracy: 0.9655 - val_loss: 0.5196\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9851 - loss: 0.3014 - val_accuracy: 0.9655 - val_loss: 0.5205\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9893 - loss: 0.2780 - val_accuracy: 0.9655 - val_loss: 0.5007\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9962 - loss: 0.2525 - val_accuracy: 0.9540 - val_loss: 0.5080\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9856 - loss: 0.2803 - val_accuracy: 0.9655 - val_loss: 0.5099\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9885 - loss: 0.2872 - val_accuracy: 0.9540 - val_loss: 0.5452\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.2561 - val_accuracy: 0.9540 - val_loss: 0.5406\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9881 - loss: 0.2693 - val_accuracy: 0.9540 - val_loss: 0.5356\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9928 - loss: 0.2483 - val_accuracy: 0.9655 - val_loss: 0.5139\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9861 - loss: 0.2686 - val_accuracy: 0.9425 - val_loss: 0.6676\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9103 - loss: 0.5675 - val_accuracy: 0.9080 - val_loss: 0.7270\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9326 - loss: 0.4549 - val_accuracy: 0.9540 - val_loss: 0.5561\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9293 - loss: 0.4435 - val_accuracy: 0.9655 - val_loss: 0.5014\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9448 - loss: 0.4409 - val_accuracy: 0.8506 - val_loss: 0.7022\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8862 - loss: 0.5661 - val_accuracy: 0.9770 - val_loss: 0.5069\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9507 - loss: 0.3815 - val_accuracy: 0.9540 - val_loss: 0.4791\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9622 - loss: 0.3597 - val_accuracy: 0.9655 - val_loss: 0.4838\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9528 - loss: 0.3585 - val_accuracy: 0.9195 - val_loss: 0.5462\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9662 - loss: 0.3434 - val_accuracy: 0.9540 - val_loss: 0.5277\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9767 - loss: 0.3439 - val_accuracy: 0.9425 - val_loss: 0.5749\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9761 - loss: 0.3059 - val_accuracy: 0.9540 - val_loss: 0.5112\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9809 - loss: 0.2927 - val_accuracy: 0.9425 - val_loss: 0.5341\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9532 - loss: 0.3439 - val_accuracy: 0.9655 - val_loss: 0.5105\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9717 - loss: 0.3194 - val_accuracy: 0.9195 - val_loss: 0.5620\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.2874 - val_accuracy: 0.9540 - val_loss: 0.5132\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9803 - loss: 0.2733 - val_accuracy: 0.9655 - val_loss: 0.5234\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9820 - loss: 0.2791 - val_accuracy: 0.9540 - val_loss: 0.5328\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9921 - loss: 0.2515 - val_accuracy: 0.9655 - val_loss: 0.5185\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9661 - loss: 0.2925 - val_accuracy: 0.9540 - val_loss: 0.5078\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9793 - loss: 0.2737 - val_accuracy: 0.9655 - val_loss: 0.4982\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9867 - loss: 0.2478 - val_accuracy: 0.9655 - val_loss: 0.5080\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.2359 - val_accuracy: 0.9540 - val_loss: 0.4978\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9880 - loss: 0.2467 - val_accuracy: 0.7816 - val_loss: 1.9220\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8586 - loss: 0.7748 - val_accuracy: 0.8621 - val_loss: 0.6357\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9179 - loss: 0.4338 - val_accuracy: 0.8966 - val_loss: 0.6154\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define LSTM model with regularization\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(25, 84), kernel_regularizer=l2(0.001)),\n",
        "        Dropout(0.4),  # Dropout added to prevent overfitting\n",
        "        LSTM(32, return_sequences=False, kernel_regularizer=l2(0.002)),\n",
        "        Dropout(0.4),\n",
        "        Dense(32, activation='relu', kernel_regularizer=l2(0.002)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 10-Fold Cross-Validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "accuracy_scores = []\n",
        "val_losses = []  # Store validation losses\n",
        "val_accuracies = []  # Store validation accuracies\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X_seq)):\n",
        "    print(f\"\\nFold {fold+1} / {kf.get_n_splits()}\")\n",
        "\n",
        "    X_train, X_test = X_seq[train_index], X_seq[test_index]\n",
        "    y_train, y_test = Y_seq[train_index], Y_seq[test_index]\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    model = create_model()\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    val_losses.append(history.history['val_loss'])\n",
        "    val_accuracies.append(history.history['val_accuracy'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEbOYo9O22bo",
        "outputId": "b930c343-201f-41e9-e1a4-4587496476d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mean Test Accuracy over 10 folds: 0.9522\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "print(f\"\\nMean Test Accuracy over {len(accuracy_scores)} folds: {mean_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "MHWOCO0iwCEJ",
        "outputId": "4b9dc29b-a542-4304-efef-d55d3aeea823"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mean Accuracy: 0.9522\n"
          ]
        }
      ],
      "source": [
        "# Plot Validation Loss and Accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "for i in range(5):\n",
        "    plt.plot(val_losses[i], label=f'Fold {i+1}')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.title(\"Validation Loss per Fold\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot Validation Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "for i in range(5):\n",
        "    plt.plot(val_accuracies[i], label=f'Fold {i+1}')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Validation Accuracy per Fold\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nMean Accuracy: {np.mean(accuracy_scores):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVKXn2Iw4QH9"
      },
      "source": [
        "# Leave one person out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kTsha_M4mYK",
        "outputId": "4aa12043-bea4-47ef-d113-0279c00c48e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (879, 25, 84)\n",
            "Y shape: (879,)\n",
            "P shape: (879,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[ 0.73493975, -0.03614458,  0.48364887, ..., -0.28055078,\n",
              "         -0.72805506, -0.28743544],\n",
              "        [ 0.73402417, -0.04490501,  0.48531953, ..., -0.28324696,\n",
              "         -0.7202073 , -0.29360968],\n",
              "        [ 0.7241379 , -0.04827586,  0.4827586 , ..., -0.2724138 ,\n",
              "         -0.7137931 , -0.28275862],\n",
              "        ...,\n",
              "        [ 0.694859  , -0.03482587,  0.45605308, ..., -0.26699835,\n",
              "         -0.73134327, -0.28026533],\n",
              "        [ 0.70715475, -0.03494176,  0.4608985 , ..., -0.27454242,\n",
              "         -0.7237937 , -0.28785357],\n",
              "        [ 0.6981758 , -0.03980099,  0.45273632, ..., -0.2620232 ,\n",
              "         -0.7280265 , -0.27860695]],\n",
              "\n",
              "       [[ 0.69175625, -0.0609319 ,  0.41218638, ..., -0.28315413,\n",
              "         -0.60573477, -0.25448027],\n",
              "        [ 0.6802842 , -0.05861456,  0.39964476, ..., -0.28596804,\n",
              "         -0.61634105, -0.26110125],\n",
              "        [ 0.68817204, -0.05734767,  0.41218638, ..., -0.28673837,\n",
              "         -0.6236559 , -0.26523298],\n",
              "        ...,\n",
              "        [ 0.69174314, -0.07339449,  0.42018348, ..., -0.2825688 ,\n",
              "         -0.5963303 , -0.25321102],\n",
              "        [ 0.6886447 , -0.06959707,  0.41758242, ..., -0.2820513 ,\n",
              "         -0.6007326 , -0.25274727],\n",
              "        [ 0.6886447 , -0.06410256,  0.41391942, ..., -0.2838828 ,\n",
              "         -0.60805863, -0.25091577]],\n",
              "\n",
              "       [[ 0.7653061 , -0.04081633,  0.5136054 , ..., -0.26530612,\n",
              "         -0.6904762 , -0.24489796],\n",
              "        [ 0.74453783, -0.04201681,  0.49579832, ..., -0.26386556,\n",
              "         -0.687395  , -0.24369748],\n",
              "        [ 0.7483221 , -0.0352349 ,  0.4966443 , ..., -0.26677853,\n",
              "         -0.7013423 , -0.23993288],\n",
              "        ...,\n",
              "        [ 0.75972927, -0.04060914,  0.5025381 , ..., -0.26395938,\n",
              "         -0.69204736, -0.23688664],\n",
              "        [ 0.7631134 , -0.04060914,  0.5025381 , ..., -0.26395938,\n",
              "         -0.69204736, -0.23688664],\n",
              "        [ 0.75634515, -0.04060914,  0.49915397, ..., -0.2605753 ,\n",
              "         -0.6988156 , -0.23011844]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.32814372, -0.05868264,  0.1988024 , ..., -0.26946107,\n",
              "          0.23473054, -0.24311377],\n",
              "        [ 0.32806805, -0.05710814,  0.19684082, ..., -0.2636695 ,\n",
              "          0.2381531 , -0.23936817],\n",
              "        [ 0.32971016, -0.04830918,  0.19202898, ..., -0.2753623 ,\n",
              "          0.23309179, -0.25603864],\n",
              "        ...,\n",
              "        [ 0.3271028 , -0.03504673,  0.17523365, ..., -0.28738317,\n",
              "          0.20560747, -0.29205608],\n",
              "        [ 0.3278302 , -0.04245283,  0.18160377, ..., -0.28537735,\n",
              "          0.19339623, -0.29245284],\n",
              "        [ 0.33450294, -0.03391813,  0.18245614, ..., -0.29122806,\n",
              "          0.21052632, -0.29356724]],\n",
              "\n",
              "       [[ 0.33411214, -0.03037383,  0.17523365, ..., -0.29672897,\n",
              "          0.21962617, -0.30140188],\n",
              "        [ 0.34      , -0.03058824,  0.18      , ..., -0.29647058,\n",
              "          0.21529412, -0.29882354],\n",
              "        [ 0.32827103, -0.02570093,  0.18341121, ..., -0.29439253,\n",
              "          0.20443925, -0.29439253],\n",
              "        ...,\n",
              "        [ 0.40880504,  0.01383648,  0.27044025, ..., -0.22012578,\n",
              "          0.27295598, -0.23018868],\n",
              "        [ 0.4118388 ,  0.01259446,  0.27581865, ..., -0.21914358,\n",
              "          0.28085643, -0.22921914],\n",
              "        [ 0.40948814,  0.01123596,  0.27715355, ..., -0.22846442,\n",
              "          0.28214732, -0.23595506]],\n",
              "\n",
              "       [[ 0.40717822,  0.01732673,  0.27351484, ..., -0.23019803,\n",
              "          0.27351484, -0.24009901],\n",
              "        [ 0.41044775,  0.0199005 ,  0.27860695, ..., -0.22636816,\n",
              "          0.2761194 , -0.23383084],\n",
              "        [ 0.41016108,  0.02106567,  0.28376704, ..., -0.22428748,\n",
              "          0.27137548, -0.23172243],\n",
              "        ...,\n",
              "        [ 0.477208  ,  0.07692308,  0.32905984, ..., -0.21937323,\n",
              "          0.2777778 , -0.2022792 ],\n",
              "        [ 0.477208  ,  0.07692308,  0.33760685, ..., -0.22222222,\n",
              "          0.28917378, -0.2079772 ],\n",
              "        [ 0.47857141,  0.07714286,  0.34428573, ..., -0.22      ,\n",
              "          0.2957143 , -0.20857143]]], dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def load_and_prepare_data(csv_path):\n",
        "    # Load data from CSV\n",
        "    data = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "    # Convert to NumPy array for efficient processing\n",
        "    data = data.values\n",
        "\n",
        "    # Separate X (features) and Y (first column as labels)\n",
        "    Y = data[:, 0]  # First column as labels\n",
        "    P = data[:,1] # second column as Person number\n",
        "    X = data[:, 2:]  # All other columns as features (shape: num_samples, 84)\n",
        "\n",
        "    # Define sequence length\n",
        "    sequence_length = 25\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_seq, Y_seq , P_seq = [], [], []\n",
        "    num_sequences = len(X) // sequence_length\n",
        "\n",
        "    for i in range(num_sequences):\n",
        "        start_idx = i * sequence_length\n",
        "        X_seq.append(X[start_idx:start_idx + sequence_length])  # 25 rows of features\n",
        "        Y_seq.append(Y[start_idx])  # First column value corresponding to the sequence\n",
        "        P_seq.append(P[start_idx])\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_seq = np.array(X_seq)  # Shape: (num_sequences, 25, 84)\n",
        "    Y_seq = np.array(Y_seq)  # Shape: (num_sequences,)\n",
        "    P_seq = np.array(P_seq)\n",
        "\n",
        "    return X_seq, Y_seq, P_seq\n",
        "\n",
        "# Example usage\n",
        "csv_path = \"/content/Double Handed Keypoints 8th April-LSTM.csv\"  # Replace with actual path\n",
        "X_seq, Y_seq, P_seq = load_and_prepare_data(csv_path)\n",
        "print(\"X shape:\", X_seq.shape)  # Expected: (num_sequences, 25, 84)\n",
        "print(\"Y shape:\", Y_seq.shape)  # Expected: (num_sequences,)\n",
        "print(\"P shape:\", P_seq.shape)  # Expected: (num_sequences,\n",
        "\n",
        "# Encode Y_seq (convert string labels to integers)\n",
        "label_encoder = LabelEncoder()\n",
        "Y_seq = label_encoder.fit_transform(Y_seq)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "Y_seq = to_categorical(Y_seq, num_classes)\n",
        "\n",
        "X_seq.astype('float32')\n",
        "# Y_seq.dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJl_cSkB3MDs",
        "outputId": "2fa12618-6d39-4b6a-ff7a-e91f33e188a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==> Leave Person 1 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.0712 - loss: 3.5453\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2388 - loss: 3.1861\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3792 - loss: 2.7331\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5324 - loss: 2.2640\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6036 - loss: 1.8770\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6886 - loss: 1.5975\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7406 - loss: 1.4056\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7594 - loss: 1.3124\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7433 - loss: 1.3210\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8053 - loss: 1.1011\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8517 - loss: 0.9434\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8763 - loss: 0.8965\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8790 - loss: 0.8193\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8782 - loss: 0.7873\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8593 - loss: 0.7801\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9036 - loss: 0.7354\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8767 - loss: 0.7398\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8895 - loss: 0.7057\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8837 - loss: 0.7050\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8443 - loss: 0.8242\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8860 - loss: 0.7305\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9126 - loss: 0.6345\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9229 - loss: 0.6213\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9281 - loss: 0.5617\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9229 - loss: 0.6035\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9442 - loss: 0.5481\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9219 - loss: 0.5700\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9065 - loss: 0.5752\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9035 - loss: 0.5130\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8589 - loss: 0.8328\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8909 - loss: 0.6201\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9188 - loss: 0.5643\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8900 - loss: 0.6033\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9265 - loss: 0.4998\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9268 - loss: 0.5058\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9283 - loss: 0.4893\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9527 - loss: 0.4323\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9244 - loss: 0.4801\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9177 - loss: 0.5251\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9419 - loss: 0.4973\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9066 - loss: 0.4717\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9157 - loss: 0.4800\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9314 - loss: 0.4555\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9306 - loss: 0.4626\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9467 - loss: 0.4136\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9428 - loss: 0.4029\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.4195\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9575 - loss: 0.4027\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9471 - loss: 0.4056\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9592 - loss: 0.3831\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9532 - loss: 0.3654\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9410 - loss: 0.3857\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9321 - loss: 0.4170\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9209 - loss: 0.4091\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9205 - loss: 0.4264\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9427 - loss: 0.3778\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9440 - loss: 0.4029\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9674 - loss: 0.3352\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9467 - loss: 0.4040\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8563 - loss: 0.7334\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.5511\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8969 - loss: 0.5700\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9540 - loss: 0.4245\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9458 - loss: 0.4094\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9476 - loss: 0.4134\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9607 - loss: 0.3656\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.3755\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9581 - loss: 0.3691\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9617 - loss: 0.3392\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9673 - loss: 0.3236\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9258 - loss: 0.4524\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9340 - loss: 0.4067\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9457 - loss: 0.4114\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.3762\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9226 - loss: 0.4019\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9197 - loss: 0.3893\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9239 - loss: 0.3785\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9285 - loss: 0.3653\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9104 - loss: 0.3857\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9375 - loss: 0.3521\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9503 - loss: 0.3358\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9238 - loss: 0.3832\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9243 - loss: 0.3678\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9149 - loss: 0.3681\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9091 - loss: 0.3653\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9394 - loss: 0.3575\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9331 - loss: 0.3495\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9457 - loss: 0.3370\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9334 - loss: 0.3524\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9691 - loss: 0.3215\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8804 - loss: 0.5978\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8972 - loss: 0.5300\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9323 - loss: 0.4468\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.3430\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9814 - loss: 0.3065\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9513 - loss: 0.3277\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9506 - loss: 0.3015\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9579 - loss: 0.3069\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9780 - loss: 0.2869\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9761 - loss: 0.2922\n",
            "\n",
            "==> Leave Person 2 Out\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.0765 - loss: 3.5480\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1907 - loss: 3.2058\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3530 - loss: 2.8303\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4193 - loss: 2.3886\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5165 - loss: 2.0049\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5773 - loss: 1.7231\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6467 - loss: 1.5316\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7418 - loss: 1.3371\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7535 - loss: 1.1913\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8203 - loss: 1.0228\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8085 - loss: 0.9924\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8880 - loss: 0.8512\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8200 - loss: 0.9083\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8894 - loss: 0.8461\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8841 - loss: 0.7642\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8520 - loss: 0.8391\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.7511\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8956 - loss: 0.7110\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9263 - loss: 0.6305\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8848 - loss: 0.6988\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8762 - loss: 0.7049\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9437 - loss: 0.5903\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9378 - loss: 0.5822\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9614 - loss: 0.5136\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9342 - loss: 0.5546\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9651 - loss: 0.5130\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.5184\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9396 - loss: 0.5411\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9458 - loss: 0.4993\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9725 - loss: 0.4495\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9586 - loss: 0.4761\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9648 - loss: 0.4580\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.4308\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9649 - loss: 0.4418\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9778 - loss: 0.4093\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9777 - loss: 0.3958\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.3761\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9749 - loss: 0.3787\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9862 - loss: 0.3553\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.3481\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9718 - loss: 0.4060\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9735 - loss: 0.3831\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9598 - loss: 0.4013\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9366 - loss: 0.5452\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.4103\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9653 - loss: 0.4064\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9686 - loss: 0.3795\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.3494\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.3206\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9839 - loss: 0.3274\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.3482\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.3243\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.3116\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9854 - loss: 0.3136\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9761 - loss: 0.3546\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9528 - loss: 0.4004\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9629 - loss: 0.3832\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9425 - loss: 0.3747\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9666 - loss: 0.3463\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9864 - loss: 0.3099\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9885 - loss: 0.3008\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9666 - loss: 0.3798\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9903 - loss: 0.2872\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9768 - loss: 0.3055\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9563 - loss: 0.3867\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9481 - loss: 0.4676\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9608 - loss: 0.3547\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.2897\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.2819\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.3025\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.2976\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.2556\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9794 - loss: 0.3036\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9510 - loss: 0.4096\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9726 - loss: 0.3276\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9738 - loss: 0.3012\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.2770\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.2601\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.2750\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.2436\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.2566\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.2521\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.2459\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.2389\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.2338\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.2178\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.2287\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.2187\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.2354\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9863 - loss: 0.2487\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.2257\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9346 - loss: 0.4788\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9552 - loss: 0.3410\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9361 - loss: 0.4009\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9723 - loss: 0.3205\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9600 - loss: 0.3422\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.2509\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.2118\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9872 - loss: 0.2514\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9944 - loss: 0.2156\n",
            "\n",
            "==> Leave Person 3 Out\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0928 - loss: 3.5211\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2351 - loss: 3.1786\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3326 - loss: 2.7486\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5257 - loss: 2.1871\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5983 - loss: 1.8310\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6790 - loss: 1.5332\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7508 - loss: 1.3682\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8023 - loss: 1.1540\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8196 - loss: 1.0565\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8315 - loss: 0.9858\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8578 - loss: 0.8950\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8916 - loss: 0.8071\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8647 - loss: 0.8029\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9094 - loss: 0.6961\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8860 - loss: 0.7113\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8995 - loss: 0.6597\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9083 - loss: 0.6113\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9015 - loss: 0.6301\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8924 - loss: 0.6520\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9347 - loss: 0.5522\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8205 - loss: 0.8757\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8553 - loss: 0.7248\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9003 - loss: 0.5959\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8835 - loss: 0.6485\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9165 - loss: 0.5610\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9240 - loss: 0.5648\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9036 - loss: 0.5838\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8587 - loss: 0.7655\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9101 - loss: 0.5230\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9233 - loss: 0.5559\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9539 - loss: 0.4699\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9626 - loss: 0.4447\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9482 - loss: 0.4780\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9599 - loss: 0.4524\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9528 - loss: 0.4446\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.4898\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9267 - loss: 0.4641\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9264 - loss: 0.4471\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9611 - loss: 0.4347\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9660 - loss: 0.4071\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9456 - loss: 0.4478\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9229 - loss: 0.5565\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9135 - loss: 0.5219\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9118 - loss: 0.4929\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9410 - loss: 0.4539\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9370 - loss: 0.4724\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9274 - loss: 0.4623\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9212 - loss: 0.5272\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9410 - loss: 0.4464\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9615 - loss: 0.3921\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9709 - loss: 0.3836\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9579 - loss: 0.4103\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.3819\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.3878\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9655 - loss: 0.3805\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.3530\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9789 - loss: 0.3359\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9775 - loss: 0.3485\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.2939\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9848 - loss: 0.2902\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9878 - loss: 0.3068\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9839 - loss: 0.3053\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.3120\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.3065\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.2785\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.2795\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.2633\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9813 - loss: 0.3052\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.2924\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.2745\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9700 - loss: 0.3306\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9618 - loss: 0.3606\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.2885\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9827 - loss: 0.2930\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9160 - loss: 0.4885\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9410 - loss: 0.4200\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9723 - loss: 0.3199\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9555 - loss: 0.3720\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9666 - loss: 0.3858\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9586 - loss: 0.3372\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9630 - loss: 0.3249\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9539 - loss: 0.3402\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9614 - loss: 0.3064\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9768 - loss: 0.2787\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.2605\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.2459\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9755 - loss: 0.2632\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.2306\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.2400\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9959 - loss: 0.2304\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.2340\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9908 - loss: 0.2555\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9969 - loss: 0.2249\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.2490\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9906 - loss: 0.2390\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.2192\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.2187\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.2210\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.2046\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.2479\n",
            "\n",
            "==> Leave Person 4 Out\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.0765 - loss: 3.5641\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2500 - loss: 3.2592\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3665 - loss: 2.8718\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5309 - loss: 2.2690\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6531 - loss: 1.7816\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6200 - loss: 1.6021\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7055 - loss: 1.3647\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7254 - loss: 1.2427\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7304 - loss: 1.1559\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7794 - loss: 1.0511\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8300 - loss: 0.9845\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8449 - loss: 0.9157\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8093 - loss: 0.9406\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8454 - loss: 0.8711\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8714 - loss: 0.7755\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8539 - loss: 0.7689\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8864 - loss: 0.7037\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8687 - loss: 0.7331\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9080 - loss: 0.6979\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9175 - loss: 0.5909\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8982 - loss: 0.6472\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9108 - loss: 0.5930\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8900 - loss: 0.6263\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9009 - loss: 0.5532\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9205 - loss: 0.5494\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9450 - loss: 0.4977\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9494 - loss: 0.4554\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.4445\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9175 - loss: 0.5418\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9432 - loss: 0.4733\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9422 - loss: 0.4634\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9300 - loss: 0.4777\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8983 - loss: 0.5543\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9069 - loss: 0.5909\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8950 - loss: 0.5528\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9047 - loss: 0.5362\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8961 - loss: 0.6234\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9330 - loss: 0.4853\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9191 - loss: 0.4888\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9480 - loss: 0.4151\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9190 - loss: 0.5062\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9399 - loss: 0.4381\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9415 - loss: 0.4158\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9561 - loss: 0.3816\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9366 - loss: 0.3994\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9490 - loss: 0.3743\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9328 - loss: 0.4086\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9440 - loss: 0.3886\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9404 - loss: 0.4047\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9613 - loss: 0.3552\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9661 - loss: 0.3238\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9652 - loss: 0.3214\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9418 - loss: 0.3848\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9337 - loss: 0.4671\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9456 - loss: 0.3971\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9507 - loss: 0.3439\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9536 - loss: 0.3738\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9556 - loss: 0.3500\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9501 - loss: 0.3376\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9240 - loss: 0.4505\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8807 - loss: 0.5660\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9012 - loss: 0.4561\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9380 - loss: 0.4041\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9540 - loss: 0.3469\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9380 - loss: 0.3569\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9655 - loss: 0.3036\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9678 - loss: 0.3054\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9621 - loss: 0.2832\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9759 - loss: 0.2927\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9614 - loss: 0.3023\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9708 - loss: 0.2817\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.2897\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9622 - loss: 0.2873\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9597 - loss: 0.2863\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9649 - loss: 0.2887\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9462 - loss: 0.2845\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9606 - loss: 0.3010\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9433 - loss: 0.3476\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9263 - loss: 0.3638\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9492 - loss: 0.3272\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9598 - loss: 0.2928\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9617 - loss: 0.3149\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9376 - loss: 0.3366\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9599 - loss: 0.2780\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9667 - loss: 0.2779\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9670 - loss: 0.2768\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.2600\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9774 - loss: 0.2846\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9295 - loss: 0.4557\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9101 - loss: 0.4777\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8454 - loss: 0.7070\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9154 - loss: 0.4473\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9389 - loss: 0.3942\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9413 - loss: 0.3438\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.3149\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9659 - loss: 0.2746\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9817 - loss: 0.2764\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9737 - loss: 0.2651\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9726 - loss: 0.2670\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.2556\n",
            "Mean Accuracy (Leave one Person Out): 0.9293\n"
          ]
        }
      ],
      "source": [
        "# Define LSTM model with regularization\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(25, 84), kernel_regularizer=l2(0.001)),\n",
        "        Dropout(0.4),  # Dropout added to prevent overfitting\n",
        "        LSTM(32, return_sequences=False, kernel_regularizer=l2(0.002)),\n",
        "        Dropout(0.4),\n",
        "        Dense(32, activation='relu', kernel_regularizer=l2(0.002)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "unique_persons = [1, 2, 3, 4]  # Assuming person IDs go from 1 to 4\n",
        "accuracy_scores = []\n",
        "\n",
        "for person_id in unique_persons:\n",
        "    print(f\"\\n==> Leave Person {person_id} Out\")\n",
        "\n",
        "    # Create train-test split based on person ID\n",
        "    test_mask = (P_seq == person_id)  # Second column = person ID\n",
        "    train_mask = ~test_mask\n",
        "\n",
        "    # Extract samples\n",
        "    X_train, X_test = X_seq[train_mask], X_seq[test_mask]\n",
        "    y_train, y_test = Y_seq[train_mask], Y_seq[test_mask]\n",
        "\n",
        "    # Remove person ID column (keep only features)\n",
        "    X_train = X_train[:, :, :]  # shape: (samples, 25, 84)\n",
        "    X_test = X_test[:, :, :]\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    # Create and train a new model for each iteration\n",
        "    model = create_model()\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)  # Set verbose=1 to see progress\n",
        "\n",
        "    # Evaluate on the single test sample\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "# Compute mean accuracy across all LOOCV iterations\n",
        "print(f\"Mean Accuracy (Leave one Person Out): {np.mean(accuracy_scores):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u6HwcLo6q5n",
        "outputId": "db3fd1d1-d495-4ecc-e710-fd1c2a267b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==> Leave Person 1 Out\n",
            "(739, 25, 84)\n",
            "(140, 25, 84)\n",
            "\n",
            "==> Leave Person 2 Out\n",
            "(749, 25, 84)\n",
            "(130, 25, 84)\n",
            "\n",
            "==> Leave Person 3 Out\n",
            "(749, 25, 84)\n",
            "(130, 25, 84)\n",
            "\n",
            "==> Leave Person 4 Out\n",
            "(749, 25, 84)\n",
            "(130, 25, 84)\n"
          ]
        }
      ],
      "source": [
        "for person_id in unique_persons:\n",
        "    print(f\"\\n==> Leave Person {person_id} Out\")\n",
        "\n",
        "    # Create train-test split based on person ID\n",
        "    test_mask = (P_seq == person_id)  # Second column = person ID\n",
        "    train_mask = ~test_mask\n",
        "\n",
        "    # Extract samples\n",
        "    X_train, X_test = X_seq[train_mask], X_seq[test_mask]\n",
        "    y_train, y_test = Y_seq[train_mask], Y_seq[test_mask]\n",
        "\n",
        "    # Remove person ID column (keep only features)\n",
        "    X_train = X_train[:, :, :]  # shape: (samples, 25, 84)\n",
        "    X_test = X_test[:, :, :]\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    # check for correctness\n",
        "    print(X_train.shape)\n",
        "    print(X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-LkMJPbAs7k",
        "outputId": "e9bbf126-eea3-4151-b524-8b41b980d0e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold class distribution:\n",
            "[12  8]\n",
            "[11  9]\n",
            "[14  6]\n",
            "[ 5 15]\n",
            "[ 8 12]\n",
            "\n",
            "StratifiedKFold class distribution:\n",
            "[10 10]\n",
            "[10 10]\n",
            "[10 10]\n",
            "[10 10]\n",
            "[10 10]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "y = np.array([0] * 50 + [1] * 50)  # example binary target\n",
        "\n",
        "# Try both\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"KFold class distribution:\")\n",
        "for train_idx, test_idx in kf.split(np.zeros(len(y)), y):\n",
        "    print(np.bincount(y[test_idx]))\n",
        "\n",
        "print(\"\\nStratifiedKFold class distribution:\")\n",
        "for train_idx, test_idx in skf.split(np.zeros(len(y)), y):\n",
        "    print(np.bincount(y[test_idx]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA7fM_G4BNcE"
      },
      "source": [
        "# Stratified Kfold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u_cfTplAuRU",
        "outputId": "3c73c2d4-d791-4899-a175-2db6d73abacc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (882, 25, 84)\n",
            "Y shape: (882,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.73493975, -0.03614458,  0.48364887, ..., -0.28055078,\n",
              "         -0.72805506, -0.28743544],\n",
              "        [ 0.73402417, -0.04490501,  0.48531953, ..., -0.28324696,\n",
              "         -0.7202073 , -0.29360968],\n",
              "        [ 0.7241379 , -0.04827586,  0.4827586 , ..., -0.2724138 ,\n",
              "         -0.7137931 , -0.28275862],\n",
              "        ...,\n",
              "        [ 0.694859  , -0.03482587,  0.45605308, ..., -0.26699835,\n",
              "         -0.73134327, -0.28026533],\n",
              "        [ 0.70715475, -0.03494176,  0.4608985 , ..., -0.27454242,\n",
              "         -0.7237937 , -0.28785357],\n",
              "        [ 0.6981758 , -0.03980099,  0.45273632, ..., -0.2620232 ,\n",
              "         -0.7280265 , -0.27860695]],\n",
              "\n",
              "       [[ 0.69175625, -0.0609319 ,  0.41218638, ..., -0.28315413,\n",
              "         -0.60573477, -0.25448027],\n",
              "        [ 0.6802842 , -0.05861456,  0.39964476, ..., -0.28596804,\n",
              "         -0.61634105, -0.26110125],\n",
              "        [ 0.68817204, -0.05734767,  0.41218638, ..., -0.28673837,\n",
              "         -0.6236559 , -0.26523298],\n",
              "        ...,\n",
              "        [ 0.69174314, -0.07339449,  0.42018348, ..., -0.2825688 ,\n",
              "         -0.5963303 , -0.25321102],\n",
              "        [ 0.6886447 , -0.06959707,  0.41758242, ..., -0.2820513 ,\n",
              "         -0.6007326 , -0.25274727],\n",
              "        [ 0.6886447 , -0.06410256,  0.41391942, ..., -0.2838828 ,\n",
              "         -0.60805863, -0.25091577]],\n",
              "\n",
              "       [[ 0.7653061 , -0.04081633,  0.5136054 , ..., -0.26530612,\n",
              "         -0.6904762 , -0.24489796],\n",
              "        [ 0.74453783, -0.04201681,  0.49579832, ..., -0.26386556,\n",
              "         -0.687395  , -0.24369748],\n",
              "        [ 0.7483221 , -0.0352349 ,  0.4966443 , ..., -0.26677853,\n",
              "         -0.7013423 , -0.23993288],\n",
              "        ...,\n",
              "        [ 0.75972927, -0.04060914,  0.5025381 , ..., -0.26395938,\n",
              "         -0.69204736, -0.23688664],\n",
              "        [ 0.7631134 , -0.04060914,  0.5025381 , ..., -0.26395938,\n",
              "         -0.69204736, -0.23688664],\n",
              "        [ 0.75634515, -0.04060914,  0.49915397, ..., -0.2605753 ,\n",
              "         -0.6988156 , -0.23011844]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.3282532 , -0.02461899,  0.17819461, ..., -0.29191092,\n",
              "          0.20867527, -0.29191092],\n",
              "        [ 0.33689204, -0.02728351,  0.18030842, ..., -0.2906287 ,\n",
              "          0.21589561, -0.29300117],\n",
              "        [ 0.33766234, -0.02479339,  0.17709564, ..., -0.28217238,\n",
              "          0.20070839, -0.2892562 ],\n",
              "        ...,\n",
              "        [ 0.32786885, -0.0234192 ,  0.18501171, ..., -0.29274005,\n",
              "          0.20843092, -0.29274005],\n",
              "        [ 0.33138856, -0.02917153,  0.17736289, ..., -0.2975496 ,\n",
              "          0.21236873, -0.2998833 ],\n",
              "        [ 0.33411214, -0.02803738,  0.17757009, ..., -0.2990654 ,\n",
              "          0.20794393, -0.30373833]],\n",
              "\n",
              "       [[ 0.3282532 , -0.02461899,  0.17819461, ..., -0.29191092,\n",
              "          0.20867527, -0.29191092],\n",
              "        [ 0.33689204, -0.02728351,  0.18030842, ..., -0.2906287 ,\n",
              "          0.21589561, -0.29300117],\n",
              "        [ 0.33766234, -0.02479339,  0.17709564, ..., -0.28217238,\n",
              "          0.20070839, -0.2892562 ],\n",
              "        ...,\n",
              "        [ 0.32786885, -0.0234192 ,  0.18501171, ..., -0.29274005,\n",
              "          0.20843092, -0.29274005],\n",
              "        [ 0.33138856, -0.02917153,  0.17736289, ..., -0.2975496 ,\n",
              "          0.21236873, -0.2998833 ],\n",
              "        [ 0.33411214, -0.02803738,  0.17757009, ..., -0.2990654 ,\n",
              "          0.20794393, -0.30373833]],\n",
              "\n",
              "       [[ 0.3282532 , -0.02461899,  0.17819461, ..., -0.29191092,\n",
              "          0.20867527, -0.29191092],\n",
              "        [ 0.33689204, -0.02728351,  0.18030842, ..., -0.2906287 ,\n",
              "          0.21589561, -0.29300117],\n",
              "        [ 0.33766234, -0.02479339,  0.17709564, ..., -0.28217238,\n",
              "          0.20070839, -0.2892562 ],\n",
              "        ...,\n",
              "        [ 0.32786885, -0.0234192 ,  0.18501171, ..., -0.29274005,\n",
              "          0.20843092, -0.29274005],\n",
              "        [ 0.33138856, -0.02917153,  0.17736289, ..., -0.2975496 ,\n",
              "          0.21236873, -0.2998833 ],\n",
              "        [ 0.33411214, -0.02803738,  0.17757009, ..., -0.2990654 ,\n",
              "          0.20794393, -0.30373833]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def load_and_prepare_data(csv_path):\n",
        "    # Load data from CSV\n",
        "    data = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "    # Convert to NumPy array for efficient processing\n",
        "    data = data.values\n",
        "\n",
        "    # Separate X (features) and Y (first column as labels)\n",
        "    Y = data[:, 0]  # First column as labels\n",
        "    X = data[:, 2:]  # All other columns as features (shape: num_samples, 84)\n",
        "\n",
        "    # Define sequence length\n",
        "    sequence_length = 25\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_seq, Y_seq = [], []\n",
        "    num_sequences = len(X) // sequence_length\n",
        "\n",
        "    for i in range(num_sequences):\n",
        "        start_idx = i * sequence_length\n",
        "        X_seq.append(X[start_idx:start_idx + sequence_length])  # 25 rows of features\n",
        "        Y_seq.append(Y[start_idx])  # First column value corresponding to the sequence\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_seq = np.array(X_seq)  # Shape: (num_sequences, 25, 84)\n",
        "    Y_seq = np.array(Y_seq)  # Shape: (num_sequences,)\n",
        "\n",
        "    return X_seq, Y_seq\n",
        "\n",
        "# Example usage\n",
        "csv_path = \"/content/Double and Single-Handed Keypoints 14th April-LSTM.csv\"  # Replace with actual path\n",
        "X_seq, Y_seq = load_and_prepare_data(csv_path)\n",
        "print(\"X shape:\", X_seq.shape)  # Expected: (num_sequences, 25, 84)\n",
        "print(\"Y shape:\", Y_seq.shape)  # Expected: (num_sequences,)\n",
        "\n",
        "# Encode Y_seq (convert string labels to integers)\n",
        "label_encoder = LabelEncoder()\n",
        "Y_seq = label_encoder.fit_transform(Y_seq)\n",
        "np.save(\"label_classes.npy\", label_encoder.classes_)\n",
        "\n",
        "\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "Y_seq = to_categorical(Y_seq, num_classes)\n",
        "\n",
        "X_seq.astype('float32')\n",
        "# Y_seq.dtype\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Defination"
      ],
      "metadata": {
        "id": "GGRp7BcAUvFk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE8f7p8JgV2e",
        "outputId": "dcf83608-6189-489c-afbd-fca74c796918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1 / 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1303 - loss: 3.1166 - val_accuracy: 0.3820 - val_loss: 2.7002\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4055 - loss: 2.5589 - val_accuracy: 0.5730 - val_loss: 2.1680\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5572 - loss: 1.9731 - val_accuracy: 0.7079 - val_loss: 1.6712\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7136 - loss: 1.5070 - val_accuracy: 0.7978 - val_loss: 1.3552\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8318 - loss: 1.1761 - val_accuracy: 0.8652 - val_loss: 1.1006\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8632 - loss: 0.9231 - val_accuracy: 0.8652 - val_loss: 0.9200\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8998 - loss: 0.7690 - val_accuracy: 0.9101 - val_loss: 0.7847\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9213 - loss: 0.6479 - val_accuracy: 0.9101 - val_loss: 0.7032\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9044 - loss: 0.5653 - val_accuracy: 0.8989 - val_loss: 0.6630\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9370 - loss: 0.4843 - val_accuracy: 0.9101 - val_loss: 0.5897\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9442 - loss: 0.4388 - val_accuracy: 0.9213 - val_loss: 0.5511\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9458 - loss: 0.4062 - val_accuracy: 0.8539 - val_loss: 0.5659\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9253 - loss: 0.3940 - val_accuracy: 0.8876 - val_loss: 0.4809\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9489 - loss: 0.3479 - val_accuracy: 0.8989 - val_loss: 0.5028\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9527 - loss: 0.3164 - val_accuracy: 0.9326 - val_loss: 0.3774\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9605 - loss: 0.2859 - val_accuracy: 0.9326 - val_loss: 0.3535\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9787 - loss: 0.2393 - val_accuracy: 0.9213 - val_loss: 0.4448\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9398 - loss: 0.3021 - val_accuracy: 0.9438 - val_loss: 0.3280\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9594 - loss: 0.2637 - val_accuracy: 0.8764 - val_loss: 0.4172\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.2526 - val_accuracy: 0.9438 - val_loss: 0.3053\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9748 - loss: 0.1832 - val_accuracy: 0.9438 - val_loss: 0.2899\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9795 - loss: 0.1860 - val_accuracy: 0.9438 - val_loss: 0.2743\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9734 - loss: 0.1700 - val_accuracy: 0.9551 - val_loss: 0.2629\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9824 - loss: 0.1534 - val_accuracy: 0.9551 - val_loss: 0.2689\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.2114 - val_accuracy: 0.9551 - val_loss: 0.2572\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.1724 - val_accuracy: 0.9101 - val_loss: 0.3277\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9489 - loss: 0.2042 - val_accuracy: 0.8876 - val_loss: 0.3277\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9565 - loss: 0.1799 - val_accuracy: 0.9551 - val_loss: 0.2264\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9765 - loss: 0.1466 - val_accuracy: 0.9213 - val_loss: 0.2594\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.1277 - val_accuracy: 0.9551 - val_loss: 0.1967\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0893 - val_accuracy: 0.9551 - val_loss: 0.1877\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.1128 - val_accuracy: 0.9551 - val_loss: 0.1887\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.1015 - val_accuracy: 0.9326 - val_loss: 0.2191\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0972 - val_accuracy: 0.9326 - val_loss: 0.1966\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.0794 - val_accuracy: 0.9326 - val_loss: 0.1885\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0720 - val_accuracy: 0.9326 - val_loss: 0.1799\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9903 - loss: 0.0640 - val_accuracy: 0.9551 - val_loss: 0.1830\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0776 - val_accuracy: 0.9551 - val_loss: 0.1776\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0624 - val_accuracy: 0.9551 - val_loss: 0.1679\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0685 - val_accuracy: 0.9551 - val_loss: 0.1631\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.0568 - val_accuracy: 0.9551 - val_loss: 0.1570\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0606 - val_accuracy: 0.9551 - val_loss: 0.1516\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0523 - val_accuracy: 0.9551 - val_loss: 0.1474\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0542 - val_accuracy: 0.9551 - val_loss: 0.1428\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0558 - val_accuracy: 0.9551 - val_loss: 0.1389\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0440 - val_accuracy: 0.9551 - val_loss: 0.1355\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9912 - loss: 0.0604 - val_accuracy: 0.9551 - val_loss: 0.1451\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0622 - val_accuracy: 0.9551 - val_loss: 0.1936\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9799 - loss: 0.0931 - val_accuracy: 0.9775 - val_loss: 0.1721\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.1194 - val_accuracy: 0.9775 - val_loss: 0.1130\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9626 - loss: 0.1275 - val_accuracy: 0.9438 - val_loss: 0.1830\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9824 - loss: 0.1177 - val_accuracy: 0.9551 - val_loss: 0.1960\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0975 - val_accuracy: 0.9438 - val_loss: 0.2070\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9492 - loss: 0.1456 - val_accuracy: 0.9663 - val_loss: 0.1518\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9782 - loss: 0.0944 - val_accuracy: 0.9326 - val_loss: 0.2340\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.2160 - val_accuracy: 0.9775 - val_loss: 0.1433\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0897 - val_accuracy: 0.9775 - val_loss: 0.1255\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9703 - loss: 0.1006 - val_accuracy: 0.9663 - val_loss: 0.1151\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9785 - loss: 0.0964 - val_accuracy: 0.9326 - val_loss: 0.2978\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9248 - loss: 0.2668 - val_accuracy: 0.9663 - val_loss: 0.1552\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.1044 - val_accuracy: 0.9663 - val_loss: 0.1414\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0695 - val_accuracy: 0.9663 - val_loss: 0.1274\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9970 - loss: 0.0535 - val_accuracy: 0.9663 - val_loss: 0.1265\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.0593 - val_accuracy: 0.9663 - val_loss: 0.1237\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0521 - val_accuracy: 0.9663 - val_loss: 0.1224\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0489 - val_accuracy: 0.9663 - val_loss: 0.1184\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0548 - val_accuracy: 0.9663 - val_loss: 0.1160\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0400 - val_accuracy: 0.9663 - val_loss: 0.1148\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0578 - val_accuracy: 0.9663 - val_loss: 0.1082\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0407 - val_accuracy: 0.9663 - val_loss: 0.1040\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0585 - val_accuracy: 0.9663 - val_loss: 0.0999\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0464 - val_accuracy: 0.9663 - val_loss: 0.0981\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0424 - val_accuracy: 0.9663 - val_loss: 0.0952\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0386 - val_accuracy: 0.9663 - val_loss: 0.0927\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0327 - val_accuracy: 0.9663 - val_loss: 0.0933\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0275 - val_accuracy: 0.9663 - val_loss: 0.0916\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.0324 - val_accuracy: 0.9775 - val_loss: 0.0882\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.0327 - val_accuracy: 0.9775 - val_loss: 0.0839\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9605 - loss: 0.0993 - val_accuracy: 0.9213 - val_loss: 0.1721\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9617 - loss: 0.0958 - val_accuracy: 0.9326 - val_loss: 0.2312\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9288 - loss: 0.2253 - val_accuracy: 0.8876 - val_loss: 0.2504\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9173 - loss: 0.1908 - val_accuracy: 0.9326 - val_loss: 0.2247\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9608 - loss: 0.1246 - val_accuracy: 0.8989 - val_loss: 0.2304\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.1129 - val_accuracy: 0.9326 - val_loss: 0.2436\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9834 - loss: 0.0810 - val_accuracy: 0.9326 - val_loss: 0.1667\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0643 - val_accuracy: 0.9663 - val_loss: 0.1239\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0588 - val_accuracy: 0.9775 - val_loss: 0.0944\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0555 - val_accuracy: 0.9775 - val_loss: 0.0910\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9873 - loss: 0.0556 - val_accuracy: 0.9551 - val_loss: 0.1298\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0687 - val_accuracy: 0.9775 - val_loss: 0.1007\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0355 - val_accuracy: 0.9438 - val_loss: 0.1280\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0459 - val_accuracy: 0.9551 - val_loss: 0.1061\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0419 - val_accuracy: 0.9663 - val_loss: 0.0959\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0338 - val_accuracy: 0.9663 - val_loss: 0.0962\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0434 - val_accuracy: 0.9663 - val_loss: 0.0940\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0387 - val_accuracy: 0.9438 - val_loss: 0.1290\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0333 - val_accuracy: 0.9663 - val_loss: 0.0937\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0356 - val_accuracy: 0.9663 - val_loss: 0.0894\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0319 - val_accuracy: 0.9663 - val_loss: 0.0887\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0324 - val_accuracy: 0.9663 - val_loss: 0.0940\n",
            "\n",
            "Fold 2 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.1393 - loss: 3.1611 - val_accuracy: 0.3371 - val_loss: 2.7347\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3988 - loss: 2.5931 - val_accuracy: 0.5393 - val_loss: 2.1037\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6055 - loss: 1.9251 - val_accuracy: 0.6966 - val_loss: 1.5502\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7410 - loss: 1.4278 - val_accuracy: 0.7079 - val_loss: 1.2104\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8269 - loss: 1.1165 - val_accuracy: 0.8539 - val_loss: 0.9640\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8810 - loss: 0.8706 - val_accuracy: 0.8539 - val_loss: 0.8073\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8785 - loss: 0.7810 - val_accuracy: 0.9101 - val_loss: 0.6249\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9241 - loss: 0.6633 - val_accuracy: 0.9101 - val_loss: 0.5594\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.5526 - val_accuracy: 0.9438 - val_loss: 0.4486\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9405 - loss: 0.4809 - val_accuracy: 0.9551 - val_loss: 0.3837\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9355 - loss: 0.4114 - val_accuracy: 0.9326 - val_loss: 0.3701\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9713 - loss: 0.3202 - val_accuracy: 0.9438 - val_loss: 0.3111\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.2868 - val_accuracy: 0.9101 - val_loss: 0.3852\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9406 - loss: 0.3523 - val_accuracy: 0.9551 - val_loss: 0.2666\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9741 - loss: 0.2671 - val_accuracy: 0.9326 - val_loss: 0.2708\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9870 - loss: 0.2087 - val_accuracy: 0.9438 - val_loss: 0.2515\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9805 - loss: 0.1948 - val_accuracy: 0.9213 - val_loss: 0.2935\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9457 - loss: 0.2931 - val_accuracy: 0.8876 - val_loss: 0.3120\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9490 - loss: 0.2714 - val_accuracy: 0.8764 - val_loss: 0.3701\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9048 - loss: 0.3472 - val_accuracy: 0.9326 - val_loss: 0.2457\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9442 - loss: 0.2476 - val_accuracy: 0.8989 - val_loss: 0.2860\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9652 - loss: 0.1974 - val_accuracy: 0.9101 - val_loss: 0.2167\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9732 - loss: 0.1674 - val_accuracy: 0.9551 - val_loss: 0.1750\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9780 - loss: 0.1318 - val_accuracy: 0.9213 - val_loss: 0.2465\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9707 - loss: 0.1822 - val_accuracy: 0.9101 - val_loss: 0.2165\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9435 - loss: 0.1923 - val_accuracy: 0.9438 - val_loss: 0.1885\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.1470 - val_accuracy: 0.9326 - val_loss: 0.2440\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9600 - loss: 0.1736 - val_accuracy: 0.9438 - val_loss: 0.1835\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.1078 - val_accuracy: 0.9551 - val_loss: 0.1610\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.1114 - val_accuracy: 0.9438 - val_loss: 0.1639\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0903 - val_accuracy: 0.9551 - val_loss: 0.1564\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0970 - val_accuracy: 0.9775 - val_loss: 0.1446\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9907 - loss: 0.0838 - val_accuracy: 0.9663 - val_loss: 0.1425\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0916 - val_accuracy: 0.9775 - val_loss: 0.1231\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0677 - val_accuracy: 0.9551 - val_loss: 0.1633\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0854 - val_accuracy: 0.9663 - val_loss: 0.1208\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0611 - val_accuracy: 0.9775 - val_loss: 0.0999\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0742 - val_accuracy: 0.9775 - val_loss: 0.1162\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0649 - val_accuracy: 0.9775 - val_loss: 0.1218\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9891 - loss: 0.0684 - val_accuracy: 0.9551 - val_loss: 0.2022\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9557 - loss: 0.1618 - val_accuracy: 0.9551 - val_loss: 0.1509\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9591 - loss: 0.1562 - val_accuracy: 0.9663 - val_loss: 0.1273\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.1150 - val_accuracy: 0.9775 - val_loss: 0.1257\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9900 - loss: 0.0855 - val_accuracy: 0.9663 - val_loss: 0.1259\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0775 - val_accuracy: 0.9663 - val_loss: 0.1212\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0587 - val_accuracy: 0.9663 - val_loss: 0.1196\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0722 - val_accuracy: 0.9775 - val_loss: 0.1358\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0793 - val_accuracy: 0.9438 - val_loss: 0.1682\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9790 - loss: 0.0733 - val_accuracy: 0.9663 - val_loss: 0.1353\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0801 - val_accuracy: 0.9438 - val_loss: 0.1482\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.1334 - val_accuracy: 0.9213 - val_loss: 0.2455\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9203 - loss: 0.2703 - val_accuracy: 0.8876 - val_loss: 0.2650\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9459 - loss: 0.1897 - val_accuracy: 0.9663 - val_loss: 0.1686\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0950 - val_accuracy: 0.9663 - val_loss: 0.1326\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0733 - val_accuracy: 0.9775 - val_loss: 0.1155\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0880 - val_accuracy: 0.9775 - val_loss: 0.1040\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.0587 - val_accuracy: 0.9775 - val_loss: 0.0935\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0451 - val_accuracy: 0.9775 - val_loss: 0.0901\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0517 - val_accuracy: 0.9888 - val_loss: 0.0848\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0465 - val_accuracy: 0.9888 - val_loss: 0.0806\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0531 - val_accuracy: 0.9888 - val_loss: 0.0788\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0333 - val_accuracy: 0.9888 - val_loss: 0.0763\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0310 - val_accuracy: 0.9888 - val_loss: 0.0736\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0351 - val_accuracy: 0.9888 - val_loss: 0.0707\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0289 - val_accuracy: 0.9888 - val_loss: 0.0695\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0348 - val_accuracy: 0.9888 - val_loss: 0.0695\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0371 - val_accuracy: 0.9888 - val_loss: 0.0683\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0279 - val_accuracy: 0.9888 - val_loss: 0.0661\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0246 - val_accuracy: 0.9888 - val_loss: 0.0652\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0302 - val_accuracy: 0.9888 - val_loss: 0.0642\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0248 - val_accuracy: 0.9888 - val_loss: 0.0635\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0304 - val_accuracy: 0.9888 - val_loss: 0.0646\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0167 - val_accuracy: 0.9888 - val_loss: 0.0632\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0323 - val_accuracy: 0.9888 - val_loss: 0.0617\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0179 - val_accuracy: 0.9888 - val_loss: 0.0607\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0152 - val_accuracy: 0.9888 - val_loss: 0.0600\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0195 - val_accuracy: 0.9888 - val_loss: 0.0591\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0179 - val_accuracy: 0.9888 - val_loss: 0.0587\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0204 - val_accuracy: 0.9888 - val_loss: 0.0587\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0220 - val_accuracy: 0.9888 - val_loss: 0.0585\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0200 - val_accuracy: 0.9888 - val_loss: 0.0576\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0189 - val_accuracy: 0.9888 - val_loss: 0.0581\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0151 - val_accuracy: 0.9888 - val_loss: 0.0579\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0145 - val_accuracy: 0.9888 - val_loss: 0.0580\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0143 - val_accuracy: 0.9888 - val_loss: 0.0580\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0145 - val_accuracy: 0.9888 - val_loss: 0.0590\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0156 - val_accuracy: 0.9888 - val_loss: 0.0592\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0147 - val_accuracy: 0.9888 - val_loss: 0.0584\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0184 - val_accuracy: 0.9888 - val_loss: 0.0576\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0144 - val_accuracy: 0.9888 - val_loss: 0.0576\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0162 - val_accuracy: 0.9775 - val_loss: 0.0576\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0220 - val_accuracy: 0.9775 - val_loss: 0.0578\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0176 - val_accuracy: 0.9775 - val_loss: 0.0619\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0159 - val_accuracy: 0.9775 - val_loss: 0.0737\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0466 - val_accuracy: 0.8989 - val_loss: 0.3014\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9581 - loss: 0.1549 - val_accuracy: 0.9326 - val_loss: 0.2487\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9480 - loss: 0.1875 - val_accuracy: 0.9438 - val_loss: 0.2099\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.1033 - val_accuracy: 0.9326 - val_loss: 0.1618\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9505 - loss: 0.1697 - val_accuracy: 0.9663 - val_loss: 0.1273\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9604 - loss: 0.1253 - val_accuracy: 0.9438 - val_loss: 0.1722\n",
            "\n",
            "Fold 3 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.1444 - loss: 3.1649 - val_accuracy: 0.3864 - val_loss: 2.7549\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4383 - loss: 2.5814 - val_accuracy: 0.6023 - val_loss: 2.2207\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6890 - loss: 2.0359 - val_accuracy: 0.7159 - val_loss: 1.7203\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7577 - loss: 1.5579 - val_accuracy: 0.7386 - val_loss: 1.3837\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8044 - loss: 1.2670 - val_accuracy: 0.7955 - val_loss: 1.1066\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8742 - loss: 0.9493 - val_accuracy: 0.8409 - val_loss: 0.9144\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8931 - loss: 0.7974 - val_accuracy: 0.8750 - val_loss: 0.8057\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9115 - loss: 0.6628 - val_accuracy: 0.8750 - val_loss: 0.7039\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9092 - loss: 0.6255 - val_accuracy: 0.8295 - val_loss: 0.7233\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9152 - loss: 0.5233 - val_accuracy: 0.8977 - val_loss: 0.6150\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9184 - loss: 0.4968 - val_accuracy: 0.8977 - val_loss: 0.5087\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9420 - loss: 0.4252 - val_accuracy: 0.9318 - val_loss: 0.5036\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9163 - loss: 0.4778 - val_accuracy: 0.9205 - val_loss: 0.5139\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9464 - loss: 0.4133 - val_accuracy: 0.9432 - val_loss: 0.4206\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9450 - loss: 0.3621 - val_accuracy: 0.9318 - val_loss: 0.4341\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9609 - loss: 0.3375 - val_accuracy: 0.9205 - val_loss: 0.4333\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9692 - loss: 0.2653 - val_accuracy: 0.9545 - val_loss: 0.3642\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9666 - loss: 0.2691 - val_accuracy: 0.9545 - val_loss: 0.3264\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.2036 - val_accuracy: 0.9432 - val_loss: 0.3395\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.2003 - val_accuracy: 0.9659 - val_loss: 0.2836\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.1843 - val_accuracy: 0.9318 - val_loss: 0.3545\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9774 - loss: 0.1819 - val_accuracy: 0.9545 - val_loss: 0.2825\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.1639 - val_accuracy: 0.9659 - val_loss: 0.2451\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.1372 - val_accuracy: 0.9545 - val_loss: 0.2963\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9745 - loss: 0.1653 - val_accuracy: 0.9318 - val_loss: 0.2612\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.1785 - val_accuracy: 0.9318 - val_loss: 0.2683\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9718 - loss: 0.1658 - val_accuracy: 0.8977 - val_loss: 0.3076\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.2155 - val_accuracy: 0.9545 - val_loss: 0.2640\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9741 - loss: 0.1760 - val_accuracy: 0.9205 - val_loss: 0.3548\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9724 - loss: 0.2144 - val_accuracy: 0.9545 - val_loss: 0.2849\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9795 - loss: 0.1432 - val_accuracy: 0.9432 - val_loss: 0.2067\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.1338 - val_accuracy: 0.9659 - val_loss: 0.1814\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9885 - loss: 0.0892 - val_accuracy: 0.9659 - val_loss: 0.1657\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0764 - val_accuracy: 0.9773 - val_loss: 0.1652\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0763 - val_accuracy: 0.9659 - val_loss: 0.1607\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.0982 - val_accuracy: 0.9773 - val_loss: 0.1467\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9915 - loss: 0.0762 - val_accuracy: 0.9773 - val_loss: 0.1453\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0656 - val_accuracy: 0.9773 - val_loss: 0.1420\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0636 - val_accuracy: 0.9773 - val_loss: 0.1381\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0571 - val_accuracy: 0.9773 - val_loss: 0.1354\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0530 - val_accuracy: 0.9773 - val_loss: 0.1330\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0566 - val_accuracy: 0.9773 - val_loss: 0.1288\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0634 - val_accuracy: 0.9773 - val_loss: 0.1251\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0464 - val_accuracy: 0.9773 - val_loss: 0.1217\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0489 - val_accuracy: 0.9773 - val_loss: 0.1203\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0558 - val_accuracy: 0.9773 - val_loss: 0.1184\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0434 - val_accuracy: 0.9773 - val_loss: 0.1167\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0487 - val_accuracy: 0.9773 - val_loss: 0.1147\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0463 - val_accuracy: 0.9773 - val_loss: 0.1147\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0491 - val_accuracy: 0.9773 - val_loss: 0.1127\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0449 - val_accuracy: 0.9773 - val_loss: 0.1135\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9922 - loss: 0.0468 - val_accuracy: 0.9773 - val_loss: 0.1103\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0308 - val_accuracy: 0.9773 - val_loss: 0.1093\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0418 - val_accuracy: 0.9773 - val_loss: 0.1076\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9954 - loss: 0.0382 - val_accuracy: 0.9773 - val_loss: 0.1075\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 0.0340 - val_accuracy: 0.9773 - val_loss: 0.1067\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9925 - loss: 0.0412 - val_accuracy: 0.9773 - val_loss: 0.1071\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0367 - val_accuracy: 0.9773 - val_loss: 0.1061\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0311 - val_accuracy: 0.9773 - val_loss: 0.1052\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0266 - val_accuracy: 0.9773 - val_loss: 0.1047\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0360 - val_accuracy: 0.9773 - val_loss: 0.1047\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0257 - val_accuracy: 0.9773 - val_loss: 0.1041\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0353 - val_accuracy: 0.9773 - val_loss: 0.1046\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0367 - val_accuracy: 0.9773 - val_loss: 0.1035\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0326 - val_accuracy: 0.9773 - val_loss: 0.1038\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0532 - val_accuracy: 0.8864 - val_loss: 0.3917\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9185 - loss: 0.2931 - val_accuracy: 0.8068 - val_loss: 0.4776\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9271 - loss: 0.2672 - val_accuracy: 0.8977 - val_loss: 0.3615\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9366 - loss: 0.1860 - val_accuracy: 0.8750 - val_loss: 0.3987\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9236 - loss: 0.1973 - val_accuracy: 0.9091 - val_loss: 0.3279\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9376 - loss: 0.1655 - val_accuracy: 0.9091 - val_loss: 0.2904\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9396 - loss: 0.1405 - val_accuracy: 0.9318 - val_loss: 0.2413\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9810 - loss: 0.0701 - val_accuracy: 0.9432 - val_loss: 0.2548\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9736 - loss: 0.1360 - val_accuracy: 0.9432 - val_loss: 0.2358\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.0727 - val_accuracy: 0.9545 - val_loss: 0.2372\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0594 - val_accuracy: 0.9545 - val_loss: 0.2244\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9728 - loss: 0.1031 - val_accuracy: 0.8864 - val_loss: 0.4021\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9333 - loss: 0.1886 - val_accuracy: 0.8977 - val_loss: 0.3082\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9175 - loss: 0.2129 - val_accuracy: 0.9091 - val_loss: 0.3658\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9466 - loss: 0.1679 - val_accuracy: 0.8977 - val_loss: 0.3601\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9473 - loss: 0.1669 - val_accuracy: 0.9091 - val_loss: 0.3257\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9643 - loss: 0.1375 - val_accuracy: 0.9318 - val_loss: 0.2854\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9820 - loss: 0.1021 - val_accuracy: 0.9545 - val_loss: 0.2725\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9898 - loss: 0.0872 - val_accuracy: 0.9318 - val_loss: 0.2885\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0800 - val_accuracy: 0.9318 - val_loss: 0.2975\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0742 - val_accuracy: 0.9318 - val_loss: 0.2768\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0603 - val_accuracy: 0.9318 - val_loss: 0.2631\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0438 - val_accuracy: 0.9318 - val_loss: 0.2586\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0418 - val_accuracy: 0.9432 - val_loss: 0.2536\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0391 - val_accuracy: 0.9432 - val_loss: 0.2448\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0314 - val_accuracy: 0.9432 - val_loss: 0.2415\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0335 - val_accuracy: 0.9432 - val_loss: 0.2392\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.0248 - val_accuracy: 0.9432 - val_loss: 0.2378\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0372 - val_accuracy: 0.9432 - val_loss: 0.2370\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0308 - val_accuracy: 0.9432 - val_loss: 0.2361\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0232 - val_accuracy: 0.9432 - val_loss: 0.2363\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.0264 - val_accuracy: 0.9432 - val_loss: 0.2345\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.0183 - val_accuracy: 0.9432 - val_loss: 0.2320\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9960 - loss: 0.0248 - val_accuracy: 0.9432 - val_loss: 0.2319\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0205 - val_accuracy: 0.9432 - val_loss: 0.2322\n",
            "\n",
            "Fold 4 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0890 - loss: 3.1522 - val_accuracy: 0.4318 - val_loss: 2.7295\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4533 - loss: 2.6148 - val_accuracy: 0.5000 - val_loss: 2.2346\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5067 - loss: 2.1378 - val_accuracy: 0.6136 - val_loss: 1.8041\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6906 - loss: 1.7094 - val_accuracy: 0.7955 - val_loss: 1.4626\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8344 - loss: 1.3782 - val_accuracy: 0.8409 - val_loss: 1.1690\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8306 - loss: 1.0905 - val_accuracy: 0.8636 - val_loss: 0.9873\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9028 - loss: 0.8712 - val_accuracy: 0.9091 - val_loss: 0.8365\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9176 - loss: 0.7364 - val_accuracy: 0.8977 - val_loss: 0.7310\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9242 - loss: 0.6228 - val_accuracy: 0.9545 - val_loss: 0.6184\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9364 - loss: 0.5710 - val_accuracy: 0.9545 - val_loss: 0.5521\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9366 - loss: 0.4960 - val_accuracy: 0.9318 - val_loss: 0.5257\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9244 - loss: 0.4874 - val_accuracy: 0.9545 - val_loss: 0.4905\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9544 - loss: 0.4321 - val_accuracy: 0.9773 - val_loss: 0.3967\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9668 - loss: 0.3648 - val_accuracy: 0.9545 - val_loss: 0.3994\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.3629 - val_accuracy: 0.9318 - val_loss: 0.3665\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9522 - loss: 0.3469 - val_accuracy: 0.9773 - val_loss: 0.3253\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9648 - loss: 0.3183 - val_accuracy: 0.9886 - val_loss: 0.3180\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9625 - loss: 0.2777 - val_accuracy: 0.9773 - val_loss: 0.2727\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9696 - loss: 0.2575 - val_accuracy: 1.0000 - val_loss: 0.2335\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9779 - loss: 0.2336 - val_accuracy: 0.9773 - val_loss: 0.2407\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.2549 - val_accuracy: 1.0000 - val_loss: 0.2612\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.2181 - val_accuracy: 0.8864 - val_loss: 0.4239\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9654 - loss: 0.2665 - val_accuracy: 0.9545 - val_loss: 0.3103\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9519 - loss: 0.2523 - val_accuracy: 0.9886 - val_loss: 0.2184\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9690 - loss: 0.2011 - val_accuracy: 0.9886 - val_loss: 0.2121\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9901 - loss: 0.1556 - val_accuracy: 1.0000 - val_loss: 0.1583\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.1340 - val_accuracy: 1.0000 - val_loss: 0.1626\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9830 - loss: 0.1432 - val_accuracy: 0.9886 - val_loss: 0.2001\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9767 - loss: 0.1445 - val_accuracy: 0.9886 - val_loss: 0.1705\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9839 - loss: 0.1449 - val_accuracy: 1.0000 - val_loss: 0.1264\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9868 - loss: 0.1285 - val_accuracy: 1.0000 - val_loss: 0.1248\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9936 - loss: 0.0987 - val_accuracy: 0.9886 - val_loss: 0.1258\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.1173 - val_accuracy: 1.0000 - val_loss: 0.1126\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0914 - val_accuracy: 0.9659 - val_loss: 0.2279\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9417 - loss: 0.2754 - val_accuracy: 0.9659 - val_loss: 0.2201\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9743 - loss: 0.1653 - val_accuracy: 0.9545 - val_loss: 0.2057\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.1266 - val_accuracy: 0.9659 - val_loss: 0.1604\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9848 - loss: 0.1213 - val_accuracy: 0.9773 - val_loss: 0.1365\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.1112 - val_accuracy: 0.9886 - val_loss: 0.1072\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.0980 - val_accuracy: 1.0000 - val_loss: 0.0919\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.1006 - val_accuracy: 0.9886 - val_loss: 0.1104\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0682 - val_accuracy: 0.9886 - val_loss: 0.0997\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.1026 - val_accuracy: 1.0000 - val_loss: 0.0791\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0882 - val_accuracy: 0.9773 - val_loss: 0.1262\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9714 - loss: 0.1226 - val_accuracy: 0.9659 - val_loss: 0.1660\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9769 - loss: 0.1393 - val_accuracy: 0.9773 - val_loss: 0.1616\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9833 - loss: 0.1251 - val_accuracy: 0.9886 - val_loss: 0.0943\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.0807 - val_accuracy: 1.0000 - val_loss: 0.0709\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0706 - val_accuracy: 1.0000 - val_loss: 0.0655\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9862 - loss: 0.0859 - val_accuracy: 1.0000 - val_loss: 0.0619\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 0.0585\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9961 - loss: 0.0407 - val_accuracy: 1.0000 - val_loss: 0.0571\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0418 - val_accuracy: 1.0000 - val_loss: 0.0584\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0598 - val_accuracy: 1.0000 - val_loss: 0.0533\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0487 - val_accuracy: 1.0000 - val_loss: 0.0511\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0461 - val_accuracy: 1.0000 - val_loss: 0.0518\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0417 - val_accuracy: 1.0000 - val_loss: 0.0470\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0424 - val_accuracy: 1.0000 - val_loss: 0.0459\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0443 - val_accuracy: 1.0000 - val_loss: 0.0451\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9922 - loss: 0.0520 - val_accuracy: 1.0000 - val_loss: 0.0431\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0415 - val_accuracy: 1.0000 - val_loss: 0.0419\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0460 - val_accuracy: 1.0000 - val_loss: 0.0407\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.0364 - val_accuracy: 1.0000 - val_loss: 0.0396\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0494 - val_accuracy: 1.0000 - val_loss: 0.0397\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0353 - val_accuracy: 1.0000 - val_loss: 0.0382\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0425 - val_accuracy: 1.0000 - val_loss: 0.0388\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0351 - val_accuracy: 1.0000 - val_loss: 0.0369\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0382 - val_accuracy: 1.0000 - val_loss: 0.0393\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9897 - loss: 0.0418 - val_accuracy: 1.0000 - val_loss: 0.0381\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9966 - loss: 0.0366 - val_accuracy: 1.0000 - val_loss: 0.0380\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 0.0348\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.0324 - val_accuracy: 1.0000 - val_loss: 0.0337\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0246 - val_accuracy: 1.0000 - val_loss: 0.0318\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.0380 - val_accuracy: 1.0000 - val_loss: 0.0312\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0212 - val_accuracy: 1.0000 - val_loss: 0.0296\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 0.0298\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.0232 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0266 - val_accuracy: 1.0000 - val_loss: 0.0278\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0226 - val_accuracy: 1.0000 - val_loss: 0.0280\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0232 - val_accuracy: 1.0000 - val_loss: 0.0286\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0284 - val_accuracy: 1.0000 - val_loss: 0.0265\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0288 - val_accuracy: 1.0000 - val_loss: 0.0261\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0317 - val_accuracy: 1.0000 - val_loss: 0.0255\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.0252\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 0.0244\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0315 - val_accuracy: 1.0000 - val_loss: 0.0240\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0328 - val_accuracy: 1.0000 - val_loss: 0.0240\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0231\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0248 - val_accuracy: 1.0000 - val_loss: 0.0224\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0221\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0215\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0313 - val_accuracy: 1.0000 - val_loss: 0.0209\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0192 - val_accuracy: 1.0000 - val_loss: 0.0211\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0335 - val_accuracy: 0.9545 - val_loss: 0.2453\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.0647 - val_accuracy: 0.9886 - val_loss: 0.0615\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9496 - loss: 0.1741 - val_accuracy: 0.9091 - val_loss: 0.3712\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8791 - loss: 0.3608 - val_accuracy: 0.9318 - val_loss: 0.2804\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9466 - loss: 0.2214 - val_accuracy: 0.9545 - val_loss: 0.1705\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9580 - loss: 0.1800 - val_accuracy: 0.9886 - val_loss: 0.1147\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9666 - loss: 0.1426 - val_accuracy: 0.9773 - val_loss: 0.1178\n",
            "\n",
            "Fold 5 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.1137 - loss: 3.1464 - val_accuracy: 0.3750 - val_loss: 2.7573\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4402 - loss: 2.6053 - val_accuracy: 0.5114 - val_loss: 2.2149\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5794 - loss: 2.0746 - val_accuracy: 0.6364 - val_loss: 1.7007\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6803 - loss: 1.5473 - val_accuracy: 0.6705 - val_loss: 1.3804\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7900 - loss: 1.2159 - val_accuracy: 0.7159 - val_loss: 1.2073\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7839 - loss: 1.0725 - val_accuracy: 0.7727 - val_loss: 1.0300\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8697 - loss: 0.8944 - val_accuracy: 0.8295 - val_loss: 0.8890\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9098 - loss: 0.7351 - val_accuracy: 0.8523 - val_loss: 0.8081\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9108 - loss: 0.6429 - val_accuracy: 0.8295 - val_loss: 0.7478\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8920 - loss: 0.6022 - val_accuracy: 0.8523 - val_loss: 0.6833\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9426 - loss: 0.4805 - val_accuracy: 0.8750 - val_loss: 0.5771\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9399 - loss: 0.4269 - val_accuracy: 0.8864 - val_loss: 0.5431\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9515 - loss: 0.3708 - val_accuracy: 0.8636 - val_loss: 0.5446\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9436 - loss: 0.3611 - val_accuracy: 0.8864 - val_loss: 0.4906\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9602 - loss: 0.3234 - val_accuracy: 0.8864 - val_loss: 0.4599\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9327 - loss: 0.3337 - val_accuracy: 0.9091 - val_loss: 0.4126\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9747 - loss: 0.2492 - val_accuracy: 0.9205 - val_loss: 0.3803\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9467 - loss: 0.2685 - val_accuracy: 0.8977 - val_loss: 0.3945\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9459 - loss: 0.2885 - val_accuracy: 0.9205 - val_loss: 0.3867\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9614 - loss: 0.2096 - val_accuracy: 0.9432 - val_loss: 0.3275\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9645 - loss: 0.2130 - val_accuracy: 0.9318 - val_loss: 0.3485\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.1985 - val_accuracy: 0.9091 - val_loss: 0.3536\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9762 - loss: 0.1915 - val_accuracy: 0.9091 - val_loss: 0.3702\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9555 - loss: 0.2251 - val_accuracy: 0.9318 - val_loss: 0.2933\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9675 - loss: 0.1888 - val_accuracy: 0.9318 - val_loss: 0.3154\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.1705 - val_accuracy: 0.9205 - val_loss: 0.3050\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9759 - loss: 0.1669 - val_accuracy: 0.9432 - val_loss: 0.2530\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9740 - loss: 0.1517 - val_accuracy: 0.9432 - val_loss: 0.2515\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.1209 - val_accuracy: 0.9545 - val_loss: 0.2370\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0992 - val_accuracy: 0.9432 - val_loss: 0.2237\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0935 - val_accuracy: 0.9432 - val_loss: 0.2268\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9778 - loss: 0.1222 - val_accuracy: 0.8750 - val_loss: 0.4256\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9266 - loss: 0.2315 - val_accuracy: 0.8977 - val_loss: 0.3767\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9406 - loss: 0.2443 - val_accuracy: 0.8523 - val_loss: 0.4129\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9216 - loss: 0.2711 - val_accuracy: 0.9091 - val_loss: 0.3677\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9631 - loss: 0.2049 - val_accuracy: 0.8977 - val_loss: 0.2957\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9690 - loss: 0.1445 - val_accuracy: 0.9205 - val_loss: 0.2361\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.1164 - val_accuracy: 0.9318 - val_loss: 0.2252\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9849 - loss: 0.0961 - val_accuracy: 0.9318 - val_loss: 0.2224\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9887 - loss: 0.0863 - val_accuracy: 0.9318 - val_loss: 0.2116\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9790 - loss: 0.0948 - val_accuracy: 0.9318 - val_loss: 0.2046\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9822 - loss: 0.0884 - val_accuracy: 0.9318 - val_loss: 0.1968\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9852 - loss: 0.0861 - val_accuracy: 0.9318 - val_loss: 0.1878\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0622 - val_accuracy: 0.8977 - val_loss: 0.3003\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9648 - loss: 0.1374 - val_accuracy: 0.9205 - val_loss: 0.2663\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.1184 - val_accuracy: 0.8977 - val_loss: 0.2911\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.1722 - val_accuracy: 0.9659 - val_loss: 0.1727\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9854 - loss: 0.1060 - val_accuracy: 0.9432 - val_loss: 0.1883\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9960 - loss: 0.0607 - val_accuracy: 0.9318 - val_loss: 0.2010\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9910 - loss: 0.0755 - val_accuracy: 0.9205 - val_loss: 0.2086\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0527 - val_accuracy: 0.9545 - val_loss: 0.1593\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0517 - val_accuracy: 0.9545 - val_loss: 0.1574\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0549 - val_accuracy: 0.9432 - val_loss: 0.1558\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0421 - val_accuracy: 0.9432 - val_loss: 0.1516\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0469 - val_accuracy: 0.9432 - val_loss: 0.1482\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9921 - loss: 0.0589 - val_accuracy: 0.9432 - val_loss: 0.1516\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0357 - val_accuracy: 0.9432 - val_loss: 0.1561\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0326 - val_accuracy: 0.9432 - val_loss: 0.1542\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0421 - val_accuracy: 0.9432 - val_loss: 0.1530\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9972 - loss: 0.0414 - val_accuracy: 0.9432 - val_loss: 0.1519\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0295 - val_accuracy: 0.9545 - val_loss: 0.1523\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0297 - val_accuracy: 0.9545 - val_loss: 0.1528\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0280 - val_accuracy: 0.9545 - val_loss: 0.1497\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0249 - val_accuracy: 0.9545 - val_loss: 0.1509\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0296 - val_accuracy: 0.9545 - val_loss: 0.1502\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0268 - val_accuracy: 0.9545 - val_loss: 0.1473\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9972 - loss: 0.0291 - val_accuracy: 0.9545 - val_loss: 0.1469\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0226 - val_accuracy: 0.9545 - val_loss: 0.1458\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0323 - val_accuracy: 0.9545 - val_loss: 0.1461\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0234 - val_accuracy: 0.9545 - val_loss: 0.1426\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0239 - val_accuracy: 0.9545 - val_loss: 0.1403\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0275 - val_accuracy: 0.9545 - val_loss: 0.1382\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0268 - val_accuracy: 0.9545 - val_loss: 0.1374\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0207 - val_accuracy: 0.9545 - val_loss: 0.1349\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0168 - val_accuracy: 0.9545 - val_loss: 0.1341\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0216 - val_accuracy: 0.9545 - val_loss: 0.1359\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0157 - val_accuracy: 0.9545 - val_loss: 0.1332\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0164 - val_accuracy: 0.9545 - val_loss: 0.1351\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0140 - val_accuracy: 0.9545 - val_loss: 0.1335\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0185 - val_accuracy: 0.9545 - val_loss: 0.1370\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0160 - val_accuracy: 0.9545 - val_loss: 0.1337\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0141 - val_accuracy: 0.9545 - val_loss: 0.1327\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0212 - val_accuracy: 0.9545 - val_loss: 0.1324\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0167 - val_accuracy: 0.9545 - val_loss: 0.1339\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0157 - val_accuracy: 0.9545 - val_loss: 0.1319\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0137 - val_accuracy: 0.9545 - val_loss: 0.1304\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0134 - val_accuracy: 0.9545 - val_loss: 0.1311\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9996 - loss: 0.0123 - val_accuracy: 0.9545 - val_loss: 0.1299\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9954 - loss: 0.0174 - val_accuracy: 0.9545 - val_loss: 0.1318\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0146 - val_accuracy: 0.9545 - val_loss: 0.1300\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0107 - val_accuracy: 0.9545 - val_loss: 0.1302\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0167 - val_accuracy: 0.9545 - val_loss: 0.1329\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0101 - val_accuracy: 0.9545 - val_loss: 0.1303\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9545 - val_loss: 0.1308\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9545 - val_loss: 0.1313\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9545 - val_loss: 0.1325\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9545 - val_loss: 0.1328\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9545 - val_loss: 0.1323\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9545 - val_loss: 0.1333\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9545 - val_loss: 0.1341\n",
            "\n",
            "Fold 6 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.0688 - loss: 3.1805 - val_accuracy: 0.3864 - val_loss: 2.7883\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4282 - loss: 2.6684 - val_accuracy: 0.5909 - val_loss: 2.1272\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6018 - loss: 2.0110 - val_accuracy: 0.7159 - val_loss: 1.5284\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7076 - loss: 1.5140 - val_accuracy: 0.8295 - val_loss: 1.1427\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7639 - loss: 1.1722 - val_accuracy: 0.8523 - val_loss: 0.8867\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8504 - loss: 0.9156 - val_accuracy: 0.8295 - val_loss: 0.7306\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8261 - loss: 0.8247 - val_accuracy: 0.9545 - val_loss: 0.5949\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9094 - loss: 0.6629 - val_accuracy: 0.9318 - val_loss: 0.5279\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9065 - loss: 0.6138 - val_accuracy: 0.9545 - val_loss: 0.4659\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8938 - loss: 0.5684 - val_accuracy: 0.8864 - val_loss: 0.4471\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8905 - loss: 0.5221 - val_accuracy: 0.8409 - val_loss: 0.5310\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9044 - loss: 0.4786 - val_accuracy: 0.9318 - val_loss: 0.3960\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9125 - loss: 0.4241 - val_accuracy: 0.9205 - val_loss: 0.3541\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9123 - loss: 0.4190 - val_accuracy: 0.9545 - val_loss: 0.3779\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9193 - loss: 0.4195 - val_accuracy: 0.9545 - val_loss: 0.3070\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9521 - loss: 0.3121 - val_accuracy: 0.9545 - val_loss: 0.2770\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9637 - loss: 0.2762 - val_accuracy: 0.9773 - val_loss: 0.2298\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9557 - loss: 0.2824 - val_accuracy: 0.9773 - val_loss: 0.2185\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9524 - loss: 0.2626 - val_accuracy: 0.9773 - val_loss: 0.2074\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.2219 - val_accuracy: 0.9659 - val_loss: 0.2102\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9674 - loss: 0.2413 - val_accuracy: 0.9773 - val_loss: 0.2313\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9611 - loss: 0.2447 - val_accuracy: 0.9659 - val_loss: 0.1803\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9774 - loss: 0.1891 - val_accuracy: 0.9773 - val_loss: 0.1595\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.1757 - val_accuracy: 0.9545 - val_loss: 0.2086\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9674 - loss: 0.1964 - val_accuracy: 0.9432 - val_loss: 0.2094\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9501 - loss: 0.2226 - val_accuracy: 0.9659 - val_loss: 0.1746\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9636 - loss: 0.1844 - val_accuracy: 0.9545 - val_loss: 0.1649\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9828 - loss: 0.1590 - val_accuracy: 0.9545 - val_loss: 0.1491\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.1505 - val_accuracy: 0.9318 - val_loss: 0.2266\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9706 - loss: 0.1521 - val_accuracy: 0.9773 - val_loss: 0.1433\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9634 - loss: 0.1753 - val_accuracy: 0.9659 - val_loss: 0.1518\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.1556 - val_accuracy: 0.9773 - val_loss: 0.1126\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9783 - loss: 0.1407 - val_accuracy: 0.9886 - val_loss: 0.1082\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.1217 - val_accuracy: 0.9886 - val_loss: 0.1044\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.1338 - val_accuracy: 0.9886 - val_loss: 0.1089\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0919 - val_accuracy: 0.9886 - val_loss: 0.1038\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0946 - val_accuracy: 0.9886 - val_loss: 0.1000\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.0882 - val_accuracy: 0.9886 - val_loss: 0.0969\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9910 - loss: 0.0811 - val_accuracy: 0.9886 - val_loss: 0.0929\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.0953 - val_accuracy: 0.9886 - val_loss: 0.0863\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.1027 - val_accuracy: 0.9886 - val_loss: 0.0953\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0777 - val_accuracy: 0.9886 - val_loss: 0.1066\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9685 - loss: 0.1205 - val_accuracy: 0.9318 - val_loss: 0.1859\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9810 - loss: 0.1131 - val_accuracy: 0.9886 - val_loss: 0.0848\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9679 - loss: 0.1275 - val_accuracy: 0.9773 - val_loss: 0.1606\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9726 - loss: 0.1297 - val_accuracy: 0.9545 - val_loss: 0.1375\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9505 - loss: 0.1702 - val_accuracy: 0.9432 - val_loss: 0.1361\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9724 - loss: 0.1055 - val_accuracy: 0.9545 - val_loss: 0.1292\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9585 - loss: 0.1171 - val_accuracy: 0.9886 - val_loss: 0.1168\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9652 - loss: 0.1301 - val_accuracy: 0.9773 - val_loss: 0.1159\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9737 - loss: 0.0971 - val_accuracy: 0.9545 - val_loss: 0.1101\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9753 - loss: 0.0898 - val_accuracy: 0.9773 - val_loss: 0.1056\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.1140 - val_accuracy: 0.9886 - val_loss: 0.0752\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0669 - val_accuracy: 0.9886 - val_loss: 0.0727\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 0.0448 - val_accuracy: 0.9886 - val_loss: 0.0656\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0509 - val_accuracy: 0.9886 - val_loss: 0.0638\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9969 - loss: 0.0409 - val_accuracy: 0.9886 - val_loss: 0.0629\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9921 - loss: 0.0523 - val_accuracy: 0.9886 - val_loss: 0.0599\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9956 - loss: 0.0395 - val_accuracy: 0.9886 - val_loss: 0.0574\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9943 - loss: 0.0382 - val_accuracy: 0.9886 - val_loss: 0.0555\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.0496 - val_accuracy: 0.9886 - val_loss: 0.0552\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0365 - val_accuracy: 0.9886 - val_loss: 0.0539\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0343 - val_accuracy: 0.9886 - val_loss: 0.0523\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0537 - val_accuracy: 0.9886 - val_loss: 0.0508\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0281 - val_accuracy: 0.9886 - val_loss: 0.0505\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0341 - val_accuracy: 0.9886 - val_loss: 0.0502\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0497 - val_accuracy: 0.9886 - val_loss: 0.0496\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0335 - val_accuracy: 0.9886 - val_loss: 0.0491\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9973 - loss: 0.0351 - val_accuracy: 0.9886 - val_loss: 0.0478\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0288 - val_accuracy: 0.9886 - val_loss: 0.0527\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0356 - val_accuracy: 0.9659 - val_loss: 0.1062\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9921 - loss: 0.0489 - val_accuracy: 0.9773 - val_loss: 0.0521\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9931 - loss: 0.0459 - val_accuracy: 0.9886 - val_loss: 0.0490\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9421 - loss: 0.2051 - val_accuracy: 0.9432 - val_loss: 0.2067\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9576 - loss: 0.1651 - val_accuracy: 0.9773 - val_loss: 0.1444\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9628 - loss: 0.1274 - val_accuracy: 0.9545 - val_loss: 0.1697\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9453 - loss: 0.1862 - val_accuracy: 0.9432 - val_loss: 0.1243\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.1019 - val_accuracy: 0.9773 - val_loss: 0.0871\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0570 - val_accuracy: 0.9545 - val_loss: 0.2017\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9542 - loss: 0.1521 - val_accuracy: 0.9659 - val_loss: 0.1387\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9343 - loss: 0.2091 - val_accuracy: 0.8977 - val_loss: 0.3232\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9236 - loss: 0.2155 - val_accuracy: 0.9318 - val_loss: 0.1345\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9557 - loss: 0.1409 - val_accuracy: 0.9659 - val_loss: 0.1048\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9543 - loss: 0.1468 - val_accuracy: 0.9432 - val_loss: 0.2127\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9621 - loss: 0.1717 - val_accuracy: 0.9432 - val_loss: 0.1536\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9723 - loss: 0.1158 - val_accuracy: 0.9886 - val_loss: 0.1132\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9804 - loss: 0.1151 - val_accuracy: 0.9091 - val_loss: 0.1605\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9236 - loss: 0.2617 - val_accuracy: 0.9432 - val_loss: 0.1206\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9718 - loss: 0.0971 - val_accuracy: 0.9545 - val_loss: 0.1009\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9843 - loss: 0.0884 - val_accuracy: 0.9659 - val_loss: 0.0870\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.0804 - val_accuracy: 0.9773 - val_loss: 0.0784\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0836 - val_accuracy: 0.9886 - val_loss: 0.0717\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9960 - loss: 0.0547 - val_accuracy: 0.9886 - val_loss: 0.0586\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0612 - val_accuracy: 0.9659 - val_loss: 0.0673\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9856 - loss: 0.0516 - val_accuracy: 0.9886 - val_loss: 0.0648\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0483 - val_accuracy: 0.9886 - val_loss: 0.0651\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0503 - val_accuracy: 0.9886 - val_loss: 0.0555\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0428 - val_accuracy: 0.9886 - val_loss: 0.0557\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0414 - val_accuracy: 0.9886 - val_loss: 0.0599\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0381 - val_accuracy: 0.9886 - val_loss: 0.0564\n",
            "\n",
            "Fold 7 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.0896 - loss: 3.1130 - val_accuracy: 0.3068 - val_loss: 2.6933\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3335 - loss: 2.5172 - val_accuracy: 0.5682 - val_loss: 2.0631\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6866 - loss: 1.9241 - val_accuracy: 0.7727 - val_loss: 1.5805\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8071 - loss: 1.4644 - val_accuracy: 0.8182 - val_loss: 1.3045\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8111 - loss: 1.1812 - val_accuracy: 0.8409 - val_loss: 1.0344\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8547 - loss: 1.0032 - val_accuracy: 0.8977 - val_loss: 0.8460\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8790 - loss: 0.8395 - val_accuracy: 0.9205 - val_loss: 0.7463\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8827 - loss: 0.7460 - val_accuracy: 0.9205 - val_loss: 0.6293\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9174 - loss: 0.6248 - val_accuracy: 0.9091 - val_loss: 0.5611\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9046 - loss: 0.5715 - val_accuracy: 0.9205 - val_loss: 0.5218\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9310 - loss: 0.4907 - val_accuracy: 0.9432 - val_loss: 0.4456\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9373 - loss: 0.4395 - val_accuracy: 0.8636 - val_loss: 0.5895\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8743 - loss: 0.5341 - val_accuracy: 0.9432 - val_loss: 0.4177\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9566 - loss: 0.3818 - val_accuracy: 0.9545 - val_loss: 0.3658\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9456 - loss: 0.3614 - val_accuracy: 0.9659 - val_loss: 0.3103\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9500 - loss: 0.3184 - val_accuracy: 0.9659 - val_loss: 0.2909\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9600 - loss: 0.2483 - val_accuracy: 0.9659 - val_loss: 0.2622\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9771 - loss: 0.2269 - val_accuracy: 0.9659 - val_loss: 0.2500\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9655 - loss: 0.2185 - val_accuracy: 0.9659 - val_loss: 0.2412\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.2037 - val_accuracy: 0.9545 - val_loss: 0.2692\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9396 - loss: 0.2952 - val_accuracy: 0.9886 - val_loss: 0.2462\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9617 - loss: 0.2498 - val_accuracy: 0.9659 - val_loss: 0.2382\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9785 - loss: 0.1822 - val_accuracy: 0.9886 - val_loss: 0.2016\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.1560 - val_accuracy: 0.9773 - val_loss: 0.1926\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.1433 - val_accuracy: 0.9886 - val_loss: 0.2096\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9832 - loss: 0.1633 - val_accuracy: 0.9886 - val_loss: 0.1770\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.1389 - val_accuracy: 0.9886 - val_loss: 0.1667\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9887 - loss: 0.1181 - val_accuracy: 0.9318 - val_loss: 0.2648\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9560 - loss: 0.1925 - val_accuracy: 0.9773 - val_loss: 0.1785\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9912 - loss: 0.1199 - val_accuracy: 0.9773 - val_loss: 0.1767\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9847 - loss: 0.1152 - val_accuracy: 0.9886 - val_loss: 0.1538\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.1080 - val_accuracy: 0.9886 - val_loss: 0.1476\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9824 - loss: 0.1173 - val_accuracy: 0.9886 - val_loss: 0.1450\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9968 - loss: 0.0756 - val_accuracy: 0.9886 - val_loss: 0.1444\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0706 - val_accuracy: 0.9886 - val_loss: 0.1374\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0872 - val_accuracy: 0.9886 - val_loss: 0.1360\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9989 - loss: 0.0711 - val_accuracy: 0.9886 - val_loss: 0.1351\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9949 - loss: 0.0688 - val_accuracy: 0.9886 - val_loss: 0.1329\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9960 - loss: 0.0657 - val_accuracy: 0.9886 - val_loss: 0.1322\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0608 - val_accuracy: 0.9886 - val_loss: 0.1315\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0644 - val_accuracy: 0.9886 - val_loss: 0.1295\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0485 - val_accuracy: 0.9886 - val_loss: 0.1290\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9972 - loss: 0.0442 - val_accuracy: 0.9886 - val_loss: 0.1289\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0505 - val_accuracy: 0.9773 - val_loss: 0.1433\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0423 - val_accuracy: 0.9659 - val_loss: 0.1406\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0402 - val_accuracy: 0.9659 - val_loss: 0.1432\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0481 - val_accuracy: 0.9659 - val_loss: 0.1532\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9959 - loss: 0.0470 - val_accuracy: 0.9659 - val_loss: 0.1632\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0479 - val_accuracy: 0.9773 - val_loss: 0.1348\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9888 - loss: 0.0561 - val_accuracy: 0.9773 - val_loss: 0.1431\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0600 - val_accuracy: 0.9205 - val_loss: 0.3402\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9159 - loss: 0.2956 - val_accuracy: 0.7273 - val_loss: 0.8611\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8550 - loss: 0.5579 - val_accuracy: 0.8750 - val_loss: 0.3657\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9186 - loss: 0.2664 - val_accuracy: 0.8977 - val_loss: 0.3753\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9316 - loss: 0.2204 - val_accuracy: 0.9205 - val_loss: 0.2810\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9221 - loss: 0.2754 - val_accuracy: 0.9545 - val_loss: 0.2768\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9582 - loss: 0.1882 - val_accuracy: 0.9773 - val_loss: 0.1886\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9787 - loss: 0.1458 - val_accuracy: 0.9205 - val_loss: 0.2390\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.1514 - val_accuracy: 0.9773 - val_loss: 0.1659\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.1078 - val_accuracy: 0.9886 - val_loss: 0.1317\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.0798 - val_accuracy: 0.9886 - val_loss: 0.1277\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0527 - val_accuracy: 0.9886 - val_loss: 0.1186\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.0770 - val_accuracy: 0.9886 - val_loss: 0.1201\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9840 - loss: 0.0729 - val_accuracy: 0.9659 - val_loss: 0.1733\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.1107 - val_accuracy: 0.9432 - val_loss: 0.2600\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9603 - loss: 0.1412 - val_accuracy: 0.9432 - val_loss: 0.2185\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9620 - loss: 0.1175 - val_accuracy: 0.9886 - val_loss: 0.1271\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9931 - loss: 0.0661 - val_accuracy: 0.9886 - val_loss: 0.1159\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0442 - val_accuracy: 0.9886 - val_loss: 0.1145\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0408 - val_accuracy: 0.9886 - val_loss: 0.1158\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.0948 - val_accuracy: 0.9659 - val_loss: 0.1559\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9635 - loss: 0.0774 - val_accuracy: 0.9886 - val_loss: 0.1393\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0595 - val_accuracy: 0.9886 - val_loss: 0.1284\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0543 - val_accuracy: 0.9886 - val_loss: 0.1223\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0417 - val_accuracy: 0.9886 - val_loss: 0.1162\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9960 - loss: 0.0373 - val_accuracy: 0.9886 - val_loss: 0.1134\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.0474 - val_accuracy: 0.9886 - val_loss: 0.1117\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0384 - val_accuracy: 0.9886 - val_loss: 0.1107\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9992 - loss: 0.0291 - val_accuracy: 0.9886 - val_loss: 0.1101\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9963 - loss: 0.0339 - val_accuracy: 0.9886 - val_loss: 0.1104\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9979 - loss: 0.0290 - val_accuracy: 0.9886 - val_loss: 0.1121\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0282 - val_accuracy: 0.9886 - val_loss: 0.1136\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0214 - val_accuracy: 0.9886 - val_loss: 0.1152\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0266 - val_accuracy: 0.9886 - val_loss: 0.1112\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0362 - val_accuracy: 0.9773 - val_loss: 0.1294\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0328 - val_accuracy: 0.9886 - val_loss: 0.1100\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.0689 - val_accuracy: 0.9886 - val_loss: 0.1154\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9842 - loss: 0.0641 - val_accuracy: 0.9545 - val_loss: 0.2031\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9723 - loss: 0.1115 - val_accuracy: 0.9773 - val_loss: 0.1474\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.0745 - val_accuracy: 0.9545 - val_loss: 0.1571\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9780 - loss: 0.0964 - val_accuracy: 0.9432 - val_loss: 0.2232\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.0864 - val_accuracy: 0.9545 - val_loss: 0.1886\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9746 - loss: 0.0857 - val_accuracy: 0.9432 - val_loss: 0.1911\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0865 - val_accuracy: 0.9886 - val_loss: 0.1189\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9610 - loss: 0.1325 - val_accuracy: 0.9773 - val_loss: 0.1810\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.0934 - val_accuracy: 0.9773 - val_loss: 0.1538\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9943 - loss: 0.0483 - val_accuracy: 0.9886 - val_loss: 0.1129\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0588 - val_accuracy: 0.9886 - val_loss: 0.1214\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9969 - loss: 0.0407 - val_accuracy: 0.9773 - val_loss: 0.1362\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0441 - val_accuracy: 0.9659 - val_loss: 0.1455\n",
            "\n",
            "Fold 8 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1219 - loss: 3.1622 - val_accuracy: 0.4091 - val_loss: 2.7066\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4077 - loss: 2.5527 - val_accuracy: 0.5455 - val_loss: 2.1669\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5659 - loss: 2.0240 - val_accuracy: 0.6364 - val_loss: 1.6743\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6784 - loss: 1.5768 - val_accuracy: 0.8295 - val_loss: 1.2873\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8766 - loss: 1.1429 - val_accuracy: 0.8636 - val_loss: 1.0476\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9066 - loss: 0.9722 - val_accuracy: 0.9091 - val_loss: 0.8205\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9371 - loss: 0.7556 - val_accuracy: 0.9091 - val_loss: 0.7104\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9264 - loss: 0.6617 - val_accuracy: 0.8977 - val_loss: 0.6233\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.5399 - val_accuracy: 0.9091 - val_loss: 0.5649\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.4822 - val_accuracy: 0.9205 - val_loss: 0.4787\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9539 - loss: 0.4334 - val_accuracy: 0.8977 - val_loss: 0.5041\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9196 - loss: 0.4687 - val_accuracy: 0.8750 - val_loss: 0.5095\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9393 - loss: 0.3830 - val_accuracy: 0.8864 - val_loss: 0.4574\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9383 - loss: 0.3372 - val_accuracy: 0.8750 - val_loss: 0.4588\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9538 - loss: 0.3070 - val_accuracy: 0.9318 - val_loss: 0.3487\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9795 - loss: 0.2411 - val_accuracy: 0.8977 - val_loss: 0.4234\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9368 - loss: 0.3208 - val_accuracy: 0.9318 - val_loss: 0.4415\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9477 - loss: 0.3418 - val_accuracy: 0.9432 - val_loss: 0.3050\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9665 - loss: 0.2223 - val_accuracy: 0.9318 - val_loss: 0.3297\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.2027 - val_accuracy: 0.8977 - val_loss: 0.3639\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9651 - loss: 0.2215 - val_accuracy: 0.8750 - val_loss: 0.3516\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9542 - loss: 0.2021 - val_accuracy: 0.9432 - val_loss: 0.3108\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.1743 - val_accuracy: 0.9318 - val_loss: 0.2849\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.1708 - val_accuracy: 0.9205 - val_loss: 0.3042\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9741 - loss: 0.1490 - val_accuracy: 0.9318 - val_loss: 0.3251\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9656 - loss: 0.1811 - val_accuracy: 0.9205 - val_loss: 0.2868\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9683 - loss: 0.1475 - val_accuracy: 0.9545 - val_loss: 0.2332\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9741 - loss: 0.1410 - val_accuracy: 0.9432 - val_loss: 0.2520\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.1089 - val_accuracy: 0.9318 - val_loss: 0.2404\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 0.0883 - val_accuracy: 0.9318 - val_loss: 0.2875\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.1006 - val_accuracy: 0.9318 - val_loss: 0.2498\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9887 - loss: 0.0902 - val_accuracy: 0.9432 - val_loss: 0.2419\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0878 - val_accuracy: 0.9318 - val_loss: 0.2461\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9833 - loss: 0.0954 - val_accuracy: 0.9318 - val_loss: 0.2463\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9845 - loss: 0.1018 - val_accuracy: 0.9545 - val_loss: 0.2516\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9697 - loss: 0.1365 - val_accuracy: 0.9432 - val_loss: 0.2854\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0719 - val_accuracy: 0.9432 - val_loss: 0.2543\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.0840 - val_accuracy: 0.9318 - val_loss: 0.2547\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0706 - val_accuracy: 0.9318 - val_loss: 0.2453\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9907 - loss: 0.0775 - val_accuracy: 0.9432 - val_loss: 0.2469\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0765 - val_accuracy: 0.9432 - val_loss: 0.2428\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0595 - val_accuracy: 0.9318 - val_loss: 0.2465\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9915 - loss: 0.0552 - val_accuracy: 0.9432 - val_loss: 0.2492\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.0767 - val_accuracy: 0.9432 - val_loss: 0.2385\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0549 - val_accuracy: 0.9432 - val_loss: 0.2296\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9927 - loss: 0.0581 - val_accuracy: 0.9432 - val_loss: 0.2501\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9907 - loss: 0.0630 - val_accuracy: 0.9318 - val_loss: 0.3118\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0498 - val_accuracy: 0.9318 - val_loss: 0.2615\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0581 - val_accuracy: 0.9545 - val_loss: 0.2292\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0691 - val_accuracy: 0.9205 - val_loss: 0.3668\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.1216 - val_accuracy: 0.9545 - val_loss: 0.2886\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9792 - loss: 0.0911 - val_accuracy: 0.9545 - val_loss: 0.2886\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9494 - loss: 0.1919 - val_accuracy: 0.8750 - val_loss: 0.4451\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8782 - loss: 0.4296 - val_accuracy: 0.8068 - val_loss: 0.7043\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8488 - loss: 0.5201 - val_accuracy: 0.8636 - val_loss: 0.4246\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8755 - loss: 0.3247 - val_accuracy: 0.9091 - val_loss: 0.3774\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9301 - loss: 0.2983 - val_accuracy: 0.8864 - val_loss: 0.3427\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9064 - loss: 0.2689 - val_accuracy: 0.9432 - val_loss: 0.2586\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9553 - loss: 0.1770 - val_accuracy: 0.9432 - val_loss: 0.2464\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.1618 - val_accuracy: 0.9545 - val_loss: 0.2443\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9768 - loss: 0.1159 - val_accuracy: 0.9432 - val_loss: 0.2273\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.0904 - val_accuracy: 0.9545 - val_loss: 0.2541\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0769 - val_accuracy: 0.9545 - val_loss: 0.2622\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0702 - val_accuracy: 0.9318 - val_loss: 0.3254\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9776 - loss: 0.1011 - val_accuracy: 0.9545 - val_loss: 0.2413\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0629 - val_accuracy: 0.9432 - val_loss: 0.2077\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0619 - val_accuracy: 0.9545 - val_loss: 0.2363\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9878 - loss: 0.0738 - val_accuracy: 0.9432 - val_loss: 0.2364\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9957 - loss: 0.0415 - val_accuracy: 0.9432 - val_loss: 0.2351\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0627 - val_accuracy: 0.9432 - val_loss: 0.2379\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0423 - val_accuracy: 0.9318 - val_loss: 0.2425\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0367 - val_accuracy: 0.9432 - val_loss: 0.2370\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0401 - val_accuracy: 0.9432 - val_loss: 0.2331\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0530 - val_accuracy: 0.9432 - val_loss: 0.2305\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0512 - val_accuracy: 0.9432 - val_loss: 0.2289\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0329 - val_accuracy: 0.9432 - val_loss: 0.2293\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0325 - val_accuracy: 0.9545 - val_loss: 0.2308\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0380 - val_accuracy: 0.9545 - val_loss: 0.2372\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0268 - val_accuracy: 0.9545 - val_loss: 0.2380\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0289 - val_accuracy: 0.9545 - val_loss: 0.2375\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0398 - val_accuracy: 0.9545 - val_loss: 0.2394\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0246 - val_accuracy: 0.9545 - val_loss: 0.2397\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9990 - loss: 0.0243 - val_accuracy: 0.9545 - val_loss: 0.2395\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.0275 - val_accuracy: 0.9545 - val_loss: 0.2408\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0355 - val_accuracy: 0.9545 - val_loss: 0.2393\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.0348 - val_accuracy: 0.9545 - val_loss: 0.2428\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0306 - val_accuracy: 0.9545 - val_loss: 0.2430\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0191 - val_accuracy: 0.9545 - val_loss: 0.2455\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9946 - loss: 0.0358 - val_accuracy: 0.9545 - val_loss: 0.2435\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0401 - val_accuracy: 0.9545 - val_loss: 0.2470\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.0221 - val_accuracy: 0.9545 - val_loss: 0.2475\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0376 - val_accuracy: 0.9545 - val_loss: 0.2488\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9973 - loss: 0.0237 - val_accuracy: 0.9545 - val_loss: 0.2510\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9965 - loss: 0.0326 - val_accuracy: 0.9545 - val_loss: 0.2520\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0247 - val_accuracy: 0.9545 - val_loss: 0.2527\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9994 - loss: 0.0218 - val_accuracy: 0.9545 - val_loss: 0.2538\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0155 - val_accuracy: 0.9545 - val_loss: 0.2538\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0201 - val_accuracy: 0.9545 - val_loss: 0.2551\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0172 - val_accuracy: 0.9545 - val_loss: 0.2558\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0253 - val_accuracy: 0.9545 - val_loss: 0.2567\n",
            "\n",
            "Fold 9 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.0855 - loss: 3.2417 - val_accuracy: 0.2955 - val_loss: 2.8337\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3532 - loss: 2.6900 - val_accuracy: 0.6591 - val_loss: 2.2766\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6300 - loss: 2.1447 - val_accuracy: 0.7273 - val_loss: 1.7395\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7410 - loss: 1.6263 - val_accuracy: 0.7841 - val_loss: 1.3770\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7757 - loss: 1.2622 - val_accuracy: 0.7614 - val_loss: 1.1524\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8141 - loss: 1.0162 - val_accuracy: 0.8636 - val_loss: 0.9408\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8657 - loss: 0.8535 - val_accuracy: 0.8523 - val_loss: 0.8341\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8704 - loss: 0.7448 - val_accuracy: 0.9205 - val_loss: 0.7141\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9359 - loss: 0.6079 - val_accuracy: 0.8977 - val_loss: 0.6501\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8732 - loss: 0.6302 - val_accuracy: 0.9432 - val_loss: 0.5896\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9338 - loss: 0.4966 - val_accuracy: 0.9545 - val_loss: 0.5084\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9219 - loss: 0.4303 - val_accuracy: 0.9091 - val_loss: 0.5170\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9319 - loss: 0.3938 - val_accuracy: 0.8977 - val_loss: 0.5406\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9425 - loss: 0.3800 - val_accuracy: 0.9318 - val_loss: 0.4208\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9654 - loss: 0.3191 - val_accuracy: 0.9205 - val_loss: 0.4243\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9608 - loss: 0.2944 - val_accuracy: 0.9205 - val_loss: 0.4111\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.2708 - val_accuracy: 0.9091 - val_loss: 0.4279\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9615 - loss: 0.3139 - val_accuracy: 0.9545 - val_loss: 0.3484\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9613 - loss: 0.2733 - val_accuracy: 0.9432 - val_loss: 0.3524\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.2295 - val_accuracy: 0.9205 - val_loss: 0.3673\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.1949 - val_accuracy: 0.9432 - val_loss: 0.2980\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.1505 - val_accuracy: 0.9432 - val_loss: 0.2873\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9748 - loss: 0.1715 - val_accuracy: 0.9545 - val_loss: 0.2856\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9886 - loss: 0.1295 - val_accuracy: 0.9432 - val_loss: 0.2756\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.1641 - val_accuracy: 0.9432 - val_loss: 0.3010\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9854 - loss: 0.1400 - val_accuracy: 0.9205 - val_loss: 0.2840\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9715 - loss: 0.1650 - val_accuracy: 0.9545 - val_loss: 0.2913\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.1301 - val_accuracy: 0.9545 - val_loss: 0.2526\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9867 - loss: 0.1372 - val_accuracy: 0.9545 - val_loss: 0.2605\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9900 - loss: 0.1092 - val_accuracy: 0.9545 - val_loss: 0.2529\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9878 - loss: 0.1118 - val_accuracy: 0.9432 - val_loss: 0.2671\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0817 - val_accuracy: 0.9545 - val_loss: 0.2406\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.1101 - val_accuracy: 0.9318 - val_loss: 0.2805\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.1206 - val_accuracy: 0.9545 - val_loss: 0.2354\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9935 - loss: 0.0840 - val_accuracy: 0.9545 - val_loss: 0.2301\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9721 - loss: 0.1581 - val_accuracy: 0.9432 - val_loss: 0.2247\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9699 - loss: 0.1412 - val_accuracy: 0.9545 - val_loss: 0.2074\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9838 - loss: 0.1071 - val_accuracy: 0.9545 - val_loss: 0.2052\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0793 - val_accuracy: 0.9432 - val_loss: 0.2130\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0802 - val_accuracy: 0.9432 - val_loss: 0.2131\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0578 - val_accuracy: 0.9432 - val_loss: 0.2211\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0602 - val_accuracy: 0.9432 - val_loss: 0.2162\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0487 - val_accuracy: 0.9432 - val_loss: 0.2139\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.0558 - val_accuracy: 0.9432 - val_loss: 0.2109\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0474 - val_accuracy: 0.9432 - val_loss: 0.2087\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9884 - loss: 0.0656 - val_accuracy: 0.9432 - val_loss: 0.2067\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0696 - val_accuracy: 0.9432 - val_loss: 0.2054\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.0451 - val_accuracy: 0.9432 - val_loss: 0.2037\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0449 - val_accuracy: 0.9432 - val_loss: 0.2015\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.0566 - val_accuracy: 0.9545 - val_loss: 0.2000\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0448 - val_accuracy: 0.9545 - val_loss: 0.1992\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9917 - loss: 0.0488 - val_accuracy: 0.9545 - val_loss: 0.1977\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0390 - val_accuracy: 0.9545 - val_loss: 0.1942\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0543 - val_accuracy: 0.9545 - val_loss: 0.1934\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0364 - val_accuracy: 0.9545 - val_loss: 0.1921\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0403 - val_accuracy: 0.9545 - val_loss: 0.1903\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0321 - val_accuracy: 0.9545 - val_loss: 0.1891\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0417 - val_accuracy: 0.9545 - val_loss: 0.1869\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0492 - val_accuracy: 0.9545 - val_loss: 0.1859\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0481 - val_accuracy: 0.9545 - val_loss: 0.1845\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0300 - val_accuracy: 0.9545 - val_loss: 0.1837\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0411 - val_accuracy: 0.9545 - val_loss: 0.1820\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0311 - val_accuracy: 0.9545 - val_loss: 0.1798\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0271 - val_accuracy: 0.9545 - val_loss: 0.1797\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9935 - loss: 0.0302 - val_accuracy: 0.9545 - val_loss: 0.1765\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9971 - loss: 0.0249 - val_accuracy: 0.9545 - val_loss: 0.1762\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9979 - loss: 0.0200 - val_accuracy: 0.9545 - val_loss: 0.1752\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9973 - loss: 0.0222 - val_accuracy: 0.9545 - val_loss: 0.1733\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9965 - loss: 0.0253 - val_accuracy: 0.9545 - val_loss: 0.1734\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0237 - val_accuracy: 0.9545 - val_loss: 0.1737\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9793 - loss: 0.0817 - val_accuracy: 0.8864 - val_loss: 0.3867\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8455 - loss: 0.4898 - val_accuracy: 0.8864 - val_loss: 0.3635\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9006 - loss: 0.3121 - val_accuracy: 0.9091 - val_loss: 0.2855\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9456 - loss: 0.2541 - val_accuracy: 0.9432 - val_loss: 0.2325\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9614 - loss: 0.1482 - val_accuracy: 0.9545 - val_loss: 0.1860\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.1204 - val_accuracy: 0.9659 - val_loss: 0.1622\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9659 - loss: 0.1477 - val_accuracy: 0.9432 - val_loss: 0.2071\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9747 - loss: 0.1058 - val_accuracy: 0.9432 - val_loss: 0.1954\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9716 - loss: 0.1058 - val_accuracy: 0.9432 - val_loss: 0.1897\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.0687 - val_accuracy: 0.9659 - val_loss: 0.1437\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.0516 - val_accuracy: 0.9659 - val_loss: 0.1310\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0468 - val_accuracy: 0.9659 - val_loss: 0.1267\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0541 - val_accuracy: 0.9659 - val_loss: 0.1249\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0547 - val_accuracy: 0.9659 - val_loss: 0.1312\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9736 - loss: 0.1074 - val_accuracy: 0.9205 - val_loss: 0.1808\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9671 - loss: 0.0943 - val_accuracy: 0.9659 - val_loss: 0.1533\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9804 - loss: 0.0793 - val_accuracy: 0.9773 - val_loss: 0.1439\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9908 - loss: 0.0602 - val_accuracy: 0.9773 - val_loss: 0.1319\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.0562 - val_accuracy: 0.9773 - val_loss: 0.1265\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0557 - val_accuracy: 0.9659 - val_loss: 0.1302\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0345 - val_accuracy: 0.9659 - val_loss: 0.1320\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0438 - val_accuracy: 0.9773 - val_loss: 0.1227\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0328 - val_accuracy: 0.9659 - val_loss: 0.1419\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9943 - loss: 0.0434 - val_accuracy: 0.9659 - val_loss: 0.1395\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0419 - val_accuracy: 0.9659 - val_loss: 0.1348\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0363 - val_accuracy: 0.9659 - val_loss: 0.1369\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0460 - val_accuracy: 0.9773 - val_loss: 0.1063\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0330 - val_accuracy: 0.9659 - val_loss: 0.1089\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0256 - val_accuracy: 0.9659 - val_loss: 0.1330\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0271 - val_accuracy: 0.9773 - val_loss: 0.1010\n",
            "\n",
            "Fold 10 / 10\n",
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.1666 - loss: 3.0898 - val_accuracy: 0.2727 - val_loss: 2.6664\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.3180 - loss: 2.5037 - val_accuracy: 0.5000 - val_loss: 2.0921\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5227 - loss: 1.9592 - val_accuracy: 0.6818 - val_loss: 1.6313\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6820 - loss: 1.5281 - val_accuracy: 0.8295 - val_loss: 1.2714\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 1.2315 - val_accuracy: 0.8295 - val_loss: 0.9925\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8220 - loss: 0.9841 - val_accuracy: 0.8523 - val_loss: 0.8791\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8358 - loss: 0.8821 - val_accuracy: 0.8864 - val_loss: 0.7328\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8884 - loss: 0.7295 - val_accuracy: 0.8523 - val_loss: 0.6890\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8138 - loss: 0.7546 - val_accuracy: 0.8750 - val_loss: 0.6253\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8686 - loss: 0.6333 - val_accuracy: 0.9318 - val_loss: 0.5339\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.5512 - val_accuracy: 0.9545 - val_loss: 0.4313\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9062 - loss: 0.5157 - val_accuracy: 0.9318 - val_loss: 0.4609\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9309 - loss: 0.4579 - val_accuracy: 0.9659 - val_loss: 0.3594\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.3708 - val_accuracy: 0.9318 - val_loss: 0.3770\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9119 - loss: 0.4106 - val_accuracy: 0.9318 - val_loss: 0.3428\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9406 - loss: 0.3511 - val_accuracy: 0.9659 - val_loss: 0.3310\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.3265 - val_accuracy: 0.9545 - val_loss: 0.2866\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9266 - loss: 0.3015 - val_accuracy: 0.9886 - val_loss: 0.2452\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9699 - loss: 0.2687 - val_accuracy: 0.9773 - val_loss: 0.2434\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9625 - loss: 0.2655 - val_accuracy: 0.9545 - val_loss: 0.2583\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9504 - loss: 0.2865 - val_accuracy: 0.9659 - val_loss: 0.2413\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.2509 - val_accuracy: 0.9432 - val_loss: 0.2728\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9610 - loss: 0.2319 - val_accuracy: 0.9659 - val_loss: 0.2151\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9663 - loss: 0.2137 - val_accuracy: 0.9773 - val_loss: 0.1832\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9785 - loss: 0.1705 - val_accuracy: 0.9659 - val_loss: 0.2028\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9146 - loss: 0.3504 - val_accuracy: 0.9545 - val_loss: 0.2622\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.2113 - val_accuracy: 0.9318 - val_loss: 0.2501\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9504 - loss: 0.2547 - val_accuracy: 0.9886 - val_loss: 0.1656\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9535 - loss: 0.2245 - val_accuracy: 0.9545 - val_loss: 0.2571\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9685 - loss: 0.1997 - val_accuracy: 0.9886 - val_loss: 0.1741\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9779 - loss: 0.1907 - val_accuracy: 0.9773 - val_loss: 0.2170\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9461 - loss: 0.2421 - val_accuracy: 0.9318 - val_loss: 0.2452\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9570 - loss: 0.2143 - val_accuracy: 0.9773 - val_loss: 0.1894\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9664 - loss: 0.2082 - val_accuracy: 0.9545 - val_loss: 0.2066\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9688 - loss: 0.1735 - val_accuracy: 0.9545 - val_loss: 0.2036\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.1471 - val_accuracy: 0.9773 - val_loss: 0.1419\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9797 - loss: 0.1318 - val_accuracy: 0.9773 - val_loss: 0.1415\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9901 - loss: 0.1083 - val_accuracy: 0.9773 - val_loss: 0.1316\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0981 - val_accuracy: 0.9659 - val_loss: 0.1578\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.0932 - val_accuracy: 0.9773 - val_loss: 0.1223\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9862 - loss: 0.0920 - val_accuracy: 0.9545 - val_loss: 0.1633\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9817 - loss: 0.1093 - val_accuracy: 0.9659 - val_loss: 0.1423\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9869 - loss: 0.0976 - val_accuracy: 0.9773 - val_loss: 0.1167\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9932 - loss: 0.0696 - val_accuracy: 0.9773 - val_loss: 0.1132\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9947 - loss: 0.0621 - val_accuracy: 0.9773 - val_loss: 0.1132\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0645 - val_accuracy: 0.9659 - val_loss: 0.1426\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9818 - loss: 0.0910 - val_accuracy: 0.9545 - val_loss: 0.1440\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0810 - val_accuracy: 0.9773 - val_loss: 0.1227\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0711 - val_accuracy: 0.9773 - val_loss: 0.1107\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0657 - val_accuracy: 0.9659 - val_loss: 0.1173\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0623 - val_accuracy: 0.9659 - val_loss: 0.1199\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.0683 - val_accuracy: 0.9659 - val_loss: 0.1217\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0716 - val_accuracy: 0.9773 - val_loss: 0.1027\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0668 - val_accuracy: 0.9773 - val_loss: 0.1033\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0499 - val_accuracy: 0.9773 - val_loss: 0.1056\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0514 - val_accuracy: 0.9886 - val_loss: 0.0820\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0495 - val_accuracy: 0.9773 - val_loss: 0.0997\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0543 - val_accuracy: 0.9773 - val_loss: 0.1243\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0523 - val_accuracy: 0.9773 - val_loss: 0.0821\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.0694 - val_accuracy: 0.9773 - val_loss: 0.0808\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0629 - val_accuracy: 0.9545 - val_loss: 0.1371\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0464 - val_accuracy: 0.9773 - val_loss: 0.1025\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.0837 - val_accuracy: 0.9659 - val_loss: 0.1359\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0681 - val_accuracy: 0.9773 - val_loss: 0.1315\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9840 - loss: 0.0735 - val_accuracy: 0.9773 - val_loss: 0.1061\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0363 - val_accuracy: 0.9773 - val_loss: 0.1005\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0337 - val_accuracy: 0.9773 - val_loss: 0.0984\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0319 - val_accuracy: 0.9773 - val_loss: 0.0957\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.0451 - val_accuracy: 0.9773 - val_loss: 0.0949\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0335 - val_accuracy: 0.9773 - val_loss: 0.0933\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0405 - val_accuracy: 0.9773 - val_loss: 0.0924\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0362 - val_accuracy: 0.9773 - val_loss: 0.0925\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0247 - val_accuracy: 0.9773 - val_loss: 0.0902\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0280 - val_accuracy: 0.9773 - val_loss: 0.0890\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0235 - val_accuracy: 0.9773 - val_loss: 0.0892\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0205 - val_accuracy: 0.9773 - val_loss: 0.0881\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0267 - val_accuracy: 0.9773 - val_loss: 0.0877\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0272 - val_accuracy: 0.9773 - val_loss: 0.0862\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0255 - val_accuracy: 0.9773 - val_loss: 0.0866\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0179 - val_accuracy: 0.9773 - val_loss: 0.0861\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.0225 - val_accuracy: 0.9773 - val_loss: 0.0855\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0180 - val_accuracy: 0.9773 - val_loss: 0.0847\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9998 - loss: 0.0183 - val_accuracy: 0.9773 - val_loss: 0.0845\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9993 - loss: 0.0233 - val_accuracy: 0.9773 - val_loss: 0.0831\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0172 - val_accuracy: 0.9773 - val_loss: 0.0831\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0165 - val_accuracy: 0.9773 - val_loss: 0.0819\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0197 - val_accuracy: 0.9773 - val_loss: 0.0834\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0177 - val_accuracy: 0.9773 - val_loss: 0.0826\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0178 - val_accuracy: 0.9773 - val_loss: 0.0833\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0165 - val_accuracy: 0.9773 - val_loss: 0.0831\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0245 - val_accuracy: 0.9773 - val_loss: 0.0842\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0203 - val_accuracy: 0.9773 - val_loss: 0.0802\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9989 - loss: 0.0227 - val_accuracy: 0.9773 - val_loss: 0.0872\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0174 - val_accuracy: 0.9659 - val_loss: 0.1181\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9540 - loss: 0.1829 - val_accuracy: 0.9432 - val_loss: 0.2264\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9160 - loss: 0.3213 - val_accuracy: 0.7727 - val_loss: 0.7032\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8395 - loss: 0.5214 - val_accuracy: 0.8864 - val_loss: 0.5249\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9210 - loss: 0.3698 - val_accuracy: 0.9318 - val_loss: 0.2736\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8931 - loss: 0.3292 - val_accuracy: 0.9205 - val_loss: 0.3120\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9213 - loss: 0.2946 - val_accuracy: 0.9318 - val_loss: 0.2790\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Define LSTM model with regularization\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=(25, 84)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "y_labels = np.argmax(Y_seq, axis=1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "accuracy_scores = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X_seq, y_labels)):\n",
        "    print(f\"\\nFold {fold+1} / {skf.get_n_splits()}\")\n",
        "\n",
        "    X_train, X_test = X_seq[train_index], X_seq[test_index]\n",
        "    y_train, y_test = Y_seq[train_index], Y_seq[test_index]\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    model = create_model()\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
        "                        validation_data=(X_test, y_test))\n",
        "\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    val_losses.append(history.history['val_loss'])\n",
        "    val_accuracies.append(history.history['val_accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model save"
      ],
      "metadata": {
        "id": "O0Lgx5YmUzbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhvI9ZUTBZML",
        "outputId": "33c90867-96a0-4404-9e9f-95afd564a7de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1 / 10\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.0656 - loss: 3.5576 - val_accuracy: 0.2360 - val_loss: 3.2503\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2196 - loss: 3.1624 - val_accuracy: 0.4494 - val_loss: 2.7231\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4214 - loss: 2.6157 - val_accuracy: 0.5281 - val_loss: 2.2152\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5017 - loss: 2.1746 - val_accuracy: 0.7079 - val_loss: 1.7765\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6559 - loss: 1.7406 - val_accuracy: 0.7079 - val_loss: 1.4196\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7111 - loss: 1.5306 - val_accuracy: 0.7978 - val_loss: 1.1854\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7445 - loss: 1.3505 - val_accuracy: 0.8427 - val_loss: 1.0283\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7673 - loss: 1.1718 - val_accuracy: 0.8427 - val_loss: 0.9832\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8217 - loss: 1.0972 - val_accuracy: 0.8764 - val_loss: 0.8859\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7766 - loss: 1.1033 - val_accuracy: 0.9101 - val_loss: 0.8347\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8179 - loss: 0.9389 - val_accuracy: 0.8876 - val_loss: 0.6931\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8637 - loss: 0.8113 - val_accuracy: 0.8876 - val_loss: 0.6686\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8691 - loss: 0.7885 - val_accuracy: 0.8876 - val_loss: 0.6109\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8858 - loss: 0.7365 - val_accuracy: 0.8876 - val_loss: 0.6124\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8648 - loss: 0.7566 - val_accuracy: 0.8876 - val_loss: 0.5843\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8811 - loss: 0.6946 - val_accuracy: 0.8427 - val_loss: 0.6666\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8366 - loss: 0.8230 - val_accuracy: 0.9101 - val_loss: 0.6225\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8388 - loss: 0.8401 - val_accuracy: 0.8876 - val_loss: 0.5647\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8782 - loss: 0.6582 - val_accuracy: 0.8876 - val_loss: 0.5309\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8308 - loss: 0.8556 - val_accuracy: 0.8652 - val_loss: 0.7789\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8351 - loss: 0.7843 - val_accuracy: 0.8876 - val_loss: 0.6810\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8398 - loss: 0.7610 - val_accuracy: 0.8652 - val_loss: 0.5693\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8624 - loss: 0.6373 - val_accuracy: 0.8876 - val_loss: 0.5321\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9227 - loss: 0.5780 - val_accuracy: 0.9101 - val_loss: 0.4873\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8966 - loss: 0.6072 - val_accuracy: 0.9438 - val_loss: 0.4399\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9201 - loss: 0.5304 - val_accuracy: 0.9551 - val_loss: 0.4328\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9120 - loss: 0.5295 - val_accuracy: 0.9438 - val_loss: 0.4108\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9232 - loss: 0.5231 - val_accuracy: 0.9326 - val_loss: 0.3998\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9335 - loss: 0.4948 - val_accuracy: 0.9438 - val_loss: 0.3931\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8804 - loss: 0.5259 - val_accuracy: 0.9438 - val_loss: 0.4103\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9126 - loss: 0.5161 - val_accuracy: 0.8989 - val_loss: 0.4357\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8927 - loss: 0.5746 - val_accuracy: 0.9326 - val_loss: 0.3801\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9190 - loss: 0.4799 - val_accuracy: 0.8989 - val_loss: 0.4607\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9125 - loss: 0.5150 - val_accuracy: 0.9438 - val_loss: 0.3941\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8996 - loss: 0.4913 - val_accuracy: 0.9551 - val_loss: 0.3822\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9099 - loss: 0.4651 - val_accuracy: 0.9213 - val_loss: 0.4033\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8629 - loss: 0.7089 - val_accuracy: 0.8652 - val_loss: 0.7043\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8555 - loss: 0.6804 - val_accuracy: 0.9326 - val_loss: 0.4233\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9084 - loss: 0.5279 - val_accuracy: 0.9326 - val_loss: 0.3852\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9054 - loss: 0.4864 - val_accuracy: 0.9438 - val_loss: 0.3721\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9060 - loss: 0.5057 - val_accuracy: 0.9326 - val_loss: 0.4049\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9343 - loss: 0.4438 - val_accuracy: 0.9326 - val_loss: 0.3546\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9416 - loss: 0.4183 - val_accuracy: 0.9551 - val_loss: 0.3293\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9452 - loss: 0.4118 - val_accuracy: 0.9438 - val_loss: 0.3336\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9394 - loss: 0.3969 - val_accuracy: 0.9663 - val_loss: 0.3125\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9424 - loss: 0.4122 - val_accuracy: 0.9326 - val_loss: 0.5392\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9079 - loss: 0.5832 - val_accuracy: 0.9326 - val_loss: 0.3526\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9260 - loss: 0.4468 - val_accuracy: 0.9326 - val_loss: 0.3665\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9295 - loss: 0.4388 - val_accuracy: 0.9101 - val_loss: 0.3690\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9276 - loss: 0.4434 - val_accuracy: 0.9438 - val_loss: 0.3201\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9546 - loss: 0.3845 - val_accuracy: 0.9438 - val_loss: 0.3431\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9629 - loss: 0.3634 - val_accuracy: 0.9438 - val_loss: 0.3130\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.4117 - val_accuracy: 0.9551 - val_loss: 0.3881\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9315 - loss: 0.4433 - val_accuracy: 0.9775 - val_loss: 0.2765\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9527 - loss: 0.3775 - val_accuracy: 0.9438 - val_loss: 0.3733\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9245 - loss: 0.4537 - val_accuracy: 0.9438 - val_loss: 0.3142\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9156 - loss: 0.4247 - val_accuracy: 0.9663 - val_loss: 0.3331\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9263 - loss: 0.3952 - val_accuracy: 0.9438 - val_loss: 0.3162\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9382 - loss: 0.3711 - val_accuracy: 0.9438 - val_loss: 0.2958\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9495 - loss: 0.3794 - val_accuracy: 0.9888 - val_loss: 0.2696\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9605 - loss: 0.3450 - val_accuracy: 0.9213 - val_loss: 0.4300\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9336 - loss: 0.3907 - val_accuracy: 0.9551 - val_loss: 0.3493\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9453 - loss: 0.3717 - val_accuracy: 0.9438 - val_loss: 0.2914\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9223 - loss: 0.4123 - val_accuracy: 0.9213 - val_loss: 0.3400\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9255 - loss: 0.4077 - val_accuracy: 0.8989 - val_loss: 0.4451\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8793 - loss: 0.5309 - val_accuracy: 0.8427 - val_loss: 0.6997\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8517 - loss: 0.6514 - val_accuracy: 0.9101 - val_loss: 0.4948\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8930 - loss: 0.5109 - val_accuracy: 0.9213 - val_loss: 0.3960\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9267 - loss: 0.4234 - val_accuracy: 0.9888 - val_loss: 0.3344\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9353 - loss: 0.4017 - val_accuracy: 0.9888 - val_loss: 0.3168\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9388 - loss: 0.3858 - val_accuracy: 0.9888 - val_loss: 0.3017\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9631 - loss: 0.3596 - val_accuracy: 0.9775 - val_loss: 0.2938\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9750 - loss: 0.3437 - val_accuracy: 0.9775 - val_loss: 0.2829\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9524 - loss: 0.3466 - val_accuracy: 0.9888 - val_loss: 0.2756\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9778 - loss: 0.3043 - val_accuracy: 0.9888 - val_loss: 0.2568\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9858 - loss: 0.3033 - val_accuracy: 0.9888 - val_loss: 0.2412\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9613 - loss: 0.3500 - val_accuracy: 0.9888 - val_loss: 0.2483\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9699 - loss: 0.3342 - val_accuracy: 0.9775 - val_loss: 0.2462\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9712 - loss: 0.3227 - val_accuracy: 0.9775 - val_loss: 0.2976\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9932 - loss: 0.2954 - val_accuracy: 0.9775 - val_loss: 0.2966\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9661 - loss: 0.3590 - val_accuracy: 0.9663 - val_loss: 0.3042\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9632 - loss: 0.3450 - val_accuracy: 1.0000 - val_loss: 0.2210\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9774 - loss: 0.3162 - val_accuracy: 0.9438 - val_loss: 0.3083\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9201 - loss: 0.4371 - val_accuracy: 0.9326 - val_loss: 0.3836\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9013 - loss: 0.4433 - val_accuracy: 0.9551 - val_loss: 0.2874\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9191 - loss: 0.3916 - val_accuracy: 0.9888 - val_loss: 0.2702\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9478 - loss: 0.3408 - val_accuracy: 0.9775 - val_loss: 0.2647\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9475 - loss: 0.3343 - val_accuracy: 0.9888 - val_loss: 0.2437\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9480 - loss: 0.3424 - val_accuracy: 0.9775 - val_loss: 0.2853\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9554 - loss: 0.3133 - val_accuracy: 1.0000 - val_loss: 0.2334\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9554 - loss: 0.3179 - val_accuracy: 0.9551 - val_loss: 0.2469\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9584 - loss: 0.2929 - val_accuracy: 1.0000 - val_loss: 0.2233\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9792 - loss: 0.2838 - val_accuracy: 0.9663 - val_loss: 0.2400\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9496 - loss: 0.3055 - val_accuracy: 1.0000 - val_loss: 0.2248\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9619 - loss: 0.2933 - val_accuracy: 1.0000 - val_loss: 0.2176\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9611 - loss: 0.2862 - val_accuracy: 1.0000 - val_loss: 0.2054\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.2907 - val_accuracy: 0.9888 - val_loss: 0.2175\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.2688 - val_accuracy: 0.9438 - val_loss: 0.2940\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9625 - loss: 0.2901 - val_accuracy: 0.9551 - val_loss: 0.2416\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9601 - loss: 0.2882 - val_accuracy: 0.9775 - val_loss: 0.2194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model for Fold 1 saved to lstm_model_fold_2.h5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Define LSTM model with regularization\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(25, 84), kernel_regularizer=l2(0.001)),\n",
        "        Dropout(0.4),  # Dropout added to prevent overfitting\n",
        "        LSTM(32, return_sequences=False, kernel_regularizer=l2(0.002)),\n",
        "        Dropout(0.4),\n",
        "        Dense(32, activation='relu', kernel_regularizer=l2(0.002)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "y_labels = np.argmax(Y_seq, axis=1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "accuracy_scores = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X_seq, y_labels)):\n",
        "    print(f\"\\nFold {fold+1} / {skf.get_n_splits()}\")\n",
        "\n",
        "    X_train, X_test = X_seq[train_index], X_seq[test_index]\n",
        "    y_train, y_test = Y_seq[train_index], Y_seq[test_index]\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    model = create_model()\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
        "                        validation_data=(X_test, y_test))\n",
        "\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    val_losses.append(history.history['val_loss'])\n",
        "    val_accuracies.append(history.history['val_accuracy'])\n",
        "\n",
        "\n",
        "    model_save_path = f\"lstm_model_fold_{fold+2}.h5\"\n",
        "    model.save(model_save_path)\n",
        "    print(f\"Model for Fold {fold+1} saved to {model_save_path}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I83BaN3uBibU",
        "outputId": "be0143b8-1b0c-4962-acfa-913a49e706a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Test Accuracy over 1 folds: 0.9775\n"
          ]
        }
      ],
      "source": [
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "print(f\"\\nMean Test Accuracy over {len(accuracy_scores)} folds: {mean_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot validation"
      ],
      "metadata": {
        "id": "7qHYpl6CU2wj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "reh7gYPDBi94",
        "outputId": "fdb59af8-34d4-43cc-8161-5423efa11c47"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mean Accuracy: 0.9636\n"
          ]
        }
      ],
      "source": [
        "# Plot Validation Loss and Accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "for i in range(5):\n",
        "    plt.plot(val_losses[i], label=f'Fold {i+1}')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.title(\"Validation Loss per Fold\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot Validation Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "for i in range(5):\n",
        "    plt.plot(val_accuracies[i], label=f'Fold {i+1}')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Validation Accuracy per Fold\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nMean Accuracy: {np.mean(accuracy_scores):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Per class accuracy"
      ],
      "metadata": {
        "id": "31cNMUh4U7NJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4uuaqOPFKGy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8f424a8-4a15-48ae-d762-025acdd3473a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Fold 1 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.0750 - loss: 3.1575 - val_accuracy: 0.4270 - val_loss: 2.7833\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4594 - loss: 2.6273 - val_accuracy: 0.5393 - val_loss: 2.2634\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6160 - loss: 2.1028 - val_accuracy: 0.6404 - val_loss: 1.7866\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7409 - loss: 1.6184 - val_accuracy: 0.7191 - val_loss: 1.4004\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7824 - loss: 1.2735 - val_accuracy: 0.7640 - val_loss: 1.1629\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8230 - loss: 1.0250 - val_accuracy: 0.8202 - val_loss: 0.9493\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8680 - loss: 0.8211 - val_accuracy: 0.8764 - val_loss: 0.7992\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8788 - loss: 0.7036 - val_accuracy: 0.8876 - val_loss: 0.6909\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8878 - loss: 0.6236 - val_accuracy: 0.9213 - val_loss: 0.6091\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9242 - loss: 0.5492 - val_accuracy: 0.9213 - val_loss: 0.5479\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.4868 - val_accuracy: 0.9326 - val_loss: 0.4893\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.4147 - val_accuracy: 0.9213 - val_loss: 0.4903\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9336 - loss: 0.4030 - val_accuracy: 0.9438 - val_loss: 0.4343\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.3809 - val_accuracy: 0.9438 - val_loss: 0.4025\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.3468 - val_accuracy: 0.9101 - val_loss: 0.3803\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.2947 - val_accuracy: 0.9326 - val_loss: 0.3541\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9537 - loss: 0.2954 - val_accuracy: 0.9326 - val_loss: 0.3338\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9605 - loss: 0.2800 - val_accuracy: 0.9326 - val_loss: 0.3146\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9788 - loss: 0.2336 - val_accuracy: 0.9326 - val_loss: 0.2674\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9696 - loss: 0.2138 - val_accuracy: 0.9326 - val_loss: 0.3115\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9403 - loss: 0.2904 - val_accuracy: 0.9213 - val_loss: 0.3231\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9568 - loss: 0.2294 - val_accuracy: 0.8764 - val_loss: 0.4521\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9122 - loss: 0.3739 - val_accuracy: 0.9326 - val_loss: 0.3270\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9635 - loss: 0.2354 - val_accuracy: 0.9326 - val_loss: 0.2625\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9614 - loss: 0.2184 - val_accuracy: 0.9326 - val_loss: 0.2498\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.1722 - val_accuracy: 0.9438 - val_loss: 0.2068\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.1473 - val_accuracy: 0.9663 - val_loss: 0.2033\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.1392 - val_accuracy: 0.9551 - val_loss: 0.2378\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.1457 - val_accuracy: 0.8876 - val_loss: 0.3905\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9521 - loss: 0.2110 - val_accuracy: 0.9438 - val_loss: 0.2749\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9619 - loss: 0.1806 - val_accuracy: 0.9663 - val_loss: 0.1968\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9686 - loss: 0.1667 - val_accuracy: 0.8876 - val_loss: 0.3747\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9221 - loss: 0.2910 - val_accuracy: 0.8989 - val_loss: 0.3387\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9405 - loss: 0.2375 - val_accuracy: 0.9775 - val_loss: 0.2196\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9493 - loss: 0.1965 - val_accuracy: 0.9775 - val_loss: 0.1895\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.1052 - val_accuracy: 0.9775 - val_loss: 0.1529\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9750 - loss: 0.1392 - val_accuracy: 0.9775 - val_loss: 0.1677\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0989 - val_accuracy: 0.9663 - val_loss: 0.1594\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0983 - val_accuracy: 0.9551 - val_loss: 0.2021\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9890 - loss: 0.0975 - val_accuracy: 0.9551 - val_loss: 0.1948\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9663 - loss: 0.1301 - val_accuracy: 0.9663 - val_loss: 0.1601\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.1095 - val_accuracy: 0.9663 - val_loss: 0.1490\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9925 - loss: 0.0806 - val_accuracy: 0.9663 - val_loss: 0.1324\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0752 - val_accuracy: 0.9663 - val_loss: 0.1308\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0606 - val_accuracy: 0.9663 - val_loss: 0.1273\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0616 - val_accuracy: 0.9663 - val_loss: 0.1258\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0542 - val_accuracy: 0.9663 - val_loss: 0.1235\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0730 - val_accuracy: 0.9663 - val_loss: 0.1230\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0545 - val_accuracy: 0.9663 - val_loss: 0.1164\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0531 - val_accuracy: 0.9663 - val_loss: 0.1175\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0537 - val_accuracy: 0.9663 - val_loss: 0.1141\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0523 - val_accuracy: 0.9663 - val_loss: 0.1097\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0478 - val_accuracy: 0.9663 - val_loss: 0.1085\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0536 - val_accuracy: 0.9663 - val_loss: 0.1051\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0394 - val_accuracy: 0.9663 - val_loss: 0.1034\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0413 - val_accuracy: 0.9663 - val_loss: 0.0997\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0399 - val_accuracy: 0.9663 - val_loss: 0.0965\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0435 - val_accuracy: 0.9663 - val_loss: 0.0939\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0345 - val_accuracy: 0.9663 - val_loss: 0.0917\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0472 - val_accuracy: 0.9663 - val_loss: 0.0901\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0352 - val_accuracy: 0.9663 - val_loss: 0.0863\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0326 - val_accuracy: 0.9663 - val_loss: 0.0847\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.0385 - val_accuracy: 0.9663 - val_loss: 0.0808\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0370 - val_accuracy: 0.9663 - val_loss: 0.0991\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0310 - val_accuracy: 0.9551 - val_loss: 0.1653\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9741 - loss: 0.0823 - val_accuracy: 0.9551 - val_loss: 0.1459\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0685 - val_accuracy: 0.9551 - val_loss: 0.1243\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9862 - loss: 0.0694 - val_accuracy: 0.9551 - val_loss: 0.1165\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9901 - loss: 0.0688 - val_accuracy: 0.9438 - val_loss: 0.2552\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9791 - loss: 0.0900 - val_accuracy: 0.9551 - val_loss: 0.1673\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0436 - val_accuracy: 0.9438 - val_loss: 0.1634\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0655 - val_accuracy: 0.9663 - val_loss: 0.1038\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9923 - loss: 0.0492 - val_accuracy: 0.9775 - val_loss: 0.0937\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0401 - val_accuracy: 0.9775 - val_loss: 0.0922\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.0353 - val_accuracy: 0.9663 - val_loss: 0.1191\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0239 - val_accuracy: 0.9775 - val_loss: 0.0969\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0320 - val_accuracy: 0.9775 - val_loss: 0.0876\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0360 - val_accuracy: 0.9775 - val_loss: 0.0871\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0238 - val_accuracy: 0.9888 - val_loss: 0.0787\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0233 - val_accuracy: 0.9888 - val_loss: 0.0788\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0246 - val_accuracy: 0.9888 - val_loss: 0.0752\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.0293 - val_accuracy: 0.9888 - val_loss: 0.0742\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0251 - val_accuracy: 0.9775 - val_loss: 0.0815\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0234 - val_accuracy: 0.9888 - val_loss: 0.0747\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0190 - val_accuracy: 0.9888 - val_loss: 0.0715\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0177 - val_accuracy: 0.9888 - val_loss: 0.0708\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0236 - val_accuracy: 0.9775 - val_loss: 0.0747\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0238 - val_accuracy: 0.9775 - val_loss: 0.0749\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0285 - val_accuracy: 0.9888 - val_loss: 0.0698\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0258 - val_accuracy: 0.9888 - val_loss: 0.0710\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0215 - val_accuracy: 0.9888 - val_loss: 0.0686\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0188 - val_accuracy: 0.9888 - val_loss: 0.0683\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0154 - val_accuracy: 0.9888 - val_loss: 0.0642\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0200 - val_accuracy: 0.9888 - val_loss: 0.0668\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0172 - val_accuracy: 0.9888 - val_loss: 0.0620\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0172 - val_accuracy: 0.9888 - val_loss: 0.0601\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0141 - val_accuracy: 0.9888 - val_loss: 0.0559\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0169 - val_accuracy: 0.9888 - val_loss: 0.0540\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0140 - val_accuracy: 0.9888 - val_loss: 0.0513\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0116 - val_accuracy: 0.9888 - val_loss: 0.0521\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (4/4)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 1.0000 (4/4)\n",
            "  Class 3: 1.0000 (3/3)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 1.0000 (3/3)\n",
            "  Class 8: 1.0000 (3/3)\n",
            "  Class 9: 1.0000 (3/3)\n",
            "  Class 10: 1.0000 (3/3)\n",
            "  Class 11: 1.0000 (4/4)\n",
            "  Class 12: 1.0000 (3/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (3/3)\n",
            "  Class 15: 1.0000 (4/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 1.0000 (4/4)\n",
            "  Class 18: 1.0000 (4/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 1.0000 (3/3)\n",
            "  Class 21: 1.0000 (4/4)\n",
            "  Class 22: 0.8000 (4/5)\n",
            "  Class 23: 1.0000 (5/5)\n",
            "  Class 24: 1.0000 (2/2)\n",
            "  Class 25: 1.0000 (5/5)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         3\n",
            "           8       1.00      1.00      1.00         3\n",
            "           9       1.00      1.00      1.00         3\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       1.00      1.00      1.00         4\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       0.75      1.00      0.86         3\n",
            "          15       1.00      1.00      1.00         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       1.00      1.00      1.00         4\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         3\n",
            "          20       1.00      1.00      1.00         3\n",
            "          21       1.00      1.00      1.00         4\n",
            "          22       1.00      0.80      0.89         5\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         2\n",
            "          25       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.99        89\n",
            "   macro avg       0.99      0.99      0.99        89\n",
            "weighted avg       0.99      0.99      0.99        89\n",
            "\n",
            "\n",
            "===== Fold 2 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.0790 - loss: 3.1613 - val_accuracy: 0.4270 - val_loss: 2.7378\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4530 - loss: 2.5707 - val_accuracy: 0.5169 - val_loss: 2.1116\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5962 - loss: 1.9652 - val_accuracy: 0.7079 - val_loss: 1.5633\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7366 - loss: 1.4984 - val_accuracy: 0.8202 - val_loss: 1.2056\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8368 - loss: 1.1053 - val_accuracy: 0.8539 - val_loss: 0.9434\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8356 - loss: 0.9146 - val_accuracy: 0.8876 - val_loss: 0.7991\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9040 - loss: 0.7537 - val_accuracy: 0.8989 - val_loss: 0.6878\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.5793 - val_accuracy: 0.9551 - val_loss: 0.5424\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9574 - loss: 0.4852 - val_accuracy: 0.9775 - val_loss: 0.4460\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.4104 - val_accuracy: 0.9438 - val_loss: 0.4480\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9492 - loss: 0.3866 - val_accuracy: 0.9775 - val_loss: 0.3659\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9669 - loss: 0.3976 - val_accuracy: 0.9663 - val_loss: 0.3413\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9739 - loss: 0.2994 - val_accuracy: 0.9438 - val_loss: 0.3720\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9508 - loss: 0.3473 - val_accuracy: 0.9775 - val_loss: 0.2816\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.2752 - val_accuracy: 0.9888 - val_loss: 0.2539\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.2586 - val_accuracy: 0.9888 - val_loss: 0.2137\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9739 - loss: 0.2032 - val_accuracy: 0.9888 - val_loss: 0.2030\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.1635 - val_accuracy: 0.9775 - val_loss: 0.1956\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9766 - loss: 0.1684 - val_accuracy: 0.9663 - val_loss: 0.1994\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.1646 - val_accuracy: 0.9663 - val_loss: 0.1849\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9825 - loss: 0.1612 - val_accuracy: 0.9775 - val_loss: 0.1661\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.1313 - val_accuracy: 0.9775 - val_loss: 0.1607\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9864 - loss: 0.1259 - val_accuracy: 0.9663 - val_loss: 0.1575\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9900 - loss: 0.1159 - val_accuracy: 0.9663 - val_loss: 0.1530\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.1106 - val_accuracy: 0.9663 - val_loss: 0.1620\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.1405 - val_accuracy: 0.9663 - val_loss: 0.1485\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.1080 - val_accuracy: 0.9438 - val_loss: 0.1910\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9620 - loss: 0.1395 - val_accuracy: 0.9551 - val_loss: 0.1669\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.1053 - val_accuracy: 0.9775 - val_loss: 0.1495\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.1002 - val_accuracy: 0.9438 - val_loss: 0.1916\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9510 - loss: 0.1598 - val_accuracy: 0.9101 - val_loss: 0.2553\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9420 - loss: 0.1682 - val_accuracy: 0.9551 - val_loss: 0.2057\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.1240 - val_accuracy: 0.9551 - val_loss: 0.2027\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9645 - loss: 0.1700 - val_accuracy: 0.9551 - val_loss: 0.1919\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9710 - loss: 0.1589 - val_accuracy: 0.9213 - val_loss: 0.3057\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9468 - loss: 0.2477 - val_accuracy: 0.9326 - val_loss: 0.2228\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9765 - loss: 0.1647 - val_accuracy: 0.9551 - val_loss: 0.1568\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9782 - loss: 0.1245 - val_accuracy: 0.9663 - val_loss: 0.1549\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9837 - loss: 0.1084 - val_accuracy: 0.9663 - val_loss: 0.1539\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.1042 - val_accuracy: 0.9438 - val_loss: 0.2168\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0860 - val_accuracy: 0.9101 - val_loss: 0.2225\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9881 - loss: 0.0791 - val_accuracy: 0.8989 - val_loss: 0.2593\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9291 - loss: 0.2008 - val_accuracy: 0.9213 - val_loss: 0.1958\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9678 - loss: 0.1317 - val_accuracy: 0.9551 - val_loss: 0.1796\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9762 - loss: 0.1072 - val_accuracy: 0.9663 - val_loss: 0.1376\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9872 - loss: 0.0869 - val_accuracy: 0.9663 - val_loss: 0.1360\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9798 - loss: 0.0906 - val_accuracy: 0.9775 - val_loss: 0.1337\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.0818 - val_accuracy: 0.9775 - val_loss: 0.1276\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9929 - loss: 0.0791 - val_accuracy: 0.9775 - val_loss: 0.1259\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9895 - loss: 0.0820 - val_accuracy: 0.9775 - val_loss: 0.1163\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0930 - val_accuracy: 0.9663 - val_loss: 0.1236\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0726 - val_accuracy: 0.9663 - val_loss: 0.1151\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9925 - loss: 0.0710 - val_accuracy: 0.9663 - val_loss: 0.1079\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0709 - val_accuracy: 0.9663 - val_loss: 0.1057\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.0685 - val_accuracy: 0.9663 - val_loss: 0.1049\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9883 - loss: 0.0553 - val_accuracy: 0.9663 - val_loss: 0.1021\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0547 - val_accuracy: 0.9888 - val_loss: 0.0978\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0506 - val_accuracy: 0.9775 - val_loss: 0.0946\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0651 - val_accuracy: 0.9888 - val_loss: 0.0903\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9917 - loss: 0.0531 - val_accuracy: 0.9775 - val_loss: 0.0717\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.0557 - val_accuracy: 0.9888 - val_loss: 0.0548\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0453 - val_accuracy: 0.9775 - val_loss: 0.0631\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0425 - val_accuracy: 0.9775 - val_loss: 0.0555\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0313 - val_accuracy: 0.9775 - val_loss: 0.0616\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0413 - val_accuracy: 0.9775 - val_loss: 0.0549\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0330 - val_accuracy: 0.9775 - val_loss: 0.0520\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0282 - val_accuracy: 0.9775 - val_loss: 0.0515\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0354 - val_accuracy: 0.9775 - val_loss: 0.0511\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0320 - val_accuracy: 0.9775 - val_loss: 0.0654\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0310 - val_accuracy: 0.9775 - val_loss: 0.0544\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0328 - val_accuracy: 0.9775 - val_loss: 0.0528\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0276 - val_accuracy: 0.9775 - val_loss: 0.0512\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0323 - val_accuracy: 0.9775 - val_loss: 0.0505\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0219 - val_accuracy: 0.9775 - val_loss: 0.0495\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0231 - val_accuracy: 0.9775 - val_loss: 0.0536\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9969 - loss: 0.0292 - val_accuracy: 0.9775 - val_loss: 0.0537\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0275 - val_accuracy: 0.9775 - val_loss: 0.0487\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0167 - val_accuracy: 0.9775 - val_loss: 0.0480\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0236 - val_accuracy: 0.9775 - val_loss: 0.0473\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0193 - val_accuracy: 0.9888 - val_loss: 0.0450\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0164 - val_accuracy: 0.9775 - val_loss: 0.0456\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0217 - val_accuracy: 0.9888 - val_loss: 0.0430\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0216 - val_accuracy: 0.9888 - val_loss: 0.0438\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0176 - val_accuracy: 0.9775 - val_loss: 0.0469\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0190 - val_accuracy: 0.9888 - val_loss: 0.0423\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.0120 - val_accuracy: 0.9888 - val_loss: 0.0420\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0251 - val_accuracy: 0.9888 - val_loss: 0.0413\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0153 - val_accuracy: 0.9888 - val_loss: 0.0397\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0143 - val_accuracy: 0.9888 - val_loss: 0.0383\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9989 - loss: 0.0143 - val_accuracy: 0.9888 - val_loss: 0.0422\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0339 - val_accuracy: 0.9663 - val_loss: 0.1005\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9207 - loss: 0.2607 - val_accuracy: 0.8539 - val_loss: 0.5322\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8984 - loss: 0.3213 - val_accuracy: 0.9663 - val_loss: 0.1644\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9449 - loss: 0.2056 - val_accuracy: 0.9775 - val_loss: 0.0952\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0849 - val_accuracy: 0.9438 - val_loss: 0.1497\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9745 - loss: 0.1116 - val_accuracy: 0.9326 - val_loss: 0.1545\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9735 - loss: 0.0895 - val_accuracy: 0.9663 - val_loss: 0.0970\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0650 - val_accuracy: 0.9326 - val_loss: 0.1303\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9628 - loss: 0.1345 - val_accuracy: 0.9663 - val_loss: 0.1468\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9793 - loss: 0.0848 - val_accuracy: 0.9775 - val_loss: 0.0808\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 4 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (4/4)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 0.7500 (3/4)\n",
            "  Class 3: 1.0000 (3/3)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 1.0000 (3/3)\n",
            "  Class 8: 1.0000 (3/3)\n",
            "  Class 9: 1.0000 (3/3)\n",
            "  Class 10: 1.0000 (3/3)\n",
            "  Class 11: 1.0000 (4/4)\n",
            "  Class 12: 1.0000 (3/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (3/3)\n",
            "  Class 15: 1.0000 (4/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 1.0000 (4/4)\n",
            "  Class 18: 1.0000 (4/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 1.0000 (3/3)\n",
            "  Class 21: 1.0000 (4/4)\n",
            "  Class 22: 0.8000 (4/5)\n",
            "  Class 23: 1.0000 (5/5)\n",
            "  Class 24: 1.0000 (2/2)\n",
            "  Class 25: 1.0000 (5/5)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         3\n",
            "           8       1.00      1.00      1.00         3\n",
            "           9       1.00      1.00      1.00         3\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       1.00      1.00      1.00         4\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       0.75      1.00      0.86         3\n",
            "          15       1.00      1.00      1.00         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       0.80      1.00      0.89         4\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         3\n",
            "          20       1.00      1.00      1.00         3\n",
            "          21       1.00      1.00      1.00         4\n",
            "          22       1.00      0.80      0.89         5\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         2\n",
            "          25       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.98        89\n",
            "   macro avg       0.98      0.98      0.98        89\n",
            "weighted avg       0.98      0.98      0.98        89\n",
            "\n",
            "\n",
            "===== Fold 3 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.1243 - loss: 3.1661 - val_accuracy: 0.2955 - val_loss: 2.7217\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3845 - loss: 2.5755 - val_accuracy: 0.5568 - val_loss: 2.1513\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6102 - loss: 1.9479 - val_accuracy: 0.7273 - val_loss: 1.6189\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7696 - loss: 1.4485 - val_accuracy: 0.7841 - val_loss: 1.2174\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7924 - loss: 1.1515 - val_accuracy: 0.8636 - val_loss: 0.9743\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8845 - loss: 0.9001 - val_accuracy: 0.8977 - val_loss: 0.8163\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9028 - loss: 0.7583 - val_accuracy: 0.8977 - val_loss: 0.7050\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9148 - loss: 0.6777 - val_accuracy: 0.8864 - val_loss: 0.6973\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9067 - loss: 0.5783 - val_accuracy: 0.9318 - val_loss: 0.5566\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9198 - loss: 0.5115 - val_accuracy: 0.9432 - val_loss: 0.4836\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9586 - loss: 0.4081 - val_accuracy: 0.9432 - val_loss: 0.4482\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9479 - loss: 0.3847 - val_accuracy: 0.9432 - val_loss: 0.4045\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9510 - loss: 0.3471 - val_accuracy: 0.9545 - val_loss: 0.3748\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9497 - loss: 0.3200 - val_accuracy: 0.9545 - val_loss: 0.3578\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9492 - loss: 0.3028 - val_accuracy: 0.9318 - val_loss: 0.3498\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9630 - loss: 0.2565 - val_accuracy: 0.9432 - val_loss: 0.3559\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9657 - loss: 0.2395 - val_accuracy: 0.9773 - val_loss: 0.2779\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9691 - loss: 0.1954 - val_accuracy: 0.9432 - val_loss: 0.2697\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9781 - loss: 0.1721 - val_accuracy: 0.9659 - val_loss: 0.2498\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9731 - loss: 0.1937 - val_accuracy: 0.9091 - val_loss: 0.3583\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9376 - loss: 0.2803 - val_accuracy: 0.9432 - val_loss: 0.2808\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9669 - loss: 0.1903 - val_accuracy: 0.9205 - val_loss: 0.3373\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9773 - loss: 0.1582 - val_accuracy: 0.9432 - val_loss: 0.2752\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9805 - loss: 0.1496 - val_accuracy: 0.9318 - val_loss: 0.2741\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.1452 - val_accuracy: 0.9545 - val_loss: 0.2346\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9585 - loss: 0.1852 - val_accuracy: 0.9432 - val_loss: 0.3178\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9567 - loss: 0.1916 - val_accuracy: 0.9545 - val_loss: 0.2959\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9724 - loss: 0.1596 - val_accuracy: 0.8750 - val_loss: 0.4831\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8034 - loss: 0.7342 - val_accuracy: 0.8750 - val_loss: 0.6997\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8745 - loss: 0.4839 - val_accuracy: 0.9318 - val_loss: 0.3895\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9553 - loss: 0.2727 - val_accuracy: 0.9545 - val_loss: 0.3091\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9755 - loss: 0.1648 - val_accuracy: 0.9432 - val_loss: 0.2845\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9736 - loss: 0.1668 - val_accuracy: 0.9432 - val_loss: 0.2838\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.1063 - val_accuracy: 0.9432 - val_loss: 0.2529\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.1231 - val_accuracy: 0.9432 - val_loss: 0.2643\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.1117 - val_accuracy: 0.9545 - val_loss: 0.2419\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.0776 - val_accuracy: 0.9545 - val_loss: 0.2328\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0783 - val_accuracy: 0.9318 - val_loss: 0.2823\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9562 - loss: 0.1691 - val_accuracy: 0.9432 - val_loss: 0.2759\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9638 - loss: 0.1570 - val_accuracy: 0.9432 - val_loss: 0.3468\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9795 - loss: 0.1509 - val_accuracy: 0.9545 - val_loss: 0.2378\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 0.1251 - val_accuracy: 0.9545 - val_loss: 0.2100\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9738 - loss: 0.1242 - val_accuracy: 0.9545 - val_loss: 0.2136\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9917 - loss: 0.0852 - val_accuracy: 0.9659 - val_loss: 0.2045\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0534 - val_accuracy: 0.9545 - val_loss: 0.1986\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0567 - val_accuracy: 0.9545 - val_loss: 0.2016\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0552 - val_accuracy: 0.9545 - val_loss: 0.2025\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0477 - val_accuracy: 0.9545 - val_loss: 0.2031\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0498 - val_accuracy: 0.9545 - val_loss: 0.2018\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0417 - val_accuracy: 0.9545 - val_loss: 0.2011\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0530 - val_accuracy: 0.9659 - val_loss: 0.2004\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0424 - val_accuracy: 0.9659 - val_loss: 0.1992\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0399 - val_accuracy: 0.9659 - val_loss: 0.1989\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0590 - val_accuracy: 0.9659 - val_loss: 0.1978\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0395 - val_accuracy: 0.9659 - val_loss: 0.1901\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0393 - val_accuracy: 0.9659 - val_loss: 0.1915\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0454 - val_accuracy: 0.9659 - val_loss: 0.1948\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0321 - val_accuracy: 0.9659 - val_loss: 0.1951\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0329 - val_accuracy: 0.9659 - val_loss: 0.1940\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0288 - val_accuracy: 0.9659 - val_loss: 0.1942\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0246 - val_accuracy: 0.9659 - val_loss: 0.1938\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0263 - val_accuracy: 0.9659 - val_loss: 0.1933\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0254 - val_accuracy: 0.9659 - val_loss: 0.1930\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0265 - val_accuracy: 0.9659 - val_loss: 0.1927\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0283 - val_accuracy: 0.9659 - val_loss: 0.1920\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0327 - val_accuracy: 0.9659 - val_loss: 0.1918\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0244 - val_accuracy: 0.9659 - val_loss: 0.1914\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0279 - val_accuracy: 0.9659 - val_loss: 0.1918\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9985 - loss: 0.0238 - val_accuracy: 0.9659 - val_loss: 0.1906\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 0.0227 - val_accuracy: 0.9659 - val_loss: 0.1905\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9958 - loss: 0.0275 - val_accuracy: 0.9659 - val_loss: 0.1912\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0183 - val_accuracy: 0.9659 - val_loss: 0.1918\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0222 - val_accuracy: 0.9659 - val_loss: 0.1800\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 0.9659 - val_loss: 0.1837\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0225 - val_accuracy: 0.9659 - val_loss: 0.1903\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.9659 - val_loss: 0.1935\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 0.9659 - val_loss: 0.1959\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0190 - val_accuracy: 0.9659 - val_loss: 0.1990\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.9659 - val_loss: 0.1997\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9659 - val_loss: 0.1980\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0152 - val_accuracy: 0.9659 - val_loss: 0.1988\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0171 - val_accuracy: 0.9659 - val_loss: 0.1977\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0171 - val_accuracy: 0.9659 - val_loss: 0.1970\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0208 - val_accuracy: 0.9545 - val_loss: 0.2076\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0236 - val_accuracy: 0.9432 - val_loss: 0.2141\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9972 - loss: 0.0272 - val_accuracy: 0.9205 - val_loss: 0.3101\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9713 - loss: 0.0907 - val_accuracy: 0.8864 - val_loss: 0.4123\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9281 - loss: 0.2307 - val_accuracy: 0.8977 - val_loss: 0.4195\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9136 - loss: 0.2842 - val_accuracy: 0.9318 - val_loss: 0.3162\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9576 - loss: 0.1669 - val_accuracy: 0.9545 - val_loss: 0.2249\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0924 - val_accuracy: 0.9545 - val_loss: 0.2242\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0523 - val_accuracy: 0.9545 - val_loss: 0.2683\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9836 - loss: 0.0814 - val_accuracy: 0.9545 - val_loss: 0.2583\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0574 - val_accuracy: 0.9432 - val_loss: 0.2760\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9845 - loss: 0.0671 - val_accuracy: 0.9659 - val_loss: 0.1779\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0580 - val_accuracy: 0.9659 - val_loss: 0.1824\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0353 - val_accuracy: 0.9659 - val_loss: 0.1742\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0250 - val_accuracy: 0.9659 - val_loss: 0.1603\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0211 - val_accuracy: 0.9773 - val_loss: 0.1342\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0250 - val_accuracy: 0.9659 - val_loss: 0.1754\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (4/4)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 0.5000 (2/4)\n",
            "  Class 3: 1.0000 (3/3)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 1.0000 (3/3)\n",
            "  Class 8: 1.0000 (3/3)\n",
            "  Class 9: 1.0000 (3/3)\n",
            "  Class 10: 1.0000 (3/3)\n",
            "  Class 11: 1.0000 (4/4)\n",
            "  Class 12: 1.0000 (3/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (3/3)\n",
            "  Class 15: 1.0000 (4/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 1.0000 (4/4)\n",
            "  Class 18: 1.0000 (4/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 1.0000 (3/3)\n",
            "  Class 21: 1.0000 (4/4)\n",
            "  Class 22: 0.7500 (3/4)\n",
            "  Class 23: 1.0000 (5/5)\n",
            "  Class 24: 1.0000 (3/3)\n",
            "  Class 25: 1.0000 (4/4)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.50      0.67         4\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         3\n",
            "           8       1.00      1.00      1.00         3\n",
            "           9       1.00      1.00      1.00         3\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       1.00      1.00      1.00         4\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       0.75      1.00      0.86         3\n",
            "          15       1.00      1.00      1.00         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       1.00      1.00      1.00         4\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         3\n",
            "          20       1.00      1.00      1.00         3\n",
            "          21       0.80      1.00      0.89         4\n",
            "          22       0.75      0.75      0.75         4\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         3\n",
            "          25       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.97        88\n",
            "   macro avg       0.97      0.97      0.97        88\n",
            "weighted avg       0.97      0.97      0.96        88\n",
            "\n",
            "\n",
            "===== Fold 4 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.0692 - loss: 3.1910 - val_accuracy: 0.3068 - val_loss: 2.7486\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4643 - loss: 2.5993 - val_accuracy: 0.7500 - val_loss: 2.1214\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7235 - loss: 1.9812 - val_accuracy: 0.7841 - val_loss: 1.6179\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7485 - loss: 1.5561 - val_accuracy: 0.8068 - val_loss: 1.2914\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7934 - loss: 1.2494 - val_accuracy: 0.8409 - val_loss: 1.0796\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8347 - loss: 0.9812 - val_accuracy: 0.8750 - val_loss: 0.8725\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9082 - loss: 0.7858 - val_accuracy: 0.8864 - val_loss: 0.8135\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8693 - loss: 0.7619 - val_accuracy: 0.9318 - val_loss: 0.6287\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9120 - loss: 0.5925 - val_accuracy: 0.9318 - val_loss: 0.5514\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9257 - loss: 0.5116 - val_accuracy: 0.8977 - val_loss: 0.5830\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9370 - loss: 0.4626 - val_accuracy: 0.8977 - val_loss: 0.5276\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - loss: 0.4584 - val_accuracy: 0.9091 - val_loss: 0.4858\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9199 - loss: 0.4193 - val_accuracy: 0.9318 - val_loss: 0.4326\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9239 - loss: 0.4037 - val_accuracy: 0.9545 - val_loss: 0.3693\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.3060 - val_accuracy: 0.9659 - val_loss: 0.3646\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9094 - loss: 0.3331 - val_accuracy: 0.9545 - val_loss: 0.3536\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9503 - loss: 0.3053 - val_accuracy: 0.9773 - val_loss: 0.3146\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9661 - loss: 0.2769 - val_accuracy: 0.9773 - val_loss: 0.3245\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9525 - loss: 0.3234 - val_accuracy: 0.9545 - val_loss: 0.2872\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9683 - loss: 0.2422 - val_accuracy: 0.9659 - val_loss: 0.2588\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.2048 - val_accuracy: 1.0000 - val_loss: 0.2004\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9760 - loss: 0.1803 - val_accuracy: 0.9545 - val_loss: 0.2296\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9610 - loss: 0.2113 - val_accuracy: 1.0000 - val_loss: 0.1785\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.1557 - val_accuracy: 0.9773 - val_loss: 0.1800\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.1483 - val_accuracy: 1.0000 - val_loss: 0.1511\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.1317 - val_accuracy: 0.9886 - val_loss: 0.1628\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9633 - loss: 0.1834 - val_accuracy: 1.0000 - val_loss: 0.1410\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.1553 - val_accuracy: 1.0000 - val_loss: 0.1428\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.1256 - val_accuracy: 0.9886 - val_loss: 0.1308\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.1273 - val_accuracy: 1.0000 - val_loss: 0.1118\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.1002 - val_accuracy: 1.0000 - val_loss: 0.1435\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.1279 - val_accuracy: 0.9545 - val_loss: 0.1734\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9650 - loss: 0.1355 - val_accuracy: 1.0000 - val_loss: 0.1217\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9840 - loss: 0.1312 - val_accuracy: 1.0000 - val_loss: 0.1066\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0757 - val_accuracy: 1.0000 - val_loss: 0.0937\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9872 - loss: 0.1012 - val_accuracy: 1.0000 - val_loss: 0.0989\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0717 - val_accuracy: 1.0000 - val_loss: 0.0919\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0721 - val_accuracy: 1.0000 - val_loss: 0.0884\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0847\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0666 - val_accuracy: 1.0000 - val_loss: 0.0804\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0578 - val_accuracy: 1.0000 - val_loss: 0.0774\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0533 - val_accuracy: 1.0000 - val_loss: 0.0735\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0626 - val_accuracy: 1.0000 - val_loss: 0.0708\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0856 - val_accuracy: 1.0000 - val_loss: 0.0679\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0501 - val_accuracy: 1.0000 - val_loss: 0.0656\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0604 - val_accuracy: 1.0000 - val_loss: 0.0642\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0528 - val_accuracy: 1.0000 - val_loss: 0.0748\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.0787 - val_accuracy: 1.0000 - val_loss: 0.0625\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0572 - val_accuracy: 0.9886 - val_loss: 0.1227\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9883 - loss: 0.0840 - val_accuracy: 0.9773 - val_loss: 0.1597\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9783 - loss: 0.1052 - val_accuracy: 1.0000 - val_loss: 0.0602\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0777 - val_accuracy: 0.9659 - val_loss: 0.2517\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9396 - loss: 0.2767 - val_accuracy: 0.9545 - val_loss: 0.1676\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9343 - loss: 0.1924 - val_accuracy: 0.8750 - val_loss: 0.3165\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9186 - loss: 0.1942 - val_accuracy: 0.9205 - val_loss: 0.2144\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9652 - loss: 0.1409 - val_accuracy: 0.9545 - val_loss: 0.1977\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9715 - loss: 0.1689 - val_accuracy: 0.9318 - val_loss: 0.1899\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9466 - loss: 0.1702 - val_accuracy: 0.9205 - val_loss: 0.1961\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9490 - loss: 0.1614 - val_accuracy: 0.9773 - val_loss: 0.1270\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9483 - loss: 0.1678 - val_accuracy: 0.9545 - val_loss: 0.1608\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9823 - loss: 0.0985 - val_accuracy: 0.9886 - val_loss: 0.0949\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.0824 - val_accuracy: 0.9886 - val_loss: 0.0995\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0852 - val_accuracy: 1.0000 - val_loss: 0.0689\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0782 - val_accuracy: 1.0000 - val_loss: 0.0670\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0560 - val_accuracy: 1.0000 - val_loss: 0.0623\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0588 - val_accuracy: 0.9886 - val_loss: 0.0770\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0530 - val_accuracy: 1.0000 - val_loss: 0.0613\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0508 - val_accuracy: 1.0000 - val_loss: 0.0570\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0668 - val_accuracy: 1.0000 - val_loss: 0.0562\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0430 - val_accuracy: 1.0000 - val_loss: 0.0570\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0408 - val_accuracy: 1.0000 - val_loss: 0.0569\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0589 - val_accuracy: 1.0000 - val_loss: 0.0594\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0331 - val_accuracy: 1.0000 - val_loss: 0.0547\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0402 - val_accuracy: 1.0000 - val_loss: 0.0506\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0548 - val_accuracy: 1.0000 - val_loss: 0.0505\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0423 - val_accuracy: 1.0000 - val_loss: 0.0496\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0401 - val_accuracy: 1.0000 - val_loss: 0.0479\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0553 - val_accuracy: 1.0000 - val_loss: 0.0483\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9903 - loss: 0.0344 - val_accuracy: 0.9886 - val_loss: 0.0684\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0368 - val_accuracy: 1.0000 - val_loss: 0.0433\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0319 - val_accuracy: 0.9773 - val_loss: 0.0486\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.0395\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0318 - val_accuracy: 1.0000 - val_loss: 0.0446\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0483 - val_accuracy: 0.9886 - val_loss: 0.0607\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0334 - val_accuracy: 1.0000 - val_loss: 0.0268\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0401 - val_accuracy: 0.9773 - val_loss: 0.0540\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.0483 - val_accuracy: 1.0000 - val_loss: 0.0361\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0299 - val_accuracy: 1.0000 - val_loss: 0.0367\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0298 - val_accuracy: 0.9886 - val_loss: 0.0622\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0216 - val_accuracy: 1.0000 - val_loss: 0.0348\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0230 - val_accuracy: 1.0000 - val_loss: 0.0310\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0175 - val_accuracy: 1.0000 - val_loss: 0.0356\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0160 - val_accuracy: 0.9886 - val_loss: 0.0557\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9989 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0379\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9998 - loss: 0.0147 - val_accuracy: 1.0000 - val_loss: 0.0316\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 0.0303\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0295\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9979 - loss: 0.0172 - val_accuracy: 1.0000 - val_loss: 0.0290\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0287\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0283\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (4/4)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 1.0000 (4/4)\n",
            "  Class 3: 1.0000 (3/3)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 1.0000 (3/3)\n",
            "  Class 8: 1.0000 (3/3)\n",
            "  Class 9: 1.0000 (3/3)\n",
            "  Class 10: 1.0000 (3/3)\n",
            "  Class 11: 1.0000 (4/4)\n",
            "  Class 12: 1.0000 (3/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (3/3)\n",
            "  Class 15: 1.0000 (4/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 1.0000 (4/4)\n",
            "  Class 18: 1.0000 (4/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 1.0000 (3/3)\n",
            "  Class 21: 1.0000 (4/4)\n",
            "  Class 22: 1.0000 (4/4)\n",
            "  Class 23: 1.0000 (5/5)\n",
            "  Class 24: 1.0000 (3/3)\n",
            "  Class 25: 1.0000 (4/4)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         3\n",
            "           8       1.00      1.00      1.00         3\n",
            "           9       1.00      1.00      1.00         3\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       1.00      1.00      1.00         4\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       1.00      1.00      1.00         3\n",
            "          15       1.00      1.00      1.00         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       1.00      1.00      1.00         4\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         3\n",
            "          20       1.00      1.00      1.00         3\n",
            "          21       1.00      1.00      1.00         4\n",
            "          22       1.00      1.00      1.00         4\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         3\n",
            "          25       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        88\n",
            "   macro avg       1.00      1.00      1.00        88\n",
            "weighted avg       1.00      1.00      1.00        88\n",
            "\n",
            "\n",
            "===== Fold 5 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.1033 - loss: 3.1294 - val_accuracy: 0.3295 - val_loss: 2.6963\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3700 - loss: 2.5761 - val_accuracy: 0.5341 - val_loss: 2.1813\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5403 - loss: 2.0453 - val_accuracy: 0.6136 - val_loss: 1.6923\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6846 - loss: 1.5246 - val_accuracy: 0.6932 - val_loss: 1.3784\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7287 - loss: 1.2373 - val_accuracy: 0.7614 - val_loss: 1.1735\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8441 - loss: 1.0291 - val_accuracy: 0.8409 - val_loss: 0.9466\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9212 - loss: 0.8291 - val_accuracy: 0.8409 - val_loss: 0.8292\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9182 - loss: 0.6664 - val_accuracy: 0.8409 - val_loss: 0.7406\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9340 - loss: 0.5661 - val_accuracy: 0.8636 - val_loss: 0.6675\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9479 - loss: 0.4753 - val_accuracy: 0.8523 - val_loss: 0.6709\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9259 - loss: 0.4818 - val_accuracy: 0.8864 - val_loss: 0.5662\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9674 - loss: 0.3506 - val_accuracy: 0.8864 - val_loss: 0.5214\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9700 - loss: 0.3106 - val_accuracy: 0.8977 - val_loss: 0.5043\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9702 - loss: 0.2698 - val_accuracy: 0.8977 - val_loss: 0.4909\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9521 - loss: 0.2977 - val_accuracy: 0.9091 - val_loss: 0.4328\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9456 - loss: 0.3102 - val_accuracy: 0.8977 - val_loss: 0.4264\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9603 - loss: 0.2827 - val_accuracy: 0.8864 - val_loss: 0.4139\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9714 - loss: 0.2342 - val_accuracy: 0.9205 - val_loss: 0.3956\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.1943 - val_accuracy: 0.9318 - val_loss: 0.3656\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9746 - loss: 0.1933 - val_accuracy: 0.9091 - val_loss: 0.3602\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9651 - loss: 0.1904 - val_accuracy: 0.9318 - val_loss: 0.3154\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.1583 - val_accuracy: 0.9432 - val_loss: 0.2916\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.1469 - val_accuracy: 0.9545 - val_loss: 0.2700\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9771 - loss: 0.1515 - val_accuracy: 0.9318 - val_loss: 0.3109\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.1346 - val_accuracy: 0.8977 - val_loss: 0.3572\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9403 - loss: 0.2304 - val_accuracy: 0.8523 - val_loss: 0.4954\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9451 - loss: 0.2229 - val_accuracy: 0.9318 - val_loss: 0.3288\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9800 - loss: 0.1352 - val_accuracy: 0.9432 - val_loss: 0.2645\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.1130 - val_accuracy: 0.9432 - val_loss: 0.2529\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9878 - loss: 0.1070 - val_accuracy: 0.9432 - val_loss: 0.2574\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9820 - loss: 0.1117 - val_accuracy: 0.9205 - val_loss: 0.3080\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9520 - loss: 0.1694 - val_accuracy: 0.9432 - val_loss: 0.2640\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9902 - loss: 0.0990 - val_accuracy: 0.9318 - val_loss: 0.2671\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9774 - loss: 0.1260 - val_accuracy: 0.9205 - val_loss: 0.2704\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0957 - val_accuracy: 0.9432 - val_loss: 0.2578\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9855 - loss: 0.0919 - val_accuracy: 0.9432 - val_loss: 0.2568\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0862 - val_accuracy: 0.9432 - val_loss: 0.2532\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0680 - val_accuracy: 0.9432 - val_loss: 0.2555\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.0810 - val_accuracy: 0.8977 - val_loss: 0.2821\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.1127 - val_accuracy: 0.9318 - val_loss: 0.2617\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9948 - loss: 0.0803 - val_accuracy: 0.9545 - val_loss: 0.2347\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0674 - val_accuracy: 0.9432 - val_loss: 0.2317\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0621 - val_accuracy: 0.9432 - val_loss: 0.2419\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0758 - val_accuracy: 0.9545 - val_loss: 0.2282\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0786 - val_accuracy: 0.9545 - val_loss: 0.2304\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0562 - val_accuracy: 0.9432 - val_loss: 0.2247\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9922 - loss: 0.0577 - val_accuracy: 0.9545 - val_loss: 0.2270\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0587 - val_accuracy: 0.9545 - val_loss: 0.2264\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0498 - val_accuracy: 0.9432 - val_loss: 0.2285\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9898 - loss: 0.0617 - val_accuracy: 0.9432 - val_loss: 0.2331\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0564 - val_accuracy: 0.9432 - val_loss: 0.2354\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9960 - loss: 0.0479 - val_accuracy: 0.9432 - val_loss: 0.2375\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0431 - val_accuracy: 0.9432 - val_loss: 0.2391\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0527 - val_accuracy: 0.9432 - val_loss: 0.2384\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0455 - val_accuracy: 0.9432 - val_loss: 0.2394\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0386 - val_accuracy: 0.9318 - val_loss: 0.2637\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0573 - val_accuracy: 0.9318 - val_loss: 0.2502\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0564 - val_accuracy: 0.9318 - val_loss: 0.2822\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9782 - loss: 0.0948 - val_accuracy: 0.8864 - val_loss: 0.4821\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9165 - loss: 0.3138 - val_accuracy: 0.8182 - val_loss: 0.5759\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8811 - loss: 0.3637 - val_accuracy: 0.8636 - val_loss: 0.4260\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9233 - loss: 0.2116 - val_accuracy: 0.9205 - val_loss: 0.3089\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9795 - loss: 0.1596 - val_accuracy: 0.9545 - val_loss: 0.2225\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.1097 - val_accuracy: 0.9318 - val_loss: 0.2383\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0953 - val_accuracy: 0.9318 - val_loss: 0.2547\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9891 - loss: 0.0897 - val_accuracy: 0.9432 - val_loss: 0.2262\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0687 - val_accuracy: 0.9432 - val_loss: 0.2070\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9900 - loss: 0.0662 - val_accuracy: 0.9545 - val_loss: 0.1910\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0498 - val_accuracy: 0.9545 - val_loss: 0.1926\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0449 - val_accuracy: 0.9545 - val_loss: 0.1847\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.0493 - val_accuracy: 0.9432 - val_loss: 0.2095\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0424 - val_accuracy: 0.9545 - val_loss: 0.1859\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.0511 - val_accuracy: 0.9545 - val_loss: 0.1762\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9908 - loss: 0.0560 - val_accuracy: 0.9545 - val_loss: 0.1743\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.0394 - val_accuracy: 0.9432 - val_loss: 0.1805\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9891 - loss: 0.0490 - val_accuracy: 0.9545 - val_loss: 0.1711\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0376 - val_accuracy: 0.9545 - val_loss: 0.1687\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0436 - val_accuracy: 0.9318 - val_loss: 0.2312\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9694 - loss: 0.0850 - val_accuracy: 0.9318 - val_loss: 0.2173\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9903 - loss: 0.0461 - val_accuracy: 0.9432 - val_loss: 0.2134\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0474 - val_accuracy: 0.9432 - val_loss: 0.1951\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9883 - loss: 0.0609 - val_accuracy: 0.9318 - val_loss: 0.2396\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0723 - val_accuracy: 0.9205 - val_loss: 0.2949\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9707 - loss: 0.1291 - val_accuracy: 0.9432 - val_loss: 0.2023\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0548 - val_accuracy: 0.9205 - val_loss: 0.2277\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0421 - val_accuracy: 0.9318 - val_loss: 0.2257\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0426 - val_accuracy: 0.9432 - val_loss: 0.1852\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0415 - val_accuracy: 0.9318 - val_loss: 0.2163\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0269 - val_accuracy: 0.9545 - val_loss: 0.1674\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0225 - val_accuracy: 0.9545 - val_loss: 0.1664\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0245 - val_accuracy: 0.9545 - val_loss: 0.1660\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0214 - val_accuracy: 0.9545 - val_loss: 0.1678\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0192 - val_accuracy: 0.9545 - val_loss: 0.1705\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0215 - val_accuracy: 0.9545 - val_loss: 0.1672\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0240 - val_accuracy: 0.9545 - val_loss: 0.1703\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0232 - val_accuracy: 0.9318 - val_loss: 0.1960\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0243 - val_accuracy: 0.9432 - val_loss: 0.2021\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0174 - val_accuracy: 0.9432 - val_loss: 0.2051\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0177 - val_accuracy: 0.9432 - val_loss: 0.2061\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9960 - loss: 0.0237 - val_accuracy: 0.9432 - val_loss: 0.2012\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (4/4)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 1.0000 (4/4)\n",
            "  Class 3: 0.6667 (2/3)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 1.0000 (3/3)\n",
            "  Class 8: 1.0000 (3/3)\n",
            "  Class 9: 1.0000 (2/2)\n",
            "  Class 10: 1.0000 (4/4)\n",
            "  Class 11: 0.6667 (2/3)\n",
            "  Class 12: 1.0000 (3/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (4/4)\n",
            "  Class 15: 1.0000 (4/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 0.6667 (2/3)\n",
            "  Class 18: 0.7500 (3/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 0.7500 (3/4)\n",
            "  Class 21: 1.0000 (3/3)\n",
            "  Class 22: 1.0000 (5/5)\n",
            "  Class 23: 1.0000 (5/5)\n",
            "  Class 24: 1.0000 (3/3)\n",
            "  Class 25: 1.0000 (4/4)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       0.80      1.00      0.89         4\n",
            "           3       1.00      0.67      0.80         3\n",
            "           4       0.67      1.00      0.80         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       0.75      1.00      0.86         3\n",
            "           8       0.75      1.00      0.86         3\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         4\n",
            "          11       1.00      0.67      0.80         3\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       1.00      1.00      1.00         4\n",
            "          15       0.80      1.00      0.89         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       1.00      0.67      0.80         3\n",
            "          18       1.00      0.75      0.86         4\n",
            "          19       1.00      1.00      1.00         3\n",
            "          20       1.00      0.75      0.86         4\n",
            "          21       1.00      1.00      1.00         3\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         3\n",
            "          25       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.94        88\n",
            "   macro avg       0.95      0.94      0.94        88\n",
            "weighted avg       0.96      0.94      0.94        88\n",
            "\n",
            "\n",
            "===== Fold 6 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1087 - loss: 3.1552 - val_accuracy: 0.3068 - val_loss: 2.7467\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3641 - loss: 2.6030 - val_accuracy: 0.5227 - val_loss: 2.1792\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5772 - loss: 2.0586 - val_accuracy: 0.7159 - val_loss: 1.6594\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7048 - loss: 1.6047 - val_accuracy: 0.8068 - val_loss: 1.3079\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7547 - loss: 1.3184 - val_accuracy: 0.8523 - val_loss: 1.0548\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8050 - loss: 1.0611 - val_accuracy: 0.7955 - val_loss: 0.9085\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8408 - loss: 0.9412 - val_accuracy: 0.8523 - val_loss: 0.7461\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8707 - loss: 0.7574 - val_accuracy: 0.9091 - val_loss: 0.6314\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8849 - loss: 0.6700 - val_accuracy: 0.8523 - val_loss: 0.5960\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8831 - loss: 0.6086 - val_accuracy: 0.9205 - val_loss: 0.5028\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8649 - loss: 0.5670 - val_accuracy: 0.8977 - val_loss: 0.4351\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9068 - loss: 0.4805 - val_accuracy: 0.9205 - val_loss: 0.4720\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8842 - loss: 0.5093 - val_accuracy: 0.9091 - val_loss: 0.3820\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9221 - loss: 0.4333 - val_accuracy: 0.9205 - val_loss: 0.3555\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9128 - loss: 0.4033 - val_accuracy: 0.9545 - val_loss: 0.3147\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9248 - loss: 0.3956 - val_accuracy: 0.9432 - val_loss: 0.3039\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9351 - loss: 0.3686 - val_accuracy: 0.9318 - val_loss: 0.2713\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9420 - loss: 0.3018 - val_accuracy: 0.9091 - val_loss: 0.3145\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9216 - loss: 0.3232 - val_accuracy: 0.9432 - val_loss: 0.2700\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9426 - loss: 0.2933 - val_accuracy: 0.9205 - val_loss: 0.2566\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.2486 - val_accuracy: 0.9318 - val_loss: 0.2296\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9552 - loss: 0.2348 - val_accuracy: 0.9432 - val_loss: 0.1935\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9473 - loss: 0.2211 - val_accuracy: 0.9545 - val_loss: 0.1786\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9742 - loss: 0.1936 - val_accuracy: 0.9545 - val_loss: 0.1722\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.2074 - val_accuracy: 0.9545 - val_loss: 0.1759\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9686 - loss: 0.2013 - val_accuracy: 0.9318 - val_loss: 0.2164\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9268 - loss: 0.2744 - val_accuracy: 0.9432 - val_loss: 0.2731\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9445 - loss: 0.2591 - val_accuracy: 0.9659 - val_loss: 0.2063\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9386 - loss: 0.2484 - val_accuracy: 0.9318 - val_loss: 0.2121\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9373 - loss: 0.2271 - val_accuracy: 0.9545 - val_loss: 0.2090\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9540 - loss: 0.2100 - val_accuracy: 0.9318 - val_loss: 0.2276\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9669 - loss: 0.1899 - val_accuracy: 0.9432 - val_loss: 0.1848\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9538 - loss: 0.1751 - val_accuracy: 0.9545 - val_loss: 0.1726\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9449 - loss: 0.2002 - val_accuracy: 0.9659 - val_loss: 0.1656\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.1894 - val_accuracy: 0.9432 - val_loss: 0.2434\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9388 - loss: 0.2395 - val_accuracy: 0.9318 - val_loss: 0.1776\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9553 - loss: 0.1899 - val_accuracy: 0.9659 - val_loss: 0.1377\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.1241 - val_accuracy: 0.9545 - val_loss: 0.1618\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.1355 - val_accuracy: 0.9773 - val_loss: 0.1139\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0967 - val_accuracy: 0.9773 - val_loss: 0.1034\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9751 - loss: 0.1231 - val_accuracy: 1.0000 - val_loss: 0.0968\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.1547 - val_accuracy: 0.9773 - val_loss: 0.1077\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9745 - loss: 0.1390 - val_accuracy: 0.9773 - val_loss: 0.0966\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.1173 - val_accuracy: 0.9773 - val_loss: 0.0936\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.1034 - val_accuracy: 1.0000 - val_loss: 0.0631\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0950 - val_accuracy: 0.9773 - val_loss: 0.1960\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.1014 - val_accuracy: 1.0000 - val_loss: 0.0597\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.1008 - val_accuracy: 0.9886 - val_loss: 0.0719\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9848 - loss: 0.0869 - val_accuracy: 0.9886 - val_loss: 0.0553\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0811 - val_accuracy: 0.9773 - val_loss: 0.0664\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0714 - val_accuracy: 0.9886 - val_loss: 0.0586\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9898 - loss: 0.0698 - val_accuracy: 0.9659 - val_loss: 0.1574\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9714 - loss: 0.1164 - val_accuracy: 0.9886 - val_loss: 0.0669\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0636 - val_accuracy: 0.9886 - val_loss: 0.0842\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9877 - loss: 0.0643 - val_accuracy: 0.9886 - val_loss: 0.0608\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0607 - val_accuracy: 0.9886 - val_loss: 0.0647\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0595 - val_accuracy: 0.9886 - val_loss: 0.0615\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0470 - val_accuracy: 0.9886 - val_loss: 0.0605\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0500 - val_accuracy: 0.9886 - val_loss: 0.0638\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0567 - val_accuracy: 0.9886 - val_loss: 0.0716\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0494 - val_accuracy: 0.9773 - val_loss: 0.0759\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.0453 - val_accuracy: 0.9886 - val_loss: 0.0724\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0431 - val_accuracy: 0.9659 - val_loss: 0.0841\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9760 - loss: 0.0688 - val_accuracy: 0.9318 - val_loss: 0.2587\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9427 - loss: 0.1830 - val_accuracy: 0.9773 - val_loss: 0.0941\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9808 - loss: 0.0846 - val_accuracy: 0.9886 - val_loss: 0.0617\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0653 - val_accuracy: 0.9773 - val_loss: 0.1219\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9705 - loss: 0.1041 - val_accuracy: 0.9773 - val_loss: 0.0748\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0733 - val_accuracy: 0.9886 - val_loss: 0.0568\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0606 - val_accuracy: 0.9659 - val_loss: 0.1111\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9827 - loss: 0.0753 - val_accuracy: 0.9545 - val_loss: 0.2309\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9785 - loss: 0.0958 - val_accuracy: 0.9886 - val_loss: 0.0773\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0549 - val_accuracy: 0.9545 - val_loss: 0.1467\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 0.0669 - val_accuracy: 0.9091 - val_loss: 0.2483\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9711 - loss: 0.1306 - val_accuracy: 0.9773 - val_loss: 0.1150\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0639 - val_accuracy: 0.9659 - val_loss: 0.1349\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0608 - val_accuracy: 0.9886 - val_loss: 0.0879\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9883 - loss: 0.0587 - val_accuracy: 0.9886 - val_loss: 0.0725\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0390 - val_accuracy: 0.9886 - val_loss: 0.0696\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0409 - val_accuracy: 0.9886 - val_loss: 0.0679\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0339 - val_accuracy: 0.9659 - val_loss: 0.1062\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0315 - val_accuracy: 0.9886 - val_loss: 0.0724\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0335 - val_accuracy: 0.9659 - val_loss: 0.1322\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9858 - loss: 0.0591 - val_accuracy: 0.9886 - val_loss: 0.0862\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0361 - val_accuracy: 0.9886 - val_loss: 0.0765\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0354 - val_accuracy: 0.9886 - val_loss: 0.0664\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0334 - val_accuracy: 0.9886 - val_loss: 0.0660\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0300 - val_accuracy: 0.9886 - val_loss: 0.0667\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0275 - val_accuracy: 0.9886 - val_loss: 0.0669\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9972 - loss: 0.0206 - val_accuracy: 0.9886 - val_loss: 0.0657\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0277 - val_accuracy: 0.9886 - val_loss: 0.0663\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9963 - loss: 0.0271 - val_accuracy: 0.9886 - val_loss: 0.0663\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9978 - loss: 0.0289 - val_accuracy: 0.9886 - val_loss: 0.0670\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9965 - loss: 0.0227 - val_accuracy: 0.9886 - val_loss: 0.0669\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9969 - loss: 0.0214 - val_accuracy: 0.9886 - val_loss: 0.0682\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.0234 - val_accuracy: 0.9886 - val_loss: 0.0675\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9962 - loss: 0.0248 - val_accuracy: 0.9886 - val_loss: 0.0711\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9972 - loss: 0.0297 - val_accuracy: 0.9886 - val_loss: 0.0678\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0252 - val_accuracy: 0.9886 - val_loss: 0.0687\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0232 - val_accuracy: 0.9773 - val_loss: 0.0765\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (3/3)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 0.7500 (3/4)\n",
            "  Class 3: 0.7500 (3/4)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 1.0000 (2/2)\n",
            "  Class 8: 1.0000 (4/4)\n",
            "  Class 9: 1.0000 (2/2)\n",
            "  Class 10: 1.0000 (4/4)\n",
            "  Class 11: 1.0000 (3/3)\n",
            "  Class 12: 1.0000 (3/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (4/4)\n",
            "  Class 15: 1.0000 (4/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 1.0000 (3/3)\n",
            "  Class 18: 1.0000 (4/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 1.0000 (4/4)\n",
            "  Class 21: 1.0000 (3/3)\n",
            "  Class 22: 1.0000 (5/5)\n",
            "  Class 23: 1.0000 (5/5)\n",
            "  Class 24: 1.0000 (3/3)\n",
            "  Class 25: 1.0000 (4/4)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       1.00      0.75      0.86         4\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         4\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         4\n",
            "          11       1.00      1.00      1.00         3\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       0.80      1.00      0.89         4\n",
            "          15       0.80      1.00      0.89         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       1.00      1.00      1.00         3\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         3\n",
            "          20       1.00      1.00      1.00         4\n",
            "          21       1.00      1.00      1.00         3\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         3\n",
            "          25       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.98        88\n",
            "   macro avg       0.98      0.98      0.98        88\n",
            "weighted avg       0.98      0.98      0.98        88\n",
            "\n",
            "\n",
            "===== Fold 7 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.0943 - loss: 3.1554 - val_accuracy: 0.3523 - val_loss: 2.7086\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3785 - loss: 2.6002 - val_accuracy: 0.5909 - val_loss: 2.1701\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6146 - loss: 2.0374 - val_accuracy: 0.6364 - val_loss: 1.6800\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7157 - loss: 1.5504 - val_accuracy: 0.7273 - val_loss: 1.3192\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7671 - loss: 1.2384 - val_accuracy: 0.7955 - val_loss: 1.0635\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8258 - loss: 0.9858 - val_accuracy: 0.8182 - val_loss: 0.8901\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8431 - loss: 0.8639 - val_accuracy: 0.8523 - val_loss: 0.7749\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8574 - loss: 0.7205 - val_accuracy: 0.8182 - val_loss: 0.7119\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8566 - loss: 0.6952 - val_accuracy: 0.9432 - val_loss: 0.5966\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8985 - loss: 0.6059 - val_accuracy: 0.9432 - val_loss: 0.5241\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9046 - loss: 0.5383 - val_accuracy: 0.9091 - val_loss: 0.5685\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9243 - loss: 0.4557 - val_accuracy: 0.9545 - val_loss: 0.4281\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9291 - loss: 0.4533 - val_accuracy: 0.9318 - val_loss: 0.4433\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9289 - loss: 0.4097 - val_accuracy: 0.9432 - val_loss: 0.3748\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9580 - loss: 0.3470 - val_accuracy: 0.9659 - val_loss: 0.3525\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9539 - loss: 0.3069 - val_accuracy: 0.9773 - val_loss: 0.3213\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9807 - loss: 0.2636 - val_accuracy: 0.9545 - val_loss: 0.3132\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.2537 - val_accuracy: 0.9773 - val_loss: 0.2847\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9705 - loss: 0.2464 - val_accuracy: 0.9659 - val_loss: 0.2702\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9586 - loss: 0.2386 - val_accuracy: 0.9659 - val_loss: 0.2823\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9355 - loss: 0.2929 - val_accuracy: 0.9318 - val_loss: 0.3756\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9625 - loss: 0.2381 - val_accuracy: 0.9773 - val_loss: 0.2689\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9649 - loss: 0.2085 - val_accuracy: 0.9886 - val_loss: 0.2325\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.1620 - val_accuracy: 0.9659 - val_loss: 0.2427\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.1668 - val_accuracy: 0.9886 - val_loss: 0.2115\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.1704 - val_accuracy: 0.9773 - val_loss: 0.2269\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.1753 - val_accuracy: 0.9773 - val_loss: 0.2407\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9743 - loss: 0.1619 - val_accuracy: 0.9773 - val_loss: 0.2486\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9622 - loss: 0.1641 - val_accuracy: 0.9545 - val_loss: 0.2592\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.1601 - val_accuracy: 0.9773 - val_loss: 0.2207\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9867 - loss: 0.1294 - val_accuracy: 0.9773 - val_loss: 0.2075\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9796 - loss: 0.1289 - val_accuracy: 0.9773 - val_loss: 0.2021\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9873 - loss: 0.1048 - val_accuracy: 0.9773 - val_loss: 0.2104\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0750 - val_accuracy: 0.9773 - val_loss: 0.2024\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.1118 - val_accuracy: 0.9773 - val_loss: 0.1980\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9815 - loss: 0.1005 - val_accuracy: 0.9432 - val_loss: 0.2779\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9716 - loss: 0.1113 - val_accuracy: 0.9545 - val_loss: 0.2080\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.1225 - val_accuracy: 0.9545 - val_loss: 0.2719\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.1796 - val_accuracy: 0.9659 - val_loss: 0.2618\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9511 - loss: 0.1881 - val_accuracy: 0.9432 - val_loss: 0.2210\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9647 - loss: 0.1631 - val_accuracy: 0.9318 - val_loss: 0.3255\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9612 - loss: 0.2015 - val_accuracy: 0.9545 - val_loss: 0.2299\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.1199 - val_accuracy: 0.9773 - val_loss: 0.1968\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9824 - loss: 0.0996 - val_accuracy: 0.9886 - val_loss: 0.1855\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9774 - loss: 0.1146 - val_accuracy: 0.9886 - val_loss: 0.1891\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.1000 - val_accuracy: 0.9886 - val_loss: 0.1716\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9785 - loss: 0.0950 - val_accuracy: 0.9773 - val_loss: 0.2012\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9760 - loss: 0.1084 - val_accuracy: 0.9886 - val_loss: 0.1686\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0952 - val_accuracy: 0.9545 - val_loss: 0.2345\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9567 - loss: 0.1107 - val_accuracy: 0.9773 - val_loss: 0.1865\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0780 - val_accuracy: 0.9886 - val_loss: 0.1580\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0586 - val_accuracy: 0.9886 - val_loss: 0.1543\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0602 - val_accuracy: 0.9773 - val_loss: 0.1902\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.0791 - val_accuracy: 0.9886 - val_loss: 0.1615\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.0654 - val_accuracy: 0.9886 - val_loss: 0.1583\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0472 - val_accuracy: 0.9886 - val_loss: 0.1536\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0540 - val_accuracy: 0.9886 - val_loss: 0.1533\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0364 - val_accuracy: 0.9886 - val_loss: 0.1525\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0394 - val_accuracy: 0.9886 - val_loss: 0.1519\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0523 - val_accuracy: 0.9886 - val_loss: 0.1516\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0368 - val_accuracy: 0.9886 - val_loss: 0.1509\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0337 - val_accuracy: 0.9886 - val_loss: 0.1514\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0283 - val_accuracy: 0.9886 - val_loss: 0.1510\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0359 - val_accuracy: 0.9886 - val_loss: 0.1503\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0337 - val_accuracy: 0.9886 - val_loss: 0.1511\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0355 - val_accuracy: 0.9886 - val_loss: 0.1515\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0327 - val_accuracy: 0.9886 - val_loss: 0.1540\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0297 - val_accuracy: 0.9886 - val_loss: 0.1564\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0311 - val_accuracy: 0.9886 - val_loss: 0.1558\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0277 - val_accuracy: 0.9886 - val_loss: 0.1555\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.0201 - val_accuracy: 0.9886 - val_loss: 0.1561\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9997 - loss: 0.0259 - val_accuracy: 0.9886 - val_loss: 0.1554\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.0253 - val_accuracy: 0.9886 - val_loss: 0.1536\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0225 - val_accuracy: 0.9886 - val_loss: 0.1547\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0198 - val_accuracy: 0.9886 - val_loss: 0.1545\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0237 - val_accuracy: 0.9886 - val_loss: 0.1548\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0233 - val_accuracy: 0.9886 - val_loss: 0.1562\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0193 - val_accuracy: 0.9773 - val_loss: 0.1599\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.9773 - val_loss: 0.1592\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.9773 - val_loss: 0.1641\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.9773 - val_loss: 0.1645\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0215 - val_accuracy: 0.9773 - val_loss: 0.1673\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.9773 - val_loss: 0.1654\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.9773 - val_loss: 0.1798\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.9773 - val_loss: 0.1838\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.9773 - val_loss: 0.1822\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0216 - val_accuracy: 0.9773 - val_loss: 0.1854\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.9773 - val_loss: 0.1859\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.9773 - val_loss: 0.1891\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.9773 - val_loss: 0.1963\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.9773 - val_loss: 0.1976\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.9773 - val_loss: 0.2008\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9773 - val_loss: 0.2036\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.9773 - val_loss: 0.2027\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9773 - val_loss: 0.2027\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9773 - val_loss: 0.2065\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.9773 - val_loss: 0.2073\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9773 - val_loss: 0.2070\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9773 - val_loss: 0.2084\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9773 - val_loss: 0.2098\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (3/3)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 1.0000 (4/4)\n",
            "  Class 3: 1.0000 (4/4)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 1.0000 (2/2)\n",
            "  Class 8: 1.0000 (4/4)\n",
            "  Class 9: 1.0000 (2/2)\n",
            "  Class 10: 1.0000 (4/4)\n",
            "  Class 11: 1.0000 (3/3)\n",
            "  Class 12: 1.0000 (3/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (4/4)\n",
            "  Class 15: 0.7500 (3/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 0.6667 (2/3)\n",
            "  Class 18: 1.0000 (4/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 1.0000 (4/4)\n",
            "  Class 21: 1.0000 (3/3)\n",
            "  Class 22: 1.0000 (5/5)\n",
            "  Class 23: 1.0000 (5/5)\n",
            "  Class 24: 1.0000 (3/3)\n",
            "  Class 25: 1.0000 (4/4)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         4\n",
            "           4       0.67      1.00      0.80         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         4\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         4\n",
            "          11       1.00      1.00      1.00         3\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       1.00      1.00      1.00         4\n",
            "          15       1.00      0.75      0.86         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       1.00      0.67      0.80         3\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       0.75      1.00      0.86         3\n",
            "          20       1.00      1.00      1.00         4\n",
            "          21       1.00      1.00      1.00         3\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         3\n",
            "          25       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           0.98        88\n",
            "   macro avg       0.98      0.98      0.97        88\n",
            "weighted avg       0.98      0.98      0.98        88\n",
            "\n",
            "\n",
            "===== Fold 8 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.0762 - loss: 3.2025 - val_accuracy: 0.3409 - val_loss: 2.7797\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4012 - loss: 2.6186 - val_accuracy: 0.5568 - val_loss: 2.2099\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6271 - loss: 2.0909 - val_accuracy: 0.6932 - val_loss: 1.6992\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7437 - loss: 1.5781 - val_accuracy: 0.7841 - val_loss: 1.3243\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8017 - loss: 1.2504 - val_accuracy: 0.8182 - val_loss: 1.0417\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8629 - loss: 0.9812 - val_accuracy: 0.8295 - val_loss: 0.8496\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8745 - loss: 0.7913 - val_accuracy: 0.9091 - val_loss: 0.7212\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9169 - loss: 0.6806 - val_accuracy: 0.8636 - val_loss: 0.6341\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9302 - loss: 0.5745 - val_accuracy: 0.9205 - val_loss: 0.5267\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9207 - loss: 0.5361 - val_accuracy: 0.8864 - val_loss: 0.5290\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9373 - loss: 0.4730 - val_accuracy: 0.8636 - val_loss: 0.5497\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9206 - loss: 0.5153 - val_accuracy: 0.9205 - val_loss: 0.4152\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9547 - loss: 0.3697 - val_accuracy: 0.9091 - val_loss: 0.4021\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9538 - loss: 0.3461 - val_accuracy: 0.9318 - val_loss: 0.3696\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9525 - loss: 0.2942 - val_accuracy: 0.8636 - val_loss: 0.3912\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9253 - loss: 0.3326 - val_accuracy: 0.9318 - val_loss: 0.2999\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9590 - loss: 0.3031 - val_accuracy: 0.8523 - val_loss: 0.4855\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8980 - loss: 0.4045 - val_accuracy: 0.8864 - val_loss: 0.3888\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9332 - loss: 0.3272 - val_accuracy: 0.8864 - val_loss: 0.3238\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.3113 - val_accuracy: 0.9205 - val_loss: 0.3126\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9605 - loss: 0.2394 - val_accuracy: 0.9205 - val_loss: 0.3062\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.2204 - val_accuracy: 0.9318 - val_loss: 0.2816\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9761 - loss: 0.2054 - val_accuracy: 0.9205 - val_loss: 0.2727\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.1860 - val_accuracy: 0.9545 - val_loss: 0.2460\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.1749 - val_accuracy: 0.9545 - val_loss: 0.2568\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.1787 - val_accuracy: 0.9432 - val_loss: 0.2533\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9685 - loss: 0.1705 - val_accuracy: 0.9205 - val_loss: 0.2859\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9438 - loss: 0.2312 - val_accuracy: 0.9432 - val_loss: 0.2524\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9858 - loss: 0.1807 - val_accuracy: 0.9318 - val_loss: 0.2263\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9652 - loss: 0.2112 - val_accuracy: 0.9091 - val_loss: 0.3026\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9510 - loss: 0.1895 - val_accuracy: 0.8977 - val_loss: 0.3325\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9364 - loss: 0.2353 - val_accuracy: 0.9318 - val_loss: 0.3146\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.1169 - val_accuracy: 0.9432 - val_loss: 0.2468\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9886 - loss: 0.1086 - val_accuracy: 0.9091 - val_loss: 0.2946\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9761 - loss: 0.1336 - val_accuracy: 0.9659 - val_loss: 0.2123\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9822 - loss: 0.1113 - val_accuracy: 0.9659 - val_loss: 0.2001\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9854 - loss: 0.1153 - val_accuracy: 0.9659 - val_loss: 0.1929\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.1032 - val_accuracy: 0.9545 - val_loss: 0.1997\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0820 - val_accuracy: 0.9659 - val_loss: 0.1866\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0805 - val_accuracy: 0.9545 - val_loss: 0.1948\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.1103 - val_accuracy: 0.9659 - val_loss: 0.2213\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.0800 - val_accuracy: 0.9659 - val_loss: 0.1786\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.0757 - val_accuracy: 0.9659 - val_loss: 0.1878\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0851 - val_accuracy: 0.9659 - val_loss: 0.1680\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9960 - loss: 0.0601 - val_accuracy: 0.9659 - val_loss: 0.1752\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9906 - loss: 0.0657 - val_accuracy: 0.9659 - val_loss: 0.1730\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.0634 - val_accuracy: 0.9659 - val_loss: 0.1736\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.0635 - val_accuracy: 0.9659 - val_loss: 0.1744\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0777 - val_accuracy: 0.9659 - val_loss: 0.1750\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0555 - val_accuracy: 0.9659 - val_loss: 0.1761\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9932 - loss: 0.0521 - val_accuracy: 0.9659 - val_loss: 0.1775\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0502 - val_accuracy: 0.9659 - val_loss: 0.1780\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0598 - val_accuracy: 0.9659 - val_loss: 0.1807\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0533 - val_accuracy: 0.9659 - val_loss: 0.1804\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.0486 - val_accuracy: 0.9659 - val_loss: 0.1801\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0515 - val_accuracy: 0.9659 - val_loss: 0.1814\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0399 - val_accuracy: 0.9659 - val_loss: 0.1824\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0392 - val_accuracy: 0.9659 - val_loss: 0.1830\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.0390 - val_accuracy: 0.9659 - val_loss: 0.1824\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0625 - val_accuracy: 0.9659 - val_loss: 0.2050\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0533 - val_accuracy: 0.9659 - val_loss: 0.2031\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0299 - val_accuracy: 0.9659 - val_loss: 0.1977\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0395 - val_accuracy: 0.9659 - val_loss: 0.1954\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9922 - loss: 0.0463 - val_accuracy: 0.9659 - val_loss: 0.1956\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.0525 - val_accuracy: 0.9659 - val_loss: 0.1965\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0429 - val_accuracy: 0.9659 - val_loss: 0.1940\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0476 - val_accuracy: 0.9659 - val_loss: 0.1952\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0228 - val_accuracy: 0.9659 - val_loss: 0.1955\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0420 - val_accuracy: 0.9659 - val_loss: 0.1970\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9883 - loss: 0.0416 - val_accuracy: 0.9659 - val_loss: 0.1975\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.0389 - val_accuracy: 0.9659 - val_loss: 0.1987\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0295 - val_accuracy: 0.9659 - val_loss: 0.2237\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.0243 - val_accuracy: 0.9659 - val_loss: 0.2020\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0291 - val_accuracy: 0.9659 - val_loss: 0.1863\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0221 - val_accuracy: 0.9659 - val_loss: 0.1824\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0385 - val_accuracy: 0.9659 - val_loss: 0.1821\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9925 - loss: 0.0299 - val_accuracy: 0.9659 - val_loss: 0.1822\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0237 - val_accuracy: 0.9659 - val_loss: 0.1844\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0230 - val_accuracy: 0.9659 - val_loss: 0.1847\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0292 - val_accuracy: 0.9659 - val_loss: 0.1862\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0237 - val_accuracy: 0.9659 - val_loss: 0.1886\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0174 - val_accuracy: 0.9659 - val_loss: 0.1920\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0219 - val_accuracy: 0.9659 - val_loss: 0.1986\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0197 - val_accuracy: 0.9659 - val_loss: 0.2025\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0266 - val_accuracy: 0.9659 - val_loss: 0.2076\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0202 - val_accuracy: 0.9659 - val_loss: 0.1995\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9986 - loss: 0.0160 - val_accuracy: 0.9659 - val_loss: 0.2002\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9967 - loss: 0.0202 - val_accuracy: 0.9659 - val_loss: 0.2030\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0178 - val_accuracy: 0.9659 - val_loss: 0.2043\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9951 - loss: 0.0209 - val_accuracy: 0.9659 - val_loss: 0.1993\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0240 - val_accuracy: 0.9659 - val_loss: 0.2054\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0146 - val_accuracy: 0.9659 - val_loss: 0.2112\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0177 - val_accuracy: 0.9659 - val_loss: 0.2163\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0174 - val_accuracy: 0.9659 - val_loss: 0.2172\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0143 - val_accuracy: 0.9659 - val_loss: 0.2174\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0182 - val_accuracy: 0.9659 - val_loss: 0.2178\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0206 - val_accuracy: 0.9659 - val_loss: 0.2183\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0227 - val_accuracy: 0.9659 - val_loss: 0.2196\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0156 - val_accuracy: 0.9659 - val_loss: 0.2197\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0216 - val_accuracy: 0.9659 - val_loss: 0.2192\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (3/3)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 1.0000 (4/4)\n",
            "  Class 3: 1.0000 (4/4)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 0.5000 (1/2)\n",
            "  Class 8: 1.0000 (4/4)\n",
            "  Class 9: 1.0000 (2/2)\n",
            "  Class 10: 1.0000 (4/4)\n",
            "  Class 11: 1.0000 (3/3)\n",
            "  Class 12: 0.6667 (2/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (4/4)\n",
            "  Class 15: 1.0000 (4/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 1.0000 (3/3)\n",
            "  Class 18: 1.0000 (4/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 1.0000 (4/4)\n",
            "  Class 21: 1.0000 (3/3)\n",
            "  Class 22: 1.0000 (5/5)\n",
            "  Class 23: 0.8000 (4/5)\n",
            "  Class 24: 1.0000 (2/2)\n",
            "  Class 25: 1.0000 (5/5)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       0.80      1.00      0.89         4\n",
            "           3       1.00      1.00      1.00         4\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      0.50      0.67         2\n",
            "           8       1.00      1.00      1.00         4\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         4\n",
            "          11       1.00      1.00      1.00         3\n",
            "          12       1.00      0.67      0.80         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       1.00      1.00      1.00         4\n",
            "          15       1.00      1.00      1.00         4\n",
            "          16       0.75      1.00      0.86         3\n",
            "          17       0.75      1.00      0.86         3\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         3\n",
            "          20       1.00      1.00      1.00         4\n",
            "          21       1.00      1.00      1.00         3\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      0.80      0.89         5\n",
            "          24       1.00      1.00      1.00         2\n",
            "          25       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.97        88\n",
            "   macro avg       0.97      0.96      0.96        88\n",
            "weighted avg       0.97      0.97      0.96        88\n",
            "\n",
            "\n",
            "===== Fold 9 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1379 - loss: 3.1174 - val_accuracy: 0.4659 - val_loss: 2.7404\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4965 - loss: 2.5903 - val_accuracy: 0.5682 - val_loss: 2.2245\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5884 - loss: 2.0355 - val_accuracy: 0.6705 - val_loss: 1.7151\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6890 - loss: 1.5867 - val_accuracy: 0.7500 - val_loss: 1.3820\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7663 - loss: 1.2555 - val_accuracy: 0.8409 - val_loss: 1.1115\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8148 - loss: 1.0103 - val_accuracy: 0.8523 - val_loss: 0.9298\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9023 - loss: 0.8288 - val_accuracy: 0.8750 - val_loss: 0.7815\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9146 - loss: 0.6785 - val_accuracy: 0.8864 - val_loss: 0.7449\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9197 - loss: 0.6136 - val_accuracy: 0.8864 - val_loss: 0.6445\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9372 - loss: 0.5138 - val_accuracy: 0.9205 - val_loss: 0.5762\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9378 - loss: 0.4616 - val_accuracy: 0.8409 - val_loss: 0.6240\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8773 - loss: 0.5133 - val_accuracy: 0.9091 - val_loss: 0.5148\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9583 - loss: 0.3485 - val_accuracy: 0.9091 - val_loss: 0.4716\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9419 - loss: 0.3539 - val_accuracy: 0.9091 - val_loss: 0.4299\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9446 - loss: 0.3335 - val_accuracy: 0.8409 - val_loss: 0.5313\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9058 - loss: 0.4169 - val_accuracy: 0.9318 - val_loss: 0.4255\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9489 - loss: 0.3084 - val_accuracy: 0.9318 - val_loss: 0.3921\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.2463 - val_accuracy: 0.9318 - val_loss: 0.3654\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9664 - loss: 0.2252 - val_accuracy: 0.9318 - val_loss: 0.3390\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9770 - loss: 0.2148 - val_accuracy: 0.9205 - val_loss: 0.3482\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9722 - loss: 0.2076 - val_accuracy: 0.9205 - val_loss: 0.3693\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.2293 - val_accuracy: 0.9318 - val_loss: 0.3327\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9524 - loss: 0.2440 - val_accuracy: 0.9432 - val_loss: 0.3049\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9690 - loss: 0.2010 - val_accuracy: 0.9432 - val_loss: 0.2877\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9812 - loss: 0.1621 - val_accuracy: 0.9318 - val_loss: 0.2813\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9806 - loss: 0.1592 - val_accuracy: 0.9432 - val_loss: 0.3081\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9847 - loss: 0.1460 - val_accuracy: 0.9432 - val_loss: 0.2847\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.1294 - val_accuracy: 0.9432 - val_loss: 0.2795\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.1414 - val_accuracy: 0.9432 - val_loss: 0.2771\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.1385 - val_accuracy: 0.9432 - val_loss: 0.2773\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.1016 - val_accuracy: 0.9432 - val_loss: 0.2706\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9873 - loss: 0.1083 - val_accuracy: 0.8750 - val_loss: 0.4083\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9356 - loss: 0.2106 - val_accuracy: 0.9318 - val_loss: 0.2946\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9703 - loss: 0.1760 - val_accuracy: 0.9318 - val_loss: 0.3145\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.1556 - val_accuracy: 0.9432 - val_loss: 0.2888\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.1109 - val_accuracy: 0.9545 - val_loss: 0.2426\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.0979 - val_accuracy: 0.9545 - val_loss: 0.2367\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0790 - val_accuracy: 0.9432 - val_loss: 0.2294\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9890 - loss: 0.0848 - val_accuracy: 0.9659 - val_loss: 0.2020\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0791 - val_accuracy: 0.9659 - val_loss: 0.1995\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0682 - val_accuracy: 0.9545 - val_loss: 0.1983\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0659 - val_accuracy: 0.9545 - val_loss: 0.2106\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0948 - val_accuracy: 0.9545 - val_loss: 0.2582\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9758 - loss: 0.1457 - val_accuracy: 0.9318 - val_loss: 0.2614\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9666 - loss: 0.1726 - val_accuracy: 0.9205 - val_loss: 0.3114\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9631 - loss: 0.1617 - val_accuracy: 0.9432 - val_loss: 0.2403\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.1143 - val_accuracy: 0.9659 - val_loss: 0.2220\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9785 - loss: 0.1068 - val_accuracy: 0.9091 - val_loss: 0.2577\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9541 - loss: 0.1355 - val_accuracy: 0.9432 - val_loss: 0.2073\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0743 - val_accuracy: 0.9659 - val_loss: 0.2012\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0687 - val_accuracy: 0.9318 - val_loss: 0.2209\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9785 - loss: 0.1072 - val_accuracy: 0.9205 - val_loss: 0.3151\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9495 - loss: 0.1752 - val_accuracy: 0.9318 - val_loss: 0.2695\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9632 - loss: 0.1532 - val_accuracy: 0.9545 - val_loss: 0.2206\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.0973 - val_accuracy: 0.9773 - val_loss: 0.1671\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0604 - val_accuracy: 0.9773 - val_loss: 0.1611\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9969 - loss: 0.0617 - val_accuracy: 0.9773 - val_loss: 0.1568\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0560 - val_accuracy: 0.9773 - val_loss: 0.1536\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0459 - val_accuracy: 0.9773 - val_loss: 0.1505\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0445 - val_accuracy: 0.9773 - val_loss: 0.1487\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0535 - val_accuracy: 0.9773 - val_loss: 0.1474\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0380 - val_accuracy: 0.9773 - val_loss: 0.1452\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0364 - val_accuracy: 0.9773 - val_loss: 0.1434\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0407 - val_accuracy: 0.9773 - val_loss: 0.1409\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0336 - val_accuracy: 0.9773 - val_loss: 0.1394\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9969 - loss: 0.0323 - val_accuracy: 0.9773 - val_loss: 0.1377\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0306 - val_accuracy: 0.9773 - val_loss: 0.1356\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9971 - loss: 0.0378 - val_accuracy: 0.9773 - val_loss: 0.1344\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9987 - loss: 0.0328 - val_accuracy: 0.9773 - val_loss: 0.1329\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0266 - val_accuracy: 0.9773 - val_loss: 0.1312\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0221 - val_accuracy: 0.9773 - val_loss: 0.1294\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0300 - val_accuracy: 0.9773 - val_loss: 0.1306\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0375 - val_accuracy: 0.9773 - val_loss: 0.1292\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0252 - val_accuracy: 0.9773 - val_loss: 0.1279\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0352 - val_accuracy: 0.9773 - val_loss: 0.1264\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0286 - val_accuracy: 0.9773 - val_loss: 0.1256\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0333 - val_accuracy: 0.9773 - val_loss: 0.1247\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0237 - val_accuracy: 0.9773 - val_loss: 0.1238\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0201 - val_accuracy: 0.9773 - val_loss: 0.1229\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0253 - val_accuracy: 0.9773 - val_loss: 0.1222\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0290 - val_accuracy: 0.9773 - val_loss: 0.1198\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0226 - val_accuracy: 0.9659 - val_loss: 0.1553\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0388 - val_accuracy: 0.9773 - val_loss: 0.1460\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9798 - loss: 0.0786 - val_accuracy: 0.9432 - val_loss: 0.2104\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9809 - loss: 0.0935 - val_accuracy: 0.9545 - val_loss: 0.2160\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9790 - loss: 0.1018 - val_accuracy: 0.9205 - val_loss: 0.2532\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9690 - loss: 0.1201 - val_accuracy: 0.9205 - val_loss: 0.3609\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9549 - loss: 0.1979 - val_accuracy: 0.9432 - val_loss: 0.2987\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9590 - loss: 0.1920 - val_accuracy: 0.8523 - val_loss: 0.3862\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9695 - loss: 0.1511 - val_accuracy: 0.9545 - val_loss: 0.2048\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0949 - val_accuracy: 0.9659 - val_loss: 0.1891\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0475 - val_accuracy: 0.9659 - val_loss: 0.2052\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0493 - val_accuracy: 0.9659 - val_loss: 0.2089\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0631 - val_accuracy: 0.9659 - val_loss: 0.2091\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0445 - val_accuracy: 0.9545 - val_loss: 0.2393\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0372 - val_accuracy: 0.9545 - val_loss: 0.1980\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0375 - val_accuracy: 0.9659 - val_loss: 0.2166\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0360 - val_accuracy: 0.9545 - val_loss: 0.2281\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0317 - val_accuracy: 0.9545 - val_loss: 0.2717\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9989 - loss: 0.0248 - val_accuracy: 0.9545 - val_loss: 0.2297\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (3/3)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 0.7500 (3/4)\n",
            "  Class 3: 1.0000 (4/4)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 1.0000 (2/2)\n",
            "  Class 8: 1.0000 (4/4)\n",
            "  Class 9: 0.5000 (1/2)\n",
            "  Class 10: 1.0000 (4/4)\n",
            "  Class 11: 1.0000 (3/3)\n",
            "  Class 12: 1.0000 (3/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (4/4)\n",
            "  Class 15: 0.7500 (3/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 1.0000 (3/3)\n",
            "  Class 18: 1.0000 (4/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 1.0000 (4/4)\n",
            "  Class 21: 0.6667 (2/3)\n",
            "  Class 22: 1.0000 (5/5)\n",
            "  Class 23: 1.0000 (5/5)\n",
            "  Class 24: 1.0000 (2/2)\n",
            "  Class 25: 1.0000 (5/5)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       0.80      1.00      0.89         4\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       0.80      1.00      0.89         4\n",
            "           9       1.00      0.50      0.67         2\n",
            "          10       1.00      1.00      1.00         4\n",
            "          11       0.75      1.00      0.86         3\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       1.00      1.00      1.00         4\n",
            "          15       1.00      0.75      0.86         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       1.00      1.00      1.00         3\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         3\n",
            "          20       1.00      1.00      1.00         4\n",
            "          21       1.00      0.67      0.80         3\n",
            "          22       0.83      1.00      0.91         5\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         2\n",
            "          25       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.95        88\n",
            "   macro avg       0.97      0.95      0.95        88\n",
            "weighted avg       0.96      0.95      0.95        88\n",
            "\n",
            "\n",
            "===== Fold 10 / 10 =====\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.1009 - loss: 3.1652 - val_accuracy: 0.4205 - val_loss: 2.7304\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5361 - loss: 2.5674 - val_accuracy: 0.5568 - val_loss: 2.1546\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6461 - loss: 1.9824 - val_accuracy: 0.7159 - val_loss: 1.6757\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7058 - loss: 1.5614 - val_accuracy: 0.7045 - val_loss: 1.3230\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7685 - loss: 1.2315 - val_accuracy: 0.7955 - val_loss: 1.1094\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8482 - loss: 0.9881 - val_accuracy: 0.8636 - val_loss: 0.9077\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8909 - loss: 0.8395 - val_accuracy: 0.8864 - val_loss: 0.7745\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9149 - loss: 0.7072 - val_accuracy: 0.8864 - val_loss: 0.6842\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9017 - loss: 0.6373 - val_accuracy: 0.9205 - val_loss: 0.5976\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8958 - loss: 0.5967 - val_accuracy: 0.9318 - val_loss: 0.5099\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8998 - loss: 0.5066 - val_accuracy: 0.8864 - val_loss: 0.5154\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9098 - loss: 0.4496 - val_accuracy: 0.8977 - val_loss: 0.4537\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9272 - loss: 0.3739 - val_accuracy: 0.9432 - val_loss: 0.4115\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9504 - loss: 0.3404 - val_accuracy: 0.9545 - val_loss: 0.3470\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9661 - loss: 0.3025 - val_accuracy: 0.9318 - val_loss: 0.3521\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9467 - loss: 0.3323 - val_accuracy: 0.9205 - val_loss: 0.3822\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9280 - loss: 0.3403 - val_accuracy: 0.8864 - val_loss: 0.4214\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.2895 - val_accuracy: 0.9432 - val_loss: 0.3227\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9649 - loss: 0.2287 - val_accuracy: 0.8864 - val_loss: 0.4300\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9048 - loss: 0.3512 - val_accuracy: 0.9432 - val_loss: 0.2801\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.2497 - val_accuracy: 0.9659 - val_loss: 0.2357\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9810 - loss: 0.1769 - val_accuracy: 0.9659 - val_loss: 0.2213\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.1471 - val_accuracy: 0.9545 - val_loss: 0.2152\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9835 - loss: 0.1443 - val_accuracy: 0.9773 - val_loss: 0.1776\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.1160 - val_accuracy: 0.9545 - val_loss: 0.1947\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9745 - loss: 0.1468 - val_accuracy: 0.9545 - val_loss: 0.2082\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.1437 - val_accuracy: 0.9773 - val_loss: 0.1507\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0969 - val_accuracy: 0.9773 - val_loss: 0.1483\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.1051 - val_accuracy: 0.9659 - val_loss: 0.1533\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9750 - loss: 0.1266 - val_accuracy: 0.9886 - val_loss: 0.1241\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.1058 - val_accuracy: 0.9886 - val_loss: 0.1211\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9915 - loss: 0.0783 - val_accuracy: 0.9773 - val_loss: 0.1195\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0808 - val_accuracy: 0.9773 - val_loss: 0.1151\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0837 - val_accuracy: 0.9773 - val_loss: 0.1123\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0835 - val_accuracy: 0.9773 - val_loss: 0.1123\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0551 - val_accuracy: 0.9773 - val_loss: 0.1076\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0709 - val_accuracy: 0.9773 - val_loss: 0.1070\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0619 - val_accuracy: 0.9773 - val_loss: 0.1049\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0758 - val_accuracy: 0.9773 - val_loss: 0.1055\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0699 - val_accuracy: 0.9773 - val_loss: 0.1027\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0461 - val_accuracy: 0.9886 - val_loss: 0.0912\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9959 - loss: 0.0453 - val_accuracy: 0.9886 - val_loss: 0.0963\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 0.0568 - val_accuracy: 0.9886 - val_loss: 0.0918\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9935 - loss: 0.0611 - val_accuracy: 0.9886 - val_loss: 0.0948\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0480 - val_accuracy: 0.9886 - val_loss: 0.0879\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0407 - val_accuracy: 0.9886 - val_loss: 0.0867\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9971 - loss: 0.0406 - val_accuracy: 0.9886 - val_loss: 0.0857\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0570 - val_accuracy: 0.9886 - val_loss: 0.0870\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0474 - val_accuracy: 0.9886 - val_loss: 0.0840\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0314 - val_accuracy: 0.9886 - val_loss: 0.0834\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0377 - val_accuracy: 0.9886 - val_loss: 0.0828\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0525 - val_accuracy: 0.9886 - val_loss: 0.0835\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0359 - val_accuracy: 0.9886 - val_loss: 0.0822\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0540 - val_accuracy: 0.9886 - val_loss: 0.0780\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0383 - val_accuracy: 0.9773 - val_loss: 0.1238\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0390 - val_accuracy: 0.9773 - val_loss: 0.1226\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9884 - loss: 0.0649 - val_accuracy: 0.8523 - val_loss: 0.4109\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9123 - loss: 0.2839 - val_accuracy: 0.8864 - val_loss: 0.3202\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8757 - loss: 0.3218 - val_accuracy: 0.9205 - val_loss: 0.2705\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9330 - loss: 0.2178 - val_accuracy: 0.8864 - val_loss: 0.3175\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8731 - loss: 0.2917 - val_accuracy: 0.9205 - val_loss: 0.2806\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9312 - loss: 0.2038 - val_accuracy: 0.9659 - val_loss: 0.1805\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.1470 - val_accuracy: 0.9432 - val_loss: 0.2125\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.1138 - val_accuracy: 0.9432 - val_loss: 0.1773\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9655 - loss: 0.1292 - val_accuracy: 0.8636 - val_loss: 0.4641\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8713 - loss: 0.3838 - val_accuracy: 0.9545 - val_loss: 0.2863\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9485 - loss: 0.2078 - val_accuracy: 0.9659 - val_loss: 0.1899\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9642 - loss: 0.1520 - val_accuracy: 0.9205 - val_loss: 0.3127\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9374 - loss: 0.2197 - val_accuracy: 0.9432 - val_loss: 0.2589\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.1189 - val_accuracy: 0.9659 - val_loss: 0.1782\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9644 - loss: 0.1407 - val_accuracy: 0.9773 - val_loss: 0.1559\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0867 - val_accuracy: 0.9659 - val_loss: 0.1501\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0846 - val_accuracy: 0.9659 - val_loss: 0.1631\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.0743 - val_accuracy: 0.9659 - val_loss: 0.1440\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0676 - val_accuracy: 0.9773 - val_loss: 0.1126\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0530 - val_accuracy: 0.9545 - val_loss: 0.1750\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.1006 - val_accuracy: 0.9659 - val_loss: 0.1348\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0468 - val_accuracy: 0.9773 - val_loss: 0.1084\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.0381 - val_accuracy: 0.9886 - val_loss: 0.0911\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0379 - val_accuracy: 0.9886 - val_loss: 0.0948\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9995 - loss: 0.0351 - val_accuracy: 0.9886 - val_loss: 0.0981\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0310 - val_accuracy: 0.9773 - val_loss: 0.0991\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0429 - val_accuracy: 0.9659 - val_loss: 0.1250\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.0651 - val_accuracy: 0.9545 - val_loss: 0.1302\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.0732 - val_accuracy: 0.9773 - val_loss: 0.0987\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 0.0438 - val_accuracy: 0.9773 - val_loss: 0.0872\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9961 - loss: 0.0306 - val_accuracy: 0.9886 - val_loss: 0.0803\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.0398 - val_accuracy: 0.9886 - val_loss: 0.0769\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9956 - loss: 0.0285 - val_accuracy: 0.9886 - val_loss: 0.0713\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0209 - val_accuracy: 0.9886 - val_loss: 0.0724\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0229 - val_accuracy: 0.9886 - val_loss: 0.0753\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0219 - val_accuracy: 0.9773 - val_loss: 0.0738\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0178 - val_accuracy: 0.9886 - val_loss: 0.0717\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9972 - loss: 0.0231 - val_accuracy: 0.9773 - val_loss: 0.0772\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0174 - val_accuracy: 0.9773 - val_loss: 0.0730\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0206 - val_accuracy: 0.9773 - val_loss: 0.0726\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.0231 - val_accuracy: 0.9773 - val_loss: 0.0708\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0251 - val_accuracy: 0.9773 - val_loss: 0.0804\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0175 - val_accuracy: 0.9886 - val_loss: 0.0685\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0145 - val_accuracy: 0.9886 - val_loss: 0.0728\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5]]\n",
            "\n",
            "Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (3/3)\n",
            "  Class 1: 1.0000 (3/3)\n",
            "  Class 2: 1.0000 (4/4)\n",
            "  Class 3: 1.0000 (4/4)\n",
            "  Class 4: 1.0000 (2/2)\n",
            "  Class 5: 1.0000 (3/3)\n",
            "  Class 6: 1.0000 (3/3)\n",
            "  Class 7: 1.0000 (2/2)\n",
            "  Class 8: 0.6667 (2/3)\n",
            "  Class 9: 1.0000 (3/3)\n",
            "  Class 10: 1.0000 (3/3)\n",
            "  Class 11: 1.0000 (4/4)\n",
            "  Class 12: 1.0000 (3/3)\n",
            "  Class 13: 1.0000 (3/3)\n",
            "  Class 14: 1.0000 (3/3)\n",
            "  Class 15: 1.0000 (4/4)\n",
            "  Class 16: 1.0000 (3/3)\n",
            "  Class 17: 1.0000 (4/4)\n",
            "  Class 18: 1.0000 (4/4)\n",
            "  Class 19: 1.0000 (3/3)\n",
            "  Class 20: 1.0000 (3/3)\n",
            "  Class 21: 1.0000 (4/4)\n",
            "  Class 22: 1.0000 (5/5)\n",
            "  Class 23: 1.0000 (5/5)\n",
            "  Class 24: 1.0000 (2/2)\n",
            "  Class 25: 1.0000 (5/5)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      1.00      1.00         3\n",
            "           2       0.80      1.00      0.89         4\n",
            "           3       1.00      1.00      1.00         4\n",
            "           4       1.00      1.00      1.00         2\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         3\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      0.67      0.80         3\n",
            "           9       1.00      1.00      1.00         3\n",
            "          10       1.00      1.00      1.00         3\n",
            "          11       1.00      1.00      1.00         4\n",
            "          12       1.00      1.00      1.00         3\n",
            "          13       1.00      1.00      1.00         3\n",
            "          14       1.00      1.00      1.00         3\n",
            "          15       1.00      1.00      1.00         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       1.00      1.00      1.00         4\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         3\n",
            "          20       1.00      1.00      1.00         3\n",
            "          21       1.00      1.00      1.00         4\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       1.00      1.00      1.00         2\n",
            "          25       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.99        88\n",
            "   macro avg       0.99      0.99      0.99        88\n",
            "weighted avg       0.99      0.99      0.99        88\n",
            "\n",
            "\n",
            "===== OVERALL RESULTS =====\n",
            "Average Accuracy across all folds: 0.9739\n",
            "\n",
            "Average Class-wise Accuracy:\n",
            "  Class 0: 1.0000 (total samples: 35)\n",
            "  Class 1: 1.0000 (total samples: 30)\n",
            "  Class 2: 0.8750 (total samples: 40)\n",
            "  Class 3: 0.9429 (total samples: 35)\n",
            "  Class 4: 1.0000 (total samples: 20)\n",
            "  Class 5: 1.0000 (total samples: 30)\n",
            "  Class 6: 1.0000 (total samples: 30)\n",
            "  Class 7: 0.9600 (total samples: 25)\n",
            "  Class 8: 0.9706 (total samples: 34)\n",
            "  Class 9: 0.9600 (total samples: 25)\n",
            "  Class 10: 1.0000 (total samples: 35)\n",
            "  Class 11: 0.9714 (total samples: 35)\n",
            "  Class 12: 0.9667 (total samples: 30)\n",
            "  Class 13: 1.0000 (total samples: 30)\n",
            "  Class 14: 1.0000 (total samples: 35)\n",
            "  Class 15: 0.9500 (total samples: 40)\n",
            "  Class 16: 1.0000 (total samples: 30)\n",
            "  Class 17: 0.9429 (total samples: 35)\n",
            "  Class 18: 0.9750 (total samples: 40)\n",
            "  Class 19: 1.0000 (total samples: 30)\n",
            "  Class 20: 0.9714 (total samples: 35)\n",
            "  Class 21: 0.9714 (total samples: 35)\n",
            "  Class 22: 0.9375 (total samples: 48)\n",
            "  Class 23: 0.9800 (total samples: 50)\n",
            "  Class 24: 1.0000 (total samples: 25)\n",
            "  Class 25: 1.0000 (total samples: 45)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can only concatenate list (not \"float\") to list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-db7a08ca2edd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclass_accuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_folds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mfold_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_folds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_indices\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"float\") to list"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Define LSTM model with regularization\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(32, input_shape=(25, 84)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "y_labels = np.argmax(Y_seq, axis=1)\n",
        "\n",
        "# Get class names or generate them if not available\n",
        "# Assuming classes are integers starting from 0\n",
        "class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
        "\n",
        "# Create dictionaries to track per-class metrics across folds\n",
        "class_accuracies = {i: [] for i in range(num_classes)}\n",
        "fold_class_samples = {i: [] for i in range(num_classes)}\n",
        "\n",
        "# Overall metrics\n",
        "accuracy_scores = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Initialize StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X_seq, y_labels)):\n",
        "    print(f\"\\n===== Fold {fold+1} / {skf.get_n_splits()} =====\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X_seq[train_index], X_seq[test_index]\n",
        "    y_train, y_test = Y_seq[train_index], Y_seq[test_index]\n",
        "\n",
        "    # Convert to float32\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    # Create and train model\n",
        "    model = create_model()\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
        "                        validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate overall performance\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    val_losses.append(history.history['val_loss'])\n",
        "    val_accuracies.append(history.history['val_accuracy'])\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Calculate and store class-wise accuracy\n",
        "    conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "    # Print confusion matrix\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Calculate per-class accuracy\n",
        "    print(\"\\nClass-wise Accuracy:\")\n",
        "    for class_idx in range(num_classes):\n",
        "        # Check if this class exists in the test set\n",
        "        class_samples = np.sum(y_true_classes == class_idx)\n",
        "\n",
        "        if class_samples > 0:\n",
        "            # Get indices where true class is class_idx\n",
        "            indices = np.where(y_true_classes == class_idx)[0]\n",
        "\n",
        "            # Calculate accuracy for this class\n",
        "            class_correct = np.sum(y_pred_classes[indices] == class_idx)\n",
        "            class_accuracy = class_correct / class_samples\n",
        "\n",
        "            # Store results\n",
        "            class_accuracies[class_idx].append(class_accuracy)\n",
        "            fold_class_samples[class_idx].append(class_samples)\n",
        "\n",
        "            print(f\"  {class_names[class_idx]}: {class_accuracy:.4f} ({class_correct}/{class_samples})\")\n",
        "        else:\n",
        "            print(f\"  {class_names[class_idx]}: N/A (no samples)\")\n",
        "\n",
        "    # Print detailed classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true_classes, y_pred_classes))\n",
        "\n",
        "# Print overall results\n",
        "print(\"\\n===== OVERALL RESULTS =====\")\n",
        "print(f\"Average Accuracy across all folds: {np.mean(accuracy_scores):.4f}\")\n",
        "\n",
        "# Calculate and print average class-wise accuracy\n",
        "print(\"\\nAverage Class-wise Accuracy:\")\n",
        "for class_idx in range(num_classes):\n",
        "    if class_accuracies[class_idx]:  # If we have any data for this class\n",
        "        # Calculate weighted average based on number of samples in each fold\n",
        "        weighted_avg = np.average(\n",
        "            class_accuracies[class_idx],\n",
        "            weights=fold_class_samples[class_idx]\n",
        "        )\n",
        "        total_samples = sum(fold_class_samples[class_idx])\n",
        "        print(f\"  {class_names[class_idx]}: {weighted_avg:.4f} (total samples: {total_samples})\")\n",
        "    else:\n",
        "        print(f\"  {class_names[class_idx]}: N/A (no samples in any fold)\")\n",
        "\n",
        "# Plot validation loss and accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "for fold in range(len(val_losses)):\n",
        "    plt.plot(val_losses[fold], label=f'Fold {fold+1}')\n",
        "plt.title('Validation Loss by Fold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "for fold in range(len(val_accuracies)):\n",
        "    plt.plot(val_accuracies[fold], label=f'Fold {fold+1}')\n",
        "plt.title('Validation Accuracy by Fold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot class-wise accuracies across folds\n",
        "plt.figure(figsize=(14, 6))\n",
        "x = np.arange(skf.get_n_splits())\n",
        "width = 0.8 / num_classes  # Width of the bars\n",
        "\n",
        "for i in range(num_classes):\n",
        "    # Only include folds where this class was present\n",
        "    valid_folds = [fold for fold, samples in enumerate(fold_class_samples[i]) if samples > 0]\n",
        "    if valid_folds:\n",
        "        accuracies = [class_accuracies[i][fold] for fold in valid_folds]\n",
        "        fold_indices = [x[fold] for fold in valid_folds]\n",
        "        plt.bar(fold_indices + i*width, accuracies, width, label=class_names[i])\n",
        "\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Class-wise Accuracy by Fold')\n",
        "plt.xticks(x + width * (num_classes-1)/2, [f'Fold {i+1}' for i in range(skf.get_n_splits())])\n",
        "plt.legend(title='Class')\n",
        "plt.ylim(0, 1.1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2H8boEIyYth"
      },
      "source": [
        "# Test on Parents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8zHTqVtyaql",
        "outputId": "766f2a1c-544c-4f8f-a479-ebad08e0b124"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "True Labels:      ['C', 'M']\n",
            "Predicted Labels: [np.str_('C'), np.str_('M')]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# === Step 1: Load the model ===\n",
        "model = load_model(\"lstm_model_fold_10.h5\")  # replace with actual model path\n",
        "\n",
        "# === Step 2: Load test CSV with exactly 50 rows (2 sequences of 25) ===\n",
        "test_csv_path = \"/content/test.csv\"  # replace with your test file path\n",
        "test_data = pd.read_csv(test_csv_path, header=None).values\n",
        "\n",
        "# Separate labels and features\n",
        "Y_test_raw = test_data[:, 0]     # First column: labels\n",
        "X_test_raw = test_data[:, 1:]    # From 3rd column onward: features\n",
        "\n",
        "# === Step 3: Reshape into 2 sequences ===\n",
        "X_test_seq = []\n",
        "Y_test_seq = []\n",
        "\n",
        "for i in range(2):\n",
        "    start_idx = i * 25\n",
        "    X_test_seq.append(X_test_raw[start_idx:start_idx + 25])\n",
        "    Y_test_seq.append(Y_test_raw[start_idx])  # use the first label of each sequence\n",
        "\n",
        "X_test_seq = np.array(X_test_seq).astype('float32')  # Shape: (2, 25, 84)\n",
        "\n",
        "# === Step 4: Encode true labels for comparison ===\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Use the same encoder from training\n",
        "label_encoder = LabelEncoder()\n",
        "# Assuming you still have `label_encoder.classes_` from training\n",
        "# Otherwise, re-initialize and fit with all possible training labels:\n",
        "label_encoder.classes_ = np.load(\"label_classes.npy\", allow_pickle=True)  # Load saved classes\n",
        "\n",
        "# Encode true labels\n",
        "Y_test_encoded = label_encoder.transform(Y_test_seq)\n",
        "Y_test_onehot = to_categorical(Y_test_encoded, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "# === Step 5: Predict ===\n",
        "predictions = model.predict(X_test_seq)\n",
        "predicted_indices = np.argmax(predictions, axis=1)\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_indices)\n",
        "\n",
        "# === Step 6: Print Results ===\n",
        "print(\"True Labels:     \", Y_test_seq)\n",
        "print(\"Predicted Labels:\", list(predicted_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GU_kHngAbpDx"
      },
      "source": [
        "# Leave One Person (8 Persons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Q0yivVbuSJ",
        "outputId": "e54864cb-e5fc-4e24-c39e-66fa6c01d791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (485, 25, 84)\n",
            "Y shape: (485,)\n",
            "P shape: (485,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.73493975, -0.03614458,  0.48364887, ..., -0.28055078,\n",
              "         -0.72805506, -0.28743544],\n",
              "        [ 0.73402417, -0.04490501,  0.48531953, ..., -0.28324696,\n",
              "         -0.7202073 , -0.29360968],\n",
              "        [ 0.7241379 , -0.04827586,  0.4827586 , ..., -0.2724138 ,\n",
              "         -0.7137931 , -0.28275862],\n",
              "        ...,\n",
              "        [ 0.694859  , -0.03482587,  0.45605308, ..., -0.26699835,\n",
              "         -0.73134327, -0.28026533],\n",
              "        [ 0.70715475, -0.03494176,  0.4608985 , ..., -0.27454242,\n",
              "         -0.7237937 , -0.28785357],\n",
              "        [ 0.6981758 , -0.03980099,  0.45273632, ..., -0.2620232 ,\n",
              "         -0.7280265 , -0.27860695]],\n",
              "\n",
              "       [[ 0.69175625, -0.0609319 ,  0.41218638, ..., -0.28315413,\n",
              "         -0.60573477, -0.25448027],\n",
              "        [ 0.6802842 , -0.05861456,  0.39964476, ..., -0.28596804,\n",
              "         -0.61634105, -0.26110125],\n",
              "        [ 0.68817204, -0.05734767,  0.41218638, ..., -0.28673837,\n",
              "         -0.6236559 , -0.26523298],\n",
              "        ...,\n",
              "        [ 0.69174314, -0.07339449,  0.42018348, ..., -0.2825688 ,\n",
              "         -0.5963303 , -0.25321102],\n",
              "        [ 0.6886447 , -0.06959707,  0.41758242, ..., -0.2820513 ,\n",
              "         -0.6007326 , -0.25274727],\n",
              "        [ 0.6886447 , -0.06410256,  0.41391942, ..., -0.2838828 ,\n",
              "         -0.60805863, -0.25091577]],\n",
              "\n",
              "       [[ 0.7653061 , -0.04081633,  0.5136054 , ..., -0.26530612,\n",
              "         -0.6904762 , -0.24489796],\n",
              "        [ 0.74453783, -0.04201681,  0.49579832, ..., -0.26386556,\n",
              "         -0.687395  , -0.24369748],\n",
              "        [ 0.7483221 , -0.0352349 ,  0.4966443 , ..., -0.26677853,\n",
              "         -0.7013423 , -0.23993288],\n",
              "        ...,\n",
              "        [ 0.75972927, -0.04060914,  0.5025381 , ..., -0.26395938,\n",
              "         -0.69204736, -0.23688664],\n",
              "        [ 0.7631134 , -0.04060914,  0.5025381 , ..., -0.26395938,\n",
              "         -0.69204736, -0.23688664],\n",
              "        [ 0.75634515, -0.04060914,  0.49915397, ..., -0.2605753 ,\n",
              "         -0.6988156 , -0.23011844]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.5696784 ,  0.3353752 ,  0.3154671 , ..., -0.6569678 ,\n",
              "         -0.30321592, -0.65390503],\n",
              "        [ 0.56548536,  0.33744222,  0.31587058, ..., -0.65793526,\n",
              "         -0.2973806 , -0.65485364],\n",
              "        [ 0.5683564 ,  0.33947772,  0.31950846, ..., -0.6528418 ,\n",
              "         -0.29800308, -0.6436252 ],\n",
              "        ...,\n",
              "        [ 0.5574273 ,  0.31699848,  0.30321592, ..., -0.6202144 ,\n",
              "         -0.30015314, -0.6202144 ],\n",
              "        [ 0.5569231 ,  0.31692308,  0.31384614, ..., -0.61846155,\n",
              "         -0.29538462, -0.61846155],\n",
              "        [ 0.54711246,  0.3069909 ,  0.3069909 , ..., -0.61702126,\n",
              "         -0.2887538 , -0.6139818 ]],\n",
              "\n",
              "       [[ 0.57903224,  0.23870967,  0.32419354, ..., -0.60645163,\n",
              "         -0.2564516 , -0.5548387 ],\n",
              "        [ 0.58132046,  0.2431562 ,  0.33333334, ..., -0.6038647 ,\n",
              "         -0.25925925, -0.55233496],\n",
              "        [ 0.57211536,  0.24358974,  0.33173078, ..., -0.6025641 ,\n",
              "         -0.25480768, -0.5480769 ],\n",
              "        ...,\n",
              "        [ 0.65587735,  0.31175467,  0.36626917, ..., -0.63202727,\n",
              "         -0.31175467, -0.6013629 ],\n",
              "        [ 0.6586621 ,  0.31389365,  0.36363637, ..., -0.6363636 ,\n",
              "         -0.31903946, -0.60548884],\n",
              "        [ 0.65807563,  0.3161512 ,  0.36254296, ..., -0.63573885,\n",
              "         -0.31099656, -0.604811  ]],\n",
              "\n",
              "       [[ 0.62112933,  0.3442623 ,  0.3697632 , ..., -0.6357013 ,\n",
              "         -0.4499089 , -0.6502732 ],\n",
              "        [ 0.6247723 ,  0.3406193 ,  0.38069215, ..., -0.63205826,\n",
              "         -0.4499089 , -0.6502732 ],\n",
              "        [ 0.63205826,  0.33697632,  0.38797814, ..., -0.6393443 ,\n",
              "         -0.4571949 , -0.65391624],\n",
              "        ...,\n",
              "        [ 0.66851854,  0.33703703,  0.43888888, ..., -0.6148148 ,\n",
              "         -0.48703703, -0.6333333 ],\n",
              "        [ 0.65750915,  0.32967034,  0.43040293, ..., -0.6007326 ,\n",
              "         -0.485348  , -0.61904764],\n",
              "        [ 0.6611418 ,  0.3296501 ,  0.44014734, ..., -0.6058932 ,\n",
              "         -0.4843462 , -0.62062615]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def load_and_prepare_data(csv_path):\n",
        "    # Load data from CSV\n",
        "    data = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "    # Convert to NumPy array for efficient processing\n",
        "    data = data.values\n",
        "\n",
        "    # Separate X (features) and Y (first column as labels)\n",
        "    Y = data[:, 0]  # First column as labels\n",
        "    P = data[:,1] # second column as Person number\n",
        "    X = data[:, 2:]  # All other columns as features (shape: num_samples, 84)\n",
        "\n",
        "    # Define sequence length\n",
        "    sequence_length = 25\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_seq, Y_seq , P_seq = [], [], []\n",
        "    num_sequences = len(X) // sequence_length\n",
        "\n",
        "    for i in range(num_sequences):\n",
        "        start_idx = i * sequence_length\n",
        "        X_seq.append(X[start_idx:start_idx + sequence_length])  # 25 rows of features\n",
        "        Y_seq.append(Y[start_idx])  # First column value corresponding to the sequence\n",
        "        P_seq.append(P[start_idx])\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_seq = np.array(X_seq)  # Shape: (num_sequences, 25, 84)\n",
        "    Y_seq = np.array(Y_seq)  # Shape: (num_sequences,)\n",
        "    P_seq = np.array(P_seq)\n",
        "\n",
        "    return X_seq, Y_seq, P_seq\n",
        "\n",
        "# Example usage\n",
        "csv_path = \"/content/Double and Single-Handed Keypoints 14th April-LSTM.csv\"  # Replace with actual path\n",
        "X_seq, Y_seq, P_seq = load_and_prepare_data(csv_path)\n",
        "print(\"X shape:\", X_seq.shape)  # Expected: (num_sequences, 25, 84)\n",
        "print(\"Y shape:\", Y_seq.shape)  # Expected: (num_sequences,)\n",
        "print(\"P shape:\", P_seq.shape)  # Expected: (num_sequences,\n",
        "\n",
        "# Encode Y_seq (convert string labels to integers)\n",
        "label_encoder = LabelEncoder()\n",
        "Y_seq = label_encoder.fit_transform(Y_seq)\n",
        "\n",
        "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
        "Y_seq = to_categorical(Y_seq, num_classes)\n",
        "\n",
        "X_seq.astype('float32')\n",
        "# Y_seq.dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlx4C5Vjbxs5",
        "outputId": "0e7160db-220d-4339-c530-39675721f0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==> Leave Person 1 Out\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.0978 - loss: 3.5132\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2073 - loss: 3.0977\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3643 - loss: 2.6329\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4909 - loss: 2.2019\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5871 - loss: 1.8090\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6696 - loss: 1.5092\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7051 - loss: 1.3630\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7336 - loss: 1.3232\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7965 - loss: 1.0998\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7917 - loss: 1.0590\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7362 - loss: 1.0888\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7864 - loss: 0.9990\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8224 - loss: 0.9111\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8210 - loss: 0.8949\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8486 - loss: 0.7968\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8175 - loss: 0.8318\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8336 - loss: 0.8551\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8624 - loss: 0.7244\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8472 - loss: 0.7796\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8719 - loss: 0.6704\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8619 - loss: 0.6945\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8853 - loss: 0.6259\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8864 - loss: 0.6067\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8991 - loss: 0.5943\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8936 - loss: 0.5747\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9039 - loss: 0.5909\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8847 - loss: 0.5506\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9153 - loss: 0.5475\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9234 - loss: 0.4926\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9248 - loss: 0.5067\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9189 - loss: 0.5053\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9338 - loss: 0.5176\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9199 - loss: 0.5299\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9047 - loss: 0.5645\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8537 - loss: 0.6208\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8906 - loss: 0.5172\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9343 - loss: 0.4895\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8838 - loss: 0.5074\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9284 - loss: 0.4453\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9150 - loss: 0.4487\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9097 - loss: 0.4736\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9315 - loss: 0.4715\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9089 - loss: 0.5053\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9316 - loss: 0.4442\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9367 - loss: 0.4078\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9447 - loss: 0.3941\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9429 - loss: 0.3900\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9578 - loss: 0.3761\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9046 - loss: 0.4845\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9319 - loss: 0.4031\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9402 - loss: 0.4227\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8968 - loss: 0.4749\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9137 - loss: 0.4498\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8310 - loss: 1.0124\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8783 - loss: 0.5803\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8906 - loss: 0.5025\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8877 - loss: 0.4787\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9077 - loss: 0.4568\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9207 - loss: 0.3969\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9125 - loss: 0.3991\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9053 - loss: 0.4046\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9185 - loss: 0.3797\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.3782\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9399 - loss: 0.3500\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9227 - loss: 0.3813\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9535 - loss: 0.3295\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9512 - loss: 0.3401\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9313 - loss: 0.3393\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.3330\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9424 - loss: 0.3416\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.3322\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9528 - loss: 0.3306\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9544 - loss: 0.3180\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9412 - loss: 0.3432\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9591 - loss: 0.3076\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.3241\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9313 - loss: 0.3308\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9066 - loss: 0.3439\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8959 - loss: 0.3732\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9189 - loss: 0.3449\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8901 - loss: 0.3654\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9237 - loss: 0.3498\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.4480\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9035 - loss: 0.4656\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9231 - loss: 0.3836\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9196 - loss: 0.4312\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9312 - loss: 0.4425\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9477 - loss: 0.3881\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9394 - loss: 0.3329\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9574 - loss: 0.3060\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9499 - loss: 0.3138\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9552 - loss: 0.3128\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9460 - loss: 0.3055\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9616 - loss: 0.3017\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9407 - loss: 0.3085\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9578 - loss: 0.2895\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9552 - loss: 0.2881\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9376 - loss: 0.3464\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8931 - loss: 0.5619\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9516 - loss: 0.3102\n",
            "X_train shape: (737, 25, 84)\n",
            "y_train shape: (737, 26)\n",
            "X_test shape: (145, 25, 84)\n",
            "y_test shape: (145, 26)\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n",
            "Accuracy for Person 1: 0.8345 on 145 samples.\n",
            "\n",
            "==> Leave Person 2 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0904 - loss: 3.5165\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3128 - loss: 3.0034\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3898 - loss: 2.5131\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5875 - loss: 2.0252\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6147 - loss: 1.7059\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7541 - loss: 1.3861\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7480 - loss: 1.2917\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8253 - loss: 1.0830\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8477 - loss: 0.9963\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8580 - loss: 0.9311\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8863 - loss: 0.8694\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8854 - loss: 0.8104\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9041 - loss: 0.7317\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9076 - loss: 0.7439\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8814 - loss: 0.7204\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9149 - loss: 0.7061\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8467 - loss: 0.8132\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8803 - loss: 0.7828\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9232 - loss: 0.6119\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9550 - loss: 0.5491\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9494 - loss: 0.5658\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9685 - loss: 0.5081\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9569 - loss: 0.4940\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9075 - loss: 0.5947\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9367 - loss: 0.5129\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9552 - loss: 0.4659\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9763 - loss: 0.4357\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9056 - loss: 0.5845\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9031 - loss: 0.5859\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9274 - loss: 0.4957\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9432 - loss: 0.4559\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9139 - loss: 0.6334\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9622 - loss: 0.4643\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9673 - loss: 0.4085\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9131 - loss: 0.5509\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8983 - loss: 0.5478\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9489 - loss: 0.4521\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9583 - loss: 0.4186\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9697 - loss: 0.4111\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9740 - loss: 0.3959\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9723 - loss: 0.3747\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9487 - loss: 0.4256\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9774 - loss: 0.3678\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9758 - loss: 0.3535\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9631 - loss: 0.4050\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9497 - loss: 0.4552\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9308 - loss: 0.4310\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9370 - loss: 0.4133\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9401 - loss: 0.4027\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9659 - loss: 0.3643\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9785 - loss: 0.3471\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.3070\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9818 - loss: 0.3079\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.2962\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.2800\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.2837\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.2666\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.2817\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.2886\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.2587\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.2728\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.2455\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.2753\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.2422\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.2359\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.2558\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9884 - loss: 0.2453\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9952 - loss: 0.2405\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9913 - loss: 0.2363\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.2401\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9923 - loss: 0.2428\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.2208\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.2436\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9790 - loss: 0.2572\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9862 - loss: 0.2422\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.3429\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9694 - loss: 0.3195\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9655 - loss: 0.3173\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9513 - loss: 0.3802\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8993 - loss: 0.5020\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8832 - loss: 0.6112\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8746 - loss: 0.5615\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9601 - loss: 0.3649\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.3364\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9669 - loss: 0.3252\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9701 - loss: 0.3081\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9742 - loss: 0.3029\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.2647\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9588 - loss: 0.3645\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9595 - loss: 0.3454\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9652 - loss: 0.3067\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9736 - loss: 0.3027\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.2586\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.2343\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.2240\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.2517\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.2756\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.2424\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.2418\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.2136\n",
            "X_train shape: (752, 25, 84)\n",
            "y_train shape: (752, 26)\n",
            "X_test shape: (130, 25, 84)\n",
            "y_test shape: (130, 26)\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Accuracy for Person 2: 0.9154 on 130 samples.\n",
            "\n",
            "==> Leave Person 3 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.1059 - loss: 3.5214\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2356 - loss: 3.0915\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4168 - loss: 2.6131\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5776 - loss: 2.1420\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6695 - loss: 1.7577\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7796 - loss: 1.3649\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8076 - loss: 1.2054\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8172 - loss: 1.1243\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7978 - loss: 1.0612\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8525 - loss: 0.9540\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8797 - loss: 0.8325\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8767 - loss: 0.8233\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9028 - loss: 0.7301\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8830 - loss: 0.7573\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9205 - loss: 0.6541\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9411 - loss: 0.6240\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9350 - loss: 0.6086\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9073 - loss: 0.6382\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9022 - loss: 0.7233\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9252 - loss: 0.5826\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9334 - loss: 0.5745\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9539 - loss: 0.5008\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9504 - loss: 0.5102\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9696 - loss: 0.4584\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9630 - loss: 0.4690\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9624 - loss: 0.4525\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9309 - loss: 0.5393\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8873 - loss: 0.6714\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9178 - loss: 0.5501\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9318 - loss: 0.5228\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9530 - loss: 0.4658\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9763 - loss: 0.4346\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.3895\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9548 - loss: 0.4395\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9457 - loss: 0.4267\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9642 - loss: 0.4166\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9649 - loss: 0.4019\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9466 - loss: 0.4496\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9666 - loss: 0.3864\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9669 - loss: 0.3844\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9745 - loss: 0.3924\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.3617\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9572 - loss: 0.4668\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9324 - loss: 0.4342\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9466 - loss: 0.4156\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9603 - loss: 0.3699\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9191 - loss: 0.5391\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9522 - loss: 0.4626\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9802 - loss: 0.3568\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.3240\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9826 - loss: 0.3233\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9357 - loss: 0.4530\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9713 - loss: 0.3416\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.3123\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.2982\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9877 - loss: 0.2804\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9796 - loss: 0.3230\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9323 - loss: 0.4533\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9594 - loss: 0.3996\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9605 - loss: 0.4006\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9402 - loss: 0.3904\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.3210\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9785 - loss: 0.3053\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9832 - loss: 0.3058\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.2893\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.3309\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9925 - loss: 0.2629\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.2767\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.2556\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.2385\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.2425\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9813 - loss: 0.2683\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9798 - loss: 0.2617\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.2419\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.2566\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.2267\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.2288\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.2141\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.2251\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.2217\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.2152\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.2095\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.2146\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.2066\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.2057\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9947 - loss: 0.2126\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 0.2101\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.2324\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9885 - loss: 0.2332\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9537 - loss: 0.3516\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9617 - loss: 0.3221\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9611 - loss: 0.3038\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9831 - loss: 0.2438\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.2539\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.2332\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.2724\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.2426\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9829 - loss: 0.2330\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.2122\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.2094\n",
            "X_train shape: (752, 25, 84)\n",
            "y_train shape: (752, 26)\n",
            "X_test shape: (130, 25, 84)\n",
            "y_test shape: (130, 26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e114ffd2fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 181ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e114ffd2fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Person 3: 0.9846 on 130 samples.\n",
            "\n",
            "==> Leave Person 4 Out\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.0941 - loss: 3.5514\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3001 - loss: 3.2160\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3453 - loss: 2.7961\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4621 - loss: 2.3660\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6151 - loss: 1.8468\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6737 - loss: 1.5905\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7248 - loss: 1.3871\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7486 - loss: 1.3302\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8145 - loss: 1.1162\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8260 - loss: 1.0042\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8842 - loss: 0.8792\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8702 - loss: 0.8524\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8533 - loss: 0.8400\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8875 - loss: 0.7442\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8416 - loss: 0.7919\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8972 - loss: 0.6742\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9117 - loss: 0.6253\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9239 - loss: 0.6002\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9253 - loss: 0.5713\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8989 - loss: 0.5996\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.5434\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9427 - loss: 0.4966\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9120 - loss: 0.5406\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9598 - loss: 0.4445\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9068 - loss: 0.5049\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9191 - loss: 0.5278\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9180 - loss: 0.5099\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9078 - loss: 0.4953\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9012 - loss: 0.4911\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9162 - loss: 0.4693\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9171 - loss: 0.4574\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9276 - loss: 0.4310\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9514 - loss: 0.4021\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9587 - loss: 0.3910\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9543 - loss: 0.3834\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9608 - loss: 0.3735\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9410 - loss: 0.3835\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.3476\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9678 - loss: 0.3554\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9530 - loss: 0.3761\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9513 - loss: 0.3866\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9187 - loss: 0.5430\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9176 - loss: 0.5069\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8803 - loss: 0.5758\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8800 - loss: 0.6152\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8690 - loss: 0.6056\n",
            "Epoch 47/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8801 - loss: 0.5810\n",
            "Epoch 48/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9303 - loss: 0.4416\n",
            "Epoch 49/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8679 - loss: 0.5772\n",
            "Epoch 50/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9057 - loss: 0.4533\n",
            "Epoch 51/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9359 - loss: 0.4037\n",
            "Epoch 52/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9372 - loss: 0.3987\n",
            "Epoch 53/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9590 - loss: 0.3569\n",
            "Epoch 54/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9723 - loss: 0.3247\n",
            "Epoch 55/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9506 - loss: 0.3544\n",
            "Epoch 56/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9557 - loss: 0.3444\n",
            "Epoch 57/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9330 - loss: 0.3639\n",
            "Epoch 58/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9593 - loss: 0.3200\n",
            "Epoch 59/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9627 - loss: 0.3199\n",
            "Epoch 60/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9628 - loss: 0.3079\n",
            "Epoch 61/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9661 - loss: 0.3127\n",
            "Epoch 62/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9502 - loss: 0.3636\n",
            "Epoch 63/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9754 - loss: 0.3032\n",
            "Epoch 64/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9600 - loss: 0.3055\n",
            "Epoch 65/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.2707\n",
            "Epoch 66/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9776 - loss: 0.2828\n",
            "Epoch 67/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9743 - loss: 0.2848\n",
            "Epoch 68/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9728 - loss: 0.2774\n",
            "Epoch 69/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9638 - loss: 0.2921\n",
            "Epoch 70/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9431 - loss: 0.2887\n",
            "Epoch 71/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9654 - loss: 0.2668\n",
            "Epoch 72/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9688 - loss: 0.2682\n",
            "Epoch 73/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9504 - loss: 0.2763\n",
            "Epoch 74/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9693 - loss: 0.2906\n",
            "Epoch 75/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.2544\n",
            "Epoch 76/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9812 - loss: 0.2466\n",
            "Epoch 77/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9686 - loss: 0.2612\n",
            "Epoch 78/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9646 - loss: 0.2658\n",
            "Epoch 79/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9745 - loss: 0.2508\n",
            "Epoch 80/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.2250\n",
            "Epoch 81/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9887 - loss: 0.2279\n",
            "Epoch 82/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.2351\n",
            "Epoch 83/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9699 - loss: 0.2449\n",
            "Epoch 84/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.2164\n",
            "Epoch 85/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.2164\n",
            "Epoch 86/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9778 - loss: 0.2332\n",
            "Epoch 87/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9835 - loss: 0.2301\n",
            "Epoch 88/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.2127\n",
            "Epoch 89/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.2058\n",
            "Epoch 90/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.2047\n",
            "Epoch 91/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.1950\n",
            "Epoch 92/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.1895\n",
            "Epoch 93/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9876 - loss: 0.2034\n",
            "Epoch 94/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.1912\n",
            "Epoch 95/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.1891\n",
            "Epoch 96/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.1948\n",
            "Epoch 97/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.2132\n",
            "Epoch 98/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9826 - loss: 0.2439\n",
            "Epoch 99/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9802 - loss: 0.2714\n",
            "Epoch 100/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9214 - loss: 0.4289\n",
            "X_train shape: (752, 25, 84)\n",
            "y_train shape: (752, 26)\n",
            "X_test shape: (130, 25, 84)\n",
            "y_test shape: (130, 26)\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Accuracy for Person 4: 0.9538 on 130 samples.\n",
            "\n",
            "==> Leave Person 5 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0645 - loss: 3.5180\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1612 - loss: 3.1452\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3403 - loss: 2.6862\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5071 - loss: 2.2049\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5849 - loss: 1.8635\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6494 - loss: 1.6055\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6752 - loss: 1.4783\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7355 - loss: 1.2810\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7400 - loss: 1.2014\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7690 - loss: 1.1025\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8259 - loss: 0.9491\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8303 - loss: 0.8877\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8603 - loss: 0.8072\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8727 - loss: 0.7921\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8664 - loss: 0.8111\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8260 - loss: 0.8388\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8336 - loss: 0.8540\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8687 - loss: 0.7194\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8907 - loss: 0.6648\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8726 - loss: 0.6964\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8840 - loss: 0.6204\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9173 - loss: 0.5824\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9115 - loss: 0.5991\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9099 - loss: 0.5649\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9266 - loss: 0.5162\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9275 - loss: 0.5373\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9162 - loss: 0.5268\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9272 - loss: 0.5462\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8705 - loss: 0.6866\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8956 - loss: 0.5831\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9264 - loss: 0.5121\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9224 - loss: 0.4868\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9249 - loss: 0.4923\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9435 - loss: 0.4393\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.4398\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9320 - loss: 0.4764\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8087 - loss: 0.9472\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8753 - loss: 0.6274\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8984 - loss: 0.5655\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9361 - loss: 0.4987\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9566 - loss: 0.4303\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9729 - loss: 0.3957\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9708 - loss: 0.3648\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9496 - loss: 0.4168\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9530 - loss: 0.4025\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9643 - loss: 0.3743\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.3392\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.3815\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9754 - loss: 0.3540\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9747 - loss: 0.3661\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9436 - loss: 0.4168\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9237 - loss: 0.5017\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9529 - loss: 0.4319\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9624 - loss: 0.3576\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9628 - loss: 0.3816\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9780 - loss: 0.3451\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9742 - loss: 0.3196\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.3232\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.2824\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9574 - loss: 0.3769\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9118 - loss: 0.5382\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9362 - loss: 0.4526\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.3686\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9798 - loss: 0.3377\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9598 - loss: 0.3715\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9716 - loss: 0.3351\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9721 - loss: 0.3196\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9755 - loss: 0.2938\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.2900\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.2854\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.2771\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.2569\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.2648\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.2608\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.2322\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.2480\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.2336\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.2445\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9941 - loss: 0.2320\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.2319\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.2318\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.2219\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9734 - loss: 0.3072\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9586 - loss: 0.3185\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9894 - loss: 0.2373\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.2388\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.2413\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9825 - loss: 0.2656\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9692 - loss: 0.2987\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9787 - loss: 0.2564\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9767 - loss: 0.2735\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.2307\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.2012\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.2165\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.2043\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.1977\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.1905\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.1971\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.1982\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9966 - loss: 0.1920\n",
            "X_train shape: (777, 25, 84)\n",
            "y_train shape: (777, 26)\n",
            "X_test shape: (105, 25, 84)\n",
            "y_test shape: (105, 26)\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Accuracy for Person 5: 0.9429 on 105 samples.\n",
            "\n",
            "==> Leave Person 7 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0640 - loss: 3.5681\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2716 - loss: 3.2021\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3824 - loss: 2.7438\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5139 - loss: 2.1853\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6106 - loss: 1.8535\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6231 - loss: 1.6244\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6974 - loss: 1.3934\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7408 - loss: 1.2581\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8005 - loss: 1.1134\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8695 - loss: 0.9316\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8347 - loss: 0.8904\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8612 - loss: 0.8301\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8324 - loss: 0.8507\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8834 - loss: 0.7663\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8879 - loss: 0.7437\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8931 - loss: 0.6527\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8805 - loss: 0.7504\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8727 - loss: 0.7068\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9285 - loss: 0.5989\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9510 - loss: 0.5022\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9327 - loss: 0.5435\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9559 - loss: 0.4908\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8959 - loss: 0.6080\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9175 - loss: 0.5329\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9096 - loss: 0.5966\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9378 - loss: 0.5237\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9533 - loss: 0.4797\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9192 - loss: 0.5680\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9179 - loss: 0.5386\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9120 - loss: 0.5345\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9495 - loss: 0.4378\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.4137\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9452 - loss: 0.4307\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9311 - loss: 0.4788\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.4393\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9703 - loss: 0.4035\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.3492\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.3687\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9832 - loss: 0.3584\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9736 - loss: 0.3793\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.3330\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9793 - loss: 0.3466\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9713 - loss: 0.3772\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9563 - loss: 0.3736\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9741 - loss: 0.3378\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9651 - loss: 0.3460\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9305 - loss: 0.4332\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9449 - loss: 0.3745\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9685 - loss: 0.3330\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.3019\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.2995\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9777 - loss: 0.3318\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9839 - loss: 0.3239\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9725 - loss: 0.3180\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9565 - loss: 0.4052\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9443 - loss: 0.3765\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9405 - loss: 0.3607\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9519 - loss: 0.3838\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9489 - loss: 0.3702\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.2971\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9672 - loss: 0.3103\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.3030\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.2989\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9775 - loss: 0.2944\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.2785\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.2797\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.2550\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.2734\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.2369\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.2496\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.2387\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.2390\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.2309\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.2279\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.2216\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.2260\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.2125\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.2355\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9977 - loss: 0.2105\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9967 - loss: 0.2026\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9977 - loss: 0.2163\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9949 - loss: 0.2045\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9785 - loss: 0.2770\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8565 - loss: 0.8114\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9382 - loss: 0.3962\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9748 - loss: 0.2973\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9780 - loss: 0.2941\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9693 - loss: 0.2912\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9661 - loss: 0.3390\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.2176\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9901 - loss: 0.2281\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9908 - loss: 0.2209\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9903 - loss: 0.2158\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.2168\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.2058\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.2069\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.1963\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.1977\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.1992\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.1944\n",
            "X_train shape: (797, 25, 84)\n",
            "y_train shape: (797, 26)\n",
            "X_test shape: (85, 25, 84)\n",
            "y_test shape: (85, 26)\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
            "Accuracy for Person 7: 1.0000 on 85 samples.\n",
            "\n",
            "==> Leave Person 8 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0853 - loss: 3.5104\n",
            "Epoch 2/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2215 - loss: 3.0929\n",
            "Epoch 3/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4293 - loss: 2.5685\n",
            "Epoch 4/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5680 - loss: 1.9888\n",
            "Epoch 5/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6554 - loss: 1.6113\n",
            "Epoch 6/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7427 - loss: 1.3973\n",
            "Epoch 7/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7939 - loss: 1.2266\n",
            "Epoch 8/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7962 - loss: 1.1476\n",
            "Epoch 9/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8147 - loss: 1.0016\n",
            "Epoch 10/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8596 - loss: 0.8963\n",
            "Epoch 11/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8871 - loss: 0.8191\n",
            "Epoch 12/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8325 - loss: 0.9148\n",
            "Epoch 13/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8446 - loss: 0.8342\n",
            "Epoch 14/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8730 - loss: 0.7452\n",
            "Epoch 15/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9064 - loss: 0.6710\n",
            "Epoch 16/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9129 - loss: 0.6226\n",
            "Epoch 17/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8789 - loss: 0.6607\n",
            "Epoch 18/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8698 - loss: 0.7498\n",
            "Epoch 19/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9022 - loss: 0.5960\n",
            "Epoch 20/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9121 - loss: 0.5818\n",
            "Epoch 21/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9053 - loss: 0.5896\n",
            "Epoch 22/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9267 - loss: 0.5514\n",
            "Epoch 23/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9416 - loss: 0.4873\n",
            "Epoch 24/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9578 - loss: 0.4747\n",
            "Epoch 25/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9215 - loss: 0.4949\n",
            "Epoch 26/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9218 - loss: 0.4846\n",
            "Epoch 27/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9302 - loss: 0.4754\n",
            "Epoch 28/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.4182\n",
            "Epoch 29/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9663 - loss: 0.4154\n",
            "Epoch 30/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9743 - loss: 0.4076\n",
            "Epoch 31/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9692 - loss: 0.3979\n",
            "Epoch 32/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9780 - loss: 0.3750\n",
            "Epoch 33/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9696 - loss: 0.3962\n",
            "Epoch 34/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9618 - loss: 0.3887\n",
            "Epoch 35/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.3675\n",
            "Epoch 36/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9803 - loss: 0.3480\n",
            "Epoch 37/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9750 - loss: 0.3466\n",
            "Epoch 38/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9116 - loss: 0.5323\n",
            "Epoch 39/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9489 - loss: 0.4173\n",
            "Epoch 40/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9624 - loss: 0.4108\n",
            "Epoch 41/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9403 - loss: 0.4451\n",
            "Epoch 42/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9617 - loss: 0.3829\n",
            "Epoch 43/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9796 - loss: 0.3428\n",
            "Epoch 44/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9734 - loss: 0.3468\n",
            "Epoch 45/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9638 - loss: 0.3600\n",
            "Epoch 46/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9617 - loss: 0.3683\n",
            "Epoch 47/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.3269\n",
            "Epoch 48/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9755 - loss: 0.3158\n",
            "Epoch 49/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9465 - loss: 0.4391\n",
            "Epoch 50/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9223 - loss: 0.4860\n",
            "Epoch 51/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9376 - loss: 0.4602\n",
            "Epoch 52/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9236 - loss: 0.4957\n",
            "Epoch 53/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9504 - loss: 0.4103\n",
            "Epoch 54/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9475 - loss: 0.4288\n",
            "Epoch 55/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9775 - loss: 0.3513\n",
            "Epoch 56/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9733 - loss: 0.3217\n",
            "Epoch 57/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9790 - loss: 0.3288\n",
            "Epoch 58/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.3013\n",
            "Epoch 59/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.2714\n",
            "Epoch 60/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.2655\n",
            "Epoch 61/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.2642\n",
            "Epoch 62/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.2902\n",
            "Epoch 63/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9566 - loss: 0.4056\n",
            "Epoch 64/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9657 - loss: 0.3108\n",
            "Epoch 65/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.2747\n",
            "Epoch 66/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9824 - loss: 0.2811\n",
            "Epoch 67/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.2704\n",
            "Epoch 68/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.2495\n",
            "Epoch 69/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.2476\n",
            "Epoch 70/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.2907\n",
            "Epoch 71/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.3069\n",
            "Epoch 72/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.2567\n",
            "Epoch 73/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8881 - loss: 0.6260\n",
            "Epoch 74/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9411 - loss: 0.4317\n",
            "Epoch 75/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9638 - loss: 0.3289\n",
            "Epoch 76/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 0.2721\n",
            "Epoch 77/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9793 - loss: 0.2753\n",
            "Epoch 78/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.2641\n",
            "Epoch 79/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.2495\n",
            "Epoch 80/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.3104\n",
            "Epoch 81/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9657 - loss: 0.3013\n",
            "Epoch 82/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.2578\n",
            "Epoch 83/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.2279\n",
            "Epoch 84/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.2181\n",
            "Epoch 85/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.2186\n",
            "Epoch 86/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.2103\n",
            "Epoch 87/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.2164\n",
            "Epoch 88/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.2095\n",
            "Epoch 89/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.2062\n",
            "Epoch 90/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.2065\n",
            "Epoch 91/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9937 - loss: 0.1982\n",
            "Epoch 92/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9962 - loss: 0.1974\n",
            "Epoch 93/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9996 - loss: 0.1915\n",
            "Epoch 94/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.1916\n",
            "Epoch 95/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.1835\n",
            "Epoch 96/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.1827\n",
            "Epoch 97/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.2008\n",
            "Epoch 98/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.1891\n",
            "Epoch 99/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.1901\n",
            "Epoch 100/100\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.1915\n",
            "X_train shape: (857, 25, 84)\n",
            "y_train shape: (857, 26)\n",
            "X_test shape: (25, 25, 84)\n",
            "y_test shape: (25, 26)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
            "Accuracy for Person 8: 1.0000 on 25 samples.\n",
            "\n",
            "Weighted Mean Accuracy (Leave One Person Out): 0.9367\n"
          ]
        }
      ],
      "source": [
        "# Define LSTM model with regularization\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.regularizers import l2\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(25, 84), kernel_regularizer=l2(0.001)),\n",
        "        Dropout(0.4),  # Dropout added to prevent overfitting\n",
        "        LSTM(32, return_sequences=False, kernel_regularizer=l2(0.002)),\n",
        "        Dropout(0.4),\n",
        "        Dense(32, activation='relu', kernel_regularizer=l2(0.002)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "unique_persons = [1, 2, 3, 4, 5, 7, 8]  # Assuming person IDs go from 1 to 4\n",
        "accuracy_scores = []\n",
        "sample_counts = []\n",
        "\n",
        "for person_id in unique_persons:\n",
        "    print(f\"\\n==> Leave Person {person_id} Out\")\n",
        "\n",
        "    # Create train-test split based on person ID\n",
        "    test_mask = (P_seq == person_id)  # Second column = person ID\n",
        "    train_mask = ~test_mask\n",
        "\n",
        "    # Extract samples\n",
        "    X_train, X_test = X_seq[train_mask], X_seq[test_mask]\n",
        "    y_train, y_test = Y_seq[train_mask], Y_seq[test_mask]\n",
        "\n",
        "    # If the person has no samples, skip\n",
        "    if len(X_test) == 0:\n",
        "        print(f\"No samples for Person {person_id}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Remove person ID column (keep only features)\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    # Create and train a new model for each iteration\n",
        "    model = create_model()\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)  # Set verbose=1 to see progress\n",
        "\n",
        "    #print shape of x_train, y_train and x_test, y_test\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"X_test shape:\", X_test.shape)\n",
        "    print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Filter classes that exist in this person's test set\n",
        "    unique_classes = np.unique(y_true_classes)\n",
        "\n",
        "    # Compute accuracy only for present classes\n",
        "    mask = np.isin(y_true_classes, unique_classes)\n",
        "    filtered_y_true = y_true_classes[mask]\n",
        "    filtered_y_pred = y_pred_classes[mask]\n",
        "\n",
        "    acc = accuracy_score(filtered_y_true, filtered_y_pred)\n",
        "    accuracy_scores.append(acc)\n",
        "    # sample_counts.append(len(filtered_y_true))\n",
        "    num_unique_classes = len(np.unique(filtered_y_true))\n",
        "    sample_counts.append(num_unique_classes)  # new\n",
        "\n",
        "\n",
        "    print(f\"Accuracy for Person {person_id}: {acc:.4f} on {len(filtered_y_true)} samples.\")\n",
        "\n",
        "# Weighted mean accuracy\n",
        "weighted_accuracy = np.average(accuracy_scores, weights=sample_counts)\n",
        "print(f\"\\nWeighted Mean Accuracy (Leave One Person Out): {weighted_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import numpy as np\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(25, 84), kernel_regularizer=l2(0.001)),\n",
        "        Dropout(0.4),  # Dropout added to prevent overfitting\n",
        "        LSTM(32, return_sequences=False, kernel_regularizer=l2(0.002)),\n",
        "        Dropout(0.4),\n",
        "        Dense(32, activation='relu', kernel_regularizer=l2(0.002)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "unique_persons = [1, 2, 3, 4, 5, 7, 8]  # Assuming person IDs go from 1 to 8\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "sample_counts = []\n",
        "\n",
        "for person_id in unique_persons:\n",
        "    print(f\"\\n==> Leave Person {person_id} Out\")\n",
        "\n",
        "    # Create train-test split based on person ID\n",
        "    test_mask = (P_seq == person_id)  # Second column = person ID\n",
        "    train_mask = ~test_mask\n",
        "\n",
        "    # Extract samples\n",
        "    X_train, X_test = X_seq[train_mask], X_seq[test_mask]\n",
        "    y_train, y_test = Y_seq[train_mask], Y_seq[test_mask]\n",
        "\n",
        "    # If the person has no samples, skip\n",
        "    if len(X_test) == 0:\n",
        "        print(f\"No samples for Person {person_id}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Convert to float32\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    # Create and train a new model for each iteration\n",
        "    model = create_model()\n",
        "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "    # Print shapes for debugging\n",
        "    print(\"X_train shape:\", X_train.shape)\n",
        "    print(\"y_train shape:\", y_train.shape)\n",
        "    print(\"X_test shape:\", X_test.shape)\n",
        "    print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # Filter classes that exist in this person's test set\n",
        "    unique_classes = np.unique(y_true_classes)\n",
        "\n",
        "    # Compute metrics only for present classes\n",
        "    mask = np.isin(y_true_classes, unique_classes)\n",
        "    filtered_y_true = y_true_classes[mask]\n",
        "    filtered_y_pred = y_pred_classes[mask]\n",
        "\n",
        "    # Calculate all metrics\n",
        "    acc = accuracy_score(filtered_y_true, filtered_y_pred)\n",
        "\n",
        "    # For precision, recall, and f1, handle potential warnings with average parameter\n",
        "    # Using 'weighted' average to account for class imbalance\n",
        "    prec = precision_score(filtered_y_true, filtered_y_pred, average='weighted', zero_division=0)\n",
        "    rec = recall_score(filtered_y_true, filtered_y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(filtered_y_true, filtered_y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # Store metrics\n",
        "    accuracy_scores.append(acc)\n",
        "    precision_scores.append(prec)\n",
        "    recall_scores.append(rec)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    num_samples = len(filtered_y_true)\n",
        "    sample_counts.append(num_samples)\n",
        "\n",
        "    num_unique_classes = len(np.unique(filtered_y_true))\n",
        "\n",
        "    # Print individual results\n",
        "    print(f\"Results for Person {person_id} (with {num_samples} samples, {num_unique_classes} classes):\")\n",
        "    print(f\"  Accuracy:  {acc:.4f}\")\n",
        "    print(f\"  Precision: {prec:.4f}\")\n",
        "    print(f\"  Recall:    {rec:.4f}\")\n",
        "    print(f\"  F1 Score:  {f1:.4f}\")\n",
        "\n",
        "    # Optional: Print detailed classification report\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(filtered_y_true, filtered_y_pred,\n",
        "                               labels=unique_classes,\n",
        "                               zero_division=0))\n",
        "\n",
        "# Calculate weighted metrics\n",
        "weighted_accuracy = np.average(accuracy_scores, weights=sample_counts)\n",
        "weighted_precision = np.average(precision_scores, weights=sample_counts)\n",
        "weighted_recall = np.average(recall_scores, weights=sample_counts)\n",
        "weighted_f1 = np.average(f1_scores, weights=sample_counts)\n",
        "\n",
        "# Print overall weighted results\n",
        "print(\"\\n===== OVERALL RESULTS (LEAVE-ONE-PERSON-OUT) =====\")\n",
        "print(f\"Weighted Accuracy:  {weighted_accuracy:.4f}\")\n",
        "print(f\"Weighted Precision: {weighted_precision:.4f}\")\n",
        "print(f\"Weighted Recall:    {weighted_recall:.4f}\")\n",
        "print(f\"Weighted F1 Score:  {weighted_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzfmbeMBRhbG",
        "outputId": "7410e9ac-ee48-47ab-8e50-d940f560b6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==> Leave Person 1 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1377 - loss: 3.1069\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2871 - loss: 2.8799\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4479 - loss: 2.5841\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6136 - loss: 2.1804\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7308 - loss: 1.7949\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7868 - loss: 1.4765\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8633 - loss: 1.1752\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8529 - loss: 1.0758\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9161 - loss: 0.8914\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9282 - loss: 0.7804\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9074 - loss: 0.7995\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8815 - loss: 0.7519\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8955 - loss: 0.6987\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9224 - loss: 0.6243\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9087 - loss: 0.7159\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9206 - loss: 0.6094\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9531 - loss: 0.5569\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9671 - loss: 0.5339\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9028 - loss: 0.5550\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9459 - loss: 0.5118\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9345 - loss: 0.5585\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9528 - loss: 0.4721\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9378 - loss: 0.4887\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9217 - loss: 0.5283\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8888 - loss: 0.5075\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9476 - loss: 0.4368\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9466 - loss: 0.4187\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9128 - loss: 0.4804\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9106 - loss: 0.4562\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9306 - loss: 0.4321\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9290 - loss: 0.4199\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9376 - loss: 0.4328\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9216 - loss: 0.4549\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9312 - loss: 0.4027\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9435 - loss: 0.3764\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9531 - loss: 0.3724\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9385 - loss: 0.3816\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9681 - loss: 0.3452\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9562 - loss: 0.3622\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9744 - loss: 0.3215\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.3102\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9908 - loss: 0.3092\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.3051\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9912 - loss: 0.2989\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9389 - loss: 0.3903\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9646 - loss: 0.3530\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.2950\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9757 - loss: 0.3048\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.3235\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9597 - loss: 0.3638\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9794 - loss: 0.2891\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.2619\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.2660\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.2600\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9871 - loss: 0.2600\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.2564\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9803 - loss: 0.3053\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.2913\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9593 - loss: 0.2959\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9369 - loss: 0.3997\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9086 - loss: 0.4381\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9145 - loss: 0.3585\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9166 - loss: 0.3287\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9161 - loss: 0.3252\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9190 - loss: 0.3938\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8928 - loss: 0.4232\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9252 - loss: 0.3662\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9444 - loss: 0.3378\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9595 - loss: 0.3015\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9476 - loss: 0.3100\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9398 - loss: 0.3114\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9505 - loss: 0.2915\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9484 - loss: 0.2823\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9799 - loss: 0.2721\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9769 - loss: 0.2787\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9778 - loss: 0.2621\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9344 - loss: 0.3372\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9394 - loss: 0.2997\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9583 - loss: 0.3287\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9735 - loss: 0.2848\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9745 - loss: 0.3287\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.2946\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9811 - loss: 0.2670\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.2516\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.2321\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9599 - loss: 0.2865\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9553 - loss: 0.2843\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.2245\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.2188\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.2073\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9805 - loss: 0.2425\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.2267\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.2478\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.2146\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9881 - loss: 0.2074\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.2013\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1924\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.1791\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.1950\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.1896\n",
            "X_train shape: (405, 25, 84)\n",
            "y_train shape: (405, 16)\n",
            "X_test shape: (80, 25, 84)\n",
            "y_test shape: (80, 16)\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "Results for Person 1 (with 80 samples, 16 classes):\n",
            "  Accuracy:  0.8375\n",
            "  Precision: 0.8446\n",
            "  Recall:    0.8375\n",
            "  F1 Score:  0.8137\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       1.00      0.60      0.75         5\n",
            "           3       1.00      0.40      0.57         5\n",
            "           4       0.00      0.00      0.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       0.83      1.00      0.91         5\n",
            "           7       0.50      1.00      0.67         5\n",
            "           8       1.00      0.60      0.75         5\n",
            "           9       1.00      0.80      0.89         5\n",
            "          10       1.00      1.00      1.00         5\n",
            "          11       0.56      1.00      0.71         5\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       1.00      1.00      1.00         5\n",
            "          15       0.62      1.00      0.77         5\n",
            "\n",
            "    accuracy                           0.84        80\n",
            "   macro avg       0.84      0.84      0.81        80\n",
            "weighted avg       0.84      0.84      0.81        80\n",
            "\n",
            "\n",
            "==> Leave Person 2 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.1538 - loss: 3.0536\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3959 - loss: 2.6959\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4263 - loss: 2.3757\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5220 - loss: 2.0573\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5584 - loss: 1.8109\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6497 - loss: 1.5378\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7322 - loss: 1.3604\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7296 - loss: 1.1434\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7742 - loss: 1.0567\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7967 - loss: 0.9516\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7955 - loss: 0.9463\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8720 - loss: 0.7884\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8931 - loss: 0.7837\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8371 - loss: 0.7737\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8761 - loss: 0.7223\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9014 - loss: 0.6823\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9332 - loss: 0.6122\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9254 - loss: 0.5774\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8942 - loss: 0.6427\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8959 - loss: 0.6140\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9221 - loss: 0.5644\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9012 - loss: 0.5774\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8989 - loss: 0.5442\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.5796\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9202 - loss: 0.5271\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9062 - loss: 0.5727\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8353 - loss: 0.6946\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8646 - loss: 0.5809\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9005 - loss: 0.5146\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9197 - loss: 0.4730\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9092 - loss: 0.4773\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9132 - loss: 0.4613\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9554 - loss: 0.4125\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9603 - loss: 0.4255\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9533 - loss: 0.4152\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9594 - loss: 0.4019\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9731 - loss: 0.3612\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9770 - loss: 0.3642\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9521 - loss: 0.3941\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9244 - loss: 0.5067\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8992 - loss: 0.5066\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9515 - loss: 0.4192\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9561 - loss: 0.4022\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9604 - loss: 0.4049\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9569 - loss: 0.3845\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9648 - loss: 0.3431\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.3117\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9661 - loss: 0.3837\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.4105\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9109 - loss: 0.4727\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.3993\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.3277\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.3126\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.2833\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.2787\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9439 - loss: 0.4746\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8984 - loss: 0.5208\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8652 - loss: 0.5330\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8782 - loss: 0.7866\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9365 - loss: 0.4172\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9754 - loss: 0.3290\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9512 - loss: 0.3723\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9902 - loss: 0.2819\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.2694\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.2925\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.2623\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9915 - loss: 0.2544\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.2559\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9366 - loss: 0.4307\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9301 - loss: 0.3510\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9127 - loss: 0.4052\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9240 - loss: 0.3415\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9495 - loss: 0.3060\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9355 - loss: 0.3270\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9803 - loss: 0.2765\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9792 - loss: 0.2572\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9760 - loss: 0.2675\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9683 - loss: 0.2691\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9892 - loss: 0.2440\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.2315\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9903 - loss: 0.2405\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.2402\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9760 - loss: 0.2778\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9378 - loss: 0.3412\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9756 - loss: 0.2514\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.2532\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.2211\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.2296\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.2101\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2126\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.2217\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.2038\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.2043\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1928\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.2006\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9950 - loss: 0.1964\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2019\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.1986\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1902\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.1823\n",
            "X_train shape: (405, 25, 84)\n",
            "y_train shape: (405, 16)\n",
            "X_test shape: (80, 25, 84)\n",
            "y_test shape: (80, 16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 26 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4864d3fec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 156ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 28 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4864d3fec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "Results for Person 2 (with 80 samples, 16 classes):\n",
            "  Accuracy:  0.9625\n",
            "  Precision: 0.9688\n",
            "  Recall:    0.9625\n",
            "  F1 Score:  0.9604\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       0.83      1.00      0.91         5\n",
            "           3       1.00      0.80      0.89         5\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00         5\n",
            "           7       1.00      0.60      0.75         5\n",
            "           8       1.00      1.00      1.00         5\n",
            "           9       1.00      1.00      1.00         5\n",
            "          10       1.00      1.00      1.00         5\n",
            "          11       1.00      1.00      1.00         5\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       1.00      1.00      1.00         5\n",
            "          15       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.97      0.96      0.96        80\n",
            "weighted avg       0.97      0.96      0.96        80\n",
            "\n",
            "\n",
            "==> Leave Person 3 Out\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1283 - loss: 3.1015\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2970 - loss: 2.8114\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4894 - loss: 2.4892\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5738 - loss: 2.1763\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6801 - loss: 1.8515\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7293 - loss: 1.5638\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8274 - loss: 1.3175\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8496 - loss: 1.1610\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8670 - loss: 1.0262\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8404 - loss: 1.0341\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8295 - loss: 0.9601\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8517 - loss: 0.8825\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8555 - loss: 0.8090\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8963 - loss: 0.7544\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8969 - loss: 0.6725\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8720 - loss: 0.7057\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8881 - loss: 0.6911\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9373 - loss: 0.6003\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9347 - loss: 0.5972\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9053 - loss: 0.6027\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9351 - loss: 0.5242\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9025 - loss: 0.5297\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9250 - loss: 0.5409\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9523 - loss: 0.4721\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9513 - loss: 0.4854\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9825 - loss: 0.4423\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9760 - loss: 0.4220\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9594 - loss: 0.4123\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9844 - loss: 0.3804\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9670 - loss: 0.4124\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9209 - loss: 0.4624\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8946 - loss: 0.5122\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8948 - loss: 0.5891\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8913 - loss: 0.6593\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9109 - loss: 0.5224\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9449 - loss: 0.4497\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.4244\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9364 - loss: 0.4078\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9760 - loss: 0.3750\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9782 - loss: 0.3575\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9521 - loss: 0.3863\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9641 - loss: 0.3613\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9668 - loss: 0.3977\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9604 - loss: 0.3869\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9366 - loss: 0.4186\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9206 - loss: 0.4716\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9487 - loss: 0.4051\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9583 - loss: 0.3520\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.2993\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9671 - loss: 0.3557\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9065 - loss: 0.4742\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9336 - loss: 0.4130\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.3195\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9761 - loss: 0.3080\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9863 - loss: 0.2943\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.2842\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.3146\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9810 - loss: 0.3000\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.2728\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.2728\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.2539\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9784 - loss: 0.2758\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9760 - loss: 0.2895\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9391 - loss: 0.4010\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.2770\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9665 - loss: 0.3069\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9948 - loss: 0.2532\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.2627\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.2445\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9604 - loss: 0.3756\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.3603\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.2589\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.2503\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9855 - loss: 0.2503\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9847 - loss: 0.2565\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9919 - loss: 0.2320\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.2357\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.2173\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.2176\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2124\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2082\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.2013\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.2060\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1995\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.1999\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1932\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1919\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.1967\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.1914\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1846\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1859\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.1866\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1831\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1756\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1781\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1700\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.1871\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.1787\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.1733\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9942 - loss: 0.1826\n",
            "X_train shape: (405, 25, 84)\n",
            "y_train shape: (405, 16)\n",
            "X_test shape: (80, 25, 84)\n",
            "y_test shape: (80, 16)\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "Results for Person 3 (with 80 samples, 16 classes):\n",
            "  Accuracy:  0.9125\n",
            "  Precision: 0.9439\n",
            "  Recall:    0.9125\n",
            "  F1 Score:  0.9097\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       0.71      1.00      0.83         5\n",
            "           3       0.56      1.00      0.71         5\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00         5\n",
            "           7       1.00      1.00      1.00         5\n",
            "           8       1.00      1.00      1.00         5\n",
            "           9       1.00      1.00      1.00         5\n",
            "          10       1.00      1.00      1.00         5\n",
            "          11       1.00      1.00      1.00         5\n",
            "          12       0.83      1.00      0.91         5\n",
            "          13       1.00      0.80      0.89         5\n",
            "          14       1.00      0.60      0.75         5\n",
            "          15       1.00      0.40      0.57         5\n",
            "\n",
            "    accuracy                           0.91        80\n",
            "   macro avg       0.94      0.91      0.91        80\n",
            "weighted avg       0.94      0.91      0.91        80\n",
            "\n",
            "\n",
            "==> Leave Person 4 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.1297 - loss: 3.0692\n",
            "Epoch 2/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2917 - loss: 2.7584\n",
            "Epoch 3/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4479 - loss: 2.4672\n",
            "Epoch 4/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5238 - loss: 2.1331\n",
            "Epoch 5/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6062 - loss: 1.8494\n",
            "Epoch 6/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7322 - loss: 1.5300\n",
            "Epoch 7/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7888 - loss: 1.2954\n",
            "Epoch 8/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8117 - loss: 1.1628\n",
            "Epoch 9/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8127 - loss: 1.0516\n",
            "Epoch 10/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8277 - loss: 0.9904\n",
            "Epoch 11/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8458 - loss: 0.9553\n",
            "Epoch 12/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8497 - loss: 0.8680\n",
            "Epoch 13/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8814 - loss: 0.7940\n",
            "Epoch 14/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8503 - loss: 0.7956\n",
            "Epoch 15/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8391 - loss: 0.7760\n",
            "Epoch 16/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8828 - loss: 0.6940\n",
            "Epoch 17/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8754 - loss: 0.6969\n",
            "Epoch 18/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9181 - loss: 0.6103\n",
            "Epoch 19/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9007 - loss: 0.5975\n",
            "Epoch 20/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9151 - loss: 0.5902\n",
            "Epoch 21/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9327 - loss: 0.5076\n",
            "Epoch 22/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9258 - loss: 0.5211\n",
            "Epoch 23/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9275 - loss: 0.5125\n",
            "Epoch 24/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.4403\n",
            "Epoch 25/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8690 - loss: 0.6532\n",
            "Epoch 26/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8992 - loss: 0.5810\n",
            "Epoch 27/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8522 - loss: 0.6634\n",
            "Epoch 28/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9271 - loss: 0.5386\n",
            "Epoch 29/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9287 - loss: 0.4851\n",
            "Epoch 30/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9762 - loss: 0.4299\n",
            "Epoch 31/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.3741\n",
            "Epoch 32/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9806 - loss: 0.3880\n",
            "Epoch 33/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9765 - loss: 0.3691\n",
            "Epoch 34/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.3502\n",
            "Epoch 35/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9289 - loss: 0.5293\n",
            "Epoch 36/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9629 - loss: 0.4003\n",
            "Epoch 37/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9487 - loss: 0.4022\n",
            "Epoch 38/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9540 - loss: 0.4201\n",
            "Epoch 39/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9585 - loss: 0.3883\n",
            "Epoch 40/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9412 - loss: 0.4298\n",
            "Epoch 41/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9669 - loss: 0.3722\n",
            "Epoch 42/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.3384\n",
            "Epoch 43/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9656 - loss: 0.3697\n",
            "Epoch 44/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9696 - loss: 0.3465\n",
            "Epoch 45/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9752 - loss: 0.3178\n",
            "Epoch 46/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9612 - loss: 0.3357\n",
            "Epoch 47/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.3073\n",
            "Epoch 48/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9741 - loss: 0.3133\n",
            "Epoch 49/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.3200\n",
            "Epoch 50/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.2928\n",
            "Epoch 51/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.2853\n",
            "Epoch 52/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9901 - loss: 0.2648\n",
            "Epoch 53/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.2676\n",
            "Epoch 54/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.2641\n",
            "Epoch 55/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.2672\n",
            "Epoch 56/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.2346\n",
            "Epoch 57/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.2633\n",
            "Epoch 58/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.2451\n",
            "Epoch 59/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9776 - loss: 0.2843\n",
            "Epoch 60/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.2386\n",
            "Epoch 61/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9848 - loss: 0.2672\n",
            "Epoch 62/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9839 - loss: 0.2493\n",
            "Epoch 63/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9646 - loss: 0.3054\n",
            "Epoch 64/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9945 - loss: 0.2340\n",
            "Epoch 65/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9921 - loss: 0.2515\n",
            "Epoch 66/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.2411\n",
            "Epoch 67/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9695 - loss: 0.2996\n",
            "Epoch 68/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9902 - loss: 0.2259\n",
            "Epoch 69/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9774 - loss: 0.2648\n",
            "Epoch 70/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9651 - loss: 0.2855\n",
            "Epoch 71/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9874 - loss: 0.2438\n",
            "Epoch 72/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.2503\n",
            "Epoch 73/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.2368\n",
            "Epoch 74/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9724 - loss: 0.2712\n",
            "Epoch 75/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9639 - loss: 0.2764\n",
            "Epoch 76/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.2202\n",
            "Epoch 77/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.2085\n",
            "Epoch 78/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9990 - loss: 0.2056\n",
            "Epoch 79/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.2205\n",
            "Epoch 80/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.2101\n",
            "Epoch 81/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.2036\n",
            "Epoch 82/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.2155\n",
            "Epoch 83/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9961 - loss: 0.2089\n",
            "Epoch 84/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.1931\n",
            "Epoch 85/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.1956\n",
            "Epoch 86/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9915 - loss: 0.1956\n",
            "Epoch 87/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.1765\n",
            "Epoch 88/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9819 - loss: 0.2024\n",
            "Epoch 89/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.1781\n",
            "Epoch 90/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.1803\n",
            "Epoch 91/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9983 - loss: 0.1800\n",
            "Epoch 92/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.1827\n",
            "Epoch 93/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.1850\n",
            "Epoch 94/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.1774\n",
            "Epoch 95/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1775\n",
            "Epoch 96/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.1696\n",
            "Epoch 97/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.1843\n",
            "Epoch 98/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.1820\n",
            "Epoch 99/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.1712\n",
            "Epoch 100/100\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.1631\n",
            "X_train shape: (409, 25, 84)\n",
            "y_train shape: (409, 16)\n",
            "X_test shape: (76, 25, 84)\n",
            "y_test shape: (76, 16)\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "Results for Person 4 (with 76 samples, 16 classes):\n",
            "  Accuracy:  0.9868\n",
            "  Precision: 0.9890\n",
            "  Recall:    0.9868\n",
            "  F1 Score:  0.9867\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       0.83      1.00      0.91         5\n",
            "           3       1.00      1.00      1.00         5\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00         5\n",
            "           7       1.00      1.00      1.00         5\n",
            "           8       1.00      1.00      1.00         5\n",
            "           9       1.00      1.00      1.00         5\n",
            "          10       1.00      1.00      1.00         5\n",
            "          11       1.00      0.80      0.89         5\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       1.00      1.00      1.00         5\n",
            "          15       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.99        76\n",
            "   macro avg       0.99      0.99      0.99        76\n",
            "weighted avg       0.99      0.99      0.99        76\n",
            "\n",
            "\n",
            "==> Leave Person 5 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.1436 - loss: 3.0678\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2735 - loss: 2.7611\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3693 - loss: 2.5027\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4900 - loss: 2.0920\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6190 - loss: 1.8133\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6579 - loss: 1.5781\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7691 - loss: 1.3302\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8159 - loss: 1.1650\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8319 - loss: 1.0641\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7834 - loss: 1.0547\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8063 - loss: 0.9241\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8842 - loss: 0.7604\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8968 - loss: 0.7321\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8529 - loss: 0.7597\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8831 - loss: 0.6910\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8875 - loss: 0.6412\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8953 - loss: 0.6203\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9075 - loss: 0.5948\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8925 - loss: 0.6141\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9414 - loss: 0.5413\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9010 - loss: 0.5571\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9419 - loss: 0.4996\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9289 - loss: 0.5153\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8871 - loss: 0.5123\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9631 - loss: 0.4249\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.4239\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9134 - loss: 0.4705\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9236 - loss: 0.4553\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9026 - loss: 0.4918\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9159 - loss: 0.4599\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9257 - loss: 0.4254\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9355 - loss: 0.4090\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.4124\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.3802\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9312 - loss: 0.4195\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9301 - loss: 0.4018\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9738 - loss: 0.3684\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.4005\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9710 - loss: 0.3630\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9636 - loss: 0.3932\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8168 - loss: 0.7590\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8407 - loss: 0.6827\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9301 - loss: 0.4686\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9535 - loss: 0.4236\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9581 - loss: 0.3551\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9465 - loss: 0.3821\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9528 - loss: 0.3689\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9595 - loss: 0.3514\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9687 - loss: 0.3475\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9779 - loss: 0.3216\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9744 - loss: 0.3381\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9773 - loss: 0.3038\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9791 - loss: 0.3135\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9619 - loss: 0.3799\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9439 - loss: 0.3669\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9245 - loss: 0.4342\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8391 - loss: 0.5301\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8899 - loss: 0.4474\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9054 - loss: 0.4042\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9515 - loss: 0.3492\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9442 - loss: 0.3444\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.3824\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9350 - loss: 0.3382\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9358 - loss: 0.3419\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9461 - loss: 0.3364\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9563 - loss: 0.3130\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9189 - loss: 0.3553\n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9565 - loss: 0.3103\n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9435 - loss: 0.3158\n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9484 - loss: 0.2971\n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9245 - loss: 0.3276\n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9262 - loss: 0.3651\n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9273 - loss: 0.3480\n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9282 - loss: 0.3330\n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9376 - loss: 0.3296\n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8785 - loss: 0.4626\n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8909 - loss: 0.3914\n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8895 - loss: 0.3563\n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9361 - loss: 0.3198\n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9322 - loss: 0.3292\n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9622 - loss: 0.3031\n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9649 - loss: 0.2849\n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9421 - loss: 0.2891\n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9720 - loss: 0.2828\n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9776 - loss: 0.2701\n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9671 - loss: 0.2933\n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9843 - loss: 0.2521\n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9857 - loss: 0.2378\n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9903 - loss: 0.2328\n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.2185\n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.2195\n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.2138\n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.2121\n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.2014\n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9969 - loss: 0.1940\n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.2120\n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.1912\n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.2041\n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1856\n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.1906\n",
            "X_train shape: (425, 25, 84)\n",
            "y_train shape: (425, 16)\n",
            "X_test shape: (60, 25, 84)\n",
            "y_test shape: (60, 16)\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497ms/step\n",
            "Results for Person 5 (with 60 samples, 12 classes):\n",
            "  Accuracy:  1.0000\n",
            "  Precision: 1.0000\n",
            "  Recall:    1.0000\n",
            "  F1 Score:  1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      1.00      1.00         5\n",
            "           5       1.00      1.00      1.00         5\n",
            "           7       1.00      1.00      1.00         5\n",
            "           8       1.00      1.00      1.00         5\n",
            "           9       1.00      1.00      1.00         5\n",
            "          10       1.00      1.00      1.00         5\n",
            "          11       1.00      1.00      1.00         5\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        60\n",
            "   macro avg       1.00      1.00      1.00        60\n",
            "weighted avg       1.00      1.00      1.00        60\n",
            "\n",
            "\n",
            "==> Leave Person 7 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1244 - loss: 3.0561\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3721 - loss: 2.7499\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3987 - loss: 2.5241\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4980 - loss: 2.1768\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6563 - loss: 1.7973\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7540 - loss: 1.4650\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7380 - loss: 1.3364\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8311 - loss: 1.1188\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8596 - loss: 0.9363\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8476 - loss: 0.9153\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8775 - loss: 0.7785\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9121 - loss: 0.7355\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8993 - loss: 0.7029\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9008 - loss: 0.6780\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8760 - loss: 0.6719\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8860 - loss: 0.6959\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8499 - loss: 0.7144\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8281 - loss: 0.7645\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8832 - loss: 0.6388\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8302 - loss: 0.6649\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9050 - loss: 0.5481\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9015 - loss: 0.5496\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9360 - loss: 0.5071\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9270 - loss: 0.4886\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9307 - loss: 0.4626\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9673 - loss: 0.4332\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9365 - loss: 0.4385\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8921 - loss: 0.4785\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8928 - loss: 0.5380\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8510 - loss: 0.5951\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8967 - loss: 0.4655\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8995 - loss: 0.4710\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9345 - loss: 0.4244\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9083 - loss: 0.4320\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8965 - loss: 0.4614\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9519 - loss: 0.4058\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9596 - loss: 0.3817\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9493 - loss: 0.3557\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9490 - loss: 0.3596\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9487 - loss: 0.3610\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9656 - loss: 0.3508\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9660 - loss: 0.3401\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9568 - loss: 0.3336\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9696 - loss: 0.3223\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9831 - loss: 0.3092\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9577 - loss: 0.3237\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9608 - loss: 0.3114\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9535 - loss: 0.3140\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9848 - loss: 0.2847\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.3011\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9529 - loss: 0.3262\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9329 - loss: 0.3624\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9364 - loss: 0.3695\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9315 - loss: 0.3939\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9315 - loss: 0.3635\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9439 - loss: 0.3339\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9468 - loss: 0.3305\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9479 - loss: 0.3242\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9768 - loss: 0.2855\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9574 - loss: 0.3034\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9671 - loss: 0.2742\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.2947\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8958 - loss: 0.5354\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9130 - loss: 0.3881\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9472 - loss: 0.3346\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9757 - loss: 0.2964\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9596 - loss: 0.3180\n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9180 - loss: 0.3716\n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9237 - loss: 0.3390\n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9029 - loss: 0.3488\n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9333 - loss: 0.3231\n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9495 - loss: 0.3085\n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.3062\n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9604 - loss: 0.2816\n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9588 - loss: 0.2923\n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9439 - loss: 0.2899\n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.2411\n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9912 - loss: 0.2293\n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9834 - loss: 0.2372\n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.2316\n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.2135\n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.2432\n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9651 - loss: 0.2702\n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9521 - loss: 0.2871\n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9014 - loss: 0.4923\n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9544 - loss: 0.2988\n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9420 - loss: 0.3135\n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9642 - loss: 0.2746\n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9543 - loss: 0.3036\n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.2326\n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9890 - loss: 0.2288\n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.1980\n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.2204\n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.1909\n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.2061\n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9924 - loss: 0.1970\n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9897 - loss: 0.1956\n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9946 - loss: 0.1888\n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9974 - loss: 0.1839\n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9949 - loss: 0.1810\n",
            "X_train shape: (440, 25, 84)\n",
            "y_train shape: (440, 16)\n",
            "X_test shape: (45, 25, 84)\n",
            "y_test shape: (45, 16)\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
            "Results for Person 7 (with 45 samples, 9 classes):\n",
            "  Accuracy:  1.0000\n",
            "  Precision: 1.0000\n",
            "  Recall:    1.0000\n",
            "  F1 Score:  1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      1.00      1.00         5\n",
            "           6       1.00      1.00      1.00         5\n",
            "           8       1.00      1.00      1.00         5\n",
            "          10       1.00      1.00      1.00         5\n",
            "          11       1.00      1.00      1.00         5\n",
            "          14       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "\n",
            "==> Leave Person 8 Out\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1368 - loss: 3.0264\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3176 - loss: 2.6395\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4684 - loss: 2.2183\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6014 - loss: 1.8894\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7101 - loss: 1.5654\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7442 - loss: 1.3075\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7670 - loss: 1.1606\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8701 - loss: 0.9368\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8732 - loss: 0.9142\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8634 - loss: 0.7694\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8392 - loss: 0.8087\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8828 - loss: 0.7203\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8700 - loss: 0.7714\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8941 - loss: 0.6631\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8284 - loss: 0.7716\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8690 - loss: 0.6584\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8805 - loss: 0.6355\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9012 - loss: 0.5899\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9204 - loss: 0.5400\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9513 - loss: 0.4834\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9355 - loss: 0.5010\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9184 - loss: 0.5119\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9265 - loss: 0.5135\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9401 - loss: 0.4903\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9385 - loss: 0.4699\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9535 - loss: 0.4257\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9318 - loss: 0.4389\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8987 - loss: 0.5425\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9399 - loss: 0.4464\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9047 - loss: 0.4604\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9706 - loss: 0.3830\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9597 - loss: 0.3711\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9483 - loss: 0.3905\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9665 - loss: 0.3481\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9787 - loss: 0.3462\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9659 - loss: 0.3490\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9142 - loss: 0.4698\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9583 - loss: 0.3735\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9523 - loss: 0.4148\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9449 - loss: 0.4069\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.3362\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9498 - loss: 0.3746\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9364 - loss: 0.4128\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9359 - loss: 0.4181\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9609 - loss: 0.3569\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.3064\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9762 - loss: 0.3035\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.2909\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9753 - loss: 0.3236\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.3112\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9733 - loss: 0.3042\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9806 - loss: 0.2748\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9830 - loss: 0.2806\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9588 - loss: 0.3144\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9774 - loss: 0.2891\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9781 - loss: 0.2535\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9808 - loss: 0.2643\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9652 - loss: 0.3059\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9500 - loss: 0.3295\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9327 - loss: 0.3374\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9330 - loss: 0.3063\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9610 - loss: 0.2907\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9614 - loss: 0.3103\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9620 - loss: 0.2795\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9825 - loss: 0.2545\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.2478\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9747 - loss: 0.2444\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.2311\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.2301\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.2230\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.2621\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9697 - loss: 0.2639\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9687 - loss: 0.2612\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.2125\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.2420\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9927 - loss: 0.2101\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.2157\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9783 - loss: 0.2324\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9652 - loss: 0.2610\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9600 - loss: 0.2524\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9787 - loss: 0.2209\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9737 - loss: 0.2395\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.2220\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9875 - loss: 0.1967\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.2020\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.1947\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.1953\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.1895\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.1722\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1722\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.1773\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.1712\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.1690\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9970 - loss: 0.1683\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.1652\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9768 - loss: 0.2928\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 0.1962\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.1798\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9458 - loss: 0.3506\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8910 - loss: 0.4720\n",
            "X_train shape: (480, 25, 84)\n",
            "y_train shape: (480, 16)\n",
            "X_test shape: (5, 25, 84)\n",
            "y_test shape: (5, 16)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "Results for Person 8 (with 5 samples, 1 classes):\n",
            "  Accuracy:  0.0000\n",
            "  Precision: 0.0000\n",
            "  Recall:    0.0000\n",
            "  F1 Score:  0.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          12       0.00      0.00      0.00       5.0\n",
            "\n",
            "   micro avg       0.00      0.00      0.00       5.0\n",
            "   macro avg       0.00      0.00      0.00       5.0\n",
            "weighted avg       0.00      0.00      0.00       5.0\n",
            "\n",
            "\n",
            "===== OVERALL RESULTS (LEAVE-ONE-PERSON-OUT) =====\n",
            "Weighted Accuracy:  0.9319\n",
            "Weighted Precision: 0.9407\n",
            "Weighted Recall:    0.9319\n",
            "Weighted F1 Score:  0.9265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bijiWLJUBs8a"
      },
      "source": [
        "# Testing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Eiuu5QruQHC",
        "outputId": "031272ea-0198-43b7-e41e-7302c6a47ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed sequence: 0-62 (length: 62, class: T)\n",
            "Processed sequence: 62-124 (length: 62, class: M)\n",
            "Processed sequence: 124-185 (length: 61, class: G)\n",
            "Processed sequence: 185-246 (length: 61, class: D)\n",
            "Processed sequence: 246-308 (length: 62, class: C)\n",
            "Processed sequence: 308-370 (length: 62, class: T)\n",
            "Processed sequence: 370-432 (length: 62, class: M)\n",
            "Processed sequence: 432-494 (length: 62, class: G)\n",
            "Processed sequence: 494-556 (length: 62, class: D)\n",
            "Processed sequence: 556-680 (length: 124, class: C)\n",
            "Processed sequence: 680-866 (length: 186, class: T)\n",
            "Processed sequence: 866-928 (length: 62, class: M)\n",
            "Processed sequence: 928-990 (length: 62, class: D)\n",
            "Processed sequence: 990-1052 (length: 62, class: C)\n",
            "Processed sequence: 1052-1176 (length: 124, class: W)\n",
            "Processed sequence: 1176-1238 (length: 62, class: P)\n",
            "Processed sequence: 1238-1320 (length: 82, class: N)\n",
            "Processed sequence: 1320-1382 (length: 62, class: L)\n",
            "Processed sequence: 1382-1506 (length: 124, class: R)\n",
            "Processed sequence: 1506-1568 (length: 62, class: O)\n",
            "Processed sequence: 1568-1630 (length: 62, class: K)\n",
            "Processed sequence: 1630-1692 (length: 62, class: F)\n",
            "Processed sequence: 1692-1754 (length: 62, class: U)\n",
            "Processed sequence: 1754-1816 (length: 62, class: Q)\n",
            "Processed sequence: 1816-1878 (length: 62, class: I)\n",
            "Processed sequence: 1878-1940 (length: 62, class: A)\n",
            "Processed sequence: 1940-2064 (length: 124, class: Z)\n",
            "Processed sequence: 2064-2126 (length: 62, class: X)\n",
            "Processed sequence: 2126-2188 (length: 62, class: V)\n",
            "Processed sequence: 2188-2250 (length: 62, class: S)\n",
            "Processed sequence: 2250-2312 (length: 62, class: B)\n",
            "Processed sequence: 2312-2436 (length: 124, class: Z)\n",
            "Processed sequence: 2436-2498 (length: 62, class: X)\n",
            "Processed sequence: 2498-2560 (length: 62, class: V)\n",
            "Processed sequence: 2560-2622 (length: 62, class: S)\n",
            "Processed sequence: 2622-2684 (length: 62, class: B)\n",
            "Processed sequence: 2684-2746 (length: 62, class: T)\n",
            "Processed sequence: 2746-2808 (length: 62, class: M)\n",
            "Processed sequence: 2808-2870 (length: 62, class: G)\n",
            "Processed sequence: 2870-2932 (length: 62, class: D)\n",
            "Processed sequence: 2932-2994 (length: 62, class: C)\n",
            "Processed sequence: 2994-3056 (length: 62, class: W)\n",
            "Processed sequence: 3056-3118 (length: 62, class: P)\n",
            "Processed sequence: 3118-3180 (length: 62, class: N)\n",
            "Processed sequence: 3180-3304 (length: 124, class: L)\n",
            "Processed sequence: 3304-3366 (length: 62, class: R)\n",
            "Processed sequence: 3366-3428 (length: 62, class: O)\n",
            "Processed sequence: 3428-3490 (length: 62, class: K)\n",
            "Processed sequence: 3490-3552 (length: 62, class: F)\n",
            "Processed sequence: 3552-3614 (length: 62, class: U)\n",
            "Processed sequence: 3614-3659 (length: 45, class: Q)\n",
            "Processed sequence: 3659-3721 (length: 62, class: U)\n",
            "Processed sequence: 3721-3788 (length: 67, class: Q)\n",
            "Processed sequence: 3788-3850 (length: 62, class: I)\n",
            "Processed sequence: 3850-3912 (length: 62, class: U)\n",
            "Processed sequence: 3912-3974 (length: 62, class: Q)\n",
            "Processed sequence: 3974-4036 (length: 62, class: I)\n",
            "Processed sequence: 4036-4098 (length: 62, class: A)\n",
            "Processed sequence: 4098-4160 (length: 62, class: Z)\n",
            "Processed sequence: 4160-4222 (length: 62, class: X)\n",
            "Processed sequence: 4222-4284 (length: 62, class: V)\n",
            "Processed sequence: 4284-4346 (length: 62, class: S)\n",
            "Processed sequence: 4346-4408 (length: 62, class: B)\n",
            "Processed sequence: 4408-4594 (length: 186, class: T)\n",
            "Processed sequence: 4594-4718 (length: 124, class: M)\n",
            "Processed sequence: 4718-4780 (length: 62, class: G)\n",
            "Processed sequence: 4780-5050 (length: 270, class: C)\n",
            "Processed sequence: 5050-5112 (length: 62, class: G)\n",
            "Processed sequence: 5112-5174 (length: 62, class: W)\n",
            "Processed sequence: 5174-5236 (length: 62, class: K)\n",
            "Processed sequence: 5236-5298 (length: 62, class: M)\n",
            "Processed sequence: 5298-5360 (length: 62, class: U)\n",
            "Processed sequence: 5360-5422 (length: 62, class: G)\n",
            "Processed sequence: 5422-5484 (length: 62, class: I)\n",
            "Processed sequence: 5484-5608 (length: 124, class: A)\n",
            "Processed sequence: 5608-5670 (length: 62, class: Z)\n",
            "Processed sequence: 5670-5732 (length: 62, class: S)\n",
            "Processed sequence: 5732-5918 (length: 186, class: Z)\n",
            "Processed sequence: 5918-5980 (length: 62, class: T)\n",
            "Processed sequence: 5980-6038 (length: 58, class: M)\n",
            "Processed sequence: 6038-6099 (length: 61, class: G)\n",
            "Processed sequence: 6099-6161 (length: 62, class: T)\n",
            "Processed sequence: 6161-6284 (length: 123, class: M)\n",
            "Processed sequence: 6284-6335 (length: 51, class: G)\n",
            "Processed sequence: 6335-6397 (length: 62, class: D)\n",
            "Processed sequence: 6397-6459 (length: 62, class: C)\n",
            "Processed sequence: 6459-6486 (length: 27, class: W)\n",
            "Processed sequence: 6486-6543 (length: 57, class: P)\n",
            "Processed sequence: 6543-6632 (length: 89, class: N)\n",
            "Processed sequence: 6632-6756 (length: 124, class: L)\n",
            "Processed sequence: 6756-6818 (length: 62, class: R)\n",
            "Processed sequence: 6818-6880 (length: 62, class: O)\n",
            "Warning: Sequence at index 6880 (class K) has fewer than 25 frames (23). Skipping.\n",
            "Processed sequence: 6903-6961 (length: 58, class: F)\n",
            "Processed sequence: 6961-7023 (length: 62, class: U)\n",
            "Processed sequence: 7023-7085 (length: 62, class: Q)\n",
            "Processed sequence: 7085-7147 (length: 62, class: I)\n",
            "Processed sequence: 7147-7181 (length: 34, class: A)\n",
            "Processed sequence: 7181-7218 (length: 37, class: Z)\n",
            "Processed sequence: 7218-7280 (length: 62, class: X)\n",
            "Processed sequence: 7280-7342 (length: 62, class: V)\n",
            "Warning: Sequence at index 7342 (class S) has fewer than 25 frames (15). Skipping.\n",
            "Processed sequence: 7357-7427 (length: 70, class: Z)\n",
            "Warning: Sequence at index 7427 (class X) has fewer than 25 frames (4). Skipping.\n",
            "Processed sequence: 7431-7493 (length: 62, class: V)\n",
            "Processed sequence: 7493-7550 (length: 57, class: Z)\n",
            "Processed sequence: 7550-7610 (length: 60, class: X)\n",
            "Processed sequence: 7610-7734 (length: 124, class: V)\n",
            "Processed sequence: 7734-7770 (length: 36, class: S)\n",
            "Processed sequence: 7770-7832 (length: 62, class: Z)\n",
            "Processed sequence: 7832-7887 (length: 55, class: X)\n",
            "Processed sequence: 7887-7949 (length: 62, class: V)\n",
            "Processed sequence: 7949-8073 (length: 124, class: S)\n",
            "Processed sequence: 8073-8135 (length: 62, class: B)\n",
            "Processed sequence: 8135-8247 (length: 112, class: T)\n",
            "Processed sequence: 8247-8303 (length: 56, class: M)\n",
            "Processed sequence: 8303-8363 (length: 60, class: G)\n",
            "Processed sequence: 8363-8425 (length: 62, class: D)\n",
            "Processed sequence: 8425-8487 (length: 62, class: C)\n",
            "Processed sequence: 8487-8548 (length: 61, class: W)\n",
            "Processed sequence: 8548-8610 (length: 62, class: P)\n",
            "Processed sequence: 8610-8666 (length: 56, class: N)\n",
            "Processed sequence: 8666-8728 (length: 62, class: T)\n",
            "Processed sequence: 8728-8852 (length: 124, class: M)\n",
            "Processed sequence: 8852-8914 (length: 62, class: G)\n",
            "Processed sequence: 8914-8976 (length: 62, class: D)\n",
            "Processed sequence: 8976-9038 (length: 62, class: C)\n",
            "Processed sequence: 9038-9162 (length: 124, class: W)\n",
            "Processed sequence: 9162-9224 (length: 62, class: P)\n",
            "Processed sequence: 9224-9286 (length: 62, class: N)\n",
            "Processed sequence: 9286-9348 (length: 62, class: L)\n",
            "Processed sequence: 9348-9410 (length: 62, class: R)\n",
            "Processed sequence: 9410-9472 (length: 62, class: O)\n",
            "Processed sequence: 9472-9534 (length: 62, class: K)\n",
            "Processed sequence: 9534-9596 (length: 62, class: F)\n",
            "Processed sequence: 9596-9658 (length: 62, class: U)\n",
            "Processed sequence: 9658-9720 (length: 62, class: Q)\n",
            "Processed sequence: 9720-9782 (length: 62, class: I)\n",
            "Processed sequence: 9782-9844 (length: 62, class: A)\n",
            "Processed sequence: 9844-9906 (length: 62, class: Z)\n",
            "Processed sequence: 9906-9935 (length: 29, class: 2)\n",
            "Processed sequence: 9935-9997 (length: 62, class: X)\n",
            "Processed sequence: 9997-10059 (length: 62, class: V)\n",
            "Processed sequence: 10059-10121 (length: 62, class: S)\n",
            "Processed sequence: 10121-10183 (length: 62, class: B)\n",
            "Processed sequence: 10183-10245 (length: 62, class: T)\n",
            "Processed sequence: 10245-10307 (length: 62, class: M)\n",
            "Processed sequence: 10307-10369 (length: 62, class: G)\n",
            "Processed sequence: 10369-10431 (length: 62, class: D)\n",
            "Processed sequence: 10431-10555 (length: 124, class: C)\n",
            "Processed sequence: 10555-10617 (length: 62, class: W)\n",
            "Processed sequence: 10617-10679 (length: 62, class: P)\n",
            "Processed sequence: 10679-10741 (length: 62, class: V)\n",
            "Processed sequence: 10741-10865 (length: 124, class: L)\n",
            "Processed sequence: 10865-10989 (length: 124, class: R)\n",
            "Processed sequence: 10989-11051 (length: 62, class: O)\n",
            "Processed sequence: 11051-11113 (length: 62, class: K)\n",
            "Processed sequence: 11113-11175 (length: 62, class: F)\n",
            "Processed sequence: 11175-11237 (length: 62, class: U)\n",
            "Processed sequence: 11237-11299 (length: 62, class: Q)\n",
            "Processed sequence: 11299-11361 (length: 62, class: I)\n",
            "Processed sequence: 11361-11423 (length: 62, class: A)\n",
            "Processed sequence: 11423-11485 (length: 62, class: Z)\n",
            "Processed sequence: 11485-11547 (length: 62, class: X)\n",
            "Processed sequence: 11547-11609 (length: 62, class: V)\n",
            "Processed sequence: 11609-11671 (length: 62, class: S)\n",
            "Processed sequence: 11671-11733 (length: 62, class: B)\n",
            "Processed sequence: 11733-11795 (length: 62, class: C)\n",
            "Processed sequence: 11795-11857 (length: 62, class: I)\n",
            "Processed sequence: 11857-11919 (length: 62, class: P)\n",
            "Processed sequence: 11919-12043 (length: 124, class: M)\n",
            "Processed sequence: 12043-12105 (length: 62, class: C)\n",
            "Processed sequence: 12105-12167 (length: 62, class: B)\n",
            "Processed sequence: 12167-12291 (length: 124, class: V)\n",
            "Processed sequence: 12291-12353 (length: 62, class: L)\n",
            "Processed sequence: 12353-12400 (length: 47, class: R)\n",
            "Processed sequence: 12400-12524 (length: 124, class: W)\n",
            "Processed sequence: 12524-12586 (length: 62, class: X)\n",
            "Processed sequence: 12586-12648 (length: 62, class: U)\n",
            "Processed sequence: 12648-12710 (length: 62, class: O)\n",
            "Processed sequence: 12710-12772 (length: 62, class: A)\n",
            "Processed sequence: 12772-12834 (length: 62, class: G)\n",
            "Processed sequence: 12834-12896 (length: 62, class: T)\n",
            "Processed sequence: 12896-12958 (length: 62, class: I)\n",
            "Processed sequence: 12958-13020 (length: 62, class: S)\n",
            "Processed sequence: 13020-13082 (length: 62, class: Z)\n",
            "Processed sequence: 13082-13125 (length: 43, class: R)\n",
            "Processed sequence: 13125-13187 (length: 62, class: D)\n",
            "Processed sequence: 13187-13311 (length: 124, class: Q)\n",
            "Processed sequence: 13311-13373 (length: 62, class: N)\n",
            "Processed sequence: 13373-13435 (length: 62, class: G)\n",
            "Processed sequence: 13435-13559 (length: 124, class: Q)\n",
            "Processed sequence: 13559-13621 (length: 62, class: S)\n",
            "Processed sequence: 13621-13678 (length: 57, class: W)\n",
            "Processed sequence: 13678-13740 (length: 62, class: B)\n",
            "Processed sequence: 13740-13802 (length: 62, class: R)\n",
            "Processed sequence: 13802-13864 (length: 62, class: C)\n",
            "Processed sequence: 13864-13926 (length: 62, class: N)\n",
            "Processed sequence: 13926-13988 (length: 62, class: U)\n",
            "Processed sequence: 13988-14050 (length: 62, class: Z)\n",
            "Processed sequence: 14050-14112 (length: 62, class: O)\n",
            "Processed sequence: 14112-14174 (length: 62, class: I)\n",
            "Processed sequence: 14174-14236 (length: 62, class: L)\n",
            "Processed sequence: 14236-14298 (length: 62, class: A)\n",
            "Processed sequence: 14298-14360 (length: 62, class: X)\n",
            "Processed sequence: 14360-14484 (length: 124, class: D)\n",
            "Processed sequence: 14484-14546 (length: 62, class: K)\n",
            "Processed sequence: 14546-14608 (length: 62, class: M)\n",
            "Processed sequence: 14608-14670 (length: 62, class: K)\n",
            "Processed sequence: 14670-14794 (length: 124, class: M)\n",
            "Processed sequence: 14794-14856 (length: 62, class: T)\n",
            "Processed sequence: 14856-14918 (length: 62, class: M)\n",
            "Processed sequence: 14918-14980 (length: 62, class: G)\n",
            "Processed sequence: 14980-15042 (length: 62, class: D)\n",
            "Processed sequence: 15042-15104 (length: 62, class: C)\n",
            "Processed sequence: 15104-15166 (length: 62, class: W)\n",
            "Processed sequence: 15166-15228 (length: 62, class: P)\n",
            "Processed sequence: 15228-15290 (length: 62, class: M)\n",
            "Processed sequence: 15290-15352 (length: 62, class: N)\n",
            "Processed sequence: 15352-15414 (length: 62, class: L)\n",
            "Processed sequence: 15414-15476 (length: 62, class: R)\n",
            "Processed sequence: 15476-15538 (length: 62, class: O)\n",
            "Processed sequence: 15538-15600 (length: 62, class: K)\n",
            "Processed sequence: 15600-15662 (length: 62, class: F)\n",
            "Processed sequence: 15662-15724 (length: 62, class: U)\n",
            "Processed sequence: 15724-15786 (length: 62, class: Q)\n",
            "Processed sequence: 15786-15848 (length: 62, class: I)\n",
            "Processed sequence: 15848-15910 (length: 62, class: A)\n",
            "Processed sequence: 15910-15972 (length: 62, class: Z)\n",
            "Processed sequence: 15972-16034 (length: 62, class: X)\n",
            "Processed sequence: 16034-16096 (length: 62, class: V)\n",
            "Processed sequence: 16096-16155 (length: 59, class: S)\n",
            "Processed sequence: 16155-16217 (length: 62, class: B)\n",
            "Processed sequence: 16217-16279 (length: 62, class: Z)\n",
            "Processed sequence: 16279-16341 (length: 62, class: X)\n",
            "Processed sequence: 16341-16403 (length: 62, class: V)\n",
            "Processed sequence: 16403-16465 (length: 62, class: S)\n",
            "Processed sequence: 16465-16527 (length: 62, class: B)\n",
            "Processed sequence: 16527-16651 (length: 124, class: C)\n",
            "Processed sequence: 16651-16775 (length: 124, class: D)\n",
            "Processed sequence: 16775-16837 (length: 62, class: G)\n",
            "Processed sequence: 16837-16899 (length: 62, class: M)\n",
            "Processed sequence: 16899-17023 (length: 124, class: T)\n",
            "Processed sequence: 17023-17085 (length: 62, class: C)\n",
            "Processed sequence: 17085-17146 (length: 61, class: D)\n",
            "Processed sequence: 17146-17208 (length: 62, class: G)\n",
            "Processed sequence: 17208-17270 (length: 62, class: M)\n",
            "Processed sequence: 17270-17332 (length: 62, class: T)\n",
            "Processed sequence: 17332-17394 (length: 62, class: L)\n",
            "Processed sequence: 17394-17432 (length: 38, class: N)\n",
            "Processed sequence: 17432-17494 (length: 62, class: D)\n",
            "Processed sequence: 17494-17556 (length: 62, class: W)\n",
            "Processed sequence: 17556-17680 (length: 124, class: F)\n",
            "Processed sequence: 17680-17742 (length: 62, class: K)\n",
            "Processed sequence: 17742-17804 (length: 62, class: O)\n",
            "Processed sequence: 17804-17866 (length: 62, class: R)\n",
            "Processed sequence: 17866-17928 (length: 62, class: A)\n",
            "Processed sequence: 17928-17990 (length: 62, class: I)\n",
            "Processed sequence: 17990-18052 (length: 62, class: Q)\n",
            "Processed sequence: 18052-18114 (length: 62, class: U)\n",
            "Processed sequence: 18114-18176 (length: 62, class: B)\n",
            "Processed sequence: 18176-18238 (length: 62, class: S)\n",
            "Processed sequence: 18238-18300 (length: 62, class: V)\n",
            "Processed sequence: 18300-18362 (length: 62, class: C)\n",
            "Processed sequence: 18362-18424 (length: 62, class: D)\n",
            "Processed sequence: 18424-18486 (length: 62, class: G)\n",
            "Processed sequence: 18486-18548 (length: 62, class: M)\n",
            "Processed sequence: 18548-18610 (length: 62, class: T)\n",
            "Processed sequence: 18610-18672 (length: 62, class: L)\n",
            "Processed sequence: 18672-18734 (length: 62, class: N)\n",
            "Processed sequence: 18734-18796 (length: 62, class: P)\n",
            "Processed sequence: 18796-18858 (length: 62, class: W)\n",
            "Processed sequence: 18858-18920 (length: 62, class: F)\n",
            "Processed sequence: 18920-18982 (length: 62, class: K)\n",
            "Processed sequence: 18982-19044 (length: 62, class: O)\n",
            "Processed sequence: 19044-19106 (length: 62, class: R)\n",
            "Processed sequence: 19106-19168 (length: 62, class: A)\n",
            "Processed sequence: 19168-19230 (length: 62, class: I)\n",
            "Processed sequence: 19230-19292 (length: 62, class: Q)\n",
            "Processed sequence: 19292-19354 (length: 62, class: U)\n",
            "Processed sequence: 19354-19416 (length: 62, class: B)\n",
            "Processed sequence: 19416-19478 (length: 62, class: S)\n",
            "Processed sequence: 19478-19540 (length: 62, class: V)\n",
            "Processed sequence: 19540-19602 (length: 62, class: C)\n",
            "Processed sequence: 19602-19664 (length: 62, class: D)\n",
            "Processed sequence: 19664-19726 (length: 62, class: G)\n",
            "Processed sequence: 19726-19788 (length: 62, class: T)\n",
            "Processed sequence: 19788-19850 (length: 62, class: L)\n",
            "Processed sequence: 19850-19912 (length: 62, class: N)\n",
            "Processed sequence: 19912-19974 (length: 62, class: P)\n",
            "Processed sequence: 19974-20036 (length: 62, class: W)\n",
            "Processed sequence: 20036-20098 (length: 62, class: E)\n",
            "Processed sequence: 20098-20160 (length: 62, class: K)\n",
            "Processed sequence: 20160-20222 (length: 62, class: O)\n",
            "Processed sequence: 20222-20284 (length: 62, class: R)\n",
            "Processed sequence: 20284-20346 (length: 62, class: A)\n",
            "Processed sequence: 20346-20408 (length: 62, class: I)\n",
            "Processed sequence: 20408-20470 (length: 62, class: Q)\n",
            "Processed sequence: 20470-20532 (length: 62, class: U)\n",
            "Processed sequence: 20532-20594 (length: 62, class: B)\n",
            "Processed sequence: 20594-20656 (length: 62, class: S)\n",
            "Processed sequence: 20656-20718 (length: 62, class: V)\n",
            "Processed sequence: 20718-20780 (length: 62, class: D)\n",
            "Processed sequence: 20780-20842 (length: 62, class: G)\n",
            "Processed sequence: 20842-20904 (length: 62, class: M)\n",
            "Processed sequence: 20904-21028 (length: 124, class: L)\n",
            "Processed sequence: 21028-21152 (length: 124, class: N)\n",
            "Processed sequence: 21152-21214 (length: 62, class: W)\n",
            "Processed sequence: 21214-21276 (length: 62, class: F)\n",
            "Processed sequence: 21276-21338 (length: 62, class: R)\n",
            "Processed sequence: 21338-21400 (length: 62, class: O)\n",
            "Processed sequence: 21400-21462 (length: 62, class: R)\n",
            "Processed sequence: 21462-21523 (length: 61, class: A)\n",
            "Processed sequence: 21523-21585 (length: 62, class: I)\n",
            "Processed sequence: 21585-21647 (length: 62, class: Q)\n",
            "Processed sequence: 21647-21709 (length: 62, class: Y)\n",
            "Processed sequence: 21709-21771 (length: 62, class: U)\n",
            "Processed sequence: 21771-21833 (length: 62, class: B)\n",
            "Processed sequence: 21833-21895 (length: 62, class: S)\n",
            "Processed sequence: 21895-21957 (length: 62, class: V)\n",
            "Processed sequence: 21957-22019 (length: 62, class: C)\n",
            "Processed sequence: 22019-22143 (length: 124, class: D)\n",
            "Processed sequence: 22143-22205 (length: 62, class: G)\n",
            "Processed sequence: 22205-22267 (length: 62, class: M)\n",
            "Processed sequence: 22267-22329 (length: 62, class: L)\n",
            "Processed sequence: 22329-22391 (length: 62, class: N)\n",
            "Processed sequence: 22391-22453 (length: 62, class: P)\n",
            "Processed sequence: 22453-22515 (length: 62, class: W)\n",
            "Processed sequence: 22515-22639 (length: 124, class: F)\n",
            "Processed sequence: 22639-22701 (length: 62, class: K)\n",
            "Processed sequence: 22701-22763 (length: 62, class: O)\n",
            "Processed sequence: 22763-22825 (length: 62, class: A)\n",
            "Processed sequence: 22825-22887 (length: 62, class: I)\n",
            "Processed sequence: 22887-22949 (length: 62, class: Q)\n",
            "Processed sequence: 22949-23011 (length: 62, class: U)\n",
            "Processed sequence: 23011-23073 (length: 62, class: B)\n",
            "Processed sequence: 23073-23135 (length: 62, class: S)\n",
            "Processed sequence: 23135-23197 (length: 62, class: C)\n",
            "Processed sequence: 23197-23321 (length: 124, class: D)\n",
            "Processed sequence: 23321-23383 (length: 62, class: G)\n",
            "Processed sequence: 23383-23445 (length: 62, class: M)\n",
            "Processed sequence: 23445-23507 (length: 62, class: L)\n",
            "Processed sequence: 23507-23631 (length: 124, class: N)\n",
            "Processed sequence: 23631-23693 (length: 62, class: P)\n",
            "Processed sequence: 23693-23754 (length: 61, class: W)\n",
            "Processed sequence: 23754-23816 (length: 62, class: F)\n",
            "Processed sequence: 23816-23878 (length: 62, class: K)\n",
            "Processed sequence: 23878-23940 (length: 62, class: O)\n",
            "Processed sequence: 23940-24002 (length: 62, class: R)\n",
            "Processed sequence: 24002-24064 (length: 62, class: A)\n",
            "Processed sequence: 24064-24126 (length: 62, class: I)\n",
            "Processed sequence: 24126-24188 (length: 62, class: Q)\n",
            "Processed sequence: 24188-24250 (length: 62, class: U)\n",
            "Processed sequence: 24250-24312 (length: 62, class: B)\n",
            "Processed sequence: 24312-24436 (length: 124, class: S)\n",
            "Processed sequence: 24436-24498 (length: 62, class: V)\n",
            "Processed sequence: 24498-24560 (length: 62, class: C)\n",
            "Processed sequence: 24560-24684 (length: 124, class: D)\n",
            "Processed sequence: 24684-24746 (length: 62, class: G)\n",
            "Processed sequence: 24746-24808 (length: 62, class: M)\n",
            "Processed sequence: 24808-24870 (length: 62, class: T)\n",
            "Processed sequence: 24870-24932 (length: 62, class: L)\n",
            "Processed sequence: 24932-24994 (length: 62, class: N)\n",
            "Processed sequence: 24994-25118 (length: 124, class: D)\n",
            "Processed sequence: 25118-25180 (length: 62, class: W)\n",
            "Processed sequence: 25180-25242 (length: 62, class: F)\n",
            "Processed sequence: 25242-25304 (length: 62, class: K)\n",
            "Processed sequence: 25304-25366 (length: 62, class: O)\n",
            "Processed sequence: 25366-25428 (length: 62, class: R)\n",
            "Processed sequence: 25428-25490 (length: 62, class: A)\n",
            "Processed sequence: 25490-25552 (length: 62, class: I)\n",
            "Processed sequence: 25552-25614 (length: 62, class: Q)\n",
            "Processed sequence: 25614-25676 (length: 62, class: U)\n",
            "Processed sequence: 25676-25738 (length: 62, class: B)\n",
            "Processed sequence: 25738-25800 (length: 62, class: S)\n",
            "Processed sequence: 25800-25862 (length: 62, class: V)\n",
            "Processed sequence: 25862-25924 (length: 62, class: C)\n",
            "Processed sequence: 25924-25986 (length: 62, class: D)\n",
            "Processed sequence: 25986-26048 (length: 62, class: G)\n",
            "Processed sequence: 26048-26110 (length: 62, class: M)\n",
            "Processed sequence: 26110-26172 (length: 62, class: T)\n",
            "Processed sequence: 26172-26234 (length: 62, class: L)\n",
            "Processed sequence: 26234-26296 (length: 62, class: N)\n",
            "Processed sequence: 26296-26358 (length: 62, class: P)\n",
            "Processed sequence: 26358-26420 (length: 62, class: W)\n",
            "Processed sequence: 26420-26482 (length: 62, class: F)\n",
            "Processed sequence: 26482-26544 (length: 62, class: K)\n",
            "Processed sequence: 26544-26606 (length: 62, class: O)\n",
            "Processed sequence: 26606-26668 (length: 62, class: R)\n",
            "Processed sequence: 26668-26730 (length: 62, class: A)\n",
            "Processed sequence: 26730-26791 (length: 61, class: I)\n",
            "Processed sequence: 26791-26915 (length: 124, class: Q)\n",
            "Processed sequence: 26915-26977 (length: 62, class: U)\n",
            "Processed sequence: 26977-27039 (length: 62, class: B)\n",
            "Processed sequence: 27039-27101 (length: 62, class: S)\n",
            "Processed sequence: 27101-27163 (length: 62, class: V)\n",
            "Processed sequence: 27163-27225 (length: 62, class: C)\n",
            "Processed sequence: 27225-27287 (length: 62, class: D)\n",
            "Processed sequence: 27287-27411 (length: 124, class: G)\n",
            "Processed sequence: 27411-27535 (length: 124, class: M)\n",
            "Processed sequence: 27535-27659 (length: 124, class: T)\n",
            "Processed sequence: 27659-27783 (length: 124, class: L)\n",
            "Processed sequence: 27783-27845 (length: 62, class: N)\n",
            "Processed sequence: 27845-27907 (length: 62, class: P)\n",
            "Processed sequence: 27907-27969 (length: 62, class: W)\n",
            "Processed sequence: 27969-28031 (length: 62, class: E)\n",
            "Processed sequence: 28031-28093 (length: 62, class: K)\n",
            "Processed sequence: 28093-28217 (length: 124, class: O)\n",
            "Processed sequence: 28217-28279 (length: 62, class: R)\n",
            "Processed sequence: 28279-28340 (length: 61, class: A)\n",
            "Processed sequence: 28340-28402 (length: 62, class: I)\n",
            "Processed sequence: 28402-28464 (length: 62, class: Q)\n",
            "Processed sequence: 28464-28526 (length: 62, class: U)\n",
            "Processed sequence: 28526-28588 (length: 62, class: B)\n",
            "Processed sequence: 28588-28650 (length: 62, class: S)\n",
            "Processed sequence: 28650-28712 (length: 62, class: V)\n",
            "Processed sequence: 28712-28774 (length: 62, class: C)\n",
            "Processed sequence: 28774-28898 (length: 124, class: D)\n",
            "Processed sequence: 28898-28960 (length: 62, class: G)\n",
            "Processed sequence: 28960-29022 (length: 62, class: M)\n",
            "Processed sequence: 29022-29084 (length: 62, class: T)\n",
            "Processed sequence: 29084-29146 (length: 62, class: L)\n",
            "Processed sequence: 29146-29208 (length: 62, class: N)\n",
            "Processed sequence: 29208-29270 (length: 62, class: P)\n",
            "Processed sequence: 29270-29315 (length: 45, class: W)\n",
            "Processed sequence: 29315-29377 (length: 62, class: F)\n",
            "Processed sequence: 29377-29439 (length: 62, class: K)\n",
            "Processed sequence: 29439-29501 (length: 62, class: O)\n",
            "Processed sequence: 29501-29563 (length: 62, class: R)\n",
            "Processed sequence: 29563-29625 (length: 62, class: A)\n",
            "Processed sequence: 29625-29687 (length: 62, class: I)\n",
            "Processed sequence: 29687-29749 (length: 62, class: Q)\n",
            "Processed sequence: 29749-29811 (length: 62, class: U)\n",
            "Processed sequence: 29811-29873 (length: 62, class: B)\n",
            "Processed sequence: 29873-29911 (length: 38, class: S)\n",
            "Processed sequence: 29911-29973 (length: 62, class: V)\n",
            "Processed sequence: 29973-30035 (length: 62, class: G)\n",
            "Processed sequence: 30035-30097 (length: 62, class: M)\n",
            "Processed sequence: 30097-30159 (length: 62, class: L)\n",
            "Processed sequence: 30159-30221 (length: 62, class: N)\n",
            "Processed sequence: 30221-30283 (length: 62, class: W)\n",
            "Processed sequence: 30283-30345 (length: 62, class: F)\n",
            "Processed sequence: 30345-30469 (length: 124, class: R)\n",
            "Processed sequence: 30469-30531 (length: 62, class: O)\n",
            "Processed sequence: 30531-30593 (length: 62, class: A)\n",
            "Processed sequence: 30593-30655 (length: 62, class: I)\n",
            "Processed sequence: 30655-30717 (length: 62, class: Q)\n",
            "Processed sequence: 30717-30779 (length: 62, class: B)\n",
            "Processed sequence: 30779-30841 (length: 62, class: S)\n",
            "Processed sequence: 30841-30903 (length: 62, class: V)\n",
            "Processed sequence: 30903-30965 (length: 62, class: C)\n",
            "Processed sequence: 30965-31027 (length: 62, class: D)\n",
            "Processed sequence: 31027-31089 (length: 62, class: G)\n",
            "Processed sequence: 31089-31151 (length: 62, class: M)\n",
            "Processed sequence: 31151-31213 (length: 62, class: L)\n",
            "Processed sequence: 31213-31275 (length: 62, class: N)\n",
            "Processed sequence: 31275-31337 (length: 62, class: P)\n",
            "Processed sequence: 31337-31399 (length: 62, class: W)\n",
            "Processed sequence: 31399-31523 (length: 124, class: F)\n",
            "Processed sequence: 31523-31585 (length: 62, class: K)\n",
            "Processed sequence: 31585-31647 (length: 62, class: O)\n",
            "Processed sequence: 31647-31709 (length: 62, class: R)\n",
            "Processed sequence: 31709-31867 (length: 158, class: A)\n",
            "Processed sequence: 31867-31929 (length: 62, class: I)\n",
            "Processed sequence: 31929-32053 (length: 124, class: Q)\n",
            "Processed sequence: 32053-32115 (length: 62, class: U)\n",
            "Processed sequence: 32115-32177 (length: 62, class: B)\n",
            "Processed sequence: 32177-32239 (length: 62, class: S)\n",
            "Processed sequence: 32239-32301 (length: 62, class: V)\n",
            "Processed sequence: 32301-32363 (length: 62, class: C)\n",
            "Processed sequence: 32363-32487 (length: 124, class: D)\n",
            "Processed sequence: 32487-32540 (length: 53, class: G)\n",
            "Processed sequence: 32540-32602 (length: 62, class: M)\n",
            "Processed sequence: 32602-32725 (length: 123, class: C)\n",
            "Processed sequence: 32725-32787 (length: 62, class: D)\n",
            "Processed sequence: 32787-32911 (length: 124, class: C)\n",
            "Processed sequence: 32911-32973 (length: 62, class: D)\n",
            "Processed sequence: 32973-33035 (length: 62, class: G)\n",
            "Processed sequence: 33035-33070 (length: 35, class: M)\n",
            "Processed sequence: 33070-33132 (length: 62, class: L)\n",
            "Processed sequence: 33132-33194 (length: 62, class: N)\n",
            "Processed sequence: 33194-33256 (length: 62, class: P)\n",
            "Processed sequence: 33256-33318 (length: 62, class: W)\n",
            "Processed sequence: 33318-33380 (length: 62, class: F)\n",
            "Processed sequence: 33380-33442 (length: 62, class: K)\n",
            "Processed sequence: 33442-33504 (length: 62, class: O)\n",
            "Processed sequence: 33504-33566 (length: 62, class: R)\n",
            "Processed sequence: 33566-33628 (length: 62, class: A)\n",
            "Processed sequence: 33628-33690 (length: 62, class: I)\n",
            "Processed sequence: 33690-33752 (length: 62, class: Q)\n",
            "Processed sequence: 33752-33814 (length: 62, class: U)\n",
            "Processed sequence: 33814-33876 (length: 62, class: B)\n",
            "Processed sequence: 33876-33938 (length: 62, class: S)\n",
            "Processed sequence: 33938-34000 (length: 62, class: V)\n",
            "Processed sequence: 34000-34062 (length: 62, class: C)\n",
            "Processed sequence: 34062-34124 (length: 62, class: D)\n",
            "Processed sequence: 34124-34186 (length: 62, class: G)\n",
            "Processed sequence: 34186-34248 (length: 62, class: M)\n",
            "Processed sequence: 34248-34309 (length: 61, class: T)\n",
            "Processed sequence: 34309-34433 (length: 124, class: L)\n",
            "Processed sequence: 34433-34495 (length: 62, class: N)\n",
            "Processed sequence: 34495-34557 (length: 62, class: P)\n",
            "Processed sequence: 34557-34619 (length: 62, class: W)\n",
            "Processed sequence: 34619-34681 (length: 62, class: F)\n",
            "Processed sequence: 34681-34743 (length: 62, class: K)\n",
            "Processed sequence: 34743-34805 (length: 62, class: O)\n",
            "Processed sequence: 34805-34929 (length: 124, class: R)\n",
            "Processed sequence: 34929-34991 (length: 62, class: A)\n",
            "Processed sequence: 34991-35053 (length: 62, class: I)\n",
            "Processed sequence: 35053-35115 (length: 62, class: Q)\n",
            "Processed sequence: 35115-35177 (length: 62, class: U)\n",
            "Processed sequence: 35177-35239 (length: 62, class: B)\n",
            "Processed sequence: 35239-35301 (length: 62, class: S)\n",
            "Processed sequence: 35301-35363 (length: 62, class: V)\n",
            "Processed sequence: 35363-35425 (length: 62, class: C)\n",
            "Processed sequence: 35425-35487 (length: 62, class: D)\n",
            "Processed sequence: 35487-35549 (length: 62, class: G)\n",
            "Processed sequence: 35549-35611 (length: 62, class: M)\n",
            "Processed sequence: 35611-35673 (length: 62, class: T)\n",
            "Processed sequence: 35673-35735 (length: 62, class: L)\n",
            "Processed sequence: 35735-35797 (length: 62, class: N)\n",
            "Processed sequence: 35797-35859 (length: 62, class: P)\n",
            "Processed sequence: 35859-35983 (length: 124, class: W)\n",
            "Processed sequence: 35983-36045 (length: 62, class: F)\n",
            "Processed sequence: 36045-36107 (length: 62, class: K)\n",
            "Processed sequence: 36107-36169 (length: 62, class: O)\n",
            "Processed sequence: 36169-36231 (length: 62, class: R)\n",
            "Processed sequence: 36231-36293 (length: 62, class: A)\n",
            "Processed sequence: 36293-36355 (length: 62, class: I)\n",
            "Processed sequence: 36355-36417 (length: 62, class: Q)\n",
            "Processed sequence: 36417-36479 (length: 62, class: U)\n",
            "Processed sequence: 36479-36541 (length: 62, class: B)\n",
            "Processed sequence: 36541-36665 (length: 124, class: S)\n",
            "Processed sequence: 36665-36727 (length: 62, class: V)\n",
            "Processed sequence: 36727-36789 (length: 62, class: C)\n",
            "Processed sequence: 36789-36913 (length: 124, class: D)\n",
            "Processed sequence: 36913-36975 (length: 62, class: M)\n",
            "Processed sequence: 36975-37037 (length: 62, class: L)\n",
            "Processed sequence: 37037-37099 (length: 62, class: N)\n",
            "Processed sequence: 37099-37161 (length: 62, class: P)\n",
            "Processed sequence: 37161-37223 (length: 62, class: W)\n",
            "Processed sequence: 37223-37258 (length: 35, class: F)\n",
            "Processed sequence: 37258-37320 (length: 62, class: K)\n",
            "Processed sequence: 37320-37382 (length: 62, class: O)\n",
            "Processed sequence: 37382-37444 (length: 62, class: R)\n",
            "Processed sequence: 37444-37506 (length: 62, class: A)\n",
            "Processed sequence: 37506-37568 (length: 62, class: I)\n",
            "Processed sequence: 37568-37630 (length: 62, class: Q)\n",
            "Processed sequence: 37630-37692 (length: 62, class: U)\n",
            "Processed sequence: 37692-37754 (length: 62, class: B)\n",
            "Processed sequence: 37754-37816 (length: 62, class: S)\n",
            "Processed sequence: 37816-37878 (length: 62, class: V)\n",
            "Processed sequence: 37878-38002 (length: 124, class: C)\n",
            "Processed sequence: 38002-38064 (length: 62, class: D)\n",
            "Processed sequence: 38064-38188 (length: 124, class: C)\n",
            "Processed sequence: 38188-38250 (length: 62, class: D)\n",
            "Processed sequence: 38250-38312 (length: 62, class: G)\n",
            "Processed sequence: 38312-38374 (length: 62, class: M)\n",
            "Processed sequence: 38374-38436 (length: 62, class: L)\n",
            "Processed sequence: 38436-38498 (length: 62, class: N)\n",
            "Processed sequence: 38498-38622 (length: 124, class: P)\n",
            "Processed sequence: 38622-38684 (length: 62, class: W)\n",
            "Processed sequence: 38684-38746 (length: 62, class: F)\n",
            "Processed sequence: 38746-38808 (length: 62, class: K)\n",
            "Processed sequence: 38808-38870 (length: 62, class: O)\n",
            "Processed sequence: 38870-38932 (length: 62, class: R)\n",
            "Processed sequence: 38932-38994 (length: 62, class: A)\n",
            "Processed sequence: 38994-39056 (length: 62, class: I)\n",
            "Processed sequence: 39056-39118 (length: 62, class: Q)\n",
            "Processed sequence: 39118-39180 (length: 62, class: U)\n",
            "Processed sequence: 39180-39242 (length: 62, class: B)\n",
            "Processed sequence: 39242-39304 (length: 62, class: S)\n",
            "Processed sequence: 39304-39366 (length: 62, class: V)\n",
            "Processed sequence: 39366-39428 (length: 62, class: C)\n",
            "Processed sequence: 39428-39490 (length: 62, class: D)\n",
            "Processed sequence: 39490-39614 (length: 124, class: G)\n",
            "Processed sequence: 39614-39676 (length: 62, class: M)\n",
            "Processed sequence: 39676-39738 (length: 62, class: T)\n",
            "Processed sequence: 39738-39800 (length: 62, class: L)\n",
            "Processed sequence: 39800-39862 (length: 62, class: N)\n",
            "Processed sequence: 39862-39924 (length: 62, class: P)\n",
            "Processed sequence: 39924-40048 (length: 124, class: W)\n",
            "Processed sequence: 40048-40110 (length: 62, class: F)\n",
            "Processed sequence: 40110-40172 (length: 62, class: K)\n",
            "Processed sequence: 40172-40234 (length: 62, class: O)\n",
            "Processed sequence: 40234-40296 (length: 62, class: R)\n",
            "Processed sequence: 40296-40358 (length: 62, class: A)\n",
            "Processed sequence: 40358-40420 (length: 62, class: I)\n",
            "Processed sequence: 40420-40482 (length: 62, class: Q)\n",
            "Processed sequence: 40482-40544 (length: 62, class: U)\n",
            "Processed sequence: 40544-40606 (length: 62, class: B)\n",
            "Processed sequence: 40606-40668 (length: 62, class: S)\n",
            "Processed sequence: 40668-40730 (length: 62, class: V)\n",
            "Processed sequence: 40730-40792 (length: 62, class: C)\n",
            "Processed sequence: 40792-40854 (length: 62, class: G)\n",
            "Processed sequence: 40854-40916 (length: 62, class: C)\n",
            "Processed sequence: 40916-40978 (length: 62, class: D)\n",
            "Processed sequence: 40978-41039 (length: 61, class: G)\n",
            "Processed sequence: 41039-41101 (length: 62, class: M)\n",
            "Processed sequence: 41101-41163 (length: 62, class: T)\n",
            "Processed sequence: 41163-41225 (length: 62, class: L)\n",
            "Processed sequence: 41225-41349 (length: 124, class: N)\n",
            "Processed sequence: 41349-41411 (length: 62, class: P)\n",
            "Processed sequence: 41411-41597 (length: 186, class: W)\n",
            "Processed sequence: 41597-41659 (length: 62, class: K)\n",
            "Processed sequence: 41659-41721 (length: 62, class: W)\n",
            "Processed sequence: 41721-41783 (length: 62, class: R)\n",
            "Processed sequence: 41783-41845 (length: 62, class: A)\n",
            "Processed sequence: 41845-41907 (length: 62, class: I)\n",
            "Processed sequence: 41907-41969 (length: 62, class: Q)\n",
            "Processed sequence: 41969-42031 (length: 62, class: U)\n",
            "Processed sequence: 42031-42093 (length: 62, class: B)\n",
            "Processed sequence: 42093-42155 (length: 62, class: S)\n",
            "Processed sequence: 42155-42217 (length: 62, class: V)\n",
            "Processed sequence: 42217-42279 (length: 62, class: S)\n",
            "Processed sequence: 42279-42341 (length: 62, class: C)\n",
            "Processed sequence: 42341-42403 (length: 62, class: X)\n",
            "Processed sequence: 42403-42465 (length: 62, class: F)\n",
            "Processed sequence: 42465-42527 (length: 62, class: A)\n",
            "Processed sequence: 42527-42589 (length: 62, class: O)\n",
            "Processed sequence: 42589-42650 (length: 61, class: Z)\n",
            "Processed sequence: 42650-42712 (length: 62, class: L)\n",
            "Processed sequence: 42712-42774 (length: 62, class: V)\n",
            "Processed sequence: 42774-42836 (length: 62, class: K)\n",
            "Processed sequence: 42836-42888 (length: 52, class: B)\n",
            "Processed sequence: 42888-42950 (length: 62, class: I)\n",
            "Processed sequence: 42950-43012 (length: 62, class: N)\n",
            "Processed sequence: 43012-43074 (length: 62, class: F)\n",
            "Processed sequence: 43074-43197 (length: 123, class: S)\n",
            "Processed sequence: 43197-43259 (length: 62, class: Q)\n",
            "Processed sequence: 43259-43321 (length: 62, class: Z)\n",
            "Processed sequence: 43321-43383 (length: 62, class: O)\n",
            "Processed sequence: 43383-43445 (length: 62, class: X)\n",
            "Processed sequence: 43445-43507 (length: 62, class: W)\n",
            "Processed sequence: 43507-43569 (length: 62, class: M)\n",
            "Processed sequence: 43569-43631 (length: 62, class: D)\n",
            "Processed sequence: 43631-43693 (length: 62, class: C)\n",
            "Processed sequence: 43693-43755 (length: 62, class: U)\n",
            "Processed sequence: 43755-43817 (length: 62, class: P)\n",
            "Processed sequence: 43817-43879 (length: 62, class: G)\n",
            "Processed sequence: 43879-43941 (length: 62, class: R)\n",
            "Processed sequence: 43941-44003 (length: 62, class: A)\n",
            "Processed sequence: 44003-44127 (length: 124, class: V)\n",
            "Processed sequence: 44127-44189 (length: 62, class: K)\n",
            "Processed sequence: 44189-44251 (length: 62, class: U)\n",
            "Processed sequence: 44251-44313 (length: 62, class: Q)\n",
            "Processed sequence: 44313-44375 (length: 62, class: W)\n",
            "Processed sequence: 44375-44437 (length: 62, class: A)\n",
            "Processed sequence: 44437-44499 (length: 62, class: V)\n",
            "Processed sequence: 44499-44561 (length: 62, class: F)\n",
            "Processed sequence: 44561-44599 (length: 38, class: Z)\n",
            "Processed sequence: 44599-44661 (length: 62, class: X)\n",
            "Processed sequence: 44661-44723 (length: 62, class: R)\n",
            "Processed sequence: 44723-44785 (length: 62, class: G)\n",
            "Processed sequence: 44785-44847 (length: 62, class: L)\n",
            "Processed sequence: 44847-44909 (length: 62, class: N)\n",
            "Processed sequence: 44909-45033 (length: 124, class: O)\n",
            "Processed sequence: 45033-45157 (length: 124, class: M)\n",
            "Processed sequence: 45157-45219 (length: 62, class: B)\n",
            "Processed sequence: 45219-45281 (length: 62, class: G)\n",
            "Processed sequence: 45281-45343 (length: 62, class: N)\n",
            "Processed sequence: 45343-45405 (length: 62, class: O)\n",
            "Processed sequence: 45405-45467 (length: 62, class: V)\n",
            "Processed sequence: 45467-45529 (length: 62, class: P)\n",
            "Processed sequence: 45529-45591 (length: 62, class: Z)\n",
            "Processed sequence: 45591-45653 (length: 62, class: F)\n",
            "Processed sequence: 45653-45715 (length: 62, class: U)\n",
            "Processed sequence: 45715-45777 (length: 62, class: M)\n",
            "Processed sequence: 45777-45839 (length: 62, class: K)\n",
            "Processed sequence: 45839-45901 (length: 62, class: D)\n",
            "Processed sequence: 45901-45963 (length: 62, class: C)\n",
            "Processed sequence: 45963-46025 (length: 62, class: W)\n",
            "Processed sequence: 46025-46087 (length: 62, class: X)\n",
            "Processed sequence: 46087-46149 (length: 62, class: T)\n",
            "Processed sequence: 46149-46211 (length: 62, class: B)\n",
            "Processed sequence: 46211-46273 (length: 62, class: Q)\n",
            "Processed sequence: 46273-46392 (length: 119, class: S)\n",
            "Processed sequence: 46392-46454 (length: 62, class: I)\n",
            "Processed sequence: 46454-46578 (length: 124, class: A)\n",
            "Processed sequence: 46578-46640 (length: 62, class: T)\n",
            "Processed sequence: 46640-46764 (length: 124, class: S)\n",
            "Processed sequence: 46764-46826 (length: 62, class: G)\n",
            "Processed sequence: 46826-46888 (length: 62, class: B)\n",
            "Processed sequence: 46888-46950 (length: 62, class: M)\n",
            "Processed sequence: 46950-47012 (length: 62, class: C)\n",
            "Processed sequence: 47012-47074 (length: 62, class: N)\n",
            "Processed sequence: 47074-47136 (length: 62, class: W)\n",
            "Processed sequence: 47136-47198 (length: 62, class: U)\n",
            "Processed sequence: 47198-47260 (length: 62, class: Q)\n",
            "Processed sequence: 47260-47322 (length: 62, class: R)\n",
            "Processed sequence: 47322-47384 (length: 62, class: V)\n",
            "Processed sequence: 47384-47446 (length: 62, class: K)\n",
            "Processed sequence: 47446-47508 (length: 62, class: I)\n",
            "Processed sequence: 47508-47570 (length: 62, class: L)\n",
            "Processed sequence: 47570-47694 (length: 124, class: Z)\n",
            "Processed sequence: 47694-47756 (length: 62, class: O)\n",
            "Processed sequence: 47756-47880 (length: 124, class: P)\n",
            "Processed sequence: 47880-47942 (length: 62, class: N)\n",
            "Processed sequence: 47942-48004 (length: 62, class: F)\n",
            "Processed sequence: 48004-48066 (length: 62, class: Z)\n",
            "Processed sequence: 48066-48128 (length: 62, class: N)\n",
            "Processed sequence: 48128-48190 (length: 62, class: I)\n",
            "Processed sequence: 48190-48314 (length: 124, class: R)\n",
            "Processed sequence: 48314-48376 (length: 62, class: D)\n",
            "Processed sequence: 48376-48438 (length: 62, class: A)\n",
            "Processed sequence: 48438-48484 (length: 46, class: Q)\n",
            "Processed sequence: 48484-48670 (length: 186, class: S)\n",
            "Processed sequence: 48670-48794 (length: 124, class: L)\n",
            "Processed sequence: 48794-48856 (length: 62, class: W)\n",
            "Processed sequence: 48856-48918 (length: 62, class: O)\n",
            "Processed sequence: 48918-48980 (length: 62, class: G)\n",
            "Processed sequence: 48980-49042 (length: 62, class: U)\n",
            "Processed sequence: 49042-49104 (length: 62, class: C)\n",
            "Processed sequence: 49104-49166 (length: 62, class: T)\n",
            "Processed sequence: 49166-49228 (length: 62, class: K)\n",
            "Processed sequence: 49228-49290 (length: 62, class: B)\n",
            "Processed sequence: 49290-49386 (length: 96, class: V)\n",
            "Processed sequence: 49386-49510 (length: 124, class: M)\n",
            "Processed sequence: 49510-49572 (length: 62, class: F)\n",
            "Processed sequence: 49572-49634 (length: 62, class: I)\n",
            "Processed sequence: 49634-49696 (length: 62, class: B)\n",
            "Processed sequence: 49696-49758 (length: 62, class: T)\n",
            "Processed sequence: 49758-49820 (length: 62, class: U)\n",
            "Processed sequence: 49820-49882 (length: 62, class: M)\n",
            "Processed sequence: 49882-49944 (length: 62, class: S)\n",
            "Processed sequence: 49944-50006 (length: 62, class: D)\n",
            "Processed sequence: 50006-50068 (length: 62, class: O)\n",
            "Processed sequence: 50068-50130 (length: 62, class: N)\n",
            "Processed sequence: 50130-50254 (length: 124, class: Z)\n",
            "Processed sequence: 50254-50316 (length: 62, class: A)\n",
            "Processed sequence: 50316-50378 (length: 62, class: K)\n",
            "Processed sequence: 50378-50440 (length: 62, class: Q)\n",
            "Processed sequence: 50440-50502 (length: 62, class: R)\n",
            "Processed sequence: 50502-50564 (length: 62, class: E)\n",
            "Processed sequence: 50564-50626 (length: 62, class: G)\n",
            "Processed sequence: 50626-50688 (length: 62, class: L)\n",
            "Processed sequence: 50688-50750 (length: 62, class: V)\n",
            "Processed sequence: 50750-50812 (length: 62, class: C)\n",
            "Processed sequence: 50812-50874 (length: 62, class: X)\n",
            "Processed sequence: 50874-50936 (length: 62, class: Z)\n",
            "Processed sequence: 50936-50998 (length: 62, class: N)\n",
            "Processed sequence: 50998-51060 (length: 62, class: G)\n",
            "Processed sequence: 51060-51122 (length: 62, class: S)\n",
            "Processed sequence: 51122-51184 (length: 62, class: B)\n",
            "Processed sequence: 51184-51246 (length: 62, class: O)\n",
            "Processed sequence: 51246-51370 (length: 124, class: L)\n",
            "Processed sequence: 51370-51432 (length: 62, class: M)\n",
            "Processed sequence: 51432-51494 (length: 62, class: U)\n",
            "Processed sequence: 51494-51556 (length: 62, class: F)\n",
            "Processed sequence: 51556-51618 (length: 62, class: R)\n",
            "Processed sequence: 51618-51680 (length: 62, class: D)\n",
            "Processed sequence: 51680-51742 (length: 62, class: Q)\n",
            "Processed sequence: 51742-51804 (length: 62, class: X)\n",
            "Processed sequence: 51804-51866 (length: 62, class: T)\n",
            "Processed sequence: 51866-51928 (length: 62, class: A)\n",
            "Processed sequence: 51928-51990 (length: 62, class: W)\n",
            "Processed sequence: 51990-52052 (length: 62, class: D)\n",
            "Processed sequence: 52052-52114 (length: 62, class: B)\n",
            "Processed sequence: 52114-52176 (length: 62, class: P)\n",
            "Processed sequence: 52176-52238 (length: 62, class: M)\n",
            "Processed sequence: 52238-52300 (length: 62, class: Z)\n",
            "Processed sequence: 52300-52362 (length: 62, class: W)\n",
            "Processed sequence: 52362-52424 (length: 62, class: X)\n",
            "Processed sequence: 52424-52486 (length: 62, class: N)\n",
            "Processed sequence: 52486-52548 (length: 62, class: V)\n",
            "Processed sequence: 52548-52610 (length: 62, class: L)\n",
            "Processed sequence: 52610-52672 (length: 62, class: U)\n",
            "Processed sequence: 52672-52734 (length: 62, class: O)\n",
            "Processed sequence: 52734-52796 (length: 62, class: F)\n",
            "Processed sequence: 52796-52858 (length: 62, class: I)\n",
            "Processed sequence: 52858-52920 (length: 62, class: S)\n",
            "Processed sequence: 52920-52982 (length: 62, class: R)\n",
            "Processed sequence: 52982-53044 (length: 62, class: A)\n",
            "Processed sequence: 53044-53106 (length: 62, class: Q)\n",
            "Processed sequence: 53106-53168 (length: 62, class: G)\n",
            "Processed sequence: 53168-53292 (length: 124, class: K)\n",
            "Processed sequence: 53292-53354 (length: 62, class: S)\n",
            "Processed sequence: 53354-53416 (length: 62, class: Z)\n",
            "Processed sequence: 53416-53478 (length: 62, class: X)\n",
            "Processed sequence: 53478-53540 (length: 62, class: U)\n",
            "Processed sequence: 53540-53602 (length: 62, class: K)\n",
            "Processed sequence: 53602-53664 (length: 62, class: M)\n",
            "Processed sequence: 53664-53726 (length: 62, class: G)\n",
            "Processed sequence: 53726-53788 (length: 62, class: W)\n",
            "Processed sequence: 53788-53850 (length: 62, class: T)\n",
            "Processed sequence: 53850-53974 (length: 124, class: C)\n",
            "Processed sequence: 53974-54036 (length: 62, class: D)\n",
            "Processed sequence: 54036-54098 (length: 62, class: R)\n",
            "Processed sequence: 54098-54160 (length: 62, class: A)\n",
            "Processed sequence: 54160-54222 (length: 62, class: I)\n",
            "Processed sequence: 54222-54284 (length: 62, class: N)\n",
            "Processed sequence: 54284-54346 (length: 62, class: L)\n",
            "Processed sequence: 54346-54408 (length: 62, class: F)\n",
            "Processed sequence: 54408-54470 (length: 62, class: V)\n",
            "Processed sequence: 54470-54594 (length: 124, class: B)\n",
            "Processed sequence: 54594-54656 (length: 62, class: P)\n",
            "Processed sequence: 54656-54718 (length: 62, class: Q)\n",
            "Processed sequence: 54718-54780 (length: 62, class: V)\n",
            "Processed sequence: 54780-54842 (length: 62, class: S)\n",
            "Processed sequence: 54842-54904 (length: 62, class: N)\n",
            "Processed sequence: 54904-54966 (length: 62, class: C)\n",
            "Processed sequence: 54966-55028 (length: 62, class: X)\n",
            "Processed sequence: 55028-55090 (length: 62, class: W)\n",
            "Processed sequence: 55090-55214 (length: 124, class: O)\n",
            "Processed sequence: 55214-55276 (length: 62, class: A)\n",
            "Processed sequence: 55276-55338 (length: 62, class: D)\n",
            "Processed sequence: 55338-55387 (length: 49, class: F)\n",
            "Processed sequence: 55387-55449 (length: 62, class: K)\n",
            "Processed sequence: 55449-55511 (length: 62, class: I)\n",
            "Processed sequence: 55511-55635 (length: 124, class: Z)\n",
            "Processed sequence: 55635-55697 (length: 62, class: T)\n",
            "Processed sequence: 55697-55759 (length: 62, class: U)\n",
            "Processed sequence: 55759-55821 (length: 62, class: V)\n",
            "Processed sequence: 55821-55883 (length: 62, class: B)\n",
            "Processed sequence: 55883-55945 (length: 62, class: L)\n",
            "Processed sequence: 55945-56007 (length: 62, class: N)\n",
            "Processed sequence: 56007-56069 (length: 62, class: P)\n",
            "Processed sequence: 56069-56131 (length: 62, class: Q)\n",
            "Processed sequence: 56131-56193 (length: 62, class: M)\n",
            "Processed sequence: 56193-56255 (length: 62, class: Z)\n",
            "Processed sequence: 56255-56317 (length: 62, class: C)\n",
            "Processed sequence: 56317-56379 (length: 62, class: B)\n",
            "Processed sequence: 56379-56441 (length: 62, class: Z)\n",
            "Processed sequence: 56441-56503 (length: 62, class: V)\n",
            "Processed sequence: 56503-56565 (length: 62, class: L)\n",
            "Processed sequence: 56565-56627 (length: 62, class: U)\n",
            "Processed sequence: 56627-56689 (length: 62, class: S)\n",
            "Processed sequence: 56689-56751 (length: 62, class: X)\n",
            "Processed sequence: 56751-56813 (length: 62, class: A)\n",
            "Processed sequence: 56813-56999 (length: 186, class: N)\n",
            "Processed sequence: 56999-57061 (length: 62, class: P)\n",
            "Processed sequence: 57061-57123 (length: 62, class: D)\n",
            "Processed sequence: 57123-57247 (length: 124, class: O)\n",
            "Processed sequence: 57247-57309 (length: 62, class: G)\n",
            "Processed sequence: 57309-57371 (length: 62, class: Q)\n",
            "Processed sequence: 57371-57433 (length: 62, class: T)\n",
            "Processed sequence: 57433-57495 (length: 62, class: F)\n",
            "Processed sequence: 57495-57557 (length: 62, class: V)\n",
            "Processed sequence: 57557-57619 (length: 62, class: U)\n",
            "Processed sequence: 57619-57681 (length: 62, class: P)\n",
            "Processed sequence: 57681-57743 (length: 62, class: G)\n",
            "Processed sequence: 57743-57805 (length: 62, class: X)\n",
            "Processed sequence: 57805-57867 (length: 62, class: A)\n",
            "Processed sequence: 57867-57929 (length: 62, class: B)\n",
            "Processed sequence: 57929-58053 (length: 124, class: C)\n",
            "Processed sequence: 58053-58115 (length: 62, class: D)\n",
            "Processed sequence: 58115-58301 (length: 186, class: F)\n",
            "Processed sequence: 58301-58363 (length: 62, class: O)\n",
            "Processed sequence: 58363-58425 (length: 62, class: A)\n",
            "Processed sequence: 58425-58549 (length: 124, class: K)\n",
            "Processed sequence: 58549-58611 (length: 62, class: U)\n",
            "Processed sequence: 58611-58673 (length: 62, class: Z)\n",
            "Processed sequence: 58673-58735 (length: 62, class: L)\n",
            "Processed sequence: 58735-58796 (length: 61, class: G)\n",
            "Processed sequence: 58796-58920 (length: 124, class: D)\n",
            "Processed sequence: 58920-58982 (length: 62, class: S)\n",
            "Processed sequence: 58982-59044 (length: 62, class: M)\n",
            "Processed sequence: 59044-59106 (length: 62, class: Q)\n",
            "Processed sequence: 59106-59229 (length: 123, class: N)\n",
            "Processed sequence: 59229-59291 (length: 62, class: C)\n",
            "Processed sequence: 59291-59330 (length: 39, class: R)\n",
            "Processed sequence: 59330-59392 (length: 62, class: V)\n",
            "Processed sequence: 59392-59454 (length: 62, class: I)\n",
            "Processed sequence: 59454-59556 (length: 102, class: W)\n",
            "Processed sequence: 59556-59618 (length: 62, class: T)\n",
            "Processed sequence: 59618-59680 (length: 62, class: B)\n",
            "Processed sequence: 59680-59742 (length: 62, class: O)\n",
            "Processed sequence: 59742-59804 (length: 62, class: Q)\n",
            "Processed sequence: 59804-59866 (length: 62, class: D)\n",
            "Processed sequence: 59866-59923 (length: 57, class: S)\n",
            "Processed sequence: 59923-59985 (length: 62, class: U)\n",
            "Processed sequence: 59985-60047 (length: 62, class: V)\n",
            "Processed sequence: 60047-60109 (length: 62, class: N)\n",
            "Processed sequence: 60109-60171 (length: 62, class: Z)\n",
            "Processed sequence: 60171-60233 (length: 62, class: G)\n",
            "Processed sequence: 60233-60295 (length: 62, class: T)\n",
            "Processed sequence: 60295-60357 (length: 62, class: K)\n",
            "Processed sequence: 60357-60419 (length: 62, class: M)\n",
            "Processed sequence: 60419-60481 (length: 62, class: I)\n",
            "Processed sequence: 60481-60543 (length: 62, class: L)\n",
            "Processed sequence: 60543-60605 (length: 62, class: R)\n",
            "Processed sequence: 60605-60667 (length: 62, class: C)\n",
            "Processed sequence: 60667-60729 (length: 62, class: W)\n",
            "Processed sequence: 60729-60791 (length: 62, class: A)\n",
            "Processed sequence: 60791-60853 (length: 62, class: F)\n",
            "Processed sequence: 60853-60915 (length: 62, class: X)\n",
            "Processed sequence: 60915-60977 (length: 62, class: D)\n",
            "Processed sequence: 60977-61101 (length: 124, class: T)\n",
            "Processed sequence: 61101-61225 (length: 124, class: M)\n",
            "Processed sequence: 61225-61287 (length: 62, class: C)\n",
            "Processed sequence: 61287-61349 (length: 62, class: G)\n",
            "Processed sequence: 61349-61411 (length: 62, class: L)\n",
            "Processed sequence: 61411-61473 (length: 62, class: W)\n",
            "Processed sequence: 61473-61535 (length: 62, class: P)\n",
            "Processed sequence: 61535-61597 (length: 62, class: N)\n",
            "Processed sequence: 61597-61659 (length: 62, class: F)\n",
            "Processed sequence: 61659-61721 (length: 62, class: O)\n",
            "Processed sequence: 61721-61783 (length: 62, class: R)\n",
            "Processed sequence: 61783-61845 (length: 62, class: U)\n",
            "Processed sequence: 61845-61907 (length: 62, class: A)\n",
            "Processed sequence: 61907-61969 (length: 62, class: Q)\n",
            "Processed sequence: 61969-62031 (length: 62, class: I)\n",
            "Processed sequence: 62031-62093 (length: 62, class: X)\n",
            "Processed sequence: 62093-62155 (length: 62, class: Z)\n",
            "Processed sequence: 62155-62217 (length: 62, class: S)\n",
            "Processed sequence: 62217-62279 (length: 62, class: V)\n",
            "Processed sequence: 62279-62341 (length: 62, class: B)\n",
            "Processed sequence: 62341-62403 (length: 62, class: K)\n",
            "Processed sequence: 62403-62465 (length: 62, class: G)\n",
            "Processed sequence: 62465-62527 (length: 62, class: P)\n",
            "Processed sequence: 62527-62589 (length: 62, class: A)\n",
            "Processed sequence: 62589-62651 (length: 62, class: C)\n",
            "Processed sequence: 62651-62745 (length: 94, class: U)\n",
            "Processed sequence: 62745-62807 (length: 62, class: V)\n",
            "Processed sequence: 62807-62869 (length: 62, class: D)\n",
            "Processed sequence: 62869-62931 (length: 62, class: K)\n",
            "Processed sequence: 62931-62993 (length: 62, class: T)\n",
            "Processed sequence: 62993-63055 (length: 62, class: S)\n",
            "Processed sequence: 63055-63117 (length: 62, class: O)\n",
            "Processed sequence: 63117-63179 (length: 62, class: M)\n",
            "Processed sequence: 63179-63241 (length: 62, class: X)\n",
            "Processed sequence: 63241-63303 (length: 62, class: W)\n",
            "Processed sequence: 63303-63365 (length: 62, class: Q)\n",
            "Processed sequence: 63365-63427 (length: 62, class: L)\n",
            "Processed sequence: 63427-63489 (length: 62, class: I)\n",
            "Processed sequence: 63489-63551 (length: 62, class: R)\n",
            "Processed sequence: 63551-63612 (length: 61, class: N)\n",
            "Processed sequence: 63612-63736 (length: 124, class: A)\n",
            "Processed sequence: 63736-63798 (length: 62, class: W)\n",
            "Processed sequence: 63798-63860 (length: 62, class: X)\n",
            "Processed sequence: 63860-63922 (length: 62, class: Z)\n",
            "Processed sequence: 63922-63984 (length: 62, class: U)\n",
            "Processed sequence: 63984-64046 (length: 62, class: S)\n",
            "Processed sequence: 64046-64108 (length: 62, class: K)\n",
            "Processed sequence: 64108-64170 (length: 62, class: C)\n",
            "Processed sequence: 64170-64232 (length: 62, class: O)\n",
            "Processed sequence: 64232-64294 (length: 62, class: B)\n",
            "Processed sequence: 64294-64356 (length: 62, class: Q)\n",
            "Processed sequence: 64356-64418 (length: 62, class: V)\n",
            "Processed sequence: 64418-64480 (length: 62, class: G)\n",
            "Processed sequence: 64480-64542 (length: 62, class: P)\n",
            "Processed sequence: 64542-64604 (length: 62, class: N)\n",
            "Processed sequence: 64604-64666 (length: 62, class: T)\n",
            "Processed sequence: 64666-64728 (length: 62, class: R)\n",
            "Processed sequence: 64728-64790 (length: 62, class: F)\n",
            "Processed sequence: 64790-64852 (length: 62, class: I)\n",
            "Processed sequence: 64852-64914 (length: 62, class: W)\n",
            "Processed sequence: 64914-64976 (length: 62, class: N)\n",
            "Processed sequence: 64976-65100 (length: 124, class: U)\n",
            "Processed sequence: 65100-65162 (length: 62, class: O)\n",
            "Processed sequence: 65162-65224 (length: 62, class: V)\n",
            "Processed sequence: 65224-65286 (length: 62, class: R)\n",
            "Processed sequence: 65286-65348 (length: 62, class: K)\n",
            "Processed sequence: 65348-65410 (length: 62, class: C)\n",
            "Processed sequence: 65410-65472 (length: 62, class: A)\n",
            "Processed sequence: 65472-65534 (length: 62, class: Z)\n",
            "Processed sequence: 65534-65596 (length: 62, class: M)\n",
            "Processed sequence: 65596-65658 (length: 62, class: W)\n",
            "Processed sequence: 65658-65720 (length: 62, class: X)\n",
            "Processed sequence: 65720-65782 (length: 62, class: I)\n",
            "Processed sequence: 65782-65844 (length: 62, class: T)\n",
            "Processed sequence: 65844-65906 (length: 62, class: B)\n",
            "Processed sequence: 65906-65968 (length: 62, class: G)\n",
            "Processed sequence: 65968-66030 (length: 62, class: F)\n",
            "Processed sequence: 66030-66092 (length: 62, class: P)\n",
            "Processed sequence: 66092-66154 (length: 62, class: L)\n",
            "Processed sequence: 66154-66216 (length: 62, class: D)\n",
            "Processed sequence: 66216-66278 (length: 62, class: T)\n",
            "Processed sequence: 66278-66340 (length: 62, class: O)\n",
            "Processed sequence: 66340-66402 (length: 62, class: I)\n",
            "Processed sequence: 66402-66464 (length: 62, class: S)\n",
            "Processed sequence: 66464-66588 (length: 124, class: T)\n",
            "Processed sequence: 66588-66650 (length: 62, class: B)\n",
            "Processed sequence: 66650-66712 (length: 62, class: G)\n",
            "Processed sequence: 66712-66774 (length: 62, class: F)\n",
            "Processed sequence: 66774-66836 (length: 62, class: K)\n",
            "Processed sequence: 66836-66898 (length: 62, class: Z)\n",
            "Processed sequence: 66898-67022 (length: 124, class: Q)\n",
            "Processed sequence: 67022-67084 (length: 62, class: M)\n",
            "Processed sequence: 67084-67146 (length: 62, class: A)\n",
            "Processed sequence: 67146-67208 (length: 62, class: R)\n",
            "Processed sequence: 67208-67270 (length: 62, class: P)\n",
            "Processed sequence: 67270-67332 (length: 62, class: C)\n",
            "Processed sequence: 67332-67394 (length: 62, class: V)\n",
            "Processed sequence: 67394-67518 (length: 124, class: N)\n",
            "Processed sequence: 67518-67580 (length: 62, class: D)\n",
            "Processed sequence: 67580-67704 (length: 124, class: W)\n",
            "Processed sequence: 67704-67766 (length: 62, class: U)\n",
            "Processed sequence: 67766-67828 (length: 62, class: M)\n",
            "Processed sequence: 67828-67890 (length: 62, class: B)\n",
            "Processed sequence: 67890-67952 (length: 62, class: V)\n",
            "Processed sequence: 67952-68014 (length: 62, class: R)\n",
            "Processed sequence: 68014-68138 (length: 124, class: T)\n",
            "Processed sequence: 68138-68200 (length: 62, class: X)\n",
            "Processed sequence: 68200-68262 (length: 62, class: C)\n",
            "Processed sequence: 68262-68324 (length: 62, class: D)\n",
            "Processed sequence: 68324-68386 (length: 62, class: L)\n",
            "Processed sequence: 68386-68448 (length: 62, class: I)\n",
            "Processed sequence: 68448-68510 (length: 62, class: G)\n",
            "Processed sequence: 68510-68572 (length: 62, class: K)\n",
            "Processed sequence: 68572-68634 (length: 62, class: N)\n",
            "Processed sequence: 68634-68696 (length: 62, class: F)\n",
            "Processed sequence: 68696-68820 (length: 124, class: U)\n",
            "Processed sequence: 68820-68882 (length: 62, class: O)\n",
            "Processed sequence: 68882-68944 (length: 62, class: A)\n",
            "Processed sequence: 68944-68998 (length: 54, class: W)\n",
            "Processed sequence: 68998-69060 (length: 62, class: S)\n",
            "Processed sequence: 69060-69184 (length: 124, class: Q)\n",
            "Processed sequence: 69184-69246 (length: 62, class: T)\n",
            "Processed sequence: 69246-69299 (length: 53, class: M)\n",
            "Processed sequence: 69299-69361 (length: 62, class: C)\n",
            "Processed sequence: 69361-69423 (length: 62, class: I)\n",
            "Processed sequence: 69423-69485 (length: 62, class: B)\n",
            "Processed sequence: 69485-69547 (length: 62, class: G)\n",
            "Processed sequence: 69547-69609 (length: 62, class: Z)\n",
            "Processed sequence: 69609-69733 (length: 124, class: L)\n",
            "Processed sequence: 69733-69795 (length: 62, class: P)\n",
            "Processed sequence: 69795-69856 (length: 61, class: W)\n",
            "Processed sequence: 69856-69918 (length: 62, class: Q)\n",
            "Processed sequence: 69918-69980 (length: 62, class: K)\n",
            "Processed sequence: 69980-70042 (length: 62, class: V)\n",
            "Processed sequence: 70042-70104 (length: 62, class: X)\n",
            "Processed sequence: 70104-70166 (length: 62, class: H)\n",
            "Processed sequence: 70166-70228 (length: 62, class: R)\n",
            "Processed sequence: 70228-70290 (length: 62, class: N)\n",
            "Processed sequence: 70290-70352 (length: 62, class: U)\n",
            "Processed sequence: 70352-70414 (length: 62, class: D)\n",
            "Processed sequence: 70414-70476 (length: 62, class: A)\n",
            "Processed sequence: 70476-70600 (length: 124, class: G)\n",
            "Processed sequence: 70600-70662 (length: 62, class: A)\n",
            "Processed sequence: 70662-70724 (length: 62, class: R)\n",
            "Processed sequence: 70724-70848 (length: 124, class: N)\n",
            "Processed sequence: 70848-70910 (length: 62, class: Q)\n",
            "Processed sequence: 70910-70972 (length: 62, class: B)\n",
            "Processed sequence: 70972-71034 (length: 62, class: C)\n",
            "Processed sequence: 71034-71096 (length: 62, class: I)\n",
            "Processed sequence: 71096-71158 (length: 62, class: P)\n",
            "Processed sequence: 71158-71220 (length: 62, class: F)\n",
            "Processed sequence: 71220-71282 (length: 62, class: O)\n",
            "Processed sequence: 71282-71344 (length: 62, class: L)\n",
            "Processed sequence: 71344-71406 (length: 62, class: K)\n",
            "Processed sequence: 71406-71468 (length: 62, class: T)\n",
            "Processed sequence: 71468-71530 (length: 62, class: X)\n",
            "Processed sequence: 71530-71592 (length: 62, class: D)\n",
            "Processed sequence: 71592-71654 (length: 62, class: V)\n",
            "Processed sequence: 71654-71778 (length: 124, class: S)\n",
            "Processed sequence: 71778-71840 (length: 62, class: W)\n",
            "Processed sequence: 71840-71902 (length: 62, class: S)\n",
            "Processed sequence: 71902-71964 (length: 62, class: U)\n",
            "Processed sequence: 71964-72026 (length: 62, class: O)\n",
            "Processed sequence: 72026-72088 (length: 62, class: I)\n",
            "Processed sequence: 72088-72150 (length: 62, class: K)\n",
            "Processed sequence: 72150-72212 (length: 62, class: V)\n",
            "Processed sequence: 72212-72274 (length: 62, class: G)\n",
            "Processed sequence: 72274-72336 (length: 62, class: V)\n",
            "Processed sequence: 72336-72398 (length: 62, class: N)\n",
            "Processed sequence: 72398-72460 (length: 62, class: Q)\n",
            "Processed sequence: 72460-72522 (length: 62, class: B)\n",
            "Processed sequence: 72522-72584 (length: 62, class: C)\n",
            "Processed sequence: 72584-72646 (length: 62, class: K)\n",
            "Processed sequence: 72646-72708 (length: 62, class: T)\n",
            "Processed sequence: 72708-72770 (length: 62, class: O)\n",
            "Processed sequence: 72770-72832 (length: 62, class: U)\n",
            "Processed sequence: 72832-72894 (length: 62, class: W)\n",
            "Processed sequence: 72894-72956 (length: 62, class: Z)\n",
            "Processed sequence: 72956-73018 (length: 62, class: X)\n",
            "Processed sequence: 73018-73080 (length: 62, class: P)\n",
            "Processed sequence: 73080-73142 (length: 62, class: M)\n",
            "Processed sequence: 73142-73204 (length: 62, class: A)\n",
            "Processed sequence: 73204-73266 (length: 62, class: F)\n",
            "Processed sequence: 73266-73328 (length: 62, class: S)\n",
            "Processed sequence: 73328-73390 (length: 62, class: R)\n",
            "Processed sequence: 73390-73452 (length: 62, class: L)\n",
            "Processed sequence: 73452-73511 (length: 59, class: W)\n",
            "Processed sequence: 73511-73573 (length: 62, class: C)\n",
            "Processed sequence: 73573-73635 (length: 62, class: Z)\n",
            "Processed sequence: 73635-73697 (length: 62, class: K)\n",
            "Processed sequence: 73697-73759 (length: 62, class: P)\n",
            "Processed sequence: 73759-73821 (length: 62, class: U)\n",
            "Processed sequence: 73821-73883 (length: 62, class: T)\n",
            "Processed sequence: 73883-74007 (length: 124, class: M)\n",
            "Processed sequence: 74007-74069 (length: 62, class: S)\n",
            "Processed sequence: 74069-74131 (length: 62, class: G)\n",
            "Processed sequence: 74131-74193 (length: 62, class: X)\n",
            "Processed sequence: 74193-74255 (length: 62, class: A)\n",
            "Processed sequence: 74255-74317 (length: 62, class: N)\n",
            "Processed sequence: 74317-74379 (length: 62, class: P)\n",
            "Processed sequence: 74379-74441 (length: 62, class: L)\n",
            "Processed sequence: 74441-74503 (length: 62, class: B)\n",
            "Processed sequence: 74503-74565 (length: 62, class: I)\n",
            "Processed sequence: 74565-74627 (length: 62, class: R)\n",
            "Processed sequence: 74627-74689 (length: 62, class: O)\n",
            "Processed sequence: 74689-74751 (length: 62, class: F)\n",
            "Processed sequence: 74751-74813 (length: 62, class: D)\n",
            "Processed sequence: 74813-74875 (length: 62, class: X)\n",
            "Processed sequence: 74875-74937 (length: 62, class: R)\n",
            "Processed sequence: 74937-74990 (length: 53, class: W)\n",
            "Processed sequence: 74990-75052 (length: 62, class: L)\n",
            "Processed sequence: 75052-75114 (length: 62, class: I)\n",
            "Processed sequence: 75114-75176 (length: 62, class: P)\n",
            "Processed sequence: 75176-75238 (length: 62, class: C)\n",
            "Processed sequence: 75238-75300 (length: 62, class: U)\n",
            "Processed sequence: 75300-75362 (length: 62, class: A)\n",
            "Processed sequence: 75362-75424 (length: 62, class: O)\n",
            "Processed sequence: 75424-75486 (length: 62, class: N)\n",
            "Processed sequence: 75486-75548 (length: 62, class: Z)\n",
            "Processed sequence: 75548-75610 (length: 62, class: F)\n",
            "Processed sequence: 75610-75672 (length: 62, class: M)\n",
            "Processed sequence: 75672-75734 (length: 62, class: G)\n",
            "Processed sequence: 75734-75796 (length: 62, class: B)\n",
            "Processed sequence: 75796-75920 (length: 124, class: Q)\n",
            "Processed sequence: 75920-75982 (length: 62, class: S)\n",
            "Processed sequence: 75982-76044 (length: 62, class: T)\n",
            "Processed sequence: 76044-76106 (length: 62, class: I)\n",
            "Processed sequence: 76106-76168 (length: 62, class: W)\n",
            "Processed sequence: 76168-76230 (length: 62, class: T)\n",
            "Processed sequence: 76230-76292 (length: 62, class: K)\n",
            "Processed sequence: 76292-76354 (length: 62, class: U)\n",
            "Processed sequence: 76354-76478 (length: 124, class: Z)\n",
            "Processed sequence: 76478-76540 (length: 62, class: D)\n",
            "Processed sequence: 76540-76602 (length: 62, class: L)\n",
            "Processed sequence: 76602-76664 (length: 62, class: Q)\n",
            "Processed sequence: 76664-76726 (length: 62, class: R)\n",
            "Processed sequence: 76726-76788 (length: 62, class: X)\n",
            "Processed sequence: 76788-76912 (length: 124, class: O)\n",
            "Processed sequence: 76912-76974 (length: 62, class: N)\n",
            "Processed sequence: 76974-77036 (length: 62, class: G)\n",
            "Processed sequence: 77036-77098 (length: 62, class: S)\n",
            "Processed sequence: 77098-77160 (length: 62, class: M)\n",
            "Processed sequence: 77160-77222 (length: 62, class: F)\n",
            "Processed sequence: 77222-77284 (length: 62, class: P)\n",
            "Processed sequence: 77284-77346 (length: 62, class: V)\n",
            "Processed sequence: 77346-77469 (length: 123, class: C)\n",
            "Processed sequence: 77469-77531 (length: 62, class: D)\n",
            "Processed sequence: 77531-77593 (length: 62, class: Q)\n",
            "Processed sequence: 77593-77655 (length: 62, class: B)\n",
            "Processed sequence: 77655-77717 (length: 62, class: W)\n",
            "Processed sequence: 77717-77779 (length: 62, class: V)\n",
            "Processed sequence: 77779-77841 (length: 62, class: I)\n",
            "Processed sequence: 77841-77903 (length: 62, class: T)\n",
            "Processed sequence: 77903-77965 (length: 62, class: R)\n",
            "Processed sequence: 77965-78027 (length: 62, class: M)\n",
            "Processed sequence: 78027-78089 (length: 62, class: Z)\n",
            "Processed sequence: 78089-78151 (length: 62, class: S)\n",
            "Processed sequence: 78151-78213 (length: 62, class: A)\n",
            "Processed sequence: 78213-78275 (length: 62, class: F)\n",
            "Processed sequence: 78275-78337 (length: 62, class: N)\n",
            "Processed sequence: 78337-78399 (length: 62, class: P)\n",
            "Processed sequence: 78399-78461 (length: 62, class: X)\n",
            "Processed sequence: 78461-78523 (length: 62, class: O)\n",
            "Processed sequence: 78523-78709 (length: 186, class: G)\n",
            "Processed sequence: 78709-78771 (length: 62, class: L)\n",
            "Processed sequence: 78771-78833 (length: 62, class: V)\n",
            "Processed sequence: 78833-78895 (length: 62, class: O)\n",
            "Processed sequence: 78895-78957 (length: 62, class: U)\n",
            "Processed sequence: 78957-79019 (length: 62, class: D)\n",
            "Processed sequence: 79019-79059 (length: 40, class: W)\n",
            "Warning: Sequence at index 79059 (class A) has fewer than 25 frames (1). Skipping.\n",
            "Processed sequence: 79060-79122 (length: 62, class: V)\n",
            "Processed sequence: 79122-79184 (length: 62, class: N)\n",
            "Processed sequence: 79184-79243 (length: 59, class: T)\n",
            "Processed sequence: 79243-79305 (length: 62, class: W)\n",
            "Processed sequence: 79305-79367 (length: 62, class: O)\n",
            "Processed sequence: 79367-79429 (length: 62, class: A)\n",
            "Processed sequence: 79429-79491 (length: 62, class: Q)\n",
            "Processed sequence: 79491-79546 (length: 55, class: M)\n",
            "Processed sequence: 79546-79607 (length: 61, class: W)\n",
            "Processed sequence: 79607-79661 (length: 54, class: Q)\n",
            "Processed sequence: 79661-79723 (length: 62, class: P)\n",
            "Processed sequence: 79723-79785 (length: 62, class: L)\n",
            "Processed sequence: 79785-79847 (length: 62, class: C)\n",
            "Processed sequence: 79847-79909 (length: 62, class: W)\n",
            "Processed sequence: 79909-79971 (length: 62, class: K)\n",
            "Processed sequence: 79971-80033 (length: 62, class: U)\n",
            "Processed sequence: 80033-80095 (length: 62, class: Q)\n",
            "Processed sequence: 80095-80157 (length: 62, class: M)\n",
            "Processed sequence: 80157-80219 (length: 62, class: R)\n",
            "Processed sequence: 80219-80281 (length: 62, class: D)\n",
            "Processed sequence: 80281-80343 (length: 62, class: P)\n",
            "Processed sequence: 80343-80405 (length: 62, class: I)\n",
            "Processed sequence: 80405-80467 (length: 62, class: N)\n",
            "Processed sequence: 80467-80529 (length: 62, class: T)\n",
            "Processed sequence: 80529-80591 (length: 62, class: V)\n",
            "Processed sequence: 80591-80651 (length: 60, class: W)\n",
            "Processed sequence: 80651-80713 (length: 62, class: L)\n",
            "Processed sequence: 80713-80743 (length: 30, class: Q)\n",
            "Processed sequence: 80743-80805 (length: 62, class: V)\n",
            "Processed sequence: 80805-80867 (length: 62, class: O)\n",
            "Processed sequence: 80867-80929 (length: 62, class: R)\n",
            "Processed sequence: 80929-80991 (length: 62, class: U)\n",
            "Processed sequence: 80991-81053 (length: 62, class: D)\n",
            "Processed sequence: 81053-81115 (length: 62, class: B)\n",
            "Processed sequence: 81115-81177 (length: 62, class: G)\n",
            "Processed sequence: 81177-81239 (length: 62, class: O)\n",
            "Processed sequence: 81239-81301 (length: 62, class: K)\n",
            "Processed sequence: 81301-81363 (length: 62, class: G)\n",
            "Processed sequence: 81363-81425 (length: 62, class: R)\n",
            "Processed sequence: 81425-81487 (length: 62, class: P)\n",
            "Processed sequence: 81487-81549 (length: 62, class: L)\n",
            "Processed sequence: 81549-81611 (length: 62, class: C)\n",
            "Processed sequence: 81611-81673 (length: 62, class: D)\n",
            "Processed sequence: 81673-81793 (length: 120, class: F)\n",
            "Processed sequence: 81793-81855 (length: 62, class: Z)\n",
            "Processed sequence: 81855-81917 (length: 62, class: Q)\n",
            "Processed sequence: 81917-81979 (length: 62, class: P)\n",
            "Processed sequence: 81979-82041 (length: 62, class: A)\n",
            "Processed sequence: 82041-82103 (length: 62, class: D)\n",
            "Processed sequence: 82103-82164 (length: 61, class: W)\n",
            "Processed sequence: 82164-82226 (length: 62, class: O)\n",
            "Processed sequence: 82226-82288 (length: 62, class: L)\n",
            "Processed sequence: 82288-82331 (length: 43, class: G)\n",
            "Processed sequence: 82331-82393 (length: 62, class: I)\n",
            "Processed sequence: 82393-82443 (length: 50, class: K)\n",
            "Processed sequence: 82443-82505 (length: 62, class: A)\n",
            "Processed sequence: 82505-82567 (length: 62, class: X)\n",
            "Processed sequence: 82567-82629 (length: 62, class: K)\n",
            "Processed sequence: 82629-82691 (length: 62, class: M)\n",
            "Processed sequence: 82691-82753 (length: 62, class: V)\n",
            "Processed sequence: 82753-82815 (length: 62, class: F)\n",
            "Processed sequence: 82815-82877 (length: 62, class: L)\n",
            "Processed sequence: 82877-82939 (length: 62, class: C)\n",
            "Processed sequence: 82939-83001 (length: 62, class: B)\n",
            "Processed sequence: 83001-83063 (length: 62, class: A)\n",
            "Processed sequence: 83063-83125 (length: 62, class: T)\n",
            "Processed sequence: 83125-83187 (length: 62, class: X)\n",
            "Processed sequence: 83187-83249 (length: 62, class: U)\n",
            "Processed sequence: 83249-83311 (length: 62, class: I)\n",
            "Processed sequence: 83311-83373 (length: 62, class: W)\n",
            "Processed sequence: 83373-83435 (length: 62, class: O)\n",
            "Processed sequence: 83435-83497 (length: 62, class: Z)\n",
            "Processed sequence: 83497-83559 (length: 62, class: D)\n",
            "Processed sequence: 83559-83621 (length: 62, class: N)\n",
            "Processed sequence: 83621-83683 (length: 62, class: P)\n",
            "Processed sequence: 83683-83745 (length: 62, class: G)\n",
            "Processed sequence: 83745-83807 (length: 62, class: R)\n",
            "Processed sequence: 83807-83869 (length: 62, class: X)\n",
            "Processed sequence: 83869-83931 (length: 62, class: N)\n",
            "Processed sequence: 83931-83993 (length: 62, class: O)\n",
            "Processed sequence: 83993-84055 (length: 62, class: Q)\n",
            "Processed sequence: 84055-84117 (length: 62, class: P)\n",
            "Processed sequence: 84117-84179 (length: 62, class: W)\n",
            "Processed sequence: 84179-84241 (length: 62, class: M)\n",
            "Processed sequence: 84241-84303 (length: 62, class: D)\n",
            "Processed sequence: 84303-84365 (length: 62, class: I)\n",
            "Processed sequence: 84365-84427 (length: 62, class: T)\n",
            "Processed sequence: 84427-84489 (length: 62, class: L)\n",
            "Processed sequence: 84489-84551 (length: 62, class: B)\n",
            "Processed sequence: 84551-84613 (length: 62, class: V)\n",
            "Processed sequence: 84613-84675 (length: 62, class: U)\n",
            "Processed sequence: 84675-84737 (length: 62, class: K)\n",
            "Processed sequence: 84737-84799 (length: 62, class: A)\n",
            "Processed sequence: 84799-84861 (length: 62, class: U)\n",
            "Warning: Sequence at index 84861 (class G) has fewer than 25 frames (1). Skipping.\n",
            "Processed sequence: 84862-84924 (length: 62, class: T)\n",
            "Processed sequence: 84924-84986 (length: 62, class: S)\n",
            "Processed sequence: 84986-85048 (length: 62, class: A)\n",
            "Processed sequence: 85048-85131 (length: 83, class: R)\n",
            "Processed sequence: 85131-85193 (length: 62, class: K)\n",
            "Processed sequence: 85193-85255 (length: 62, class: Q)\n",
            "Processed sequence: 85255-85317 (length: 62, class: Z)\n",
            "Processed sequence: 85317-85379 (length: 62, class: B)\n",
            "Processed sequence: 85379-85441 (length: 62, class: C)\n",
            "Processed sequence: 85441-85503 (length: 62, class: O)\n",
            "Processed sequence: 85503-85565 (length: 62, class: P)\n",
            "Processed sequence: 85565-85627 (length: 62, class: F)\n",
            "Processed sequence: 85627-85689 (length: 62, class: L)\n",
            "Warning: Sequence at index 85689 (class G) has fewer than 25 frames (2). Skipping.\n",
            "Processed sequence: 85691-85753 (length: 62, class: S)\n",
            "Processed sequence: 85753-85877 (length: 124, class: T)\n",
            "Processed sequence: 85877-85939 (length: 62, class: N)\n",
            "Processed sequence: 85939-86001 (length: 62, class: O)\n",
            "Processed sequence: 86001-86063 (length: 62, class: K)\n",
            "Processed sequence: 86063-86125 (length: 62, class: V)\n",
            "Processed sequence: 86125-86187 (length: 62, class: X)\n",
            "Processed sequence: 86187-86249 (length: 62, class: U)\n",
            "Processed sequence: 86249-86373 (length: 124, class: D)\n",
            "Processed sequence: 86373-86435 (length: 62, class: I)\n",
            "Processed sequence: 86435-86497 (length: 62, class: W)\n",
            "Processed sequence: 86497-86621 (length: 124, class: B)\n",
            "Processed sequence: 86621-86683 (length: 62, class: L)\n",
            "Processed sequence: 86683-86745 (length: 62, class: F)\n",
            "Processed sequence: 86745-86807 (length: 62, class: Z)\n",
            "Processed sequence: 86807-86869 (length: 62, class: M)\n",
            "Processed sequence: 86869-86931 (length: 62, class: G)\n",
            "Processed sequence: 86931-86993 (length: 62, class: Q)\n",
            "Processed sequence: 86993-87055 (length: 62, class: C)\n",
            "Processed sequence: 87055-87117 (length: 62, class: A)\n",
            "Processed sequence: 87117-87179 (length: 62, class: Q)\n",
            "Processed sequence: 87179-87241 (length: 62, class: 2)\n",
            "Processed sequence: 87241-87303 (length: 62, class: A)\n",
            "Processed sequence: 87303-87365 (length: 62, class: F)\n",
            "Processed sequence: 87365-87427 (length: 62, class: L)\n",
            "Processed sequence: 87427-87489 (length: 62, class: X)\n",
            "Processed sequence: 87489-87551 (length: 62, class: B)\n",
            "Processed sequence: 87551-87613 (length: 62, class: T)\n",
            "Processed sequence: 87613-87675 (length: 62, class: O)\n",
            "Processed sequence: 87675-87737 (length: 62, class: C)\n",
            "Processed sequence: 87737-87799 (length: 62, class: W)\n",
            "Processed sequence: 87799-87861 (length: 62, class: N)\n",
            "Processed sequence: 87861-87923 (length: 62, class: U)\n",
            "Processed sequence: 87923-87985 (length: 62, class: V)\n",
            "Processed sequence: 87985-88047 (length: 62, class: N)\n",
            "Processed sequence: 88047-88109 (length: 62, class: M)\n",
            "Processed sequence: 88109-88171 (length: 62, class: S)\n",
            "Processed sequence: 88171-88233 (length: 62, class: K)\n",
            "Processed sequence: 88233-88295 (length: 62, class: D)\n",
            "Warning: Sequence at index 88295 (class G) has fewer than 25 frames (24). Skipping.\n",
            "Processed sequence: 88319-88381 (length: 62, class: N)\n",
            "Processed sequence: 88381-88443 (length: 62, class: T)\n",
            "Processed sequence: 88443-88505 (length: 62, class: O)\n",
            "Processed sequence: 88505-88567 (length: 62, class: R)\n",
            "Processed sequence: 88567-88629 (length: 62, class: M)\n",
            "Processed sequence: 88629-88691 (length: 62, class: B)\n",
            "Processed sequence: 88691-88753 (length: 62, class: I)\n",
            "Processed sequence: 88753-88815 (length: 62, class: V)\n",
            "Processed sequence: 88815-88877 (length: 62, class: A)\n",
            "Processed sequence: 88877-88939 (length: 62, class: D)\n",
            "Processed sequence: 88939-89063 (length: 124, class: Q)\n",
            "Processed sequence: 89063-89125 (length: 62, class: L)\n",
            "Processed sequence: 89125-89187 (length: 62, class: S)\n",
            "Processed sequence: 89187-89249 (length: 62, class: Z)\n",
            "Processed sequence: 89249-89311 (length: 62, class: K)\n",
            "Processed sequence: 89311-89373 (length: 62, class: U)\n",
            "Processed sequence: 89373-89435 (length: 62, class: G)\n",
            "Processed sequence: 89435-89497 (length: 62, class: F)\n",
            "Processed sequence: 89497-89559 (length: 62, class: W)\n",
            "Processed sequence: 89559-89683 (length: 124, class: C)\n",
            "Processed sequence: 89683-89745 (length: 62, class: I)\n",
            "Processed sequence: 89745-89807 (length: 62, class: U)\n",
            "Processed sequence: 89807-89869 (length: 62, class: G)\n",
            "Processed sequence: 89869-89931 (length: 62, class: Q)\n",
            "Processed sequence: 89931-89993 (length: 62, class: F)\n",
            "Processed sequence: 89993-90055 (length: 62, class: Z)\n",
            "Processed sequence: 90055-90117 (length: 62, class: B)\n",
            "Processed sequence: 90117-90179 (length: 62, class: A)\n",
            "Processed sequence: 90179-90241 (length: 62, class: P)\n",
            "Processed sequence: 90241-90303 (length: 62, class: S)\n",
            "Processed sequence: 90303-90365 (length: 62, class: T)\n",
            "Processed sequence: 90365-90427 (length: 62, class: K)\n",
            "Processed sequence: 90427-90489 (length: 62, class: N)\n",
            "Processed sequence: 90489-90551 (length: 62, class: W)\n",
            "Processed sequence: 90551-90613 (length: 62, class: D)\n",
            "Processed sequence: 90613-90675 (length: 62, class: M)\n",
            "Processed sequence: 90675-90737 (length: 62, class: L)\n",
            "Processed sequence: 90737-90799 (length: 62, class: V)\n",
            "Processed sequence: 90799-90861 (length: 62, class: O)\n",
            "Processed sequence: 90861-90985 (length: 124, class: R)\n",
            "Processed sequence: 90985-91027 (length: 42, class: S)\n",
            "Processed sequence: 91027-91089 (length: 62, class: O)\n",
            "Processed sequence: 91089-91151 (length: 62, class: K)\n",
            "Processed sequence: 91151-91213 (length: 62, class: B)\n",
            "Processed sequence: 91213-91275 (length: 62, class: G)\n",
            "Processed sequence: 91275-91337 (length: 62, class: T)\n",
            "Processed sequence: 91337-91399 (length: 62, class: A)\n",
            "Processed sequence: 91399-91461 (length: 62, class: S)\n",
            "Processed sequence: 91461-91523 (length: 62, class: O)\n",
            "Processed sequence: 91523-91585 (length: 62, class: I)\n",
            "Processed sequence: 91585-91709 (length: 124, class: Z)\n",
            "Processed sequence: 91709-91771 (length: 62, class: R)\n",
            "Processed sequence: 91771-91833 (length: 62, class: V)\n",
            "Processed sequence: 91833-91895 (length: 62, class: P)\n",
            "Processed sequence: 91895-91957 (length: 62, class: C)\n",
            "Processed sequence: 91957-92019 (length: 62, class: M)\n",
            "Processed sequence: 92019-92074 (length: 55, class: W)\n",
            "Processed sequence: 92074-92136 (length: 62, class: U)\n",
            "Processed sequence: 92136-92198 (length: 62, class: F)\n",
            "Processed sequence: 92198-92321 (length: 123, class: Q)\n",
            "Processed sequence: 92321-92383 (length: 62, class: X)\n",
            "Processed sequence: 92383-92445 (length: 62, class: L)\n",
            "Processed sequence: 92445-92507 (length: 62, class: O)\n",
            "Processed sequence: 92507-92569 (length: 62, class: Q)\n",
            "Processed sequence: 92569-92599 (length: 30, class: G)\n",
            "Processed sequence: 92599-92661 (length: 62, class: C)\n",
            "Processed sequence: 92661-92723 (length: 62, class: F)\n",
            "Processed sequence: 92723-92785 (length: 62, class: O)\n",
            "Processed sequence: 92785-92847 (length: 62, class: I)\n",
            "Processed sequence: 92847-92909 (length: 62, class: L)\n",
            "Processed sequence: 92909-92971 (length: 62, class: S)\n",
            "Processed sequence: 92971-93033 (length: 62, class: B)\n",
            "Processed sequence: 93033-93095 (length: 62, class: A)\n",
            "Processed sequence: 93095-93157 (length: 62, class: Z)\n",
            "Processed sequence: 93157-93219 (length: 62, class: P)\n",
            "Processed sequence: 93219-93281 (length: 62, class: U)\n",
            "Processed sequence: 93281-93343 (length: 62, class: Q)\n",
            "Processed sequence: 93343-93405 (length: 62, class: R)\n",
            "Processed sequence: 93405-93529 (length: 124, class: X)\n",
            "Processed sequence: 93529-93591 (length: 62, class: W)\n",
            "Processed sequence: 93591-93653 (length: 62, class: K)\n",
            "Processed sequence: 93653-93715 (length: 62, class: V)\n",
            "Processed sequence: 93715-93777 (length: 62, class: I)\n",
            "Processed sequence: 93777-93836 (length: 59, class: F)\n",
            "Processed sequence: 93836-93898 (length: 62, class: T)\n",
            "Processed sequence: 93898-93960 (length: 62, class: Z)\n",
            "Processed sequence: 93960-94022 (length: 62, class: Q)\n",
            "Processed sequence: 94022-94084 (length: 62, class: W)\n",
            "Processed sequence: 94084-94146 (length: 62, class: C)\n",
            "Processed sequence: 94146-94208 (length: 62, class: O)\n",
            "Processed sequence: 94208-94270 (length: 62, class: K)\n",
            "Processed sequence: 94270-94332 (length: 62, class: L)\n",
            "Processed sequence: 94332-94394 (length: 62, class: A)\n",
            "Processed sequence: 94394-94456 (length: 62, class: D)\n",
            "Processed sequence: 94456-94518 (length: 62, class: B)\n",
            "Processed sequence: 94518-94580 (length: 62, class: M)\n",
            "Processed sequence: 94580-94640 (length: 60, class: G)\n",
            "Processed sequence: 94640-94702 (length: 62, class: R)\n",
            "Processed sequence: 94702-94764 (length: 62, class: S)\n",
            "Processed sequence: 94764-94826 (length: 62, class: U)\n",
            "Processed sequence: 94826-94888 (length: 62, class: N)\n",
            "Processed sequence: 94888-94950 (length: 62, class: V)\n",
            "Processed sequence: 94950-95012 (length: 62, class: N)\n",
            "Processed sequence: 95012-95074 (length: 62, class: V)\n",
            "Processed sequence: 95074-95136 (length: 62, class: B)\n",
            "Processed sequence: 95136-95198 (length: 62, class: D)\n",
            "Processed sequence: 95198-95260 (length: 62, class: C)\n",
            "Processed sequence: 95260-95322 (length: 62, class: Z)\n",
            "Processed sequence: 95322-95384 (length: 62, class: P)\n",
            "Processed sequence: 95384-95446 (length: 62, class: K)\n",
            "Processed sequence: 95446-95508 (length: 62, class: T)\n",
            "Processed sequence: 95508-95570 (length: 62, class: W)\n",
            "Processed sequence: 95570-95632 (length: 62, class: G)\n",
            "Processed sequence: 95632-95694 (length: 62, class: F)\n",
            "Processed sequence: 95694-95756 (length: 62, class: X)\n",
            "Processed sequence: 95756-95818 (length: 62, class: R)\n",
            "Processed sequence: 95818-95880 (length: 62, class: U)\n",
            "Processed sequence: 95880-95942 (length: 62, class: O)\n",
            "Processed sequence: 95942-96004 (length: 62, class: I)\n",
            "Processed sequence: 96004-96066 (length: 62, class: M)\n",
            "Processed sequence: 96066-96128 (length: 62, class: Q)\n",
            "Processed sequence: 96128-96190 (length: 62, class: S)\n",
            "Processed sequence: 96190-96252 (length: 62, class: C)\n",
            "X_test shape: (4269, 25, 84)\n",
            "y_test shape: (4269,)\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "Overall Test Accuracy: 0.7807\n",
            "\n",
            "Per-Class Performance:\n",
            "Class 'F': 39/57 correct, Accuracy: 0.6842\n",
            "Class 'D': 55/70 correct, Accuracy: 0.7857\n",
            "Class 'P': 41/55 correct, Accuracy: 0.7455\n",
            "Class 'K': 55/62 correct, Accuracy: 0.8871\n",
            "Class 'O': 67/70 correct, Accuracy: 0.9571\n",
            "Class 'H': 1/1 correct, Accuracy: 1.0000\n",
            "Class '2': 0/2 correct, Accuracy: 0.0000\n",
            "Class 'Y': 0/1 correct, Accuracy: 0.0000\n",
            "Class 'B': 57/65 correct, Accuracy: 0.8769\n",
            "Class 'I': 50/64 correct, Accuracy: 0.7812\n",
            "Class 'V': 66/72 correct, Accuracy: 0.9167\n",
            "Class 'M': 49/70 correct, Accuracy: 0.7000\n",
            "Class 'Z': 43/50 correct, Accuracy: 0.8600\n",
            "Class 'G': 63/72 correct, Accuracy: 0.8750\n",
            "Class 'N': 47/66 correct, Accuracy: 0.7121\n",
            "Class 'A': 46/67 correct, Accuracy: 0.6866\n",
            "Class 'Q': 26/69 correct, Accuracy: 0.3768\n",
            "Class 'W': 66/71 correct, Accuracy: 0.9296\n",
            "Class 'E': 2/3 correct, Accuracy: 0.6667\n",
            "Class 'X': 40/44 correct, Accuracy: 0.9091\n",
            "Class 'T': 26/60 correct, Accuracy: 0.4333\n",
            "Class 'S': 35/66 correct, Accuracy: 0.5303\n",
            "Class 'L': 62/64 correct, Accuracy: 0.9688\n",
            "Class 'C': 56/71 correct, Accuracy: 0.7887\n",
            "Class 'U': 67/69 correct, Accuracy: 0.9710\n",
            "Class 'R': 52/62 correct, Accuracy: 0.8387\n",
            "\n",
            "Predictions by Sample:\n",
            "Sample 1: Predicted 'K' (conf: 0.9986), True 'T' ✗\n",
            "Sample 2: Predicted 'M' (conf: 0.9705), True 'M' ✓\n",
            "Sample 3: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 4: Predicted 'D' (conf: 0.9947), True 'D' ✓\n",
            "Sample 5: Predicted 'C' (conf: 0.9843), True 'C' ✓\n",
            "Sample 6: Predicted 'P' (conf: 0.6518), True 'T' ✗\n",
            "Sample 7: Predicted 'M' (conf: 0.8684), True 'M' ✓\n",
            "Sample 8: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 9: Predicted 'D' (conf: 0.9944), True 'D' ✓\n",
            "Sample 10: Predicted 'C' (conf: 0.9843), True 'C' ✓\n",
            "Sample 11: Predicted 'P' (conf: 0.5490), True 'T' ✗\n",
            "Sample 12: Predicted 'W' (conf: 0.9920), True 'M' ✗\n",
            "Sample 13: Predicted 'R' (conf: 0.3791), True 'D' ✗\n",
            "Sample 14: Predicted 'O' (conf: 0.9852), True 'C' ✗\n",
            "Sample 15: Predicted 'W' (conf: 0.7513), True 'W' ✓\n",
            "Sample 16: Predicted 'T' (conf: 0.9790), True 'P' ✗\n",
            "Sample 17: Predicted 'N' (conf: 0.9857), True 'N' ✓\n",
            "Sample 18: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 19: Predicted 'R' (conf: 0.9478), True 'R' ✓\n",
            "Sample 20: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 21: Predicted 'T' (conf: 0.9691), True 'K' ✗\n",
            "Sample 22: Predicted 'F' (conf: 0.7841), True 'F' ✓\n",
            "Sample 23: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 24: Predicted 'Y' (conf: 0.9335), True 'Q' ✗\n",
            "Sample 25: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 26: Predicted 'F' (conf: 0.9783), True 'A' ✗\n",
            "Sample 27: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 28: Predicted 'X' (conf: 0.9987), True 'X' ✓\n",
            "Sample 29: Predicted 'V' (conf: 0.9956), True 'V' ✓\n",
            "Sample 30: Predicted 'S' (conf: 0.9993), True 'S' ✓\n",
            "Sample 31: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 32: Predicted 'Z' (conf: 0.9993), True 'Z' ✓\n",
            "Sample 33: Predicted 'X' (conf: 0.9986), True 'X' ✓\n",
            "Sample 34: Predicted 'V' (conf: 0.9956), True 'V' ✓\n",
            "Sample 35: Predicted 'S' (conf: 0.9991), True 'S' ✓\n",
            "Sample 36: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 37: Predicted 'K' (conf: 0.9986), True 'T' ✗\n",
            "Sample 38: Predicted 'M' (conf: 0.3892), True 'M' ✓\n",
            "Sample 39: Predicted 'H' (conf: 0.8355), True 'G' ✗\n",
            "Sample 40: Predicted 'D' (conf: 0.9950), True 'D' ✓\n",
            "Sample 41: Predicted 'C' (conf: 0.9848), True 'C' ✓\n",
            "Sample 42: Predicted 'W' (conf: 0.8463), True 'W' ✓\n",
            "Sample 43: Predicted 'P' (conf: 0.9847), True 'P' ✓\n",
            "Sample 44: Predicted 'N' (conf: 0.9832), True 'N' ✓\n",
            "Sample 45: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 46: Predicted 'R' (conf: 0.5833), True 'R' ✓\n",
            "Sample 47: Predicted 'O' (conf: 0.9878), True 'O' ✓\n",
            "Sample 48: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 49: Predicted 'T' (conf: 0.5068), True 'F' ✗\n",
            "Sample 50: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 51: Predicted 'H' (conf: 0.5405), True 'Q' ✗\n",
            "Sample 52: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 53: Predicted 'H' (conf: 0.9949), True 'Q' ✗\n",
            "Sample 54: Predicted 'L' (conf: 0.7729), True 'I' ✗\n",
            "Sample 55: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 56: Predicted 'H' (conf: 0.6191), True 'Q' ✗\n",
            "Sample 57: Predicted 'V' (conf: 0.4902), True 'I' ✗\n",
            "Sample 58: Predicted 'A' (conf: 0.9962), True 'A' ✓\n",
            "Sample 59: Predicted 'Z' (conf: 0.5703), True 'Z' ✓\n",
            "Sample 60: Predicted 'X' (conf: 0.9932), True 'X' ✓\n",
            "Sample 61: Predicted 'V' (conf: 0.9939), True 'V' ✓\n",
            "Sample 62: Predicted 'C' (conf: 0.3486), True 'S' ✗\n",
            "Sample 63: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 64: Predicted 'P' (conf: 0.7958), True 'T' ✗\n",
            "Sample 65: Predicted 'M' (conf: 0.9784), True 'M' ✓\n",
            "Sample 66: Predicted 'G' (conf: 0.9856), True 'G' ✓\n",
            "Sample 67: Predicted 'C' (conf: 0.6602), True 'C' ✓\n",
            "Sample 68: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 69: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 70: Predicted 'D' (conf: 0.9946), True 'K' ✗\n",
            "Sample 71: Predicted 'M' (conf: 0.9946), True 'M' ✓\n",
            "Sample 72: Predicted 'U' (conf: 0.9954), True 'U' ✓\n",
            "Sample 73: Predicted 'G' (conf: 0.8518), True 'G' ✓\n",
            "Sample 74: Predicted 'O' (conf: 0.9884), True 'I' ✗\n",
            "Sample 75: Predicted 'A' (conf: 0.9670), True 'A' ✓\n",
            "Sample 76: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 77: Predicted 'C' (conf: 0.6422), True 'S' ✗\n",
            "Sample 78: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 79: Predicted 'I' (conf: 0.4028), True 'T' ✗\n",
            "Sample 80: Predicted 'W' (conf: 0.6310), True 'M' ✗\n",
            "Sample 81: Predicted 'I' (conf: 0.7075), True 'G' ✗\n",
            "Sample 82: Predicted 'S' (conf: 0.9147), True 'T' ✗\n",
            "Sample 83: Predicted 'W' (conf: 0.5551), True 'M' ✗\n",
            "Sample 84: Predicted 'H' (conf: 0.9847), True 'G' ✗\n",
            "Sample 85: Predicted 'P' (conf: 0.6926), True 'D' ✗\n",
            "Sample 86: Predicted 'C' (conf: 0.9849), True 'C' ✓\n",
            "Sample 87: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 88: Predicted 'C' (conf: 0.9843), True 'P' ✗\n",
            "Sample 89: Predicted 'R' (conf: 0.6342), True 'N' ✗\n",
            "Sample 90: Predicted 'L' (conf: 0.6109), True 'L' ✓\n",
            "Sample 91: Predicted 'R' (conf: 0.9651), True 'R' ✓\n",
            "Sample 92: Predicted 'O' (conf: 0.9885), True 'O' ✓\n",
            "Sample 93: Predicted 'G' (conf: 0.9413), True 'F' ✗\n",
            "Sample 94: Predicted 'L' (conf: 0.5842), True 'U' ✗\n",
            "Sample 95: Predicted 'Q' (conf: 0.9918), True 'Q' ✓\n",
            "Sample 96: Predicted 'O' (conf: 0.7941), True 'I' ✗\n",
            "Sample 97: Predicted 'W' (conf: 0.9958), True 'A' ✗\n",
            "Sample 98: Predicted 'H' (conf: 0.2691), True 'Z' ✗\n",
            "Sample 99: Predicted 'X' (conf: 0.6685), True 'X' ✓\n",
            "Sample 100: Predicted 'V' (conf: 0.3372), True 'V' ✓\n",
            "Sample 101: Predicted 'Z' (conf: 0.8033), True 'Z' ✓\n",
            "Sample 102: Predicted 'V' (conf: 0.5899), True 'V' ✓\n",
            "Sample 103: Predicted 'C' (conf: 0.7660), True 'Z' ✗\n",
            "Sample 104: Predicted 'X' (conf: 0.3459), True 'X' ✓\n",
            "Sample 105: Predicted 'V' (conf: 0.7459), True 'V' ✓\n",
            "Sample 106: Predicted 'O' (conf: 0.9454), True 'S' ✗\n",
            "Sample 107: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 108: Predicted 'X' (conf: 0.9594), True 'X' ✓\n",
            "Sample 109: Predicted 'L' (conf: 0.5284), True 'V' ✗\n",
            "Sample 110: Predicted 'I' (conf: 0.3360), True 'S' ✗\n",
            "Sample 111: Predicted 'C' (conf: 0.9857), True 'B' ✗\n",
            "Sample 112: Predicted 'E' (conf: 0.6037), True 'T' ✗\n",
            "Sample 113: Predicted 'H' (conf: 0.9805), True 'M' ✗\n",
            "Sample 114: Predicted 'I' (conf: 0.6285), True 'G' ✗\n",
            "Sample 115: Predicted 'P' (conf: 0.6225), True 'D' ✗\n",
            "Sample 116: Predicted 'T' (conf: 0.3389), True 'C' ✗\n",
            "Sample 117: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 118: Predicted 'C' (conf: 0.6638), True 'P' ✗\n",
            "Sample 119: Predicted 'R' (conf: 0.9841), True 'N' ✗\n",
            "Sample 120: Predicted 'T' (conf: 0.9802), True 'T' ✓\n",
            "Sample 121: Predicted 'W' (conf: 0.9992), True 'M' ✗\n",
            "Sample 122: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 123: Predicted 'D' (conf: 0.9942), True 'D' ✓\n",
            "Sample 124: Predicted 'C' (conf: 0.5314), True 'C' ✓\n",
            "Sample 125: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 126: Predicted 'Z' (conf: 0.4770), True 'P' ✗\n",
            "Sample 127: Predicted 'N' (conf: 0.9154), True 'N' ✓\n",
            "Sample 128: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 129: Predicted 'R' (conf: 0.9952), True 'R' ✓\n",
            "Sample 130: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 131: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 132: Predicted 'F' (conf: 0.9216), True 'F' ✓\n",
            "Sample 133: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 134: Predicted 'Q' (conf: 0.9830), True 'Q' ✓\n",
            "Sample 135: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 136: Predicted 'A' (conf: 0.9971), True 'A' ✓\n",
            "Sample 137: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 138: Predicted 'F' (conf: 0.9930), True '2' ✗\n",
            "Sample 139: Predicted 'X' (conf: 0.9986), True 'X' ✓\n",
            "Sample 140: Predicted 'V' (conf: 0.9956), True 'V' ✓\n",
            "Sample 141: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 142: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 143: Predicted 'P' (conf: 0.9292), True 'T' ✗\n",
            "Sample 144: Predicted 'M' (conf: 0.9832), True 'M' ✓\n",
            "Sample 145: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 146: Predicted 'D' (conf: 0.9960), True 'D' ✓\n",
            "Sample 147: Predicted 'L' (conf: 0.9935), True 'C' ✗\n",
            "Sample 148: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 149: Predicted 'D' (conf: 0.9942), True 'P' ✗\n",
            "Sample 150: Predicted 'V' (conf: 0.9466), True 'V' ✓\n",
            "Sample 151: Predicted 'L' (conf: 0.9957), True 'L' ✓\n",
            "Sample 152: Predicted 'R' (conf: 0.9964), True 'R' ✓\n",
            "Sample 153: Predicted 'O' (conf: 0.3419), True 'O' ✓\n",
            "Sample 154: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 155: Predicted 'F' (conf: 0.9912), True 'F' ✓\n",
            "Sample 156: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 157: Predicted 'Q' (conf: 0.9918), True 'Q' ✓\n",
            "Sample 158: Predicted 'I' (conf: 0.9988), True 'I' ✓\n",
            "Sample 159: Predicted 'A' (conf: 0.9973), True 'A' ✓\n",
            "Sample 160: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 161: Predicted 'X' (conf: 0.9986), True 'X' ✓\n",
            "Sample 162: Predicted 'V' (conf: 0.9955), True 'V' ✓\n",
            "Sample 163: Predicted 'W' (conf: 0.9947), True 'S' ✗\n",
            "Sample 164: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 165: Predicted 'C' (conf: 0.9848), True 'C' ✓\n",
            "Sample 166: Predicted 'L' (conf: 0.5889), True 'I' ✗\n",
            "Sample 167: Predicted 'Q' (conf: 0.9848), True 'P' ✗\n",
            "Sample 168: Predicted 'W' (conf: 0.5183), True 'M' ✗\n",
            "Sample 169: Predicted 'U' (conf: 0.9950), True 'C' ✗\n",
            "Sample 170: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 171: Predicted 'V' (conf: 0.9955), True 'V' ✓\n",
            "Sample 172: Predicted 'U' (conf: 0.8307), True 'L' ✗\n",
            "Sample 173: Predicted 'L' (conf: 0.6893), True 'R' ✗\n",
            "Sample 174: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 175: Predicted 'X' (conf: 0.9987), True 'X' ✓\n",
            "Sample 176: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 177: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 178: Predicted 'X' (conf: 0.9986), True 'A' ✗\n",
            "Sample 179: Predicted 'T' (conf: 0.9166), True 'G' ✗\n",
            "Sample 180: Predicted 'T' (conf: 0.9823), True 'T' ✓\n",
            "Sample 181: Predicted 'I' (conf: 0.9991), True 'I' ✓\n",
            "Sample 182: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 183: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 184: Predicted 'W' (conf: 0.7113), True 'R' ✗\n",
            "Sample 185: Predicted 'T' (conf: 0.9804), True 'D' ✗\n",
            "Sample 186: Predicted 'Y' (conf: 0.7814), True 'Q' ✗\n",
            "Sample 187: Predicted 'N' (conf: 0.9848), True 'N' ✓\n",
            "Sample 188: Predicted 'I' (conf: 0.8514), True 'G' ✗\n",
            "Sample 189: Predicted 'W' (conf: 0.6648), True 'Q' ✗\n",
            "Sample 190: Predicted 'S' (conf: 0.9992), True 'S' ✓\n",
            "Sample 191: Predicted 'W' (conf: 0.9186), True 'W' ✓\n",
            "Sample 192: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 193: Predicted 'R' (conf: 0.9966), True 'R' ✓\n",
            "Sample 194: Predicted 'C' (conf: 0.9837), True 'C' ✓\n",
            "Sample 195: Predicted 'V' (conf: 0.9953), True 'N' ✗\n",
            "Sample 196: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 197: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 198: Predicted 'O' (conf: 0.9891), True 'O' ✓\n",
            "Sample 199: Predicted 'L' (conf: 0.7404), True 'I' ✗\n",
            "Sample 200: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 201: Predicted 'A' (conf: 0.9702), True 'A' ✓\n",
            "Sample 202: Predicted 'X' (conf: 0.9985), True 'X' ✓\n",
            "Sample 203: Predicted 'D' (conf: 0.9933), True 'D' ✓\n",
            "Sample 204: Predicted 'K' (conf: 0.9987), True 'K' ✓\n",
            "Sample 205: Predicted 'M' (conf: 0.9915), True 'M' ✓\n",
            "Sample 206: Predicted 'K' (conf: 0.8105), True 'K' ✓\n",
            "Sample 207: Predicted 'M' (conf: 0.9773), True 'M' ✓\n",
            "Sample 208: Predicted 'K' (conf: 0.9986), True 'T' ✗\n",
            "Sample 209: Predicted 'M' (conf: 0.9867), True 'M' ✓\n",
            "Sample 210: Predicted 'G' (conf: 0.6655), True 'G' ✓\n",
            "Sample 211: Predicted 'D' (conf: 0.9931), True 'D' ✓\n",
            "Sample 212: Predicted 'C' (conf: 0.9851), True 'C' ✓\n",
            "Sample 213: Predicted 'W' (conf: 0.9992), True 'W' ✓\n",
            "Sample 214: Predicted 'P' (conf: 0.9843), True 'P' ✓\n",
            "Sample 215: Predicted 'N' (conf: 0.9535), True 'M' ✗\n",
            "Sample 216: Predicted 'N' (conf: 0.6227), True 'N' ✓\n",
            "Sample 217: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 218: Predicted 'R' (conf: 0.9922), True 'R' ✓\n",
            "Sample 219: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 220: Predicted 'K' (conf: 0.9990), True 'K' ✓\n",
            "Sample 221: Predicted 'F' (conf: 0.9959), True 'F' ✓\n",
            "Sample 222: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 223: Predicted 'F' (conf: 0.7183), True 'Q' ✗\n",
            "Sample 224: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 225: Predicted 'L' (conf: 0.9706), True 'A' ✗\n",
            "Sample 226: Predicted 'W' (conf: 0.6611), True 'Z' ✗\n",
            "Sample 227: Predicted 'X' (conf: 0.9977), True 'X' ✓\n",
            "Sample 228: Predicted 'V' (conf: 0.9955), True 'V' ✓\n",
            "Sample 229: Predicted 'S' (conf: 0.6728), True 'S' ✓\n",
            "Sample 230: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 231: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 232: Predicted 'X' (conf: 0.9986), True 'X' ✓\n",
            "Sample 233: Predicted 'V' (conf: 0.9947), True 'V' ✓\n",
            "Sample 234: Predicted 'R' (conf: 0.4104), True 'S' ✗\n",
            "Sample 235: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 236: Predicted 'C' (conf: 0.9844), True 'C' ✓\n",
            "Sample 237: Predicted 'D' (conf: 0.6633), True 'D' ✓\n",
            "Sample 238: Predicted 'G' (conf: 0.9352), True 'G' ✓\n",
            "Sample 239: Predicted 'M' (conf: 0.6278), True 'M' ✓\n",
            "Sample 240: Predicted 'K' (conf: 0.6601), True 'T' ✗\n",
            "Sample 241: Predicted 'C' (conf: 0.9848), True 'C' ✓\n",
            "Sample 242: Predicted 'P' (conf: 0.4569), True 'D' ✗\n",
            "Sample 243: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 244: Predicted 'W' (conf: 0.9563), True 'M' ✗\n",
            "Sample 245: Predicted 'K' (conf: 0.9985), True 'T' ✗\n",
            "Sample 246: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 247: Predicted 'N' (conf: 0.8579), True 'N' ✓\n",
            "Sample 248: Predicted 'P' (conf: 0.9845), True 'D' ✗\n",
            "Sample 249: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 250: Predicted 'F' (conf: 0.6145), True 'F' ✓\n",
            "Sample 251: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 252: Predicted 'O' (conf: 0.9889), True 'O' ✓\n",
            "Sample 253: Predicted 'R' (conf: 0.9964), True 'R' ✓\n",
            "Sample 254: Predicted 'A' (conf: 0.9971), True 'A' ✓\n",
            "Sample 255: Predicted 'I' (conf: 0.9986), True 'I' ✓\n",
            "Sample 256: Predicted 'Q' (conf: 0.9914), True 'Q' ✓\n",
            "Sample 257: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 258: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 259: Predicted 'S' (conf: 0.6639), True 'S' ✓\n",
            "Sample 260: Predicted 'V' (conf: 0.9535), True 'V' ✓\n",
            "Sample 261: Predicted 'C' (conf: 0.9843), True 'C' ✓\n",
            "Sample 262: Predicted 'D' (conf: 0.9948), True 'D' ✓\n",
            "Sample 263: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 264: Predicted 'M' (conf: 0.9935), True 'M' ✓\n",
            "Sample 265: Predicted 'T' (conf: 0.9821), True 'T' ✓\n",
            "Sample 266: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 267: Predicted 'N' (conf: 0.9838), True 'N' ✓\n",
            "Sample 268: Predicted 'D' (conf: 0.9946), True 'P' ✗\n",
            "Sample 269: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 270: Predicted 'F' (conf: 0.9841), True 'F' ✓\n",
            "Sample 271: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 272: Predicted 'O' (conf: 0.9856), True 'O' ✓\n",
            "Sample 273: Predicted 'R' (conf: 0.9964), True 'R' ✓\n",
            "Sample 274: Predicted 'A' (conf: 0.9973), True 'A' ✓\n",
            "Sample 275: Predicted 'I' (conf: 0.9989), True 'I' ✓\n",
            "Sample 276: Predicted 'Q' (conf: 0.9918), True 'Q' ✓\n",
            "Sample 277: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 278: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 279: Predicted 'R' (conf: 0.9515), True 'S' ✗\n",
            "Sample 280: Predicted 'W' (conf: 0.9494), True 'V' ✗\n",
            "Sample 281: Predicted 'C' (conf: 0.9843), True 'C' ✓\n",
            "Sample 282: Predicted 'D' (conf: 0.9953), True 'D' ✓\n",
            "Sample 283: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 284: Predicted 'T' (conf: 0.9768), True 'T' ✓\n",
            "Sample 285: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 286: Predicted 'N' (conf: 0.3459), True 'N' ✓\n",
            "Sample 287: Predicted 'P' (conf: 0.4987), True 'P' ✓\n",
            "Sample 288: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 289: Predicted 'W' (conf: 0.9992), True 'E' ✗\n",
            "Sample 290: Predicted 'K' (conf: 0.9978), True 'K' ✓\n",
            "Sample 291: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 292: Predicted 'R' (conf: 0.7742), True 'R' ✓\n",
            "Sample 293: Predicted 'A' (conf: 0.9973), True 'A' ✓\n",
            "Sample 294: Predicted 'I' (conf: 0.9989), True 'I' ✓\n",
            "Sample 295: Predicted 'Q' (conf: 0.9869), True 'Q' ✓\n",
            "Sample 296: Predicted 'U' (conf: 0.9967), True 'U' ✓\n",
            "Sample 297: Predicted 'B' (conf: 0.9968), True 'B' ✓\n",
            "Sample 298: Predicted 'S' (conf: 0.9801), True 'S' ✓\n",
            "Sample 299: Predicted 'V' (conf: 0.9955), True 'V' ✓\n",
            "Sample 300: Predicted 'D' (conf: 0.9943), True 'D' ✓\n",
            "Sample 301: Predicted 'G' (conf: 0.4860), True 'G' ✓\n",
            "Sample 302: Predicted 'M' (conf: 0.9944), True 'M' ✓\n",
            "Sample 303: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 304: Predicted 'R' (conf: 0.9396), True 'N' ✗\n",
            "Sample 305: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 306: Predicted 'F' (conf: 0.9747), True 'F' ✓\n",
            "Sample 307: Predicted 'R' (conf: 0.8889), True 'R' ✓\n",
            "Sample 308: Predicted 'O' (conf: 0.9881), True 'O' ✓\n",
            "Sample 309: Predicted 'R' (conf: 0.9935), True 'R' ✓\n",
            "Sample 310: Predicted 'I' (conf: 0.9981), True 'A' ✗\n",
            "Sample 311: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 312: Predicted 'Y' (conf: 0.9911), True 'Q' ✗\n",
            "Sample 313: Predicted 'R' (conf: 0.9255), True 'Y' ✗\n",
            "Sample 314: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 315: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 316: Predicted 'S' (conf: 0.8871), True 'S' ✓\n",
            "Sample 317: Predicted 'V' (conf: 0.9955), True 'V' ✓\n",
            "Sample 318: Predicted 'O' (conf: 0.9647), True 'C' ✗\n",
            "Sample 319: Predicted 'D' (conf: 0.9938), True 'D' ✓\n",
            "Sample 320: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 321: Predicted 'M' (conf: 0.6615), True 'M' ✓\n",
            "Sample 322: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 323: Predicted 'N' (conf: 0.9825), True 'N' ✓\n",
            "Sample 324: Predicted 'P' (conf: 0.9847), True 'P' ✓\n",
            "Sample 325: Predicted 'W' (conf: 0.8138), True 'W' ✓\n",
            "Sample 326: Predicted 'T' (conf: 0.9039), True 'F' ✗\n",
            "Sample 327: Predicted 'K' (conf: 0.6666), True 'K' ✓\n",
            "Sample 328: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 329: Predicted 'A' (conf: 0.9971), True 'A' ✓\n",
            "Sample 330: Predicted 'I' (conf: 0.8881), True 'I' ✓\n",
            "Sample 331: Predicted 'H' (conf: 0.9969), True 'Q' ✗\n",
            "Sample 332: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 333: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 334: Predicted 'C' (conf: 0.9717), True 'S' ✗\n",
            "Sample 335: Predicted 'C' (conf: 0.9830), True 'C' ✓\n",
            "Sample 336: Predicted 'D' (conf: 0.9938), True 'D' ✓\n",
            "Sample 337: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 338: Predicted 'M' (conf: 0.9934), True 'M' ✓\n",
            "Sample 339: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 340: Predicted 'M' (conf: 0.6858), True 'N' ✗\n",
            "Sample 341: Predicted 'P' (conf: 0.9846), True 'P' ✓\n",
            "Sample 342: Predicted 'W' (conf: 0.3556), True 'W' ✓\n",
            "Sample 343: Predicted 'T' (conf: 0.7037), True 'F' ✗\n",
            "Sample 344: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 345: Predicted 'O' (conf: 0.6882), True 'O' ✓\n",
            "Sample 346: Predicted 'R' (conf: 0.9965), True 'R' ✓\n",
            "Sample 347: Predicted 'A' (conf: 0.4399), True 'A' ✓\n",
            "Sample 348: Predicted 'I' (conf: 0.9941), True 'I' ✓\n",
            "Sample 349: Predicted 'H' (conf: 0.8984), True 'Q' ✗\n",
            "Sample 350: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 351: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 352: Predicted 'C' (conf: 0.4939), True 'S' ✗\n",
            "Sample 353: Predicted 'V' (conf: 0.9954), True 'V' ✓\n",
            "Sample 354: Predicted 'C' (conf: 0.9853), True 'C' ✓\n",
            "Sample 355: Predicted 'P' (conf: 0.6565), True 'D' ✗\n",
            "Sample 356: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 357: Predicted 'R' (conf: 0.3736), True 'M' ✗\n",
            "Sample 358: Predicted 'K' (conf: 0.9987), True 'T' ✗\n",
            "Sample 359: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 360: Predicted 'N' (conf: 0.7092), True 'N' ✓\n",
            "Sample 361: Predicted 'P' (conf: 0.8158), True 'D' ✗\n",
            "Sample 362: Predicted 'W' (conf: 0.6895), True 'W' ✓\n",
            "Sample 363: Predicted 'F' (conf: 0.9910), True 'F' ✓\n",
            "Sample 364: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 365: Predicted 'O' (conf: 0.9872), True 'O' ✓\n",
            "Sample 366: Predicted 'R' (conf: 0.8778), True 'R' ✓\n",
            "Sample 367: Predicted 'R' (conf: 0.3899), True 'A' ✗\n",
            "Sample 368: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 369: Predicted 'I' (conf: 0.9539), True 'Q' ✗\n",
            "Sample 370: Predicted 'U' (conf: 0.9960), True 'U' ✓\n",
            "Sample 371: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 372: Predicted 'S' (conf: 0.6667), True 'S' ✓\n",
            "Sample 373: Predicted 'V' (conf: 0.9954), True 'V' ✓\n",
            "Sample 374: Predicted 'C' (conf: 0.9845), True 'C' ✓\n",
            "Sample 375: Predicted 'D' (conf: 0.9961), True 'D' ✓\n",
            "Sample 376: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 377: Predicted 'M' (conf: 0.9842), True 'M' ✓\n",
            "Sample 378: Predicted 'T' (conf: 0.9807), True 'T' ✓\n",
            "Sample 379: Predicted 'L' (conf: 0.9961), True 'L' ✓\n",
            "Sample 380: Predicted 'N' (conf: 0.9830), True 'N' ✓\n",
            "Sample 381: Predicted 'D' (conf: 0.9940), True 'P' ✗\n",
            "Sample 382: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 383: Predicted 'F' (conf: 0.9952), True 'F' ✓\n",
            "Sample 384: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 385: Predicted 'O' (conf: 0.9881), True 'O' ✓\n",
            "Sample 386: Predicted 'R' (conf: 0.9966), True 'R' ✓\n",
            "Sample 387: Predicted 'A' (conf: 0.9974), True 'A' ✓\n",
            "Sample 388: Predicted 'I' (conf: 0.8073), True 'I' ✓\n",
            "Sample 389: Predicted 'Q' (conf: 0.9688), True 'Q' ✓\n",
            "Sample 390: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 391: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 392: Predicted 'R' (conf: 0.6558), True 'S' ✗\n",
            "Sample 393: Predicted 'V' (conf: 0.9954), True 'V' ✓\n",
            "Sample 394: Predicted 'C' (conf: 0.9837), True 'C' ✓\n",
            "Sample 395: Predicted 'D' (conf: 0.9943), True 'D' ✓\n",
            "Sample 396: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 397: Predicted 'M' (conf: 0.9760), True 'M' ✓\n",
            "Sample 398: Predicted 'T' (conf: 0.9599), True 'T' ✓\n",
            "Sample 399: Predicted 'L' (conf: 0.9955), True 'L' ✓\n",
            "Sample 400: Predicted 'N' (conf: 0.6419), True 'N' ✓\n",
            "Sample 401: Predicted 'P' (conf: 0.9837), True 'P' ✓\n",
            "Sample 402: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 403: Predicted 'E' (conf: 0.9946), True 'E' ✓\n",
            "Sample 404: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 405: Predicted 'O' (conf: 0.6701), True 'O' ✓\n",
            "Sample 406: Predicted 'R' (conf: 0.9386), True 'R' ✓\n",
            "Sample 407: Predicted 'A' (conf: 0.9972), True 'A' ✓\n",
            "Sample 408: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 409: Predicted 'Q' (conf: 0.9913), True 'Q' ✓\n",
            "Sample 410: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 411: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 412: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 413: Predicted 'V' (conf: 0.9956), True 'V' ✓\n",
            "Sample 414: Predicted 'C' (conf: 0.9813), True 'C' ✓\n",
            "Sample 415: Predicted 'D' (conf: 0.9941), True 'D' ✓\n",
            "Sample 416: Predicted 'H' (conf: 0.9077), True 'G' ✗\n",
            "Sample 417: Predicted 'M' (conf: 0.9873), True 'M' ✓\n",
            "Sample 418: Predicted 'K' (conf: 0.9986), True 'T' ✗\n",
            "Sample 419: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 420: Predicted 'N' (conf: 0.9816), True 'N' ✓\n",
            "Sample 421: Predicted 'P' (conf: 0.9845), True 'P' ✓\n",
            "Sample 422: Predicted 'W' (conf: 0.9858), True 'W' ✓\n",
            "Sample 423: Predicted 'F' (conf: 0.8147), True 'F' ✓\n",
            "Sample 424: Predicted 'K' (conf: 0.9990), True 'K' ✓\n",
            "Sample 425: Predicted 'O' (conf: 0.9886), True 'O' ✓\n",
            "Sample 426: Predicted 'R' (conf: 0.9341), True 'R' ✓\n",
            "Sample 427: Predicted 'A' (conf: 0.4856), True 'A' ✓\n",
            "Sample 428: Predicted 'I' (conf: 0.9988), True 'I' ✓\n",
            "Sample 429: Predicted 'E' (conf: 0.8515), True 'Q' ✗\n",
            "Sample 430: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 431: Predicted 'B' (conf: 0.9968), True 'B' ✓\n",
            "Sample 432: Predicted 'S' (conf: 0.9961), True 'S' ✓\n",
            "Sample 433: Predicted 'V' (conf: 0.9940), True 'V' ✓\n",
            "Sample 434: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 435: Predicted 'M' (conf: 0.9936), True 'M' ✓\n",
            "Sample 436: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 437: Predicted 'N' (conf: 0.9854), True 'N' ✓\n",
            "Sample 438: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 439: Predicted 'F' (conf: 0.9707), True 'F' ✓\n",
            "Sample 440: Predicted 'R' (conf: 0.9938), True 'R' ✓\n",
            "Sample 441: Predicted 'O' (conf: 0.9882), True 'O' ✓\n",
            "Sample 442: Predicted 'A' (conf: 0.9729), True 'A' ✓\n",
            "Sample 443: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 444: Predicted 'Y' (conf: 0.9922), True 'Q' ✗\n",
            "Sample 445: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 446: Predicted 'U' (conf: 0.4496), True 'S' ✗\n",
            "Sample 447: Predicted 'V' (conf: 0.9956), True 'V' ✓\n",
            "Sample 448: Predicted 'C' (conf: 0.9850), True 'C' ✓\n",
            "Sample 449: Predicted 'D' (conf: 0.9936), True 'D' ✓\n",
            "Sample 450: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 451: Predicted 'M' (conf: 0.9914), True 'M' ✓\n",
            "Sample 452: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 453: Predicted 'N' (conf: 0.9847), True 'N' ✓\n",
            "Sample 454: Predicted 'P' (conf: 0.9842), True 'P' ✓\n",
            "Sample 455: Predicted 'R' (conf: 0.6687), True 'W' ✗\n",
            "Sample 456: Predicted 'F' (conf: 0.9669), True 'F' ✓\n",
            "Sample 457: Predicted 'K' (conf: 0.9990), True 'K' ✓\n",
            "Sample 458: Predicted 'O' (conf: 0.9873), True 'O' ✓\n",
            "Sample 459: Predicted 'R' (conf: 0.9965), True 'R' ✓\n",
            "Sample 460: Predicted 'A' (conf: 0.9972), True 'A' ✓\n",
            "Sample 461: Predicted 'I' (conf: 0.9988), True 'I' ✓\n",
            "Sample 462: Predicted 'Q' (conf: 0.9880), True 'Q' ✓\n",
            "Sample 463: Predicted 'U' (conf: 0.9963), True 'U' ✓\n",
            "Sample 464: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 465: Predicted 'R' (conf: 0.9638), True 'S' ✗\n",
            "Sample 466: Predicted 'E' (conf: 0.2541), True 'V' ✗\n",
            "Sample 467: Predicted 'C' (conf: 0.9845), True 'C' ✓\n",
            "Sample 468: Predicted 'P' (conf: 0.9807), True 'D' ✗\n",
            "Sample 469: Predicted 'G' (conf: 0.6660), True 'G' ✓\n",
            "Sample 470: Predicted 'R' (conf: 0.9626), True 'M' ✗\n",
            "Sample 471: Predicted 'C' (conf: 0.9846), True 'C' ✓\n",
            "Sample 472: Predicted 'P' (conf: 0.9828), True 'D' ✗\n",
            "Sample 473: Predicted 'C' (conf: 0.9842), True 'C' ✓\n",
            "Sample 474: Predicted 'P' (conf: 0.9831), True 'D' ✗\n",
            "Sample 475: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 476: Predicted 'R' (conf: 0.6501), True 'M' ✗\n",
            "Sample 477: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 478: Predicted 'N' (conf: 0.9855), True 'N' ✓\n",
            "Sample 479: Predicted 'P' (conf: 0.9842), True 'P' ✓\n",
            "Sample 480: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 481: Predicted 'Q' (conf: 0.3928), True 'F' ✗\n",
            "Sample 482: Predicted 'K' (conf: 0.9987), True 'K' ✓\n",
            "Sample 483: Predicted 'O' (conf: 0.3475), True 'O' ✓\n",
            "Sample 484: Predicted 'R' (conf: 0.7914), True 'R' ✓\n",
            "Sample 485: Predicted 'A' (conf: 0.9965), True 'A' ✓\n",
            "Sample 486: Predicted 'I' (conf: 0.9979), True 'I' ✓\n",
            "Sample 487: Predicted 'Q' (conf: 0.9916), True 'Q' ✓\n",
            "Sample 488: Predicted 'U' (conf: 0.9955), True 'U' ✓\n",
            "Sample 489: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 490: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 491: Predicted 'W' (conf: 0.6637), True 'V' ✗\n",
            "Sample 492: Predicted 'C' (conf: 0.9840), True 'C' ✓\n",
            "Sample 493: Predicted 'D' (conf: 0.9957), True 'D' ✓\n",
            "Sample 494: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 495: Predicted 'M' (conf: 0.9918), True 'M' ✓\n",
            "Sample 496: Predicted 'T' (conf: 0.9784), True 'T' ✓\n",
            "Sample 497: Predicted 'L' (conf: 0.9962), True 'L' ✓\n",
            "Sample 498: Predicted 'N' (conf: 0.9838), True 'N' ✓\n",
            "Sample 499: Predicted 'D' (conf: 0.9945), True 'P' ✗\n",
            "Sample 500: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 501: Predicted 'F' (conf: 0.9958), True 'F' ✓\n",
            "Sample 502: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 503: Predicted 'O' (conf: 0.9881), True 'O' ✓\n",
            "Sample 504: Predicted 'R' (conf: 0.9100), True 'R' ✓\n",
            "Sample 505: Predicted 'A' (conf: 0.9974), True 'A' ✓\n",
            "Sample 506: Predicted 'I' (conf: 0.9986), True 'I' ✓\n",
            "Sample 507: Predicted 'Q' (conf: 0.9916), True 'Q' ✓\n",
            "Sample 508: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 509: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 510: Predicted 'R' (conf: 0.9782), True 'S' ✗\n",
            "Sample 511: Predicted 'V' (conf: 0.9951), True 'V' ✓\n",
            "Sample 512: Predicted 'C' (conf: 0.9839), True 'C' ✓\n",
            "Sample 513: Predicted 'D' (conf: 0.9939), True 'D' ✓\n",
            "Sample 514: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 515: Predicted 'R' (conf: 0.4753), True 'M' ✗\n",
            "Sample 516: Predicted 'T' (conf: 0.9827), True 'T' ✓\n",
            "Sample 517: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 518: Predicted 'N' (conf: 0.9126), True 'N' ✓\n",
            "Sample 519: Predicted 'P' (conf: 0.9841), True 'P' ✓\n",
            "Sample 520: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 521: Predicted 'F' (conf: 0.9928), True 'F' ✓\n",
            "Sample 522: Predicted 'K' (conf: 0.9987), True 'K' ✓\n",
            "Sample 523: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 524: Predicted 'N' (conf: 0.4153), True 'R' ✗\n",
            "Sample 525: Predicted 'A' (conf: 0.9970), True 'A' ✓\n",
            "Sample 526: Predicted 'I' (conf: 0.9989), True 'I' ✓\n",
            "Sample 527: Predicted 'Y' (conf: 0.4609), True 'Q' ✗\n",
            "Sample 528: Predicted 'U' (conf: 0.9967), True 'U' ✓\n",
            "Sample 529: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 530: Predicted 'R' (conf: 0.8778), True 'S' ✗\n",
            "Sample 531: Predicted 'V' (conf: 0.9957), True 'V' ✓\n",
            "Sample 532: Predicted 'C' (conf: 0.9849), True 'C' ✓\n",
            "Sample 533: Predicted 'G' (conf: 0.3335), True 'D' ✗\n",
            "Sample 534: Predicted 'M' (conf: 0.9938), True 'M' ✓\n",
            "Sample 535: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 536: Predicted 'N' (conf: 0.8010), True 'N' ✓\n",
            "Sample 537: Predicted 'P' (conf: 0.9843), True 'P' ✓\n",
            "Sample 538: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 539: Predicted 'G' (conf: 0.5332), True 'F' ✗\n",
            "Sample 540: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 541: Predicted 'O' (conf: 0.9880), True 'O' ✓\n",
            "Sample 542: Predicted 'R' (conf: 0.9592), True 'R' ✓\n",
            "Sample 543: Predicted 'A' (conf: 0.9972), True 'A' ✓\n",
            "Sample 544: Predicted 'I' (conf: 0.9989), True 'I' ✓\n",
            "Sample 545: Predicted 'I' (conf: 0.4030), True 'Q' ✗\n",
            "Sample 546: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 547: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 548: Predicted 'R' (conf: 0.9760), True 'S' ✗\n",
            "Sample 549: Predicted 'V' (conf: 0.5068), True 'V' ✓\n",
            "Sample 550: Predicted 'C' (conf: 0.9847), True 'C' ✓\n",
            "Sample 551: Predicted 'P' (conf: 0.9822), True 'D' ✗\n",
            "Sample 552: Predicted 'C' (conf: 0.9844), True 'C' ✓\n",
            "Sample 553: Predicted 'P' (conf: 0.9827), True 'D' ✗\n",
            "Sample 554: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 555: Predicted 'M' (conf: 0.4760), True 'M' ✓\n",
            "Sample 556: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 557: Predicted 'N' (conf: 0.9852), True 'N' ✓\n",
            "Sample 558: Predicted 'P' (conf: 0.9846), True 'P' ✓\n",
            "Sample 559: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 560: Predicted 'F' (conf: 0.9741), True 'F' ✓\n",
            "Sample 561: Predicted 'R' (conf: 0.3168), True 'K' ✗\n",
            "Sample 562: Predicted 'O' (conf: 0.9886), True 'O' ✓\n",
            "Sample 563: Predicted 'R' (conf: 0.9960), True 'R' ✓\n",
            "Sample 564: Predicted 'A' (conf: 0.9972), True 'A' ✓\n",
            "Sample 565: Predicted 'L' (conf: 0.7391), True 'I' ✗\n",
            "Sample 566: Predicted 'Q' (conf: 0.9912), True 'Q' ✓\n",
            "Sample 567: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 568: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 569: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 570: Predicted 'V' (conf: 0.9952), True 'V' ✓\n",
            "Sample 571: Predicted 'C' (conf: 0.9846), True 'C' ✓\n",
            "Sample 572: Predicted 'D' (conf: 0.9958), True 'D' ✓\n",
            "Sample 573: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 574: Predicted 'M' (conf: 0.9933), True 'M' ✓\n",
            "Sample 575: Predicted 'T' (conf: 0.9797), True 'T' ✓\n",
            "Sample 576: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 577: Predicted 'N' (conf: 0.9831), True 'N' ✓\n",
            "Sample 578: Predicted 'P' (conf: 0.7719), True 'P' ✓\n",
            "Sample 579: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 580: Predicted 'F' (conf: 0.9924), True 'F' ✓\n",
            "Sample 581: Predicted 'K' (conf: 0.9986), True 'K' ✓\n",
            "Sample 582: Predicted 'O' (conf: 0.9881), True 'O' ✓\n",
            "Sample 583: Predicted 'R' (conf: 0.9966), True 'R' ✓\n",
            "Sample 584: Predicted 'A' (conf: 0.9974), True 'A' ✓\n",
            "Sample 585: Predicted 'I' (conf: 0.9980), True 'I' ✓\n",
            "Sample 586: Predicted 'Y' (conf: 0.3082), True 'Q' ✗\n",
            "Sample 587: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 588: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 589: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 590: Predicted 'V' (conf: 0.9954), True 'V' ✓\n",
            "Sample 591: Predicted 'C' (conf: 0.9843), True 'C' ✓\n",
            "Sample 592: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 593: Predicted 'C' (conf: 0.9841), True 'C' ✓\n",
            "Sample 594: Predicted 'D' (conf: 0.9944), True 'D' ✓\n",
            "Sample 595: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 596: Predicted 'N' (conf: 0.5645), True 'M' ✗\n",
            "Sample 597: Predicted 'K' (conf: 0.9972), True 'T' ✗\n",
            "Sample 598: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 599: Predicted 'N' (conf: 0.6243), True 'N' ✓\n",
            "Sample 600: Predicted 'P' (conf: 0.9837), True 'P' ✓\n",
            "Sample 601: Predicted 'W' (conf: 0.6663), True 'W' ✓\n",
            "Sample 602: Predicted 'K' (conf: 0.9987), True 'K' ✓\n",
            "Sample 603: Predicted 'O' (conf: 0.9885), True 'W' ✗\n",
            "Sample 604: Predicted 'R' (conf: 0.9954), True 'R' ✓\n",
            "Sample 605: Predicted 'A' (conf: 0.9972), True 'A' ✓\n",
            "Sample 606: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 607: Predicted 'N' (conf: 0.5993), True 'Q' ✗\n",
            "Sample 608: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 609: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 610: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 611: Predicted 'V' (conf: 0.9955), True 'V' ✓\n",
            "Sample 612: Predicted 'S' (conf: 0.9992), True 'S' ✓\n",
            "Sample 613: Predicted 'C' (conf: 0.9844), True 'C' ✓\n",
            "Sample 614: Predicted 'X' (conf: 0.9984), True 'X' ✓\n",
            "Sample 615: Predicted 'F' (conf: 0.9920), True 'F' ✓\n",
            "Sample 616: Predicted 'A' (conf: 0.9975), True 'A' ✓\n",
            "Sample 617: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 618: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 619: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 620: Predicted 'V' (conf: 0.9901), True 'V' ✓\n",
            "Sample 621: Predicted 'K' (conf: 0.9985), True 'K' ✓\n",
            "Sample 622: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 623: Predicted 'L' (conf: 0.3430), True 'I' ✗\n",
            "Sample 624: Predicted 'N' (conf: 0.9722), True 'N' ✓\n",
            "Sample 625: Predicted 'Q' (conf: 0.4589), True 'F' ✗\n",
            "Sample 626: Predicted 'C' (conf: 0.5944), True 'S' ✗\n",
            "Sample 627: Predicted 'H' (conf: 0.9971), True 'Q' ✗\n",
            "Sample 628: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 629: Predicted 'O' (conf: 0.9178), True 'O' ✓\n",
            "Sample 630: Predicted 'X' (conf: 0.9952), True 'X' ✓\n",
            "Sample 631: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 632: Predicted 'M' (conf: 0.9931), True 'M' ✓\n",
            "Sample 633: Predicted 'D' (conf: 0.9937), True 'D' ✓\n",
            "Sample 634: Predicted 'C' (conf: 0.9844), True 'C' ✓\n",
            "Sample 635: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 636: Predicted 'P' (conf: 0.9844), True 'P' ✓\n",
            "Sample 637: Predicted 'H' (conf: 0.5510), True 'G' ✗\n",
            "Sample 638: Predicted 'N' (conf: 0.6272), True 'R' ✗\n",
            "Sample 639: Predicted 'A' (conf: 0.9150), True 'A' ✓\n",
            "Sample 640: Predicted 'V' (conf: 0.9949), True 'V' ✓\n",
            "Sample 641: Predicted 'K' (conf: 0.9990), True 'K' ✓\n",
            "Sample 642: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 643: Predicted 'Y' (conf: 0.8960), True 'Q' ✗\n",
            "Sample 644: Predicted 'W' (conf: 0.8162), True 'W' ✓\n",
            "Sample 645: Predicted 'A' (conf: 0.7976), True 'A' ✓\n",
            "Sample 646: Predicted 'V' (conf: 0.9957), True 'V' ✓\n",
            "Sample 647: Predicted 'F' (conf: 0.6682), True 'F' ✓\n",
            "Sample 648: Predicted 'C' (conf: 0.3894), True 'Z' ✗\n",
            "Sample 649: Predicted 'X' (conf: 0.9987), True 'X' ✓\n",
            "Sample 650: Predicted 'R' (conf: 0.8707), True 'R' ✓\n",
            "Sample 651: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 652: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 653: Predicted 'N' (conf: 0.9841), True 'N' ✓\n",
            "Sample 654: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 655: Predicted 'M' (conf: 0.4019), True 'M' ✓\n",
            "Sample 656: Predicted 'Z' (conf: 0.6591), True 'B' ✗\n",
            "Sample 657: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 658: Predicted 'N' (conf: 0.9842), True 'N' ✓\n",
            "Sample 659: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 660: Predicted 'V' (conf: 0.9952), True 'V' ✓\n",
            "Sample 661: Predicted 'P' (conf: 0.9845), True 'P' ✓\n",
            "Sample 662: Predicted 'R' (conf: 0.7873), True 'Z' ✗\n",
            "Sample 663: Predicted 'F' (conf: 0.9332), True 'F' ✓\n",
            "Sample 664: Predicted 'U' (conf: 0.9963), True 'U' ✓\n",
            "Sample 665: Predicted 'N' (conf: 0.5101), True 'M' ✗\n",
            "Sample 666: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 667: Predicted 'D' (conf: 0.9938), True 'D' ✓\n",
            "Sample 668: Predicted 'C' (conf: 0.9848), True 'C' ✓\n",
            "Sample 669: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 670: Predicted 'X' (conf: 0.9981), True 'X' ✓\n",
            "Sample 671: Predicted 'K' (conf: 0.9988), True 'T' ✗\n",
            "Sample 672: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 673: Predicted 'Q' (conf: 0.9917), True 'Q' ✓\n",
            "Sample 674: Predicted 'S' (conf: 0.6657), True 'S' ✓\n",
            "Sample 675: Predicted 'I' (conf: 0.9989), True 'I' ✓\n",
            "Sample 676: Predicted 'A' (conf: 0.9960), True 'A' ✓\n",
            "Sample 677: Predicted 'K' (conf: 0.9986), True 'T' ✗\n",
            "Sample 678: Predicted 'S' (conf: 0.6902), True 'S' ✓\n",
            "Sample 679: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 680: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 681: Predicted 'M' (conf: 0.6683), True 'M' ✓\n",
            "Sample 682: Predicted 'C' (conf: 0.9845), True 'C' ✓\n",
            "Sample 683: Predicted 'N' (conf: 0.9845), True 'N' ✓\n",
            "Sample 684: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 685: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 686: Predicted 'Q' (conf: 0.9915), True 'Q' ✓\n",
            "Sample 687: Predicted 'R' (conf: 0.9957), True 'R' ✓\n",
            "Sample 688: Predicted 'V' (conf: 0.9237), True 'V' ✓\n",
            "Sample 689: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 690: Predicted 'I' (conf: 0.9989), True 'I' ✓\n",
            "Sample 691: Predicted 'L' (conf: 0.9958), True 'L' ✓\n",
            "Sample 692: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 693: Predicted 'O' (conf: 0.9882), True 'O' ✓\n",
            "Sample 694: Predicted 'P' (conf: 0.6788), True 'P' ✓\n",
            "Sample 695: Predicted 'N' (conf: 0.7580), True 'N' ✓\n",
            "Sample 696: Predicted 'F' (conf: 0.9757), True 'F' ✓\n",
            "Sample 697: Predicted 'W' (conf: 0.7316), True 'Z' ✗\n",
            "Sample 698: Predicted 'N' (conf: 0.9555), True 'N' ✓\n",
            "Sample 699: Predicted 'I' (conf: 0.5406), True 'I' ✓\n",
            "Sample 700: Predicted 'R' (conf: 0.9960), True 'R' ✓\n",
            "Sample 701: Predicted 'D' (conf: 0.9958), True 'D' ✓\n",
            "Sample 702: Predicted 'A' (conf: 0.9975), True 'A' ✓\n",
            "Sample 703: Predicted 'H' (conf: 0.9965), True 'Q' ✗\n",
            "Sample 704: Predicted 'S' (conf: 0.9950), True 'S' ✓\n",
            "Sample 705: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 706: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 707: Predicted 'O' (conf: 0.9881), True 'O' ✓\n",
            "Sample 708: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 709: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 710: Predicted 'C' (conf: 0.9452), True 'C' ✓\n",
            "Sample 711: Predicted 'K' (conf: 0.9977), True 'T' ✗\n",
            "Sample 712: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 713: Predicted 'B' (conf: 0.9968), True 'B' ✓\n",
            "Sample 714: Predicted 'V' (conf: 0.9931), True 'V' ✓\n",
            "Sample 715: Predicted 'M' (conf: 0.5652), True 'M' ✓\n",
            "Sample 716: Predicted 'F' (conf: 0.9928), True 'F' ✓\n",
            "Sample 717: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 718: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 719: Predicted 'D' (conf: 0.4369), True 'T' ✗\n",
            "Sample 720: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 721: Predicted 'N' (conf: 0.4228), True 'M' ✗\n",
            "Sample 722: Predicted 'W' (conf: 0.9993), True 'S' ✗\n",
            "Sample 723: Predicted 'D' (conf: 0.9947), True 'D' ✓\n",
            "Sample 724: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 725: Predicted 'N' (conf: 0.4839), True 'N' ✓\n",
            "Sample 726: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 727: Predicted 'A' (conf: 0.9969), True 'A' ✓\n",
            "Sample 728: Predicted 'Y' (conf: 0.6520), True 'K' ✗\n",
            "Sample 729: Predicted 'N' (conf: 0.9766), True 'Q' ✗\n",
            "Sample 730: Predicted 'R' (conf: 0.3296), True 'R' ✓\n",
            "Sample 731: Predicted 'E' (conf: 0.9938), True 'E' ✓\n",
            "Sample 732: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 733: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 734: Predicted 'V' (conf: 0.9946), True 'V' ✓\n",
            "Sample 735: Predicted 'C' (conf: 0.9807), True 'C' ✓\n",
            "Sample 736: Predicted 'X' (conf: 0.9985), True 'X' ✓\n",
            "Sample 737: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 738: Predicted 'N' (conf: 0.9831), True 'N' ✓\n",
            "Sample 739: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 740: Predicted 'S' (conf: 0.2687), True 'S' ✓\n",
            "Sample 741: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 742: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 743: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 744: Predicted 'M' (conf: 0.9836), True 'M' ✓\n",
            "Sample 745: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 746: Predicted 'F' (conf: 0.6100), True 'F' ✓\n",
            "Sample 747: Predicted 'R' (conf: 0.9938), True 'R' ✓\n",
            "Sample 748: Predicted 'D' (conf: 0.9945), True 'D' ✓\n",
            "Sample 749: Predicted 'E' (conf: 0.6842), True 'Q' ✗\n",
            "Sample 750: Predicted 'X' (conf: 0.9984), True 'X' ✓\n",
            "Sample 751: Predicted 'K' (conf: 0.9988), True 'T' ✗\n",
            "Sample 752: Predicted 'F' (conf: 0.8545), True 'A' ✗\n",
            "Sample 753: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 754: Predicted 'P' (conf: 0.8714), True 'D' ✗\n",
            "Sample 755: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 756: Predicted 'P' (conf: 0.9843), True 'P' ✓\n",
            "Sample 757: Predicted 'R' (conf: 0.6555), True 'M' ✗\n",
            "Sample 758: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 759: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 760: Predicted 'X' (conf: 0.9986), True 'X' ✓\n",
            "Sample 761: Predicted 'N' (conf: 0.9857), True 'N' ✓\n",
            "Sample 762: Predicted 'V' (conf: 0.5732), True 'V' ✓\n",
            "Sample 763: Predicted 'L' (conf: 0.9958), True 'L' ✓\n",
            "Sample 764: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 765: Predicted 'O' (conf: 0.9882), True 'O' ✓\n",
            "Sample 766: Predicted 'F' (conf: 0.9942), True 'F' ✓\n",
            "Sample 767: Predicted 'L' (conf: 0.8700), True 'I' ✗\n",
            "Sample 768: Predicted 'S' (conf: 0.9849), True 'S' ✓\n",
            "Sample 769: Predicted 'R' (conf: 0.5766), True 'R' ✓\n",
            "Sample 770: Predicted 'A' (conf: 0.9973), True 'A' ✓\n",
            "Sample 771: Predicted 'Q' (conf: 0.9903), True 'Q' ✓\n",
            "Sample 772: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 773: Predicted 'K' (conf: 0.9987), True 'K' ✓\n",
            "Sample 774: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 775: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 776: Predicted 'X' (conf: 0.9986), True 'X' ✓\n",
            "Sample 777: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 778: Predicted 'K' (conf: 0.9990), True 'K' ✓\n",
            "Sample 779: Predicted 'M' (conf: 0.9874), True 'M' ✓\n",
            "Sample 780: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 781: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 782: Predicted 'K' (conf: 0.9988), True 'T' ✗\n",
            "Sample 783: Predicted 'C' (conf: 0.9844), True 'C' ✓\n",
            "Sample 784: Predicted 'D' (conf: 0.9945), True 'D' ✓\n",
            "Sample 785: Predicted 'R' (conf: 0.9964), True 'R' ✓\n",
            "Sample 786: Predicted 'A' (conf: 0.9971), True 'A' ✓\n",
            "Sample 787: Predicted 'W' (conf: 0.6750), True 'I' ✗\n",
            "Sample 788: Predicted 'N' (conf: 0.5306), True 'N' ✓\n",
            "Sample 789: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 790: Predicted 'F' (conf: 0.4990), True 'F' ✓\n",
            "Sample 791: Predicted 'V' (conf: 0.9954), True 'V' ✓\n",
            "Sample 792: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 793: Predicted 'P' (conf: 0.8757), True 'P' ✓\n",
            "Sample 794: Predicted 'R' (conf: 0.6089), True 'Q' ✗\n",
            "Sample 795: Predicted 'V' (conf: 0.9894), True 'V' ✓\n",
            "Sample 796: Predicted 'I' (conf: 0.2957), True 'S' ✗\n",
            "Sample 797: Predicted 'M' (conf: 0.9945), True 'N' ✗\n",
            "Sample 798: Predicted 'C' (conf: 0.9845), True 'C' ✓\n",
            "Sample 799: Predicted 'X' (conf: 0.9985), True 'X' ✓\n",
            "Sample 800: Predicted 'W' (conf: 0.6278), True 'W' ✓\n",
            "Sample 801: Predicted 'O' (conf: 0.9888), True 'O' ✓\n",
            "Sample 802: Predicted 'F' (conf: 0.8137), True 'A' ✗\n",
            "Sample 803: Predicted 'D' (conf: 0.9957), True 'D' ✓\n",
            "Sample 804: Predicted 'F' (conf: 0.9853), True 'F' ✓\n",
            "Sample 805: Predicted 'K' (conf: 0.9939), True 'K' ✓\n",
            "Sample 806: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 807: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 808: Predicted 'T' (conf: 0.6491), True 'T' ✓\n",
            "Sample 809: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 810: Predicted 'V' (conf: 0.9954), True 'V' ✓\n",
            "Sample 811: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 812: Predicted 'L' (conf: 0.9961), True 'L' ✓\n",
            "Sample 813: Predicted 'N' (conf: 0.7788), True 'N' ✓\n",
            "Sample 814: Predicted 'I' (conf: 0.5410), True 'P' ✗\n",
            "Sample 815: Predicted 'R' (conf: 0.4727), True 'Q' ✗\n",
            "Sample 816: Predicted 'M' (conf: 0.9940), True 'M' ✓\n",
            "Sample 817: Predicted 'K' (conf: 0.9987), True 'Z' ✗\n",
            "Sample 818: Predicted 'V' (conf: 0.8317), True 'C' ✗\n",
            "Sample 819: Predicted 'F' (conf: 0.9956), True 'B' ✗\n",
            "Sample 820: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 821: Predicted 'V' (conf: 0.9953), True 'V' ✓\n",
            "Sample 822: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 823: Predicted 'U' (conf: 0.9951), True 'U' ✓\n",
            "Sample 824: Predicted 'S' (conf: 0.9992), True 'S' ✓\n",
            "Sample 825: Predicted 'L' (conf: 0.6510), True 'X' ✗\n",
            "Sample 826: Predicted 'D' (conf: 0.6205), True 'A' ✗\n",
            "Sample 827: Predicted 'N' (conf: 0.6516), True 'N' ✓\n",
            "Sample 828: Predicted 'O' (conf: 0.9827), True 'P' ✗\n",
            "Sample 829: Predicted 'D' (conf: 0.9944), True 'D' ✓\n",
            "Sample 830: Predicted 'O' (conf: 0.5161), True 'O' ✓\n",
            "Sample 831: Predicted 'G' (conf: 0.7085), True 'G' ✓\n",
            "Sample 832: Predicted 'Q' (conf: 0.6548), True 'Q' ✓\n",
            "Sample 833: Predicted 'T' (conf: 0.9702), True 'T' ✓\n",
            "Sample 834: Predicted 'F' (conf: 0.9910), True 'F' ✓\n",
            "Sample 835: Predicted 'V' (conf: 0.9911), True 'V' ✓\n",
            "Sample 836: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 837: Predicted 'P' (conf: 0.9850), True 'P' ✓\n",
            "Sample 838: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 839: Predicted 'X' (conf: 0.9985), True 'X' ✓\n",
            "Sample 840: Predicted 'A' (conf: 0.9971), True 'A' ✓\n",
            "Sample 841: Predicted 'B' (conf: 0.9973), True 'B' ✓\n",
            "Sample 842: Predicted 'C' (conf: 0.9845), True 'C' ✓\n",
            "Sample 843: Predicted 'D' (conf: 0.9949), True 'D' ✓\n",
            "Sample 844: Predicted 'F' (conf: 0.6946), True 'F' ✓\n",
            "Sample 845: Predicted 'U' (conf: 0.9967), True 'O' ✗\n",
            "Sample 846: Predicted 'A' (conf: 0.9971), True 'A' ✓\n",
            "Sample 847: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 848: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 849: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 850: Predicted 'L' (conf: 0.9958), True 'L' ✓\n",
            "Sample 851: Predicted 'G' (conf: 0.6879), True 'G' ✓\n",
            "Sample 852: Predicted 'D' (conf: 0.9945), True 'D' ✓\n",
            "Sample 853: Predicted 'O' (conf: 0.8424), True 'S' ✗\n",
            "Sample 854: Predicted 'M' (conf: 0.5802), True 'M' ✓\n",
            "Sample 855: Predicted 'Q' (conf: 0.5283), True 'Q' ✓\n",
            "Sample 856: Predicted 'M' (conf: 0.3352), True 'N' ✗\n",
            "Sample 857: Predicted 'C' (conf: 0.9848), True 'C' ✓\n",
            "Sample 858: Predicted 'W' (conf: 0.9844), True 'R' ✗\n",
            "Sample 859: Predicted 'V' (conf: 0.9956), True 'V' ✓\n",
            "Sample 860: Predicted 'I' (conf: 0.9988), True 'I' ✓\n",
            "Sample 861: Predicted 'W' (conf: 0.4726), True 'W' ✓\n",
            "Sample 862: Predicted 'T' (conf: 0.9831), True 'T' ✓\n",
            "Sample 863: Predicted 'R' (conf: 0.3391), True 'B' ✗\n",
            "Sample 864: Predicted 'O' (conf: 0.9887), True 'O' ✓\n",
            "Sample 865: Predicted 'Q' (conf: 0.9892), True 'Q' ✓\n",
            "Sample 866: Predicted 'D' (conf: 0.9937), True 'D' ✓\n",
            "Sample 867: Predicted 'W' (conf: 0.6604), True 'S' ✗\n",
            "Sample 868: Predicted 'U' (conf: 0.9956), True 'U' ✓\n",
            "Sample 869: Predicted 'V' (conf: 0.9953), True 'V' ✓\n",
            "Sample 870: Predicted 'N' (conf: 0.9847), True 'N' ✓\n",
            "Sample 871: Predicted 'Z' (conf: 0.6663), True 'Z' ✓\n",
            "Sample 872: Predicted 'G' (conf: 0.9539), True 'G' ✓\n",
            "Sample 873: Predicted 'T' (conf: 0.9209), True 'T' ✓\n",
            "Sample 874: Predicted 'K' (conf: 0.9987), True 'K' ✓\n",
            "Sample 875: Predicted 'M' (conf: 0.9897), True 'M' ✓\n",
            "Sample 876: Predicted 'I' (conf: 0.8653), True 'I' ✓\n",
            "Sample 877: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 878: Predicted 'R' (conf: 0.6628), True 'R' ✓\n",
            "Sample 879: Predicted 'L' (conf: 0.9954), True 'C' ✗\n",
            "Sample 880: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 881: Predicted 'J' (conf: 0.9871), True 'A' ✗\n",
            "Sample 882: Predicted 'Q' (conf: 0.7255), True 'F' ✗\n",
            "Sample 883: Predicted 'X' (conf: 0.9987), True 'X' ✓\n",
            "Sample 884: Predicted 'D' (conf: 0.9945), True 'D' ✓\n",
            "Sample 885: Predicted 'T' (conf: 0.9791), True 'T' ✓\n",
            "Sample 886: Predicted 'M' (conf: 0.9943), True 'M' ✓\n",
            "Sample 887: Predicted 'L' (conf: 0.9920), True 'C' ✗\n",
            "Sample 888: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 889: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 890: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 891: Predicted 'P' (conf: 0.9843), True 'P' ✓\n",
            "Sample 892: Predicted 'N' (conf: 0.4585), True 'N' ✓\n",
            "Sample 893: Predicted 'G' (conf: 0.7163), True 'F' ✗\n",
            "Sample 894: Predicted 'O' (conf: 0.9885), True 'O' ✓\n",
            "Sample 895: Predicted 'R' (conf: 0.9880), True 'R' ✓\n",
            "Sample 896: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 897: Predicted 'F' (conf: 0.7503), True 'A' ✗\n",
            "Sample 898: Predicted 'E' (conf: 0.9765), True 'Q' ✗\n",
            "Sample 899: Predicted 'I' (conf: 0.7577), True 'I' ✓\n",
            "Sample 900: Predicted 'X' (conf: 0.9984), True 'X' ✓\n",
            "Sample 901: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 902: Predicted 'T' (conf: 0.5540), True 'S' ✗\n",
            "Sample 903: Predicted 'V' (conf: 0.6624), True 'V' ✓\n",
            "Sample 904: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 905: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 906: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 907: Predicted 'P' (conf: 0.9840), True 'P' ✓\n",
            "Sample 908: Predicted 'A' (conf: 0.9971), True 'A' ✓\n",
            "Sample 909: Predicted 'C' (conf: 0.4893), True 'C' ✓\n",
            "Sample 910: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 911: Predicted 'L' (conf: 0.7771), True 'V' ✗\n",
            "Sample 912: Predicted 'D' (conf: 0.9946), True 'D' ✓\n",
            "Sample 913: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 914: Predicted 'K' (conf: 0.9989), True 'T' ✗\n",
            "Sample 915: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 916: Predicted 'O' (conf: 0.9881), True 'O' ✓\n",
            "Sample 917: Predicted 'M' (conf: 0.9816), True 'M' ✓\n",
            "Sample 918: Predicted 'X' (conf: 0.9988), True 'X' ✓\n",
            "Sample 919: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 920: Predicted 'F' (conf: 0.9900), True 'Q' ✗\n",
            "Sample 921: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 922: Predicted 'I' (conf: 0.9988), True 'I' ✓\n",
            "Sample 923: Predicted 'N' (conf: 0.7825), True 'R' ✗\n",
            "Sample 924: Predicted 'R' (conf: 0.6671), True 'N' ✗\n",
            "Sample 925: Predicted 'F' (conf: 0.5664), True 'A' ✗\n",
            "Sample 926: Predicted 'W' (conf: 0.9937), True 'W' ✓\n",
            "Sample 927: Predicted 'L' (conf: 0.9960), True 'X' ✗\n",
            "Sample 928: Predicted 'Z' (conf: 0.9993), True 'Z' ✓\n",
            "Sample 929: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 930: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 931: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 932: Predicted 'C' (conf: 0.9837), True 'C' ✓\n",
            "Sample 933: Predicted 'O' (conf: 0.9886), True 'O' ✓\n",
            "Sample 934: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 935: Predicted 'Q' (conf: 0.9918), True 'Q' ✓\n",
            "Sample 936: Predicted 'V' (conf: 0.9955), True 'V' ✓\n",
            "Sample 937: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 938: Predicted 'P' (conf: 0.9850), True 'P' ✓\n",
            "Sample 939: Predicted 'N' (conf: 0.9794), True 'N' ✓\n",
            "Sample 940: Predicted 'T' (conf: 0.9798), True 'T' ✓\n",
            "Sample 941: Predicted 'R' (conf: 0.9945), True 'R' ✓\n",
            "Sample 942: Predicted 'Q' (conf: 0.7467), True 'F' ✗\n",
            "Sample 943: Predicted 'L' (conf: 0.4581), True 'I' ✗\n",
            "Sample 944: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 945: Predicted 'M' (conf: 0.8703), True 'N' ✗\n",
            "Sample 946: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 947: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 948: Predicted 'V' (conf: 0.9954), True 'V' ✓\n",
            "Sample 949: Predicted 'R' (conf: 0.9963), True 'R' ✓\n",
            "Sample 950: Predicted 'D' (conf: 0.4326), True 'K' ✗\n",
            "Sample 951: Predicted 'L' (conf: 0.9958), True 'C' ✗\n",
            "Sample 952: Predicted 'R' (conf: 0.6955), True 'A' ✗\n",
            "Sample 953: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 954: Predicted 'M' (conf: 0.9925), True 'M' ✓\n",
            "Sample 955: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 956: Predicted 'X' (conf: 0.9984), True 'X' ✓\n",
            "Sample 957: Predicted 'I' (conf: 0.9855), True 'I' ✓\n",
            "Sample 958: Predicted 'T' (conf: 0.9352), True 'T' ✓\n",
            "Sample 959: Predicted 'B' (conf: 0.9938), True 'B' ✓\n",
            "Sample 960: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 961: Predicted 'F' (conf: 0.9783), True 'F' ✓\n",
            "Sample 962: Predicted 'P' (conf: 0.9844), True 'P' ✓\n",
            "Sample 963: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 964: Predicted 'D' (conf: 0.9940), True 'D' ✓\n",
            "Sample 965: Predicted 'T' (conf: 0.9761), True 'T' ✓\n",
            "Sample 966: Predicted 'O' (conf: 0.9732), True 'O' ✓\n",
            "Sample 967: Predicted 'I' (conf: 0.9991), True 'I' ✓\n",
            "Sample 968: Predicted 'S' (conf: 0.9961), True 'S' ✓\n",
            "Sample 969: Predicted 'T' (conf: 0.9807), True 'T' ✓\n",
            "Sample 970: Predicted 'J' (conf: 0.5167), True 'B' ✗\n",
            "Sample 971: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 972: Predicted 'F' (conf: 0.9924), True 'F' ✓\n",
            "Sample 973: Predicted 'K' (conf: 0.9983), True 'K' ✓\n",
            "Sample 974: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 975: Predicted 'A' (conf: 0.5615), True 'Q' ✗\n",
            "Sample 976: Predicted 'M' (conf: 0.9938), True 'M' ✓\n",
            "Sample 977: Predicted 'A' (conf: 0.9974), True 'A' ✓\n",
            "Sample 978: Predicted 'R' (conf: 0.9953), True 'R' ✓\n",
            "Sample 979: Predicted 'P' (conf: 0.5234), True 'P' ✓\n",
            "Sample 980: Predicted 'C' (conf: 0.9832), True 'C' ✓\n",
            "Sample 981: Predicted 'V' (conf: 0.9954), True 'V' ✓\n",
            "Sample 982: Predicted 'N' (conf: 0.8507), True 'N' ✓\n",
            "Sample 983: Predicted 'D' (conf: 0.9945), True 'D' ✓\n",
            "Sample 984: Predicted 'W' (conf: 0.9990), True 'W' ✓\n",
            "Sample 985: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 986: Predicted 'R' (conf: 0.5011), True 'M' ✗\n",
            "Sample 987: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 988: Predicted 'V' (conf: 0.9866), True 'V' ✓\n",
            "Sample 989: Predicted 'R' (conf: 0.9966), True 'R' ✓\n",
            "Sample 990: Predicted 'T' (conf: 0.6377), True 'T' ✓\n",
            "Sample 991: Predicted 'X' (conf: 0.9986), True 'X' ✓\n",
            "Sample 992: Predicted 'C' (conf: 0.9845), True 'C' ✓\n",
            "Sample 993: Predicted 'D' (conf: 0.9962), True 'D' ✓\n",
            "Sample 994: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 995: Predicted 'I' (conf: 0.9991), True 'I' ✓\n",
            "Sample 996: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 997: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 998: Predicted 'R' (conf: 0.5351), True 'N' ✗\n",
            "Sample 999: Predicted 'F' (conf: 0.9302), True 'F' ✓\n",
            "Sample 1000: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 1001: Predicted 'U' (conf: 0.9228), True 'O' ✗\n",
            "Sample 1002: Predicted 'A' (conf: 0.7636), True 'A' ✓\n",
            "Sample 1003: Predicted 'W' (conf: 0.9711), True 'W' ✓\n",
            "Sample 1004: Predicted 'W' (conf: 0.6765), True 'S' ✗\n",
            "Sample 1005: Predicted 'H' (conf: 0.9772), True 'Q' ✗\n",
            "Sample 1006: Predicted 'K' (conf: 0.9989), True 'T' ✗\n",
            "Sample 1007: Predicted 'W' (conf: 0.4913), True 'M' ✗\n",
            "Sample 1008: Predicted 'C' (conf: 0.9845), True 'C' ✓\n",
            "Sample 1009: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 1010: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 1011: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1012: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 1013: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1014: Predicted 'P' (conf: 0.9838), True 'P' ✓\n",
            "Sample 1015: Predicted 'W' (conf: 0.6778), True 'W' ✓\n",
            "Sample 1016: Predicted 'F' (conf: 0.9949), True 'Q' ✗\n",
            "Sample 1017: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 1018: Predicted 'V' (conf: 0.8100), True 'V' ✓\n",
            "Sample 1019: Predicted 'X' (conf: 0.9986), True 'X' ✓\n",
            "Sample 1020: Predicted 'H' (conf: 0.9454), True 'H' ✓\n",
            "Sample 1021: Predicted 'R' (conf: 0.4974), True 'R' ✓\n",
            "Sample 1022: Predicted 'R' (conf: 0.6378), True 'N' ✗\n",
            "Sample 1023: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 1024: Predicted 'D' (conf: 0.9938), True 'D' ✓\n",
            "Sample 1025: Predicted 'A' (conf: 0.9970), True 'A' ✓\n",
            "Sample 1026: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1027: Predicted 'A' (conf: 0.5030), True 'A' ✓\n",
            "Sample 1028: Predicted 'R' (conf: 0.9966), True 'R' ✓\n",
            "Sample 1029: Predicted 'M' (conf: 0.6655), True 'N' ✗\n",
            "Sample 1030: Predicted 'Q' (conf: 0.9919), True 'Q' ✓\n",
            "Sample 1031: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 1032: Predicted 'C' (conf: 0.9843), True 'C' ✓\n",
            "Sample 1033: Predicted 'I' (conf: 0.9626), True 'I' ✓\n",
            "Sample 1034: Predicted 'P' (conf: 0.9848), True 'P' ✓\n",
            "Sample 1035: Predicted 'Q' (conf: 0.5913), True 'F' ✗\n",
            "Sample 1036: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 1037: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 1038: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 1039: Predicted 'T' (conf: 0.9820), True 'T' ✓\n",
            "Sample 1040: Predicted 'X' (conf: 0.9985), True 'X' ✓\n",
            "Sample 1041: Predicted 'D' (conf: 0.9944), True 'D' ✓\n",
            "Sample 1042: Predicted 'V' (conf: 0.9937), True 'V' ✓\n",
            "Sample 1043: Predicted 'S' (conf: 0.3795), True 'S' ✓\n",
            "Sample 1044: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 1045: Predicted 'W' (conf: 0.9985), True 'S' ✗\n",
            "Sample 1046: Predicted 'U' (conf: 0.9961), True 'U' ✓\n",
            "Sample 1047: Predicted 'O' (conf: 0.9882), True 'O' ✓\n",
            "Sample 1048: Predicted 'O' (conf: 0.9878), True 'I' ✗\n",
            "Sample 1049: Predicted 'K' (conf: 0.9985), True 'K' ✓\n",
            "Sample 1050: Predicted 'V' (conf: 0.9954), True 'V' ✓\n",
            "Sample 1051: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1052: Predicted 'V' (conf: 0.9953), True 'V' ✓\n",
            "Sample 1053: Predicted 'M' (conf: 0.7179), True 'N' ✗\n",
            "Sample 1054: Predicted 'F' (conf: 0.9350), True 'Q' ✗\n",
            "Sample 1055: Predicted 'B' (conf: 0.9967), True 'B' ✓\n",
            "Sample 1056: Predicted 'C' (conf: 0.9838), True 'C' ✓\n",
            "Sample 1057: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 1058: Predicted 'T' (conf: 0.9592), True 'T' ✓\n",
            "Sample 1059: Predicted 'O' (conf: 0.9881), True 'O' ✓\n",
            "Sample 1060: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 1061: Predicted 'W' (conf: 0.9992), True 'W' ✓\n",
            "Sample 1062: Predicted 'Z' (conf: 0.9993), True 'Z' ✓\n",
            "Sample 1063: Predicted 'X' (conf: 0.9980), True 'X' ✓\n",
            "Sample 1064: Predicted 'P' (conf: 0.9847), True 'P' ✓\n",
            "Sample 1065: Predicted 'M' (conf: 0.9941), True 'M' ✓\n",
            "Sample 1066: Predicted 'R' (conf: 0.7929), True 'A' ✗\n",
            "Sample 1067: Predicted 'F' (conf: 0.9943), True 'F' ✓\n",
            "Sample 1068: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 1069: Predicted 'W' (conf: 0.6983), True 'R' ✗\n",
            "Sample 1070: Predicted 'V' (conf: 0.8160), True 'L' ✗\n",
            "Sample 1071: Predicted 'H' (conf: 0.6618), True 'W' ✗\n",
            "Sample 1072: Predicted 'O' (conf: 0.9799), True 'C' ✗\n",
            "Sample 1073: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 1074: Predicted 'K' (conf: 0.9985), True 'K' ✓\n",
            "Sample 1075: Predicted 'P' (conf: 0.9845), True 'P' ✓\n",
            "Sample 1076: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 1077: Predicted 'K' (conf: 0.9984), True 'T' ✗\n",
            "Sample 1078: Predicted 'M' (conf: 0.9946), True 'M' ✓\n",
            "Sample 1079: Predicted 'R' (conf: 0.7610), True 'S' ✗\n",
            "Sample 1080: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1081: Predicted 'X' (conf: 0.9985), True 'X' ✓\n",
            "Sample 1082: Predicted 'A' (conf: 0.9972), True 'A' ✓\n",
            "Sample 1083: Predicted 'M' (conf: 0.5837), True 'N' ✗\n",
            "Sample 1084: Predicted 'D' (conf: 0.9939), True 'P' ✗\n",
            "Sample 1085: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1086: Predicted 'X' (conf: 0.9153), True 'B' ✗\n",
            "Sample 1087: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 1088: Predicted 'R' (conf: 0.9889), True 'R' ✓\n",
            "Sample 1089: Predicted 'O' (conf: 0.9885), True 'O' ✓\n",
            "Sample 1090: Predicted 'F' (conf: 0.9943), True 'F' ✓\n",
            "Sample 1091: Predicted 'D' (conf: 0.9948), True 'D' ✓\n",
            "Sample 1092: Predicted 'I' (conf: 0.6785), True 'X' ✗\n",
            "Sample 1093: Predicted 'R' (conf: 0.9074), True 'R' ✓\n",
            "Sample 1094: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 1095: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 1096: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 1097: Predicted 'P' (conf: 0.6578), True 'P' ✓\n",
            "Sample 1098: Predicted 'C' (conf: 0.9844), True 'C' ✓\n",
            "Sample 1099: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 1100: Predicted 'A' (conf: 0.9859), True 'A' ✓\n",
            "Sample 1101: Predicted 'O' (conf: 0.9878), True 'O' ✓\n",
            "Sample 1102: Predicted 'R' (conf: 0.9946), True 'N' ✗\n",
            "Sample 1103: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 1104: Predicted 'F' (conf: 0.9935), True 'F' ✓\n",
            "Sample 1105: Predicted 'R' (conf: 0.9121), True 'M' ✗\n",
            "Sample 1106: Predicted 'G' (conf: 0.3531), True 'G' ✓\n",
            "Sample 1107: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 1108: Predicted 'Q' (conf: 0.9912), True 'Q' ✓\n",
            "Sample 1109: Predicted 'S' (conf: 0.9993), True 'S' ✓\n",
            "Sample 1110: Predicted 'K' (conf: 0.9988), True 'T' ✗\n",
            "Sample 1111: Predicted 'I' (conf: 0.9988), True 'I' ✓\n",
            "Sample 1112: Predicted 'H' (conf: 0.8561), True 'W' ✗\n",
            "Sample 1113: Predicted 'K' (conf: 0.9988), True 'T' ✗\n",
            "Sample 1114: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 1115: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 1116: Predicted 'Z' (conf: 0.7508), True 'Z' ✓\n",
            "Sample 1117: Predicted 'D' (conf: 0.9939), True 'D' ✓\n",
            "Sample 1118: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1119: Predicted 'F' (conf: 0.9827), True 'Q' ✗\n",
            "Sample 1120: Predicted 'R' (conf: 0.6000), True 'R' ✓\n",
            "Sample 1121: Predicted 'X' (conf: 0.9984), True 'X' ✓\n",
            "Sample 1122: Predicted 'O' (conf: 0.9854), True 'O' ✓\n",
            "Sample 1123: Predicted 'N' (conf: 0.8417), True 'N' ✓\n",
            "Sample 1124: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1125: Predicted 'C' (conf: 0.3683), True 'S' ✗\n",
            "Sample 1126: Predicted 'M' (conf: 0.9837), True 'M' ✓\n",
            "Sample 1127: Predicted 'F' (conf: 0.5930), True 'F' ✓\n",
            "Sample 1128: Predicted 'P' (conf: 0.9842), True 'P' ✓\n",
            "Sample 1129: Predicted 'L' (conf: 0.9458), True 'V' ✗\n",
            "Sample 1130: Predicted 'O' (conf: 0.6558), True 'C' ✗\n",
            "Sample 1131: Predicted 'D' (conf: 0.9944), True 'D' ✓\n",
            "Sample 1132: Predicted 'Y' (conf: 0.8849), True 'Q' ✗\n",
            "Sample 1133: Predicted 'B' (conf: 0.9968), True 'B' ✓\n",
            "Sample 1134: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 1135: Predicted 'V' (conf: 0.9955), True 'V' ✓\n",
            "Sample 1136: Predicted 'O' (conf: 0.9882), True 'I' ✗\n",
            "Sample 1137: Predicted 'P' (conf: 0.8893), True 'T' ✗\n",
            "Sample 1138: Predicted 'R' (conf: 0.9964), True 'R' ✓\n",
            "Sample 1139: Predicted 'M' (conf: 0.9939), True 'M' ✓\n",
            "Sample 1140: Predicted 'Z' (conf: 0.9993), True 'Z' ✓\n",
            "Sample 1141: Predicted 'W' (conf: 0.9991), True 'S' ✗\n",
            "Sample 1142: Predicted 'R' (conf: 0.5163), True 'A' ✗\n",
            "Sample 1143: Predicted 'F' (conf: 0.9954), True 'F' ✓\n",
            "Sample 1144: Predicted 'M' (conf: 0.9055), True 'N' ✗\n",
            "Sample 1145: Predicted 'P' (conf: 0.9846), True 'P' ✓\n",
            "Sample 1146: Predicted 'X' (conf: 0.9984), True 'X' ✓\n",
            "Sample 1147: Predicted 'O' (conf: 0.9879), True 'O' ✓\n",
            "Sample 1148: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1149: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1150: Predicted 'V' (conf: 0.9957), True 'V' ✓\n",
            "Sample 1151: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 1152: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 1153: Predicted 'D' (conf: 0.9939), True 'D' ✓\n",
            "Sample 1154: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 1155: Predicted 'V' (conf: 0.6093), True 'V' ✓\n",
            "Sample 1156: Predicted 'N' (conf: 0.9819), True 'N' ✓\n",
            "Sample 1157: Predicted 'W' (conf: 0.6667), True 'T' ✗\n",
            "Sample 1158: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 1159: Predicted 'O' (conf: 0.9887), True 'O' ✓\n",
            "Sample 1160: Predicted 'U' (conf: 0.4216), True 'A' ✗\n",
            "Sample 1161: Predicted 'Q' (conf: 0.9867), True 'Q' ✓\n",
            "Sample 1162: Predicted 'M' (conf: 0.9921), True 'M' ✓\n",
            "Sample 1163: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 1164: Predicted 'Y' (conf: 0.4411), True 'Q' ✗\n",
            "Sample 1165: Predicted 'P' (conf: 0.9848), True 'P' ✓\n",
            "Sample 1166: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1167: Predicted 'C' (conf: 0.9845), True 'C' ✓\n",
            "Sample 1168: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 1169: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 1170: Predicted 'U' (conf: 0.9915), True 'U' ✓\n",
            "Sample 1171: Predicted 'Y' (conf: 0.5752), True 'Q' ✗\n",
            "Sample 1172: Predicted 'M' (conf: 0.9942), True 'M' ✓\n",
            "Sample 1173: Predicted 'R' (conf: 0.9965), True 'R' ✓\n",
            "Sample 1174: Predicted 'D' (conf: 0.9942), True 'D' ✓\n",
            "Sample 1175: Predicted 'P' (conf: 0.9848), True 'P' ✓\n",
            "Sample 1176: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 1177: Predicted 'N' (conf: 0.9852), True 'N' ✓\n",
            "Sample 1178: Predicted 'K' (conf: 0.9984), True 'T' ✗\n",
            "Sample 1179: Predicted 'V' (conf: 0.5068), True 'V' ✓\n",
            "Sample 1180: Predicted 'W' (conf: 0.9990), True 'W' ✓\n",
            "Sample 1181: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 1182: Predicted 'E' (conf: 0.5391), True 'Q' ✗\n",
            "Sample 1183: Predicted 'V' (conf: 0.9956), True 'V' ✓\n",
            "Sample 1184: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 1185: Predicted 'N' (conf: 0.7088), True 'R' ✗\n",
            "Sample 1186: Predicted 'U' (conf: 0.9963), True 'U' ✓\n",
            "Sample 1187: Predicted 'D' (conf: 0.9941), True 'D' ✓\n",
            "Sample 1188: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "Sample 1189: Predicted 'G' (conf: 0.9989), True 'G' ✓\n",
            "Sample 1190: Predicted 'O' (conf: 0.9886), True 'O' ✓\n",
            "Sample 1191: Predicted 'D' (conf: 0.4487), True 'K' ✗\n",
            "Sample 1192: Predicted 'G' (conf: 0.9989), True 'G' ✓\n",
            "Sample 1193: Predicted 'R' (conf: 0.9110), True 'R' ✓\n",
            "Sample 1194: Predicted 'P' (conf: 0.9846), True 'P' ✓\n",
            "Sample 1195: Predicted 'L' (conf: 0.9807), True 'L' ✓\n",
            "Sample 1196: Predicted 'C' (conf: 0.9843), True 'C' ✓\n",
            "Sample 1197: Predicted 'D' (conf: 0.6674), True 'D' ✓\n",
            "Sample 1198: Predicted 'S' (conf: 0.5740), True 'F' ✗\n",
            "Sample 1199: Predicted 'Z' (conf: 0.9993), True 'Z' ✓\n",
            "Sample 1200: Predicted 'Y' (conf: 0.9963), True 'Q' ✗\n",
            "Sample 1201: Predicted 'P' (conf: 0.9845), True 'P' ✓\n",
            "Sample 1202: Predicted 'A' (conf: 0.8426), True 'A' ✓\n",
            "Sample 1203: Predicted 'D' (conf: 0.9947), True 'D' ✓\n",
            "Sample 1204: Predicted 'W' (conf: 0.6708), True 'W' ✓\n",
            "Sample 1205: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 1206: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 1207: Predicted 'G' (conf: 0.5866), True 'G' ✓\n",
            "Sample 1208: Predicted 'E' (conf: 0.2630), True 'I' ✗\n",
            "Sample 1209: Predicted 'K' (conf: 0.4118), True 'K' ✓\n",
            "Sample 1210: Predicted 'R' (conf: 0.5722), True 'A' ✗\n",
            "Sample 1211: Predicted 'I' (conf: 0.6240), True 'X' ✗\n",
            "Sample 1212: Predicted 'K' (conf: 0.9987), True 'K' ✓\n",
            "Sample 1213: Predicted 'M' (conf: 0.9886), True 'M' ✓\n",
            "Sample 1214: Predicted 'V' (conf: 0.9955), True 'V' ✓\n",
            "Sample 1215: Predicted 'E' (conf: 0.6563), True 'F' ✗\n",
            "Sample 1216: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 1217: Predicted 'C' (conf: 0.9839), True 'C' ✓\n",
            "Sample 1218: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 1219: Predicted 'A' (conf: 0.9968), True 'A' ✓\n",
            "Sample 1220: Predicted 'K' (conf: 0.9984), True 'T' ✗\n",
            "Sample 1221: Predicted 'X' (conf: 0.9982), True 'X' ✓\n",
            "Sample 1222: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 1223: Predicted 'I' (conf: 0.9149), True 'I' ✓\n",
            "Sample 1224: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 1225: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 1226: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 1227: Predicted 'D' (conf: 0.9944), True 'D' ✓\n",
            "Sample 1228: Predicted 'R' (conf: 0.9291), True 'N' ✗\n",
            "Sample 1229: Predicted 'P' (conf: 0.9846), True 'P' ✓\n",
            "Sample 1230: Predicted 'G' (conf: 0.9988), True 'G' ✓\n",
            "Sample 1231: Predicted 'R' (conf: 0.9966), True 'R' ✓\n",
            "Sample 1232: Predicted 'X' (conf: 0.3798), True 'X' ✓\n",
            "Sample 1233: Predicted 'N' (conf: 0.9672), True 'N' ✓\n",
            "Sample 1234: Predicted 'O' (conf: 0.9888), True 'O' ✓\n",
            "Sample 1235: Predicted 'F' (conf: 0.9521), True 'Q' ✗\n",
            "Sample 1236: Predicted 'P' (conf: 0.9846), True 'P' ✓\n",
            "Sample 1237: Predicted 'W' (conf: 0.9984), True 'W' ✓\n",
            "Sample 1238: Predicted 'M' (conf: 0.9944), True 'M' ✓\n",
            "Sample 1239: Predicted 'D' (conf: 0.9935), True 'D' ✓\n",
            "Sample 1240: Predicted 'I' (conf: 0.9991), True 'I' ✓\n",
            "Sample 1241: Predicted 'K' (conf: 0.9985), True 'T' ✗\n",
            "Sample 1242: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1243: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "Sample 1244: Predicted 'V' (conf: 0.9956), True 'V' ✓\n",
            "Sample 1245: Predicted 'O' (conf: 0.9874), True 'U' ✗\n",
            "Sample 1246: Predicted 'K' (conf: 0.9986), True 'K' ✓\n",
            "Sample 1247: Predicted 'F' (conf: 0.8813), True 'A' ✗\n",
            "Sample 1248: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 1249: Predicted 'K' (conf: 0.9985), True 'T' ✗\n",
            "Sample 1250: Predicted 'S' (conf: 0.9993), True 'S' ✓\n",
            "Sample 1251: Predicted 'F' (conf: 0.9188), True 'A' ✗\n",
            "Sample 1252: Predicted 'R' (conf: 0.9693), True 'R' ✓\n",
            "Sample 1253: Predicted 'K' (conf: 0.9986), True 'K' ✓\n",
            "Sample 1254: Predicted 'P' (conf: 0.8161), True 'Q' ✗\n",
            "Sample 1255: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 1256: Predicted 'B' (conf: 0.9972), True 'B' ✓\n",
            "Sample 1257: Predicted 'C' (conf: 0.7084), True 'C' ✓\n",
            "Sample 1258: Predicted 'O' (conf: 0.9882), True 'O' ✓\n",
            "Sample 1259: Predicted 'D' (conf: 0.9092), True 'P' ✗\n",
            "Sample 1260: Predicted 'T' (conf: 0.8102), True 'F' ✗\n",
            "Sample 1261: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1262: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 1263: Predicted 'K' (conf: 0.9987), True 'T' ✗\n",
            "Sample 1264: Predicted 'N' (conf: 0.9853), True 'N' ✓\n",
            "Sample 1265: Predicted 'O' (conf: 0.9885), True 'O' ✓\n",
            "Sample 1266: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 1267: Predicted 'V' (conf: 0.9956), True 'V' ✓\n",
            "Sample 1268: Predicted 'X' (conf: 0.9985), True 'X' ✓\n",
            "Sample 1269: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 1270: Predicted 'D' (conf: 0.9950), True 'D' ✓\n",
            "Sample 1271: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 1272: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 1273: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 1274: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 1275: Predicted 'F' (conf: 0.9856), True 'F' ✓\n",
            "Sample 1276: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 1277: Predicted 'R' (conf: 0.5713), True 'M' ✗\n",
            "Sample 1278: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1279: Predicted 'Q' (conf: 0.9910), True 'Q' ✓\n",
            "Sample 1280: Predicted 'C' (conf: 0.9844), True 'C' ✓\n",
            "Sample 1281: Predicted 'A' (conf: 0.9588), True 'A' ✓\n",
            "Sample 1282: Predicted 'F' (conf: 0.8713), True 'Q' ✗\n",
            "Sample 1283: Predicted 'Z' (conf: 0.9994), True '2' ✗\n",
            "Sample 1284: Predicted 'A' (conf: 0.9012), True 'A' ✓\n",
            "Sample 1285: Predicted 'T' (conf: 0.3521), True 'F' ✗\n",
            "Sample 1286: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1287: Predicted 'X' (conf: 0.9984), True 'X' ✓\n",
            "Sample 1288: Predicted 'F' (conf: 0.7888), True 'B' ✗\n",
            "Sample 1289: Predicted 'T' (conf: 0.9831), True 'T' ✓\n",
            "Sample 1290: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 1291: Predicted 'C' (conf: 0.9838), True 'C' ✓\n",
            "Sample 1292: Predicted 'W' (conf: 0.9981), True 'W' ✓\n",
            "Sample 1293: Predicted 'N' (conf: 0.9842), True 'N' ✓\n",
            "Sample 1294: Predicted 'U' (conf: 0.9899), True 'U' ✓\n",
            "Sample 1295: Predicted 'V' (conf: 0.9924), True 'V' ✓\n",
            "Sample 1296: Predicted 'M' (conf: 0.9808), True 'N' ✗\n",
            "Sample 1297: Predicted 'M' (conf: 0.9912), True 'M' ✓\n",
            "Sample 1298: Predicted 'O' (conf: 0.6550), True 'S' ✗\n",
            "Sample 1299: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 1300: Predicted 'D' (conf: 0.9932), True 'D' ✓\n",
            "Sample 1301: Predicted 'N' (conf: 0.9743), True 'N' ✓\n",
            "Sample 1302: Predicted 'T' (conf: 0.9821), True 'T' ✓\n",
            "Sample 1303: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 1304: Predicted 'R' (conf: 0.9964), True 'R' ✓\n",
            "Sample 1305: Predicted 'M' (conf: 0.9747), True 'M' ✓\n",
            "Sample 1306: Predicted 'F' (conf: 0.9966), True 'B' ✗\n",
            "Sample 1307: Predicted 'I' (conf: 0.9989), True 'I' ✓\n",
            "Sample 1308: Predicted 'V' (conf: 0.9912), True 'V' ✓\n",
            "Sample 1309: Predicted 'A' (conf: 0.9971), True 'A' ✓\n",
            "Sample 1310: Predicted 'D' (conf: 0.5453), True 'D' ✓\n",
            "Sample 1311: Predicted 'F' (conf: 0.4491), True 'Q' ✗\n",
            "Sample 1312: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1313: Predicted 'O' (conf: 0.9814), True 'S' ✗\n",
            "Sample 1314: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 1315: Predicted 'K' (conf: 0.9975), True 'K' ✓\n",
            "Sample 1316: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 1317: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1318: Predicted 'T' (conf: 0.4166), True 'F' ✗\n",
            "Sample 1319: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 1320: Predicted 'C' (conf: 0.9847), True 'C' ✓\n",
            "Sample 1321: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 1322: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 1323: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1324: Predicted 'Q' (conf: 0.9895), True 'Q' ✓\n",
            "Sample 1325: Predicted 'F' (conf: 0.9937), True 'F' ✓\n",
            "Sample 1326: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 1327: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 1328: Predicted 'A' (conf: 0.9860), True 'A' ✓\n",
            "Sample 1329: Predicted 'D' (conf: 0.6643), True 'P' ✗\n",
            "Sample 1330: Predicted 'S' (conf: 0.9991), True 'S' ✓\n",
            "Sample 1331: Predicted 'T' (conf: 0.9773), True 'T' ✓\n",
            "Sample 1332: Predicted 'K' (conf: 0.9288), True 'K' ✓\n",
            "Sample 1333: Predicted 'I' (conf: 0.2102), True 'N' ✗\n",
            "Sample 1334: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 1335: Predicted 'D' (conf: 0.9943), True 'D' ✓\n",
            "Sample 1336: Predicted 'R' (conf: 0.6925), True 'M' ✗\n",
            "Sample 1337: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 1338: Predicted 'V' (conf: 0.9911), True 'V' ✓\n",
            "Sample 1339: Predicted 'U' (conf: 0.9909), True 'O' ✗\n",
            "Sample 1340: Predicted 'N' (conf: 0.5780), True 'R' ✗\n",
            "Sample 1341: Predicted 'I' (conf: 0.5674), True 'S' ✗\n",
            "Sample 1342: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 1343: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "Sample 1344: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 1345: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "Sample 1346: Predicted 'T' (conf: 0.9823), True 'T' ✓\n",
            "Sample 1347: Predicted 'A' (conf: 0.9974), True 'A' ✓\n",
            "Sample 1348: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "Sample 1349: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 1350: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "Sample 1351: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 1352: Predicted 'R' (conf: 0.9962), True 'R' ✓\n",
            "Sample 1353: Predicted 'V' (conf: 0.9943), True 'V' ✓\n",
            "Sample 1354: Predicted 'P' (conf: 0.9846), True 'P' ✓\n",
            "Sample 1355: Predicted 'O' (conf: 0.7633), True 'C' ✗\n",
            "Sample 1356: Predicted 'M' (conf: 0.6631), True 'M' ✓\n",
            "Sample 1357: Predicted 'S' (conf: 0.3745), True 'W' ✗\n",
            "Sample 1358: Predicted 'U' (conf: 0.9962), True 'U' ✓\n",
            "Sample 1359: Predicted 'F' (conf: 0.8466), True 'F' ✓\n",
            "Sample 1360: Predicted 'E' (conf: 0.9428), True 'Q' ✗\n",
            "Sample 1361: Predicted 'X' (conf: 0.9975), True 'X' ✓\n",
            "Sample 1362: Predicted 'L' (conf: 0.9958), True 'L' ✓\n",
            "Sample 1363: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "Sample 1364: Predicted 'I' (conf: 0.8757), True 'Q' ✗\n",
            "Sample 1365: Predicted 'W' (conf: 0.4101), True 'G' ✗\n",
            "Sample 1366: Predicted 'C' (conf: 0.9831), True 'C' ✓\n",
            "Sample 1367: Predicted 'T' (conf: 0.8915), True 'F' ✗\n",
            "Sample 1368: Predicted 'O' (conf: 0.9885), True 'O' ✓\n",
            "Sample 1369: Predicted 'I' (conf: 0.9670), True 'I' ✓\n",
            "Sample 1370: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "Sample 1371: Predicted 'S' (conf: 0.4644), True 'S' ✓\n",
            "Sample 1372: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 1373: Predicted 'X' (conf: 0.8678), True 'A' ✗\n",
            "Sample 1374: Predicted 'Z' (conf: 0.9995), True 'Z' ✓\n",
            "Sample 1375: Predicted 'P' (conf: 0.9849), True 'P' ✓\n",
            "Sample 1376: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "Sample 1377: Predicted 'Q' (conf: 0.5210), True 'Q' ✓\n",
            "Sample 1378: Predicted 'R' (conf: 0.9904), True 'R' ✓\n",
            "Sample 1379: Predicted 'X' (conf: 0.9985), True 'X' ✓\n",
            "Sample 1380: Predicted 'W' (conf: 0.9982), True 'W' ✓\n",
            "Sample 1381: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 1382: Predicted 'V' (conf: 0.7401), True 'V' ✓\n",
            "Sample 1383: Predicted 'I' (conf: 0.8873), True 'I' ✓\n",
            "Sample 1384: Predicted 'T' (conf: 0.6283), True 'F' ✗\n",
            "Sample 1385: Predicted 'T' (conf: 0.9823), True 'T' ✓\n",
            "Sample 1386: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 1387: Predicted 'Q' (conf: 0.9915), True 'Q' ✓\n",
            "Sample 1388: Predicted 'W' (conf: 0.9993), True 'W' ✓\n",
            "Sample 1389: Predicted 'L' (conf: 0.6424), True 'C' ✗\n",
            "Sample 1390: Predicted 'O' (conf: 0.9883), True 'O' ✓\n",
            "Sample 1391: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "Sample 1392: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "Sample 1393: Predicted 'X' (conf: 0.5679), True 'A' ✗\n",
            "Sample 1394: Predicted 'D' (conf: 0.9955), True 'D' ✓\n",
            "Sample 1395: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "Sample 1396: Predicted 'M' (conf: 0.9797), True 'M' ✓\n",
            "Sample 1397: Predicted 'G' (conf: 0.9164), True 'G' ✓\n",
            "Sample 1398: Predicted 'R' (conf: 0.9960), True 'R' ✓\n",
            "Sample 1399: Predicted 'W' (conf: 0.6966), True 'S' ✗\n",
            "Sample 1400: Predicted 'U' (conf: 0.9964), True 'U' ✓\n",
            "Sample 1401: Predicted 'N' (conf: 0.9851), True 'N' ✓\n",
            "Sample 1402: Predicted 'V' (conf: 0.5068), True 'V' ✓\n",
            "Sample 1403: Predicted 'N' (conf: 0.9741), True 'N' ✓\n",
            "Sample 1404: Predicted 'V' (conf: 0.5687), True 'V' ✓\n",
            "Sample 1405: Predicted 'B' (conf: 0.9967), True 'B' ✓\n",
            "Sample 1406: Predicted 'D' (conf: 0.9941), True 'D' ✓\n",
            "Sample 1407: Predicted 'L' (conf: 0.9959), True 'C' ✗\n",
            "Sample 1408: Predicted 'Z' (conf: 0.9994), True 'Z' ✓\n",
            "Sample 1409: Predicted 'P' (conf: 0.9847), True 'P' ✓\n",
            "Sample 1410: Predicted 'D' (conf: 0.7433), True 'K' ✗\n",
            "Sample 1411: Predicted 'K' (conf: 0.5816), True 'T' ✗\n",
            "Sample 1412: Predicted 'W' (conf: 0.9994), True 'W' ✓\n",
            "Sample 1413: Predicted 'G' (conf: 0.9989), True 'G' ✓\n",
            "Sample 1414: Predicted 'F' (conf: 0.9951), True 'F' ✓\n",
            "Sample 1415: Predicted 'X' (conf: 0.9984), True 'X' ✓\n",
            "Sample 1416: Predicted 'J' (conf: 0.4452), True 'R' ✗\n",
            "Sample 1417: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "Sample 1418: Predicted 'O' (conf: 0.9882), True 'O' ✓\n",
            "Sample 1419: Predicted 'I' (conf: 0.4472), True 'I' ✓\n",
            "Sample 1420: Predicted 'M' (conf: 0.9944), True 'M' ✓\n",
            "Sample 1421: Predicted 'Y' (conf: 0.9180), True 'Q' ✗\n",
            "Sample 1422: Predicted 'Q' (conf: 0.4718), True 'S' ✗\n",
            "Sample 1423: Predicted 'V' (conf: 0.9628), True 'C' ✗\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "def load_test_data(csv_path):\n",
        "    # Load data from CSV\n",
        "    data = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "    # Get the first column (class labels)\n",
        "    labels = data[0].values\n",
        "\n",
        "    # Find indices where labels change - indicating start of new sequences\n",
        "    change_indices = [0] + list(np.where(labels[1:] != labels[:-1])[0] + 1) + [len(labels)]\n",
        "\n",
        "    all_sequences = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Process each sequence\n",
        "    for i in range(len(change_indices) - 1):\n",
        "        start_idx = change_indices[i]\n",
        "        end_idx = change_indices[i+1]\n",
        "\n",
        "        # Get the sequence data\n",
        "        sequence_data = data.iloc[start_idx:end_idx].values\n",
        "        label = sequence_data[0, 0]  # Get label (first column of first row)\n",
        "        features = sequence_data[:, 1:]  # Features start from column 2\n",
        "\n",
        "        num_frames = len(features)\n",
        "\n",
        "        if num_frames < 25:\n",
        "            print(f\"Warning: Sequence at index {start_idx} (class {label}) has fewer than 25 frames ({num_frames}). Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Extract first 25 frames\n",
        "        first_seq = features[:25]\n",
        "\n",
        "        # Extract middle 25 frames\n",
        "        middle_start = (num_frames - 25) // 2\n",
        "        middle_seq = features[middle_start:middle_start + 25]\n",
        "\n",
        "        # Extract last 25 frames\n",
        "        last_seq = features[-25:]\n",
        "\n",
        "        # Add sequences and labels to our lists\n",
        "        all_sequences.append(first_seq)\n",
        "        all_sequences.append(middle_seq)\n",
        "        all_sequences.append(last_seq)\n",
        "\n",
        "        all_labels.extend([label] * 3)  # Add the same label for all 3 sequences from this original sequence\n",
        "\n",
        "        # Print some info\n",
        "        print(f\"Processed sequence: {start_idx}-{end_idx} (length: {num_frames}, class: {label})\")\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_test = np.array(all_sequences)\n",
        "    y_test = np.array(all_labels)\n",
        "\n",
        "    # Print shapes for verification\n",
        "    print(f\"X_test shape: {X_test.shape}\")  # Should be (num_sequences*3, 25, 84)\n",
        "    print(f\"y_test shape: {y_test.shape}\")  # Should be (num_sequences*3,)\n",
        "\n",
        "    return X_test, y_test, change_indices\n",
        "\n",
        "def predict_with_voting(model, X_test, y_test, label_encoder, change_indices):\n",
        "    # Make predictions for all sequences\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Get the predicted class indices\n",
        "    pred_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Convert indices to class names\n",
        "    pred_classes = label_encoder.inverse_transform(pred_indices)\n",
        "\n",
        "    # Group predictions by original sequence (every 3 predictions belong to one original sequence)\n",
        "    final_predictions = []\n",
        "    final_labels = []\n",
        "    final_confidences = []\n",
        "\n",
        "    for i in range(0, len(y_test), 3):\n",
        "        # Get the 3 sequences for this sample (first, middle, last)\n",
        "        sample_preds = predictions[i:i+3]\n",
        "        original_label = y_test[i]  # All 3 sequences have the same label\n",
        "\n",
        "        # Combine the predictions (average the probabilities)\n",
        "        combined_pred = np.mean(sample_preds, axis=0)\n",
        "        pred_class_idx = np.argmax(combined_pred)\n",
        "        pred_class = label_encoder.inverse_transform([pred_class_idx])[0]\n",
        "        confidence = combined_pred[pred_class_idx]\n",
        "\n",
        "        final_predictions.append(pred_class)\n",
        "        final_labels.append(original_label)\n",
        "        final_confidences.append(confidence)\n",
        "\n",
        "    return final_predictions, final_labels, final_confidences\n",
        "\n",
        "def evaluate_results(predictions, true_labels, confidences):\n",
        "    # Calculate accuracy\n",
        "    correct = sum(1 for p, t in zip(predictions, true_labels) if p == t)\n",
        "    accuracy = correct / len(true_labels)\n",
        "\n",
        "    # Create a dictionary to store per-class metrics\n",
        "    class_metrics = {}\n",
        "\n",
        "    # Calculate per-class accuracy\n",
        "    unique_labels = set(true_labels)\n",
        "    for label in unique_labels:\n",
        "        class_indices = [i for i, t in enumerate(true_labels) if t == label]\n",
        "        class_correct = sum(1 for i in class_indices if predictions[i] == true_labels[i])\n",
        "        class_accuracy = class_correct / len(class_indices) if class_indices else 0\n",
        "        class_metrics[label] = {\n",
        "            'accuracy': class_accuracy,\n",
        "            'samples': len(class_indices),\n",
        "            'correct': class_correct\n",
        "        }\n",
        "\n",
        "    return accuracy, class_metrics\n",
        "\n",
        "# Main testing function\n",
        "def test_lstm_model(model_path, test_csv_path, label_encoder_path):\n",
        "    # Load the trained model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Load label encoder classes\n",
        "    label_classes = np.load(label_encoder_path, allow_pickle=True)\n",
        "\n",
        "    # Recreate the label encoder\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.classes_ = label_classes\n",
        "\n",
        "    # Load and prepare test data\n",
        "    X_test, y_test, change_indices = load_test_data(test_csv_path)\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    # Make predictions with voting\n",
        "    predictions, true_labels, confidences = predict_with_voting(model, X_test, y_test, label_encoder, change_indices)\n",
        "\n",
        "    # Evaluate results\n",
        "    accuracy, class_metrics = evaluate_results(predictions, true_labels, confidences)\n",
        "    print(f\"\\nOverall Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Print per-class metrics\n",
        "    print(\"\\nPer-Class Performance:\")\n",
        "    for label, metrics in class_metrics.items():\n",
        "        print(f\"Class '{label}': {metrics['correct']}/{metrics['samples']} correct, Accuracy: {metrics['accuracy']:.4f}\")\n",
        "\n",
        "    # Print individual predictions\n",
        "    print(\"\\nPredictions by Sample:\")\n",
        "    for i, (pred, true, conf) in enumerate(zip(predictions, true_labels, confidences)):\n",
        "        correct = \"✓\" if pred == true else \"✗\"\n",
        "        print(f\"Sample {i+1}: Predicted '{pred}' (conf: {conf:.4f}), True '{true}' {correct}\")\n",
        "\n",
        "    return predictions, true_labels, confidences, accuracy\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"/content/lstm_model_fold_10.h5\"  # Use one of your trained models\n",
        "    test_csv_path = \"/content/combined.csv\"\n",
        "    label_encoder_path = \"/content/label_classes.npy\"\n",
        "\n",
        "    predictions, true_labels, confidences, accuracy = test_lstm_model(model_path, test_csv_path, label_encoder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Pipeline For EHYJ"
      ],
      "metadata": {
        "id": "2grjhE8VMx9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "def load_test_data(csv_path):\n",
        "    # Load data from CSV\n",
        "    data = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "    # Find indices of 'END' markers\n",
        "    end_indices = data.index[data[0] == 'END'].tolist()\n",
        "\n",
        "    all_sequences = []\n",
        "    all_labels = []\n",
        "    all_frame_nums = []  # To store frame numbers\n",
        "\n",
        "    # Process each video sequence\n",
        "    start_idx = 0\n",
        "    for end_idx in end_indices:\n",
        "        # Get video sequence (excluding the END marker row)\n",
        "        video_data = data.iloc[start_idx:end_idx].values\n",
        "\n",
        "        if len(video_data) == 0:\n",
        "            # Skip if no data between markers\n",
        "            start_idx = end_idx + 1\n",
        "            continue\n",
        "\n",
        "        # Get label from the first row\n",
        "        label = video_data[0, 0]\n",
        "\n",
        "        # Extract features (columns 1 to 84) and frame numbers (column 85)\n",
        "        features = video_data[:, 1:85]  # Keypoints are in columns 1-84\n",
        "        frame_nums = video_data[:, 85]  # Frame numbers are in column 85\n",
        "\n",
        "        num_frames = len(features)\n",
        "\n",
        "        if num_frames < 25:\n",
        "            print(f\"Warning: Video at index {start_idx} (class {label}) has fewer than 25 frames ({num_frames}). Skipping.\")\n",
        "            start_idx = end_idx + 1\n",
        "            continue\n",
        "\n",
        "        # Extract first 25 frames\n",
        "        first_seq = features[:25]\n",
        "        first_frames = frame_nums[:25]\n",
        "\n",
        "        # Extract middle 25 frames\n",
        "        middle_start = (num_frames - 25) // 2\n",
        "        middle_seq = features[middle_start:middle_start + 25]\n",
        "        middle_frames = frame_nums[middle_start:middle_start + 25]\n",
        "\n",
        "        # Extract last 25 frames\n",
        "        last_seq = features[-25:]\n",
        "        last_frames = frame_nums[-25:]\n",
        "\n",
        "        # Add sequences and labels to our lists\n",
        "        all_sequences.append(first_seq)\n",
        "        all_sequences.append(middle_seq)\n",
        "        all_sequences.append(last_seq)\n",
        "\n",
        "        all_labels.extend([label] * 3)  # Add the same label for all 3 sequences\n",
        "\n",
        "        # Store frame numbers for reference\n",
        "        all_frame_nums.append(first_frames)\n",
        "        all_frame_nums.append(middle_frames)\n",
        "        all_frame_nums.append(last_frames)\n",
        "\n",
        "        # Print some info\n",
        "        print(f\"Processed video: {start_idx}-{end_idx} (length: {num_frames}, class: {label})\")\n",
        "\n",
        "        # Update start index for next video\n",
        "        start_idx = end_idx + 1\n",
        "\n",
        "    # Process the last segment if there's no final END marker\n",
        "    if start_idx < len(data) and end_indices:\n",
        "        video_data = data.iloc[start_idx:].values\n",
        "        if len(video_data) >= 25:\n",
        "            label = video_data[0, 0]\n",
        "            features = video_data[:, 1:85]\n",
        "            frame_nums = video_data[:, 85]\n",
        "\n",
        "            num_frames = len(features)\n",
        "\n",
        "            # Extract sequences as before\n",
        "            first_seq = features[:25]\n",
        "            first_frames = frame_nums[:25]\n",
        "\n",
        "            middle_start = (num_frames - 25) // 2\n",
        "            middle_seq = features[middle_start:middle_start + 25]\n",
        "            middle_frames = frame_nums[middle_start:middle_start + 25]\n",
        "\n",
        "            last_seq = features[-25:]\n",
        "            last_frames = frame_nums[-25:]\n",
        "\n",
        "            all_sequences.append(first_seq)\n",
        "            all_sequences.append(middle_seq)\n",
        "            all_sequences.append(last_seq)\n",
        "\n",
        "            all_labels.extend([label] * 3)\n",
        "\n",
        "            all_frame_nums.append(first_frames)\n",
        "            all_frame_nums.append(middle_frames)\n",
        "            all_frame_nums.append(last_frames)\n",
        "\n",
        "            print(f\"Processed final video: {start_idx}-{len(data)} (length: {num_frames}, class: {label})\")\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_test = np.array(all_sequences)\n",
        "    y_test = np.array(all_labels)\n",
        "\n",
        "    # Print shapes for verification\n",
        "    print(f\"X_test shape: {X_test.shape}\")  # Should be (num_videos*3, 25, 84)\n",
        "    print(f\"y_test shape: {y_test.shape}\")  # Should be (num_videos*3,)\n",
        "\n",
        "    return X_test, y_test, all_frame_nums\n",
        "\n",
        "def predict_with_voting(model, X_test, y_test, label_encoder, frame_nums):\n",
        "    # Make predictions for all sequences\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Get the predicted class indices\n",
        "    pred_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Convert indices to class names\n",
        "    pred_classes = label_encoder.inverse_transform(pred_indices)\n",
        "\n",
        "    # Group predictions by original video (every 3 predictions belong to one original video)\n",
        "    final_predictions = []\n",
        "    final_labels = []\n",
        "    final_confidences = []\n",
        "    video_details = []  # Store details about each video's predictions\n",
        "\n",
        "    for i in range(0, len(y_test), 3):\n",
        "        # Get the 3 sequences for this sample (first, middle, last)\n",
        "        sample_preds = predictions[i:i+3]\n",
        "        sample_pred_classes = pred_classes[i:i+3]\n",
        "        original_label = y_test[i]  # All 3 sequences have the same label\n",
        "\n",
        "        # Combine the predictions (average the probabilities)\n",
        "        combined_pred = np.mean(sample_preds, axis=0)\n",
        "        pred_class_idx = np.argmax(combined_pred)\n",
        "        pred_class = label_encoder.inverse_transform([pred_class_idx])[0]\n",
        "        confidence = combined_pred[pred_class_idx]\n",
        "\n",
        "        # Store prediction details\n",
        "        video_detail = {\n",
        "            'true_label': original_label,\n",
        "            'predicted_label': pred_class,\n",
        "            'confidence': confidence,\n",
        "            'first_frames_pred': sample_pred_classes[0],\n",
        "            'middle_frames_pred': sample_pred_classes[1],\n",
        "            'last_frames_pred': sample_pred_classes[2],\n",
        "            'first_frames_conf': np.max(sample_preds[0]),\n",
        "            'middle_frames_conf': np.max(sample_preds[1]),\n",
        "            'last_frames_conf': np.max(sample_preds[2]),\n",
        "            'first_frame_nums': frame_nums[i],\n",
        "            'middle_frame_nums': frame_nums[i+1],\n",
        "            'last_frame_nums': frame_nums[i+2]\n",
        "        }\n",
        "\n",
        "        final_predictions.append(pred_class)\n",
        "        final_labels.append(original_label)\n",
        "        final_confidences.append(confidence)\n",
        "        video_details.append(video_detail)\n",
        "\n",
        "    return final_predictions, final_labels, final_confidences, video_details\n",
        "\n",
        "def evaluate_results(predictions, true_labels, confidences, video_details):\n",
        "    # Calculate accuracy\n",
        "    correct = sum(1 for p, t in zip(predictions, true_labels) if p == t)\n",
        "    accuracy = correct / len(true_labels)\n",
        "\n",
        "    # Create a dictionary to store per-class metrics\n",
        "    class_metrics = {}\n",
        "\n",
        "    # Calculate per-class accuracy\n",
        "    unique_labels = set(true_labels)\n",
        "    for label in unique_labels:\n",
        "        class_indices = [i for i, t in enumerate(true_labels) if t == label]\n",
        "        class_correct = sum(1 for i in class_indices if predictions[i] == true_labels[i])\n",
        "        class_accuracy = class_correct / len(class_indices) if class_indices else 0\n",
        "        class_metrics[label] = {\n",
        "            'accuracy': class_accuracy,\n",
        "            'samples': len(class_indices),\n",
        "            'correct': class_correct\n",
        "        }\n",
        "\n",
        "    # Analyze which part of the video (start, middle, end) performs best\n",
        "    segment_correct = {\n",
        "        'first': 0,\n",
        "        'middle': 0,\n",
        "        'last': 0\n",
        "    }\n",
        "    segment_total = 0\n",
        "\n",
        "    for detail in video_details:\n",
        "        segment_total += 1\n",
        "        if detail['first_frames_pred'] == detail['true_label']:\n",
        "            segment_correct['first'] += 1\n",
        "        if detail['middle_frames_pred'] == detail['true_label']:\n",
        "            segment_correct['middle'] += 1\n",
        "        if detail['last_frames_pred'] == detail['true_label']:\n",
        "            segment_correct['last'] += 1\n",
        "\n",
        "    segment_accuracy = {\n",
        "        'first': segment_correct['first'] / segment_total if segment_total > 0 else 0,\n",
        "        'middle': segment_correct['middle'] / segment_total if segment_total > 0 else 0,\n",
        "        'last': segment_correct['last'] / segment_total if segment_total > 0 else 0\n",
        "    }\n",
        "\n",
        "    return accuracy, class_metrics, segment_accuracy\n",
        "\n",
        "# Main testing function\n",
        "def test_lstm_model(model_path, test_csv_path, label_encoder_path):\n",
        "    # Load the trained model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Load label encoder classes\n",
        "    label_classes = np.load(label_encoder_path, allow_pickle=True)\n",
        "\n",
        "    # Recreate the label encoder\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.classes_ = label_classes\n",
        "\n",
        "    # Load and prepare test data\n",
        "    X_test, y_test, frame_nums = load_test_data(test_csv_path)\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    # Make predictions with voting\n",
        "    predictions, true_labels, confidences, video_details = predict_with_voting(\n",
        "        model, X_test, y_test, label_encoder, frame_nums\n",
        "    )\n",
        "\n",
        "    # Evaluate results\n",
        "    accuracy, class_metrics, segment_accuracy = evaluate_results(\n",
        "        predictions, true_labels, confidences, video_details\n",
        "    )\n",
        "\n",
        "    print(f\"\\nOverall Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Print per-class metrics\n",
        "    print(\"\\nPer-Class Performance:\")\n",
        "    for label, metrics in class_metrics.items():\n",
        "        print(f\"Class '{label}': {metrics['correct']}/{metrics['samples']} correct, Accuracy: {metrics['accuracy']:.4f}\")\n",
        "\n",
        "    # Print segment performance\n",
        "    print(\"\\nSegment Performance:\")\n",
        "    print(f\"First 25 frames accuracy: {segment_accuracy['first']:.4f}\")\n",
        "    print(f\"Middle 25 frames accuracy: {segment_accuracy['middle']:.4f}\")\n",
        "    print(f\"Last 25 frames accuracy: {segment_accuracy['last']:.4f}\")\n",
        "\n",
        "    # Print individual predictions\n",
        "    print(\"\\nPredictions by Video:\")\n",
        "    for i, (pred, true, conf) in enumerate(zip(predictions, true_labels, confidences)):\n",
        "        correct = \"✓\" if pred == true else \"✗\"\n",
        "        detail = video_details[i]\n",
        "        print(f\"Video {i+1}: Predicted '{pred}' (conf: {conf:.4f}), True '{true}' {correct}\")\n",
        "        print(f\"  First frames: {detail['first_frames_pred']} (conf: {detail['first_frames_conf']:.4f})\")\n",
        "        print(f\"  Middle frames: {detail['middle_frames_pred']} (conf: {detail['middle_frames_conf']:.4f})\")\n",
        "        print(f\"  Last frames: {detail['last_frames_pred']} (conf: {detail['last_frames_conf']:.4f})\")\n",
        "\n",
        "    return predictions, true_labels, confidences, accuracy, video_details\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"/content/lstm_model_fold_10.h5\"  # Use your trained model\n",
        "    test_csv_path = \"/content/Parents' Keypoints (E, H, J and Y) 28th April-LSTM1.csv\"\n",
        "    label_encoder_path = \"/content/label_classes.npy\"\n",
        "\n",
        "    predictions, true_labels, confidences, accuracy, video_details = test_lstm_model(\n",
        "        model_path, test_csv_path, label_encoder_path\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBNSaHoSM102",
        "outputId": "4d84322c-888c-4a31-91a6-9247c0acd9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed video: 0-44 (length: 44, class: H)\n",
            "Processed video: 45-98 (length: 53, class: H)\n",
            "Processed video: 99-131 (length: 32, class: H)\n",
            "Processed video: 132-174 (length: 42, class: H)\n",
            "Processed video: 175-218 (length: 43, class: H)\n",
            "Processed video: 219-248 (length: 29, class: H)\n",
            "Processed video: 249-302 (length: 53, class: H)\n",
            "Processed video: 303-358 (length: 55, class: H)\n",
            "Processed video: 359-407 (length: 48, class: H)\n",
            "Processed video: 408-457 (length: 49, class: H)\n",
            "Processed video: 458-513 (length: 55, class: H)\n",
            "Processed video: 514-570 (length: 56, class: H)\n",
            "Processed video: 571-626 (length: 55, class: H)\n",
            "Processed video: 627-683 (length: 56, class: H)\n",
            "Processed video: 684-739 (length: 55, class: H)\n",
            "Processed video: 740-796 (length: 56, class: H)\n",
            "Processed video: 797-853 (length: 56, class: H)\n",
            "Processed video: 854-910 (length: 56, class: H)\n",
            "Processed video: 911-966 (length: 55, class: H)\n",
            "Processed video: 967-1022 (length: 55, class: H)\n",
            "Processed video: 1023-1079 (length: 56, class: H)\n",
            "Processed video: 1080-1136 (length: 56, class: H)\n",
            "Processed video: 1137-1193 (length: 56, class: H)\n",
            "Processed video: 1194-1249 (length: 55, class: H)\n",
            "Processed video: 1250-1306 (length: 56, class: H)\n",
            "Processed video: 1307-1351 (length: 44, class: H)\n",
            "Processed video: 1352-1408 (length: 56, class: H)\n",
            "Processed video: 1409-1464 (length: 55, class: H)\n",
            "Processed video: 1465-1510 (length: 45, class: H)\n",
            "Processed video: 1511-1564 (length: 53, class: H)\n",
            "Processed video: 1565-1620 (length: 55, class: H)\n",
            "Processed video: 1621-1677 (length: 56, class: H)\n",
            "Processed video: 1678-1734 (length: 56, class: H)\n",
            "Processed video: 1735-1790 (length: 55, class: H)\n",
            "Processed video: 1791-1847 (length: 56, class: H)\n",
            "Processed video: 1848-1903 (length: 55, class: H)\n",
            "Processed video: 1904-1960 (length: 56, class: H)\n",
            "Processed video: 1961-2012 (length: 51, class: H)\n",
            "Processed video: 2013-2068 (length: 55, class: H)\n",
            "Processed video: 2069-2125 (length: 56, class: H)\n",
            "Processed video: 2126-2181 (length: 55, class: H)\n",
            "Processed video: 2182-2229 (length: 47, class: H)\n",
            "Processed video: 2230-2271 (length: 41, class: H)\n",
            "Processed video: 2272-2327 (length: 55, class: H)\n",
            "Processed video: 2328-2384 (length: 56, class: H)\n",
            "Processed video: 2385-2438 (length: 53, class: H)\n",
            "Processed video: 2439-2493 (length: 54, class: H)\n",
            "Processed video: 2494-2548 (length: 54, class: H)\n",
            "Processed video: 2549-2602 (length: 53, class: H)\n",
            "Processed video: 2603-2658 (length: 55, class: H)\n",
            "Processed video: 2659-2711 (length: 52, class: H)\n",
            "Processed video: 2712-2765 (length: 53, class: H)\n",
            "Processed video: 2766-2815 (length: 49, class: H)\n",
            "Processed video: 2816-2868 (length: 52, class: H)\n",
            "Processed video: 2869-2921 (length: 52, class: H)\n",
            "Processed video: 2922-2974 (length: 52, class: H)\n",
            "Processed video: 2975-3028 (length: 53, class: H)\n",
            "Processed video: 3029-3083 (length: 54, class: H)\n",
            "Processed video: 3084-3137 (length: 53, class: H)\n",
            "Processed video: 3138-3188 (length: 50, class: H)\n",
            "Processed video: 3189-3239 (length: 50, class: H)\n",
            "Processed video: 3240-3297 (length: 57, class: H)\n",
            "Processed video: 3298-3354 (length: 56, class: H)\n",
            "Processed video: 3355-3411 (length: 56, class: H)\n",
            "Processed video: 3412-3468 (length: 56, class: H)\n",
            "Processed video: 3469-3525 (length: 56, class: H)\n",
            "Processed video: 3526-3582 (length: 56, class: H)\n",
            "Processed video: 3583-3640 (length: 57, class: H)\n",
            "Processed video: 3641-3697 (length: 56, class: H)\n",
            "Processed video: 3698-3753 (length: 55, class: H)\n",
            "Processed video: 3754-3810 (length: 56, class: H)\n",
            "Processed video: 3811-3866 (length: 55, class: H)\n",
            "Processed video: 3867-3924 (length: 57, class: H)\n",
            "Processed video: 3925-3981 (length: 56, class: H)\n",
            "Processed video: 3982-4038 (length: 56, class: H)\n",
            "Processed video: 4039-4096 (length: 57, class: H)\n",
            "Processed video: 4097-4151 (length: 54, class: H)\n",
            "Processed video: 4152-4207 (length: 55, class: H)\n",
            "Processed video: 4208-4264 (length: 56, class: H)\n",
            "Processed video: 4265-4321 (length: 56, class: H)\n",
            "Processed video: 4322-4378 (length: 56, class: H)\n",
            "Processed video: 4379-4432 (length: 53, class: J)\n",
            "Processed video: 4433-4488 (length: 55, class: J)\n",
            "Processed video: 4489-4540 (length: 51, class: J)\n",
            "Processed video: 4541-4594 (length: 53, class: J)\n",
            "Processed video: 4595-4650 (length: 55, class: J)\n",
            "Processed video: 4651-4704 (length: 53, class: J)\n",
            "Processed video: 4705-4753 (length: 48, class: J)\n",
            "Processed video: 4754-4805 (length: 51, class: J)\n",
            "Processed video: 4806-4854 (length: 48, class: J)\n",
            "Processed video: 4855-4900 (length: 45, class: J)\n",
            "Processed video: 4901-4954 (length: 53, class: J)\n",
            "Processed video: 4955-5007 (length: 52, class: J)\n",
            "Processed video: 5008-5059 (length: 51, class: J)\n",
            "Processed video: 5060-5114 (length: 54, class: J)\n",
            "Processed video: 5115-5168 (length: 53, class: J)\n",
            "Processed video: 5169-5217 (length: 48, class: J)\n",
            "Processed video: 5218-5267 (length: 49, class: J)\n",
            "Processed video: 5268-5317 (length: 49, class: J)\n",
            "Processed video: 5318-5368 (length: 50, class: J)\n",
            "Processed video: 5369-5408 (length: 39, class: J)\n",
            "Processed video: 5409-5463 (length: 54, class: J)\n",
            "Processed video: 5464-5519 (length: 55, class: J)\n",
            "Warning: Video at index 5520 (class J) has fewer than 25 frames (5). Skipping.\n",
            "Warning: Video at index 5526 (class J) has fewer than 25 frames (3). Skipping.\n",
            "Warning: Video at index 5530 (class J) has fewer than 25 frames (16). Skipping.\n",
            "Processed video: 5547-5588 (length: 41, class: J)\n",
            "Processed video: 5589-5622 (length: 33, class: J)\n",
            "Warning: Video at index 5623 (class J) has fewer than 25 frames (23). Skipping.\n",
            "Processed video: 5647-5678 (length: 31, class: J)\n",
            "Processed video: 5679-5717 (length: 38, class: J)\n",
            "Warning: Video at index 5718 (class J) has fewer than 25 frames (21). Skipping.\n",
            "Warning: Video at index 5740 (class J) has fewer than 25 frames (12). Skipping.\n",
            "Warning: Video at index 5753 (class J) has fewer than 25 frames (14). Skipping.\n",
            "Warning: Video at index 5768 (class J) has fewer than 25 frames (18). Skipping.\n",
            "Warning: Video at index 5787 (class J) has fewer than 25 frames (18). Skipping.\n",
            "Warning: Video at index 5806 (class J) has fewer than 25 frames (11). Skipping.\n",
            "Processed video: 5818-5852 (length: 34, class: J)\n",
            "Processed video: 5853-5882 (length: 29, class: J)\n",
            "Warning: Video at index 5883 (class J) has fewer than 25 frames (11). Skipping.\n",
            "Warning: Video at index 5895 (class J) has fewer than 25 frames (9). Skipping.\n",
            "Warning: Video at index 5905 (class J) has fewer than 25 frames (11). Skipping.\n",
            "Warning: Video at index 5917 (class J) has fewer than 25 frames (5). Skipping.\n",
            "Warning: Video at index 5923 (class J) has fewer than 25 frames (10). Skipping.\n",
            "Warning: Video at index 5934 (class J) has fewer than 25 frames (19). Skipping.\n",
            "Warning: Video at index 5954 (class J) has fewer than 25 frames (5). Skipping.\n",
            "Processed video: 5960-5997 (length: 37, class: J)\n",
            "Processed video: 5998-6041 (length: 43, class: J)\n",
            "Processed video: 6042-6081 (length: 39, class: J)\n",
            "Processed video: 6082-6124 (length: 42, class: J)\n",
            "Processed video: 6125-6170 (length: 45, class: J)\n",
            "Processed video: 6171-6220 (length: 49, class: J)\n",
            "Processed video: 6221-6269 (length: 48, class: J)\n",
            "Processed video: 6270-6323 (length: 53, class: J)\n",
            "Processed video: 6324-6372 (length: 48, class: J)\n",
            "Processed video: 6373-6421 (length: 48, class: J)\n",
            "Processed video: 6422-6476 (length: 54, class: J)\n",
            "Processed video: 6477-6527 (length: 50, class: J)\n",
            "Processed video: 6528-6579 (length: 51, class: J)\n",
            "Processed video: 6580-6629 (length: 49, class: J)\n",
            "Processed video: 6630-6678 (length: 48, class: J)\n",
            "Processed video: 6679-6730 (length: 51, class: J)\n",
            "Processed video: 6731-6785 (length: 54, class: J)\n",
            "Processed video: 6786-6840 (length: 54, class: J)\n",
            "Processed video: 6841-6881 (length: 40, class: J)\n",
            "Processed video: 6882-6938 (length: 56, class: J)\n",
            "Processed video: 6939-6984 (length: 45, class: J)\n",
            "Processed video: 6985-7041 (length: 56, class: J)\n",
            "Processed video: 7042-7098 (length: 56, class: J)\n",
            "Processed video: 7099-7155 (length: 56, class: J)\n",
            "Processed video: 7156-7213 (length: 57, class: J)\n",
            "Processed video: 7214-7262 (length: 48, class: J)\n",
            "Processed video: 7263-7318 (length: 55, class: J)\n",
            "Processed video: 7319-7374 (length: 55, class: J)\n",
            "Processed video: 7375-7431 (length: 56, class: J)\n",
            "Processed video: 7432-7488 (length: 56, class: J)\n",
            "Processed video: 7489-7545 (length: 56, class: J)\n",
            "Processed video: 7546-7602 (length: 56, class: J)\n",
            "Processed video: 7603-7658 (length: 55, class: J)\n",
            "Processed video: 7659-7709 (length: 50, class: J)\n",
            "Processed video: 7710-7765 (length: 55, class: Y)\n",
            "Processed video: 7766-7822 (length: 56, class: Y)\n",
            "Processed video: 7823-7879 (length: 56, class: Y)\n",
            "Processed video: 7880-7936 (length: 56, class: Y)\n",
            "Processed video: 7937-7993 (length: 56, class: Y)\n",
            "Processed video: 7994-8050 (length: 56, class: Y)\n",
            "Processed video: 8051-8106 (length: 55, class: Y)\n",
            "Processed video: 8107-8162 (length: 55, class: Y)\n",
            "Processed video: 8163-8219 (length: 56, class: Y)\n",
            "Processed video: 8220-8275 (length: 55, class: Y)\n",
            "Processed video: 8276-8332 (length: 56, class: Y)\n",
            "Processed video: 8333-8389 (length: 56, class: Y)\n",
            "Processed video: 8390-8445 (length: 55, class: Y)\n",
            "Processed video: 8446-8501 (length: 55, class: Y)\n",
            "Processed video: 8502-8558 (length: 56, class: Y)\n",
            "Processed video: 8559-8614 (length: 55, class: Y)\n",
            "Processed video: 8615-8671 (length: 56, class: Y)\n",
            "Processed video: 8672-8728 (length: 56, class: Y)\n",
            "Processed video: 8729-8784 (length: 55, class: Y)\n",
            "Processed video: 8785-8840 (length: 55, class: Y)\n",
            "Processed video: 8841-8897 (length: 56, class: Y)\n",
            "Processed video: 8898-8954 (length: 56, class: Y)\n",
            "Processed video: 8955-9010 (length: 55, class: Y)\n",
            "Processed video: 9011-9067 (length: 56, class: Y)\n",
            "Processed video: 9068-9124 (length: 56, class: Y)\n",
            "Processed video: 9125-9181 (length: 56, class: Y)\n",
            "Processed video: 9182-9238 (length: 56, class: Y)\n",
            "Processed video: 9239-9295 (length: 56, class: Y)\n",
            "Processed video: 9296-9352 (length: 56, class: Y)\n",
            "Processed video: 9353-9409 (length: 56, class: Y)\n",
            "Processed video: 9410-9466 (length: 56, class: Y)\n",
            "Processed video: 9467-9523 (length: 56, class: Y)\n",
            "Processed video: 9524-9580 (length: 56, class: Y)\n",
            "Processed video: 9581-9636 (length: 55, class: Y)\n",
            "Processed video: 9637-9693 (length: 56, class: Y)\n",
            "Processed video: 9694-9750 (length: 56, class: Y)\n",
            "Processed video: 9751-9807 (length: 56, class: Y)\n",
            "Processed video: 9808-9864 (length: 56, class: Y)\n",
            "Processed video: 9865-9921 (length: 56, class: Y)\n",
            "Processed video: 9922-9978 (length: 56, class: Y)\n",
            "Processed video: 9979-10035 (length: 56, class: Y)\n",
            "Processed video: 10036-10092 (length: 56, class: Y)\n",
            "Processed video: 10093-10149 (length: 56, class: Y)\n",
            "Processed video: 10150-10205 (length: 55, class: Y)\n",
            "Processed video: 10206-10261 (length: 55, class: Y)\n",
            "Processed video: 10262-10318 (length: 56, class: Y)\n",
            "Processed video: 10319-10375 (length: 56, class: Y)\n",
            "Processed video: 10376-10432 (length: 56, class: Y)\n",
            "Processed video: 10433-10488 (length: 55, class: Y)\n",
            "Processed video: 10489-10544 (length: 55, class: Y)\n",
            "Processed video: 10545-10600 (length: 55, class: Y)\n",
            "Processed video: 10601-10656 (length: 55, class: Y)\n",
            "Processed video: 10657-10711 (length: 54, class: Y)\n",
            "Processed video: 10712-10767 (length: 55, class: Y)\n",
            "Processed video: 10768-10823 (length: 55, class: Y)\n",
            "Processed video: 10824-10880 (length: 56, class: Y)\n",
            "Processed video: 10881-10936 (length: 55, class: Y)\n",
            "Processed video: 10937-10992 (length: 55, class: Y)\n",
            "Processed video: 10993-11048 (length: 55, class: Y)\n",
            "Processed video: 11049-11104 (length: 55, class: Y)\n",
            "Processed video: 11105-11160 (length: 55, class: Y)\n",
            "Processed video: 11161-11216 (length: 55, class: Y)\n",
            "Processed video: 11217-11272 (length: 55, class: Y)\n",
            "Processed video: 11273-11328 (length: 55, class: Y)\n",
            "Processed video: 11329-11384 (length: 55, class: Y)\n",
            "Processed video: 11385-11439 (length: 54, class: Y)\n",
            "Processed video: 11440-11495 (length: 55, class: Y)\n",
            "Processed video: 11496-11551 (length: 55, class: Y)\n",
            "Processed video: 11552-11607 (length: 55, class: Y)\n",
            "Processed video: 11608-11664 (length: 56, class: Y)\n",
            "Processed video: 11665-11721 (length: 56, class: Y)\n",
            "Processed video: 11722-11778 (length: 56, class: Y)\n",
            "Processed video: 11779-11836 (length: 57, class: Y)\n",
            "Processed video: 11837-11893 (length: 56, class: Y)\n",
            "Processed video: 11894-11949 (length: 55, class: Y)\n",
            "Processed video: 11950-12006 (length: 56, class: Y)\n",
            "Processed video: 12007-12064 (length: 57, class: Y)\n",
            "Processed video: 12065-12121 (length: 56, class: Y)\n",
            "Processed video: 12122-12178 (length: 56, class: Y)\n",
            "Processed video: 12179-12235 (length: 56, class: Y)\n",
            "Processed video: 12236-12292 (length: 56, class: Y)\n",
            "Processed video: 12293-12350 (length: 57, class: Y)\n",
            "Processed video: 12351-12407 (length: 56, class: Y)\n",
            "Processed video: 12408-12464 (length: 56, class: Y)\n",
            "Processed video: 12465-12521 (length: 56, class: Y)\n",
            "X_test shape: (684, 25, 84)\n",
            "y_test shape: (684,)\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\n",
            "Overall Test Accuracy: 0.5746\n",
            "\n",
            "Per-Class Performance:\n",
            "Class 'Y': 84/85 correct, Accuracy: 0.9882\n",
            "Class 'J': 13/62 correct, Accuracy: 0.2097\n",
            "Class 'H': 34/81 correct, Accuracy: 0.4198\n",
            "\n",
            "Segment Performance:\n",
            "First 25 frames accuracy: 0.5877\n",
            "Middle 25 frames accuracy: 0.5351\n",
            "Last 25 frames accuracy: 0.4956\n",
            "\n",
            "Predictions by Video:\n",
            "Video 1: Predicted 'T' (conf: 0.4258), True 'H' ✗\n",
            "  First frames: H (conf: 0.2234)\n",
            "  Middle frames: T (conf: 0.4569)\n",
            "  Last frames: T (conf: 0.7472)\n",
            "Video 2: Predicted 'T' (conf: 0.3393), True 'H' ✗\n",
            "  First frames: C (conf: 0.1669)\n",
            "  Middle frames: S (conf: 0.2105)\n",
            "  Last frames: T (conf: 0.7274)\n",
            "Video 3: Predicted 'T' (conf: 0.3799), True 'H' ✗\n",
            "  First frames: T (conf: 0.2045)\n",
            "  Middle frames: T (conf: 0.4097)\n",
            "  Last frames: T (conf: 0.5255)\n",
            "Video 4: Predicted 'T' (conf: 0.4008), True 'H' ✗\n",
            "  First frames: C (conf: 0.5113)\n",
            "  Middle frames: T (conf: 0.3966)\n",
            "  Last frames: T (conf: 0.8022)\n",
            "Video 5: Predicted 'C' (conf: 0.3065), True 'H' ✗\n",
            "  First frames: C (conf: 0.8459)\n",
            "  Middle frames: T (conf: 0.2202)\n",
            "  Last frames: Y (conf: 0.2684)\n",
            "Video 6: Predicted 'T' (conf: 0.6455), True 'H' ✗\n",
            "  First frames: S (conf: 0.5757)\n",
            "  Middle frames: T (conf: 0.7731)\n",
            "  Last frames: T (conf: 0.8148)\n",
            "Video 7: Predicted 'T' (conf: 0.5065), True 'H' ✗\n",
            "  First frames: T (conf: 0.2908)\n",
            "  Middle frames: T (conf: 0.4681)\n",
            "  Last frames: T (conf: 0.7604)\n",
            "Video 8: Predicted 'C' (conf: 0.3995), True 'H' ✗\n",
            "  First frames: S (conf: 0.5295)\n",
            "  Middle frames: C (conf: 0.9660)\n",
            "  Last frames: T (conf: 0.8402)\n",
            "Video 9: Predicted 'T' (conf: 0.5737), True 'H' ✗\n",
            "  First frames: C (conf: 0.9744)\n",
            "  Middle frames: T (conf: 0.8487)\n",
            "  Last frames: T (conf: 0.8722)\n",
            "Video 10: Predicted 'C' (conf: 0.6504), True 'H' ✗\n",
            "  First frames: C (conf: 0.9667)\n",
            "  Middle frames: C (conf: 0.9821)\n",
            "  Last frames: T (conf: 0.7677)\n",
            "Video 11: Predicted 'T' (conf: 0.4283), True 'H' ✗\n",
            "  First frames: C (conf: 0.9817)\n",
            "  Middle frames: T (conf: 0.3970)\n",
            "  Last frames: T (conf: 0.8881)\n",
            "Video 12: Predicted 'T' (conf: 0.5214), True 'H' ✗\n",
            "  First frames: C (conf: 0.9729)\n",
            "  Middle frames: T (conf: 0.7590)\n",
            "  Last frames: T (conf: 0.8051)\n",
            "Video 13: Predicted 'T' (conf: 0.8507), True 'H' ✗\n",
            "  First frames: T (conf: 0.7556)\n",
            "  Middle frames: T (conf: 0.8991)\n",
            "  Last frames: T (conf: 0.8974)\n",
            "Video 14: Predicted 'C' (conf: 0.3618), True 'H' ✗\n",
            "  First frames: C (conf: 0.9401)\n",
            "  Middle frames: S (conf: 0.5432)\n",
            "  Last frames: T (conf: 0.4027)\n",
            "Video 15: Predicted 'S' (conf: 0.4521), True 'H' ✗\n",
            "  First frames: S (conf: 0.9892)\n",
            "  Middle frames: C (conf: 0.9786)\n",
            "  Last frames: S (conf: 0.3661)\n",
            "Video 16: Predicted 'T' (conf: 0.3615), True 'H' ✗\n",
            "  First frames: C (conf: 0.9749)\n",
            "  Middle frames: S (conf: 0.3599)\n",
            "  Last frames: T (conf: 0.8023)\n",
            "Video 17: Predicted 'C' (conf: 0.6541), True 'H' ✗\n",
            "  First frames: C (conf: 0.9724)\n",
            "  Middle frames: C (conf: 0.9835)\n",
            "  Last frames: T (conf: 0.5768)\n",
            "Video 18: Predicted 'T' (conf: 0.5291), True 'H' ✗\n",
            "  First frames: C (conf: 0.7240)\n",
            "  Middle frames: T (conf: 0.7927)\n",
            "  Last frames: T (conf: 0.7917)\n",
            "Video 19: Predicted 'C' (conf: 0.3451), True 'H' ✗\n",
            "  First frames: C (conf: 0.9839)\n",
            "  Middle frames: S (conf: 0.3840)\n",
            "  Last frames: T (conf: 0.5946)\n",
            "Video 20: Predicted 'T' (conf: 0.4343), True 'H' ✗\n",
            "  First frames: C (conf: 0.9794)\n",
            "  Middle frames: T (conf: 0.7894)\n",
            "  Last frames: T (conf: 0.5134)\n",
            "Video 21: Predicted 'C' (conf: 0.6291), True 'H' ✗\n",
            "  First frames: C (conf: 0.9828)\n",
            "  Middle frames: C (conf: 0.9039)\n",
            "  Last frames: T (conf: 0.8406)\n",
            "Video 22: Predicted 'T' (conf: 0.7902), True 'H' ✗\n",
            "  First frames: T (conf: 0.8096)\n",
            "  Middle frames: T (conf: 0.7749)\n",
            "  Last frames: T (conf: 0.7860)\n",
            "Video 23: Predicted 'C' (conf: 0.6593), True 'H' ✗\n",
            "  First frames: C (conf: 0.9732)\n",
            "  Middle frames: C (conf: 0.9818)\n",
            "  Last frames: S (conf: 0.5510)\n",
            "Video 24: Predicted 'S' (conf: 0.2851), True 'H' ✗\n",
            "  First frames: C (conf: 0.6061)\n",
            "  Middle frames: T (conf: 0.7171)\n",
            "  Last frames: S (conf: 0.5327)\n",
            "Video 25: Predicted 'H' (conf: 0.9778), True 'H' ✓\n",
            "  First frames: H (conf: 0.9390)\n",
            "  Middle frames: H (conf: 0.9977)\n",
            "  Last frames: H (conf: 0.9968)\n",
            "Video 26: Predicted 'H' (conf: 0.9975), True 'H' ✓\n",
            "  First frames: H (conf: 0.9979)\n",
            "  Middle frames: H (conf: 0.9976)\n",
            "  Last frames: H (conf: 0.9969)\n",
            "Video 27: Predicted 'H' (conf: 0.9973), True 'H' ✓\n",
            "  First frames: H (conf: 0.9976)\n",
            "  Middle frames: H (conf: 0.9975)\n",
            "  Last frames: H (conf: 0.9968)\n",
            "Video 28: Predicted 'H' (conf: 0.9966), True 'H' ✓\n",
            "  First frames: H (conf: 0.9966)\n",
            "  Middle frames: H (conf: 0.9976)\n",
            "  Last frames: H (conf: 0.9958)\n",
            "Video 29: Predicted 'H' (conf: 0.9975), True 'H' ✓\n",
            "  First frames: H (conf: 0.9976)\n",
            "  Middle frames: H (conf: 0.9977)\n",
            "  Last frames: H (conf: 0.9972)\n",
            "Video 30: Predicted 'H' (conf: 0.9968), True 'H' ✓\n",
            "  First frames: H (conf: 0.9973)\n",
            "  Middle frames: H (conf: 0.9971)\n",
            "  Last frames: H (conf: 0.9960)\n",
            "Video 31: Predicted 'H' (conf: 0.9928), True 'H' ✓\n",
            "  First frames: H (conf: 0.9978)\n",
            "  Middle frames: H (conf: 0.9971)\n",
            "  Last frames: H (conf: 0.9833)\n",
            "Video 32: Predicted 'H' (conf: 0.9961), True 'H' ✓\n",
            "  First frames: H (conf: 0.9979)\n",
            "  Middle frames: H (conf: 0.9966)\n",
            "  Last frames: H (conf: 0.9939)\n",
            "Video 33: Predicted 'H' (conf: 0.9963), True 'H' ✓\n",
            "  First frames: H (conf: 0.9977)\n",
            "  Middle frames: H (conf: 0.9966)\n",
            "  Last frames: H (conf: 0.9945)\n",
            "Video 34: Predicted 'H' (conf: 0.9654), True 'H' ✓\n",
            "  First frames: H (conf: 0.9980)\n",
            "  Middle frames: H (conf: 0.9544)\n",
            "  Last frames: H (conf: 0.9436)\n",
            "Video 35: Predicted 'H' (conf: 0.9570), True 'H' ✓\n",
            "  First frames: H (conf: 0.9980)\n",
            "  Middle frames: H (conf: 0.9552)\n",
            "  Last frames: H (conf: 0.9179)\n",
            "Video 36: Predicted 'H' (conf: 0.9583), True 'H' ✓\n",
            "  First frames: H (conf: 0.9980)\n",
            "  Middle frames: H (conf: 0.9474)\n",
            "  Last frames: H (conf: 0.9296)\n",
            "Video 37: Predicted 'H' (conf: 0.9620), True 'H' ✓\n",
            "  First frames: H (conf: 0.9978)\n",
            "  Middle frames: H (conf: 0.9598)\n",
            "  Last frames: H (conf: 0.9284)\n",
            "Video 38: Predicted 'H' (conf: 0.9580), True 'H' ✓\n",
            "  First frames: H (conf: 0.9976)\n",
            "  Middle frames: H (conf: 0.9520)\n",
            "  Last frames: H (conf: 0.9246)\n",
            "Video 39: Predicted 'H' (conf: 0.9603), True 'H' ✓\n",
            "  First frames: H (conf: 0.9975)\n",
            "  Middle frames: H (conf: 0.9489)\n",
            "  Last frames: H (conf: 0.9343)\n",
            "Video 40: Predicted 'H' (conf: 0.9753), True 'H' ✓\n",
            "  First frames: H (conf: 0.9968)\n",
            "  Middle frames: H (conf: 0.9941)\n",
            "  Last frames: H (conf: 0.9348)\n",
            "Video 41: Predicted 'H' (conf: 0.9684), True 'H' ✓\n",
            "  First frames: H (conf: 0.9959)\n",
            "  Middle frames: H (conf: 0.9541)\n",
            "  Last frames: H (conf: 0.9553)\n",
            "Video 42: Predicted 'H' (conf: 0.9923), True 'H' ✓\n",
            "  First frames: H (conf: 0.9979)\n",
            "  Middle frames: H (conf: 0.9914)\n",
            "  Last frames: H (conf: 0.9875)\n",
            "Video 43: Predicted 'H' (conf: 0.9939), True 'H' ✓\n",
            "  First frames: H (conf: 0.9882)\n",
            "  Middle frames: H (conf: 0.9959)\n",
            "  Last frames: H (conf: 0.9975)\n",
            "Video 44: Predicted 'H' (conf: 0.9874), True 'H' ✓\n",
            "  First frames: H (conf: 0.9975)\n",
            "  Middle frames: H (conf: 0.9902)\n",
            "  Last frames: H (conf: 0.9745)\n",
            "Video 45: Predicted 'H' (conf: 0.9932), True 'H' ✓\n",
            "  First frames: H (conf: 0.9979)\n",
            "  Middle frames: H (conf: 0.9922)\n",
            "  Last frames: H (conf: 0.9894)\n",
            "Video 46: Predicted 'H' (conf: 0.5653), True 'H' ✓\n",
            "  First frames: H (conf: 0.9975)\n",
            "  Middle frames: H (conf: 0.6528)\n",
            "  Last frames: S (conf: 0.4704)\n",
            "Video 47: Predicted 'H' (conf: 0.5216), True 'H' ✓\n",
            "  First frames: H (conf: 0.5672)\n",
            "  Middle frames: H (conf: 0.9974)\n",
            "  Last frames: T (conf: 0.9025)\n",
            "Video 48: Predicted 'T' (conf: 0.5891), True 'H' ✗\n",
            "  First frames: H (conf: 0.9972)\n",
            "  Middle frames: T (conf: 0.8909)\n",
            "  Last frames: T (conf: 0.8764)\n",
            "Video 49: Predicted 'H' (conf: 0.4977), True 'H' ✓\n",
            "  First frames: H (conf: 0.4956)\n",
            "  Middle frames: H (conf: 0.9971)\n",
            "  Last frames: T (conf: 0.8920)\n",
            "Video 50: Predicted 'H' (conf: 0.3488), True 'H' ✓\n",
            "  First frames: S (conf: 0.9334)\n",
            "  Middle frames: H (conf: 0.9967)\n",
            "  Last frames: T (conf: 0.8711)\n",
            "Video 51: Predicted 'T' (conf: 0.5497), True 'H' ✗\n",
            "  First frames: H (conf: 0.9971)\n",
            "  Middle frames: T (conf: 0.8986)\n",
            "  Last frames: T (conf: 0.7505)\n",
            "Video 52: Predicted 'H' (conf: 0.3569), True 'H' ✓\n",
            "  First frames: H (conf: 0.9974)\n",
            "  Middle frames: S (conf: 0.4757)\n",
            "  Last frames: T (conf: 0.6469)\n",
            "Video 53: Predicted 'T' (conf: 0.4805), True 'H' ✗\n",
            "  First frames: H (conf: 0.9977)\n",
            "  Middle frames: T (conf: 0.5852)\n",
            "  Last frames: T (conf: 0.8565)\n",
            "Video 54: Predicted 'H' (conf: 0.3870), True 'H' ✓\n",
            "  First frames: H (conf: 0.9974)\n",
            "  Middle frames: S (conf: 0.4429)\n",
            "  Last frames: T (conf: 0.9049)\n",
            "Video 55: Predicted 'H' (conf: 0.4771), True 'H' ✓\n",
            "  First frames: S (conf: 0.5488)\n",
            "  Middle frames: H (conf: 0.9965)\n",
            "  Last frames: T (conf: 0.6709)\n",
            "Video 56: Predicted 'H' (conf: 0.6595), True 'H' ✓\n",
            "  First frames: H (conf: 0.9064)\n",
            "  Middle frames: H (conf: 0.9978)\n",
            "  Last frames: S (conf: 0.5438)\n",
            "Video 57: Predicted 'H' (conf: 0.6370), True 'H' ✓\n",
            "  First frames: H (conf: 0.8506)\n",
            "  Middle frames: H (conf: 0.9977)\n",
            "  Last frames: S (conf: 0.5056)\n",
            "Video 58: Predicted 'H' (conf: 0.6532), True 'H' ✓\n",
            "  First frames: H (conf: 0.9598)\n",
            "  Middle frames: H (conf: 0.9891)\n",
            "  Last frames: T (conf: 0.7373)\n",
            "Video 59: Predicted 'H' (conf: 0.5073), True 'H' ✓\n",
            "  First frames: H (conf: 0.4973)\n",
            "  Middle frames: H (conf: 0.9975)\n",
            "  Last frames: T (conf: 0.4244)\n",
            "Video 60: Predicted 'H' (conf: 0.6738), True 'H' ✓\n",
            "  First frames: H (conf: 0.9956)\n",
            "  Middle frames: H (conf: 0.9648)\n",
            "  Last frames: S (conf: 0.4750)\n",
            "Video 61: Predicted 'H' (conf: 0.6838), True 'H' ✓\n",
            "  First frames: H (conf: 0.9875)\n",
            "  Middle frames: H (conf: 0.9971)\n",
            "  Last frames: S (conf: 0.5249)\n",
            "Video 62: Predicted 'S' (conf: 0.4897), True 'H' ✗\n",
            "  First frames: S (conf: 0.6807)\n",
            "  Middle frames: S (conf: 0.5102)\n",
            "  Last frames: S (conf: 0.2783)\n",
            "Video 63: Predicted 'S' (conf: 0.6407), True 'H' ✗\n",
            "  First frames: S (conf: 0.9235)\n",
            "  Middle frames: C (conf: 0.9810)\n",
            "  Last frames: S (conf: 0.9973)\n",
            "Video 64: Predicted 'S' (conf: 0.6315), True 'H' ✗\n",
            "  First frames: S (conf: 0.7980)\n",
            "  Middle frames: S (conf: 0.9960)\n",
            "  Last frames: Q (conf: 0.3894)\n",
            "Video 65: Predicted 'S' (conf: 0.6947), True 'H' ✗\n",
            "  First frames: S (conf: 0.6771)\n",
            "  Middle frames: S (conf: 0.9992)\n",
            "  Last frames: S (conf: 0.4079)\n",
            "Video 66: Predicted 'S' (conf: 0.8846), True 'H' ✗\n",
            "  First frames: S (conf: 0.6634)\n",
            "  Middle frames: S (conf: 0.9967)\n",
            "  Last frames: S (conf: 0.9939)\n",
            "Video 67: Predicted 'S' (conf: 0.6633), True 'H' ✗\n",
            "  First frames: S (conf: 0.5426)\n",
            "  Middle frames: S (conf: 0.9942)\n",
            "  Last frames: T (conf: 0.4768)\n",
            "Video 68: Predicted 'T' (conf: 0.6194), True 'H' ✗\n",
            "  First frames: S (conf: 0.4061)\n",
            "  Middle frames: T (conf: 0.9076)\n",
            "  Last frames: T (conf: 0.9447)\n",
            "Video 69: Predicted 'S' (conf: 0.3632), True 'H' ✗\n",
            "  First frames: S (conf: 0.3691)\n",
            "  Middle frames: S (conf: 0.6804)\n",
            "  Last frames: T (conf: 0.8756)\n",
            "Video 70: Predicted 'T' (conf: 0.5896), True 'H' ✗\n",
            "  First frames: S (conf: 0.8270)\n",
            "  Middle frames: T (conf: 0.9234)\n",
            "  Last frames: T (conf: 0.8188)\n",
            "Video 71: Predicted 'T' (conf: 0.4685), True 'H' ✗\n",
            "  First frames: C (conf: 0.9176)\n",
            "  Middle frames: T (conf: 0.6436)\n",
            "  Last frames: T (conf: 0.7616)\n",
            "Video 72: Predicted 'T' (conf: 0.3376), True 'H' ✗\n",
            "  First frames: C (conf: 0.9433)\n",
            "  Middle frames: S (conf: 0.6380)\n",
            "  Last frames: T (conf: 0.9163)\n",
            "Video 73: Predicted 'T' (conf: 0.7148), True 'H' ✗\n",
            "  First frames: T (conf: 0.9063)\n",
            "  Middle frames: T (conf: 0.6729)\n",
            "  Last frames: T (conf: 0.5653)\n",
            "Video 74: Predicted 'T' (conf: 0.3854), True 'H' ✗\n",
            "  First frames: T (conf: 0.9168)\n",
            "  Middle frames: Y (conf: 0.5803)\n",
            "  Last frames: Q (conf: 0.6465)\n",
            "Video 75: Predicted 'T' (conf: 0.8531), True 'H' ✗\n",
            "  First frames: T (conf: 0.7095)\n",
            "  Middle frames: T (conf: 0.9280)\n",
            "  Last frames: T (conf: 0.9219)\n",
            "Video 76: Predicted 'S' (conf: 0.4752), True 'H' ✗\n",
            "  First frames: H (conf: 0.4396)\n",
            "  Middle frames: T (conf: 0.6122)\n",
            "  Last frames: S (conf: 0.9761)\n",
            "Video 77: Predicted 'S' (conf: 0.9677), True 'H' ✗\n",
            "  First frames: S (conf: 0.9140)\n",
            "  Middle frames: S (conf: 0.9908)\n",
            "  Last frames: S (conf: 0.9985)\n",
            "Video 78: Predicted 'S' (conf: 0.7775), True 'H' ✗\n",
            "  First frames: S (conf: 0.9558)\n",
            "  Middle frames: S (conf: 0.7764)\n",
            "  Last frames: S (conf: 0.6004)\n",
            "Video 79: Predicted 'T' (conf: 0.4476), True 'H' ✗\n",
            "  First frames: S (conf: 0.9801)\n",
            "  Middle frames: T (conf: 0.9017)\n",
            "  Last frames: T (conf: 0.4380)\n",
            "Video 80: Predicted 'S' (conf: 0.4820), True 'H' ✗\n",
            "  First frames: S (conf: 0.9763)\n",
            "  Middle frames: T (conf: 0.3760)\n",
            "  Last frames: T (conf: 0.6726)\n",
            "Video 81: Predicted 'T' (conf: 0.6389), True 'H' ✗\n",
            "  First frames: T (conf: 0.5447)\n",
            "  Middle frames: T (conf: 0.7444)\n",
            "  Last frames: T (conf: 0.6274)\n",
            "Video 82: Predicted 'W' (conf: 0.9419), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.8270)\n",
            "Video 83: Predicted 'W' (conf: 0.9993), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9991)\n",
            "Video 84: Predicted 'W' (conf: 0.9993), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9993)\n",
            "Video 85: Predicted 'W' (conf: 0.9993), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9992)\n",
            "Video 86: Predicted 'W' (conf: 0.6501), True 'J' ✗\n",
            "  First frames: W (conf: 0.9510)\n",
            "  Middle frames: W (conf: 0.9990)\n",
            "  Last frames: J (conf: 0.9976)\n",
            "Video 87: Predicted 'J' (conf: 0.6577), True 'J' ✓\n",
            "  First frames: W (conf: 0.9994)\n",
            "  Middle frames: J (conf: 0.9975)\n",
            "  Last frames: J (conf: 0.9755)\n",
            "Video 88: Predicted 'J' (conf: 0.5777), True 'J' ✓\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: J (conf: 0.8171)\n",
            "  Last frames: J (conf: 0.9158)\n",
            "Video 89: Predicted 'W' (conf: 0.5034), True 'J' ✗\n",
            "  First frames: W (conf: 0.5111)\n",
            "  Middle frames: W (conf: 0.9987)\n",
            "  Last frames: J (conf: 0.9923)\n",
            "Video 90: Predicted 'I' (conf: 0.3620), True 'J' ✗\n",
            "  First frames: W (conf: 0.9986)\n",
            "  Middle frames: G (conf: 0.7957)\n",
            "  Last frames: I (conf: 0.9983)\n",
            "Video 91: Predicted 'H' (conf: 0.6239), True 'J' ✗\n",
            "  First frames: V (conf: 0.9490)\n",
            "  Middle frames: H (conf: 0.9909)\n",
            "  Last frames: H (conf: 0.8807)\n",
            "Video 92: Predicted 'J' (conf: 0.3326), True 'J' ✓\n",
            "  First frames: J (conf: 0.9978)\n",
            "  Middle frames: E (conf: 0.9010)\n",
            "  Last frames: H (conf: 0.9684)\n",
            "Video 93: Predicted 'I' (conf: 0.3321), True 'J' ✗\n",
            "  First frames: J (conf: 0.9434)\n",
            "  Middle frames: V (conf: 0.9534)\n",
            "  Last frames: I (conf: 0.9882)\n",
            "Video 94: Predicted 'H' (conf: 0.6463), True 'J' ✗\n",
            "  First frames: J (conf: 0.9975)\n",
            "  Middle frames: H (conf: 0.9510)\n",
            "  Last frames: H (conf: 0.9880)\n",
            "Video 95: Predicted 'J' (conf: 0.6590), True 'J' ✓\n",
            "  First frames: W (conf: 0.9988)\n",
            "  Middle frames: J (conf: 0.9979)\n",
            "  Last frames: J (conf: 0.9787)\n",
            "Video 96: Predicted 'J' (conf: 0.6648), True 'J' ✓\n",
            "  First frames: J (conf: 0.9967)\n",
            "  Middle frames: J (conf: 0.9977)\n",
            "  Last frames: H (conf: 0.8635)\n",
            "Video 97: Predicted 'I' (conf: 0.5745), True 'J' ✗\n",
            "  First frames: I (conf: 0.9961)\n",
            "  Middle frames: W (conf: 0.9960)\n",
            "  Last frames: I (conf: 0.7274)\n",
            "Video 98: Predicted 'V' (conf: 0.5362), True 'J' ✗\n",
            "  First frames: V (conf: 0.7048)\n",
            "  Middle frames: V (conf: 0.9035)\n",
            "  Last frames: I (conf: 0.9923)\n",
            "Video 99: Predicted 'H' (conf: 0.6569), True 'J' ✗\n",
            "  First frames: V (conf: 0.9251)\n",
            "  Middle frames: H (conf: 0.9746)\n",
            "  Last frames: H (conf: 0.9962)\n",
            "Video 100: Predicted 'I' (conf: 0.6632), True 'J' ✗\n",
            "  First frames: I (conf: 0.9316)\n",
            "  Middle frames: H (conf: 0.8901)\n",
            "  Last frames: I (conf: 0.9711)\n",
            "Video 101: Predicted 'V' (conf: 0.3306), True 'J' ✗\n",
            "  First frames: J (conf: 0.7337)\n",
            "  Middle frames: V (conf: 0.8076)\n",
            "  Last frames: H (conf: 0.9095)\n",
            "Video 102: Predicted 'H' (conf: 0.3346), True 'J' ✗\n",
            "  First frames: V (conf: 0.8933)\n",
            "  Middle frames: W (conf: 0.9820)\n",
            "  Last frames: H (conf: 0.9941)\n",
            "Video 103: Predicted 'Y' (conf: 0.9971), True 'J' ✗\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 104: Predicted 'W' (conf: 0.9993), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9993)\n",
            "Video 105: Predicted 'W' (conf: 0.9993), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9994)\n",
            "Video 106: Predicted 'W' (conf: 0.9993), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9994)\n",
            "  Last frames: W (conf: 0.9993)\n",
            "Video 107: Predicted 'W' (conf: 0.9993), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9994)\n",
            "  Last frames: W (conf: 0.9994)\n",
            "Video 108: Predicted 'W' (conf: 0.9993), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9993)\n",
            "Video 109: Predicted 'W' (conf: 0.9994), True 'J' ✗\n",
            "  First frames: W (conf: 0.9994)\n",
            "  Middle frames: W (conf: 0.9994)\n",
            "  Last frames: W (conf: 0.9994)\n",
            "Video 110: Predicted 'I' (conf: 0.6875), True 'J' ✗\n",
            "  First frames: V (conf: 0.8811)\n",
            "  Middle frames: I (conf: 0.9981)\n",
            "  Last frames: I (conf: 0.9977)\n",
            "Video 111: Predicted 'W' (conf: 0.3350), True 'J' ✗\n",
            "  First frames: I (conf: 0.6378)\n",
            "  Middle frames: W (conf: 0.9752)\n",
            "  Last frames: H (conf: 0.7825)\n",
            "Video 112: Predicted 'S' (conf: 0.5731), True 'J' ✗\n",
            "  First frames: S (conf: 0.9887)\n",
            "  Middle frames: S (conf: 0.4581)\n",
            "  Last frames: T (conf: 0.5737)\n",
            "Video 113: Predicted 'I' (conf: 0.4653), True 'J' ✗\n",
            "  First frames: S (conf: 0.8042)\n",
            "  Middle frames: I (conf: 0.5819)\n",
            "  Last frames: I (conf: 0.6967)\n",
            "Video 114: Predicted 'S' (conf: 0.3625), True 'J' ✗\n",
            "  First frames: S (conf: 0.9108)\n",
            "  Middle frames: I (conf: 0.5901)\n",
            "  Last frames: H (conf: 0.5679)\n",
            "Video 115: Predicted 'H' (conf: 0.3198), True 'J' ✗\n",
            "  First frames: S (conf: 0.4932)\n",
            "  Middle frames: H (conf: 0.6863)\n",
            "  Last frames: W (conf: 0.6936)\n",
            "Video 116: Predicted 'I' (conf: 0.6349), True 'J' ✗\n",
            "  First frames: I (conf: 0.4068)\n",
            "  Middle frames: I (conf: 0.6047)\n",
            "  Last frames: I (conf: 0.8932)\n",
            "Video 117: Predicted 'I' (conf: 0.4282), True 'J' ✗\n",
            "  First frames: T (conf: 0.5452)\n",
            "  Middle frames: H (conf: 0.5790)\n",
            "  Last frames: I (conf: 0.9983)\n",
            "Video 118: Predicted 'I' (conf: 0.4108), True 'J' ✗\n",
            "  First frames: S (conf: 0.8168)\n",
            "  Middle frames: H (conf: 0.6976)\n",
            "  Last frames: I (conf: 0.9858)\n",
            "Video 119: Predicted 'S' (conf: 0.3863), True 'J' ✗\n",
            "  First frames: S (conf: 0.8924)\n",
            "  Middle frames: I (conf: 0.4584)\n",
            "  Last frames: H (conf: 0.8252)\n",
            "Video 120: Predicted 'I' (conf: 0.9200), True 'J' ✗\n",
            "  First frames: I (conf: 0.7770)\n",
            "  Middle frames: I (conf: 0.9843)\n",
            "  Last frames: I (conf: 0.9985)\n",
            "Video 121: Predicted 'I' (conf: 0.7413), True 'J' ✗\n",
            "  First frames: I (conf: 0.7391)\n",
            "  Middle frames: I (conf: 0.6308)\n",
            "  Last frames: I (conf: 0.8539)\n",
            "Video 122: Predicted 'I' (conf: 0.9496), True 'J' ✗\n",
            "  First frames: I (conf: 0.8615)\n",
            "  Middle frames: I (conf: 0.9909)\n",
            "  Last frames: I (conf: 0.9965)\n",
            "Video 123: Predicted 'S' (conf: 0.4076), True 'J' ✗\n",
            "  First frames: S (conf: 0.9844)\n",
            "  Middle frames: T (conf: 0.4376)\n",
            "  Last frames: I (conf: 0.9262)\n",
            "Video 124: Predicted 'I' (conf: 0.3740), True 'J' ✗\n",
            "  First frames: S (conf: 0.9158)\n",
            "  Middle frames: I (conf: 0.9988)\n",
            "  Last frames: J (conf: 0.3111)\n",
            "Video 125: Predicted 'J' (conf: 0.6652), True 'J' ✓\n",
            "  First frames: J (conf: 0.9978)\n",
            "  Middle frames: J (conf: 0.9978)\n",
            "  Last frames: W (conf: 0.9994)\n",
            "Video 126: Predicted 'J' (conf: 0.6623), True 'J' ✓\n",
            "  First frames: S (conf: 0.9872)\n",
            "  Middle frames: J (conf: 0.9890)\n",
            "  Last frames: J (conf: 0.9978)\n",
            "Video 127: Predicted 'J' (conf: 0.6653), True 'J' ✓\n",
            "  First frames: J (conf: 0.9979)\n",
            "  Middle frames: J (conf: 0.9979)\n",
            "  Last frames: W (conf: 0.9992)\n",
            "Video 128: Predicted 'L' (conf: 0.6863), True 'J' ✗\n",
            "  First frames: V (conf: 0.6141)\n",
            "  Middle frames: L (conf: 0.9859)\n",
            "  Last frames: L (conf: 0.9398)\n",
            "Video 129: Predicted 'W' (conf: 0.3395), True 'J' ✗\n",
            "  First frames: L (conf: 0.9794)\n",
            "  Middle frames: V (conf: 0.7412)\n",
            "  Last frames: W (conf: 0.9992)\n",
            "Video 130: Predicted 'J' (conf: 0.4464), True 'J' ✓\n",
            "  First frames: W (conf: 0.9525)\n",
            "  Middle frames: V (conf: 0.5658)\n",
            "  Last frames: J (conf: 0.9972)\n",
            "Video 131: Predicted 'J' (conf: 0.6650), True 'J' ✓\n",
            "  First frames: J (conf: 0.9971)\n",
            "  Middle frames: W (conf: 0.9994)\n",
            "  Last frames: J (conf: 0.9978)\n",
            "Video 132: Predicted 'W' (conf: 0.6667), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9994)\n",
            "  Last frames: L (conf: 0.6825)\n",
            "Video 133: Predicted 'W' (conf: 0.7053), True 'J' ✗\n",
            "  First frames: V (conf: 0.4390)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9994)\n",
            "Video 134: Predicted 'W' (conf: 0.6663), True 'J' ✗\n",
            "  First frames: J (conf: 0.9979)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9994)\n",
            "Video 135: Predicted 'W' (conf: 0.6710), True 'J' ✗\n",
            "  First frames: V (conf: 0.8782)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9994)\n",
            "Video 136: Predicted 'W' (conf: 0.6663), True 'J' ✗\n",
            "  First frames: J (conf: 0.9980)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9993)\n",
            "Video 137: Predicted 'J' (conf: 0.5448), True 'J' ✓\n",
            "  First frames: J (conf: 0.9967)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: J (conf: 0.6375)\n",
            "Video 138: Predicted 'J' (conf: 0.3554), True 'J' ✓\n",
            "  First frames: J (conf: 0.9977)\n",
            "  Middle frames: W (conf: 0.9994)\n",
            "  Last frames: V (conf: 0.8648)\n",
            "Video 139: Predicted 'W' (conf: 0.9993), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9993)\n",
            "Video 140: Predicted 'W' (conf: 0.7460), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: U (conf: 0.7046)\n",
            "Video 141: Predicted 'J' (conf: 0.3621), True 'J' ✓\n",
            "  First frames: J (conf: 0.9964)\n",
            "  Middle frames: W (conf: 0.9994)\n",
            "  Last frames: V (conf: 0.7568)\n",
            "Video 142: Predicted 'W' (conf: 0.9994), True 'J' ✗\n",
            "  First frames: W (conf: 0.9994)\n",
            "  Middle frames: W (conf: 0.9993)\n",
            "  Last frames: W (conf: 0.9994)\n",
            "Video 143: Predicted 'W' (conf: 0.6677), True 'J' ✗\n",
            "  First frames: W (conf: 0.9993)\n",
            "  Middle frames: W (conf: 0.9994)\n",
            "  Last frames: V (conf: 0.7124)\n",
            "Video 144: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 145: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 146: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 147: Predicted 'Y' (conf: 0.9970), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9970)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 148: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 149: Predicted 'Y' (conf: 0.9973), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9972)\n",
            "Video 150: Predicted 'Y' (conf: 0.9973), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 151: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 152: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 153: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 154: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 155: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9970)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9973)\n",
            "Video 156: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 157: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 158: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 159: Predicted 'Y' (conf: 0.9970), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9970)\n",
            "  Last frames: Y (conf: 0.9968)\n",
            "Video 160: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 161: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 162: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 163: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9971)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 164: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9970)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 165: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 166: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9971)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9972)\n",
            "Video 167: Predicted 'Y' (conf: 0.9970), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9968)\n",
            "Video 168: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9971)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 169: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9970)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 170: Predicted 'Y' (conf: 0.9970), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9971)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9968)\n",
            "Video 171: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 172: Predicted 'Y' (conf: 0.9970), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9970)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 173: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9970)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 174: Predicted 'Y' (conf: 0.9970), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9969)\n",
            "  Middle frames: Y (conf: 0.9970)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 175: Predicted 'Y' (conf: 0.9968), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9967)\n",
            "  Middle frames: Y (conf: 0.9970)\n",
            "  Last frames: Y (conf: 0.9968)\n",
            "Video 176: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9973)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 177: Predicted 'Y' (conf: 0.9970), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 178: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 179: Predicted 'Y' (conf: 0.6663), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9968)\n",
            "  Middle frames: Y (conf: 0.9961)\n",
            "  Last frames: R (conf: 0.9891)\n",
            "Video 180: Predicted 'Y' (conf: 0.6408), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9203)\n",
            "  Middle frames: Y (conf: 0.9945)\n",
            "  Last frames: R (conf: 0.9881)\n",
            "Video 181: Predicted 'Y' (conf: 0.6684), True 'Y' ✓\n",
            "  First frames: R (conf: 0.9827)\n",
            "  Middle frames: Y (conf: 0.9965)\n",
            "  Last frames: Y (conf: 0.9957)\n",
            "Video 182: Predicted 'R' (conf: 0.6025), True 'Y' ✗\n",
            "  First frames: Y (conf: 0.9957)\n",
            "  Middle frames: R (conf: 0.9498)\n",
            "  Last frames: R (conf: 0.8554)\n",
            "Video 183: Predicted 'Y' (conf: 0.8803), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9429)\n",
            "  Middle frames: Y (conf: 0.9964)\n",
            "  Last frames: Y (conf: 0.7017)\n",
            "Video 184: Predicted 'Y' (conf: 0.9093), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9965)\n",
            "  Last frames: Y (conf: 0.7341)\n",
            "Video 185: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 186: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 187: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 188: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 189: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 190: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9973)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 191: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9974)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9967)\n",
            "Video 192: Predicted 'Y' (conf: 0.9967), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9967)\n",
            "  Middle frames: Y (conf: 0.9968)\n",
            "  Last frames: Y (conf: 0.9968)\n",
            "Video 193: Predicted 'Y' (conf: 0.9946), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9916)\n",
            "  Middle frames: Y (conf: 0.9965)\n",
            "  Last frames: Y (conf: 0.9956)\n",
            "Video 194: Predicted 'Y' (conf: 0.9636), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9018)\n",
            "  Middle frames: Y (conf: 0.9922)\n",
            "  Last frames: Y (conf: 0.9967)\n",
            "Video 195: Predicted 'Y' (conf: 0.9926), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9957)\n",
            "  Middle frames: Y (conf: 0.9913)\n",
            "  Last frames: Y (conf: 0.9907)\n",
            "Video 196: Predicted 'Y' (conf: 0.9954), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9963)\n",
            "  Middle frames: Y (conf: 0.9959)\n",
            "  Last frames: Y (conf: 0.9940)\n",
            "Video 197: Predicted 'Y' (conf: 0.6794), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9823)\n",
            "  Middle frames: R (conf: 0.9273)\n",
            "  Last frames: Y (conf: 0.9961)\n",
            "Video 198: Predicted 'Y' (conf: 0.9585), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9947)\n",
            "  Middle frames: Y (conf: 0.9254)\n",
            "  Last frames: Y (conf: 0.9555)\n",
            "Video 199: Predicted 'Y' (conf: 0.9942), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9967)\n",
            "  Middle frames: Y (conf: 0.9952)\n",
            "  Last frames: Y (conf: 0.9907)\n",
            "Video 200: Predicted 'Y' (conf: 0.9954), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9958)\n",
            "  Middle frames: Y (conf: 0.9938)\n",
            "  Last frames: Y (conf: 0.9968)\n",
            "Video 201: Predicted 'Y' (conf: 0.9842), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9847)\n",
            "  Middle frames: Y (conf: 0.9747)\n",
            "  Last frames: Y (conf: 0.9931)\n",
            "Video 202: Predicted 'Y' (conf: 0.9777), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9935)\n",
            "  Middle frames: Y (conf: 0.9717)\n",
            "  Last frames: Y (conf: 0.9679)\n",
            "Video 203: Predicted 'Y' (conf: 0.9715), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9522)\n",
            "  Middle frames: Y (conf: 0.9668)\n",
            "  Last frames: Y (conf: 0.9955)\n",
            "Video 204: Predicted 'Y' (conf: 0.9942), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9952)\n",
            "  Middle frames: Y (conf: 0.9908)\n",
            "  Last frames: Y (conf: 0.9965)\n",
            "Video 205: Predicted 'Y' (conf: 0.9943), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9964)\n",
            "  Middle frames: Y (conf: 0.9969)\n",
            "  Last frames: Y (conf: 0.9898)\n",
            "Video 206: Predicted 'Y' (conf: 0.9967), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9968)\n",
            "  Middle frames: Y (conf: 0.9966)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 207: Predicted 'Y' (conf: 0.9967), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9964)\n",
            "  Middle frames: Y (conf: 0.9970)\n",
            "  Last frames: Y (conf: 0.9969)\n",
            "Video 208: Predicted 'Y' (conf: 0.9967), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9963)\n",
            "  Middle frames: Y (conf: 0.9968)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 209: Predicted 'Y' (conf: 0.9967), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9963)\n",
            "  Middle frames: Y (conf: 0.9969)\n",
            "  Last frames: Y (conf: 0.9970)\n",
            "Video 210: Predicted 'Y' (conf: 0.9947), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9957)\n",
            "  Middle frames: Y (conf: 0.9941)\n",
            "  Last frames: Y (conf: 0.9942)\n",
            "Video 211: Predicted 'Y' (conf: 0.9964), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9966)\n",
            "  Middle frames: Y (conf: 0.9961)\n",
            "  Last frames: Y (conf: 0.9965)\n",
            "Video 212: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 213: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 214: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 215: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 216: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 217: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9972)\n",
            "Video 218: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 219: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 220: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9971)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 221: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 222: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 223: Predicted 'Y' (conf: 0.9971), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9971)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 224: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9972)\n",
            "Video 225: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 226: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 227: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n",
            "Video 228: Predicted 'Y' (conf: 0.9972), True 'Y' ✓\n",
            "  First frames: Y (conf: 0.9972)\n",
            "  Middle frames: Y (conf: 0.9972)\n",
            "  Last frames: Y (conf: 0.9971)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Pipeline for Left Hnaded\n"
      ],
      "metadata": {
        "id": "gDUeSy7k-DiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "def load_test_data(csv_path):\n",
        "    # Load data from CSV\n",
        "    data = pd.read_csv(csv_path, header=None)\n",
        "\n",
        "    # Find indices of 'END' markers\n",
        "    end_indices = data.index[data[0] == 'END'].tolist()\n",
        "\n",
        "    all_sequences = []\n",
        "    all_labels = []\n",
        "    all_frame_nums = []  # To store frame numbers\n",
        "\n",
        "    # Process each video sequence\n",
        "    start_idx = 0\n",
        "    for end_idx in end_indices:\n",
        "        # Get video sequence (excluding the END marker row)\n",
        "        video_data = data.iloc[start_idx:end_idx].values\n",
        "\n",
        "        if len(video_data) == 0:\n",
        "            # Skip if no data between markers\n",
        "            start_idx = end_idx + 1\n",
        "            continue\n",
        "\n",
        "        # Get label from the first row\n",
        "        label = video_data[0, 0]\n",
        "\n",
        "        # Extract features (columns 1 to 84) and frame numbers (column 85)\n",
        "        features = video_data[:, 1:85]  # Keypoints are in columns 1-84\n",
        "        frame_nums = video_data[:, 85]  # Frame numbers are in column 85\n",
        "\n",
        "        num_frames = len(features)\n",
        "\n",
        "        if num_frames < 25:\n",
        "            print(f\"Warning: Video at index {start_idx} (class {label}) has fewer than 25 frames ({num_frames}). Skipping.\")\n",
        "            start_idx = end_idx + 1\n",
        "            continue\n",
        "\n",
        "        # Extract first 25 frames\n",
        "        first_seq = features[:25]\n",
        "        first_frames = frame_nums[:25]\n",
        "\n",
        "        # Extract middle 25 frames\n",
        "        middle_start = (num_frames - 25) // 2\n",
        "        middle_seq = features[middle_start:middle_start + 25]\n",
        "        middle_frames = frame_nums[middle_start:middle_start + 25]\n",
        "\n",
        "        # Extract last 25 frames\n",
        "        last_seq = features[-25:]\n",
        "        last_frames = frame_nums[-25:]\n",
        "\n",
        "        # Add sequences and labels to our lists\n",
        "        all_sequences.append(first_seq)\n",
        "        all_sequences.append(middle_seq)\n",
        "        all_sequences.append(last_seq)\n",
        "\n",
        "        all_labels.extend([label] * 3)  # Add the same label for all 3 sequences\n",
        "\n",
        "        # Store frame numbers for reference\n",
        "        all_frame_nums.append(first_frames)\n",
        "        all_frame_nums.append(middle_frames)\n",
        "        all_frame_nums.append(last_frames)\n",
        "\n",
        "        # Print some info\n",
        "        print(f\"Processed video: {start_idx}-{end_idx} (length: {num_frames}, class: {label})\")\n",
        "\n",
        "        # Update start index for next video\n",
        "        start_idx = end_idx + 1\n",
        "\n",
        "    # Process the last segment if there's no final END marker\n",
        "    if start_idx < len(data) and end_indices:\n",
        "        video_data = data.iloc[start_idx:].values\n",
        "        if len(video_data) >= 25:\n",
        "            label = video_data[0, 0]\n",
        "            features = video_data[:, 1:85]\n",
        "            frame_nums = video_data[:, 85]\n",
        "\n",
        "            num_frames = len(features)\n",
        "\n",
        "            # Extract sequences as before\n",
        "            first_seq = features[:25]\n",
        "            first_frames = frame_nums[:25]\n",
        "\n",
        "            middle_start = (num_frames - 25) // 2\n",
        "            middle_seq = features[middle_start:middle_start + 25]\n",
        "            middle_frames = frame_nums[middle_start:middle_start + 25]\n",
        "\n",
        "            last_seq = features[-25:]\n",
        "            last_frames = frame_nums[-25:]\n",
        "\n",
        "            all_sequences.append(first_seq)\n",
        "            all_sequences.append(middle_seq)\n",
        "            all_sequences.append(last_seq)\n",
        "\n",
        "            all_labels.extend([label] * 3)\n",
        "\n",
        "            all_frame_nums.append(first_frames)\n",
        "            all_frame_nums.append(middle_frames)\n",
        "            all_frame_nums.append(last_frames)\n",
        "\n",
        "            print(f\"Processed final video: {start_idx}-{len(data)} (length: {num_frames}, class: {label})\")\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_test = np.array(all_sequences)\n",
        "    y_test = np.array(all_labels)\n",
        "\n",
        "    # Print shapes for verification\n",
        "    print(f\"X_test shape: {X_test.shape}\")  # Should be (num_videos*3, 25, 84)\n",
        "    print(f\"y_test shape: {y_test.shape}\")  # Should be (num_videos*3,)\n",
        "\n",
        "    return X_test, y_test, all_frame_nums\n",
        "\n",
        "def predict_with_voting(model, X_test, y_test, label_encoder, frame_nums):\n",
        "    # Make predictions for all sequences\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Get the predicted class indices\n",
        "    pred_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Convert indices to class names\n",
        "    pred_classes = label_encoder.inverse_transform(pred_indices)\n",
        "\n",
        "    # Group predictions by original video (every 3 predictions belong to one original video)\n",
        "    final_predictions = []\n",
        "    final_labels = []\n",
        "    final_confidences = []\n",
        "    video_details = []  # Store details about each video's predictions\n",
        "\n",
        "    for i in range(0, len(y_test), 3):\n",
        "        # Get the 3 sequences for this sample (first, middle, last)\n",
        "        sample_preds = predictions[i:i+3]\n",
        "        sample_pred_classes = pred_classes[i:i+3]\n",
        "        original_label = y_test[i]  # All 3 sequences have the same label\n",
        "\n",
        "        # Combine the predictions (average the probabilities)\n",
        "        combined_pred = np.mean(sample_preds, axis=0)\n",
        "        pred_class_idx = np.argmax(combined_pred)\n",
        "        pred_class = label_encoder.inverse_transform([pred_class_idx])[0]\n",
        "        confidence = combined_pred[pred_class_idx]\n",
        "\n",
        "        # Store prediction details\n",
        "        video_detail = {\n",
        "            'true_label': original_label,\n",
        "            'predicted_label': pred_class,\n",
        "            'confidence': confidence,\n",
        "            'first_frames_pred': sample_pred_classes[0],\n",
        "            'middle_frames_pred': sample_pred_classes[1],\n",
        "            'last_frames_pred': sample_pred_classes[2],\n",
        "            'first_frames_conf': np.max(sample_preds[0]),\n",
        "            'middle_frames_conf': np.max(sample_preds[1]),\n",
        "            'last_frames_conf': np.max(sample_preds[2]),\n",
        "            'first_frame_nums': frame_nums[i],\n",
        "            'middle_frame_nums': frame_nums[i+1],\n",
        "            'last_frame_nums': frame_nums[i+2]\n",
        "        }\n",
        "\n",
        "        final_predictions.append(pred_class)\n",
        "        final_labels.append(original_label)\n",
        "        final_confidences.append(confidence)\n",
        "        video_details.append(video_detail)\n",
        "\n",
        "    return final_predictions, final_labels, final_confidences, video_details\n",
        "\n",
        "def evaluate_results(predictions, true_labels, confidences, video_details):\n",
        "    # Calculate accuracy\n",
        "    correct = sum(1 for p, t in zip(predictions, true_labels) if p == t)\n",
        "    accuracy = correct / len(true_labels)\n",
        "\n",
        "    # Create a dictionary to store per-class metrics\n",
        "    class_metrics = {}\n",
        "\n",
        "    # Calculate per-class accuracy\n",
        "    unique_labels = set(true_labels)\n",
        "    for label in unique_labels:\n",
        "        class_indices = [i for i, t in enumerate(true_labels) if t == label]\n",
        "        class_correct = sum(1 for i in class_indices if predictions[i] == true_labels[i])\n",
        "        class_accuracy = class_correct / len(class_indices) if class_indices else 0\n",
        "        class_metrics[label] = {\n",
        "            'accuracy': class_accuracy,\n",
        "            'samples': len(class_indices),\n",
        "            'correct': class_correct\n",
        "        }\n",
        "\n",
        "    # Analyze which part of the video (start, middle, end) performs best\n",
        "    segment_correct = {\n",
        "        'first': 0,\n",
        "        'middle': 0,\n",
        "        'last': 0\n",
        "    }\n",
        "    segment_total = 0\n",
        "\n",
        "    for detail in video_details:\n",
        "        segment_total += 1\n",
        "        if detail['first_frames_pred'] == detail['true_label']:\n",
        "            segment_correct['first'] += 1\n",
        "        if detail['middle_frames_pred'] == detail['true_label']:\n",
        "            segment_correct['middle'] += 1\n",
        "        if detail['last_frames_pred'] == detail['true_label']:\n",
        "            segment_correct['last'] += 1\n",
        "\n",
        "    segment_accuracy = {\n",
        "        'first': segment_correct['first'] / segment_total if segment_total > 0 else 0,\n",
        "        'middle': segment_correct['middle'] / segment_total if segment_total > 0 else 0,\n",
        "        'last': segment_correct['last'] / segment_total if segment_total > 0 else 0\n",
        "    }\n",
        "\n",
        "    return accuracy, class_metrics, segment_accuracy\n",
        "\n",
        "# Main testing function\n",
        "def test_lstm_model(model_path, test_csv_path, label_encoder_path):\n",
        "    # Load the trained model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Load label encoder classes\n",
        "    label_classes = np.load(label_encoder_path, allow_pickle=True)\n",
        "\n",
        "    # Recreate the label encoder\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.classes_ = label_classes\n",
        "\n",
        "    # Load and prepare test data\n",
        "    X_test, y_test, frame_nums = load_test_data(test_csv_path)\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    # Make predictions with voting\n",
        "    predictions, true_labels, confidences, video_details = predict_with_voting(\n",
        "        model, X_test, y_test, label_encoder, frame_nums\n",
        "    )\n",
        "\n",
        "    # Evaluate results\n",
        "    accuracy, class_metrics, segment_accuracy = evaluate_results(\n",
        "        predictions, true_labels, confidences, video_details\n",
        "    )\n",
        "\n",
        "    print(f\"\\nOverall Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Print per-class metrics\n",
        "    print(\"\\nPer-Class Performance:\")\n",
        "    for label, metrics in class_metrics.items():\n",
        "        print(f\"Class '{label}': {metrics['correct']}/{metrics['samples']} correct, Accuracy: {metrics['accuracy']:.4f}\")\n",
        "\n",
        "    # Print segment performance\n",
        "    print(\"\\nSegment Performance:\")\n",
        "    print(f\"First 25 frames accuracy: {segment_accuracy['first']:.4f}\")\n",
        "    print(f\"Middle 25 frames accuracy: {segment_accuracy['middle']:.4f}\")\n",
        "    print(f\"Last 25 frames accuracy: {segment_accuracy['last']:.4f}\")\n",
        "\n",
        "    # Print individual predictions\n",
        "    print(\"\\nPredictions by Video:\")\n",
        "    for i, (pred, true, conf) in enumerate(zip(predictions, true_labels, confidences)):\n",
        "        correct = \"✓\" if pred == true else \"✗\"\n",
        "        detail = video_details[i]\n",
        "        print(f\"Video {i+1}: Predicted '{pred}' (conf: {conf:.4f}), True '{true}' {correct}\")\n",
        "        print(f\"  First frames: {detail['first_frames_pred']} (conf: {detail['first_frames_conf']:.4f})\")\n",
        "        print(f\"  Middle frames: {detail['middle_frames_pred']} (conf: {detail['middle_frames_conf']:.4f})\")\n",
        "        print(f\"  Last frames: {detail['last_frames_pred']} (conf: {detail['last_frames_conf']:.4f})\")\n",
        "\n",
        "    return predictions, true_labels, confidences, accuracy, video_details\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"/content/lstm_model_fold_10.h5\"  # Use your trained model\n",
        "    test_csv_path = \"/content/combined_2.csv\"\n",
        "    label_encoder_path = \"/content/label_classes.npy\"\n",
        "\n",
        "    predictions, true_labels, confidences, accuracy, video_details = test_lstm_model(\n",
        "        model_path, test_csv_path, label_encoder_path\n",
        "    )"
      ],
      "metadata": {
        "id": "ueA_7Uc_NQvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b627ba-8a6e-405e-cb4e-69b7d8f5fcfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed video: 0-62 (length: 62, class: A)\n",
            "Processed video: 63-125 (length: 62, class: A)\n",
            "Processed video: 126-188 (length: 62, class: A)\n",
            "Processed video: 189-251 (length: 62, class: A)\n",
            "Processed video: 252-314 (length: 62, class: B)\n",
            "Processed video: 315-377 (length: 62, class: B)\n",
            "Processed video: 378-440 (length: 62, class: B)\n",
            "Processed video: 441-503 (length: 62, class: B)\n",
            "Processed video: 504-566 (length: 62, class: B)\n",
            "Processed video: 567-629 (length: 62, class: B)\n",
            "Processed video: 630-692 (length: 62, class: C)\n",
            "Processed video: 693-755 (length: 62, class: C)\n",
            "Processed video: 756-795 (length: 39, class: C)\n",
            "Processed video: 796-858 (length: 62, class: A)\n",
            "Processed video: 859-921 (length: 62, class: A)\n",
            "Processed video: 922-984 (length: 62, class: A)\n",
            "Processed video: 985-1047 (length: 62, class: A)\n",
            "Processed video: 1048-1110 (length: 62, class: A)\n",
            "Processed video: 1111-1173 (length: 62, class: B)\n",
            "Processed video: 1174-1236 (length: 62, class: B)\n",
            "Processed video: 1237-1299 (length: 62, class: B)\n",
            "Processed video: 1300-1362 (length: 62, class: B)\n",
            "Processed video: 1363-1425 (length: 62, class: C)\n",
            "Processed video: 1426-1488 (length: 62, class: C)\n",
            "Processed video: 1489-1551 (length: 62, class: C)\n",
            "Processed video: 1552-1614 (length: 62, class: C)\n",
            "Processed video: 1615-1677 (length: 62, class: D)\n",
            "Warning: Video at index 1678 (class D) has fewer than 25 frames (16). Skipping.\n",
            "Processed video: 1695-1757 (length: 62, class: D)\n",
            "Processed video: 1758-1820 (length: 62, class: D)\n",
            "Processed video: 1821-1883 (length: 62, class: D)\n",
            "Processed video: 1884-1946 (length: 62, class: F)\n",
            "Processed video: 1947-2009 (length: 62, class: F)\n",
            "Processed video: 2010-2072 (length: 62, class: F)\n",
            "Processed video: 2073-2135 (length: 62, class: G)\n",
            "Processed video: 2136-2198 (length: 62, class: G)\n",
            "Processed video: 2199-2261 (length: 62, class: G)\n",
            "Processed video: 2262-2324 (length: 62, class: G)\n",
            "Processed video: 2325-2387 (length: 62, class: I)\n",
            "Processed video: 2388-2450 (length: 62, class: I)\n",
            "Processed video: 2451-2513 (length: 62, class: I)\n",
            "Processed video: 2514-2576 (length: 62, class: I)\n",
            "Processed video: 2577-2639 (length: 62, class: K)\n",
            "Processed video: 2640-2702 (length: 62, class: K)\n",
            "Processed video: 2703-2765 (length: 62, class: K)\n",
            "Processed video: 2766-2828 (length: 62, class: K)\n",
            "Processed video: 2829-2891 (length: 62, class: L)\n",
            "Processed video: 2892-2954 (length: 62, class: L)\n",
            "Processed video: 2955-3017 (length: 62, class: L)\n",
            "Processed video: 3018-3080 (length: 62, class: L)\n",
            "Processed video: 3081-3143 (length: 62, class: L)\n",
            "Processed video: 3144-3206 (length: 62, class: M)\n",
            "Processed video: 3207-3269 (length: 62, class: M)\n",
            "Processed video: 3270-3332 (length: 62, class: M)\n",
            "Processed video: 3333-3395 (length: 62, class: N)\n",
            "Processed video: 3396-3458 (length: 62, class: N)\n",
            "Processed video: 3459-3521 (length: 62, class: N)\n",
            "Processed video: 3522-3584 (length: 62, class: N)\n",
            "Processed video: 3585-3647 (length: 62, class: N)\n",
            "Processed video: 3648-3710 (length: 62, class: O)\n",
            "Processed video: 3711-3773 (length: 62, class: O)\n",
            "Processed video: 3774-3836 (length: 62, class: O)\n",
            "Processed video: 3837-3899 (length: 62, class: O)\n",
            "Processed video: 3900-3962 (length: 62, class: P)\n",
            "Processed video: 3963-4025 (length: 62, class: P)\n",
            "Processed video: 4026-4088 (length: 62, class: P)\n",
            "Processed video: 4089-4151 (length: 62, class: P)\n",
            "Processed video: 4152-4214 (length: 62, class: Q)\n",
            "Processed video: 4215-4277 (length: 62, class: Q)\n",
            "Processed video: 4278-4340 (length: 62, class: Q)\n",
            "Processed video: 4341-4403 (length: 62, class: Q)\n",
            "Processed video: 4404-4466 (length: 62, class: R)\n",
            "Processed video: 4467-4529 (length: 62, class: R)\n",
            "Processed video: 4530-4592 (length: 62, class: R)\n",
            "Processed video: 4593-4655 (length: 62, class: S)\n",
            "Processed video: 4656-4718 (length: 62, class: S)\n",
            "Processed video: 4719-4781 (length: 62, class: S)\n",
            "Processed video: 4782-4844 (length: 62, class: S)\n",
            "Processed video: 4845-4907 (length: 62, class: T)\n",
            "Processed video: 4908-4970 (length: 62, class: T)\n",
            "Processed video: 4971-5033 (length: 62, class: T)\n",
            "Processed video: 5034-5096 (length: 62, class: U)\n",
            "Processed video: 5097-5159 (length: 62, class: U)\n",
            "Processed final video: 5160-5189 (length: 29, class: U)\n",
            "X_test shape: (249, 25, 84)\n",
            "y_test shape: (249,)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "\n",
            "Overall Test Accuracy: 0.8072\n",
            "\n",
            "Per-Class Performance:\n",
            "Class 'S': 3/4 correct, Accuracy: 0.7500\n",
            "Class 'B': 10/10 correct, Accuracy: 1.0000\n",
            "Class 'N': 3/5 correct, Accuracy: 0.6000\n",
            "Class 'U': 2/3 correct, Accuracy: 0.6667\n",
            "Class 'C': 6/7 correct, Accuracy: 0.8571\n",
            "Class 'F': 3/3 correct, Accuracy: 1.0000\n",
            "Class 'T': 0/3 correct, Accuracy: 0.0000\n",
            "Class 'M': 3/3 correct, Accuracy: 1.0000\n",
            "Class 'P': 4/4 correct, Accuracy: 1.0000\n",
            "Class 'R': 2/3 correct, Accuracy: 0.6667\n",
            "Class 'I': 4/4 correct, Accuracy: 1.0000\n",
            "Class 'L': 4/5 correct, Accuracy: 0.8000\n",
            "Class 'K': 4/4 correct, Accuracy: 1.0000\n",
            "Class 'G': 4/4 correct, Accuracy: 1.0000\n",
            "Class 'A': 7/9 correct, Accuracy: 0.7778\n",
            "Class 'D': 3/4 correct, Accuracy: 0.7500\n",
            "Class 'Q': 1/4 correct, Accuracy: 0.2500\n",
            "Class 'O': 4/4 correct, Accuracy: 1.0000\n",
            "\n",
            "Segment Performance:\n",
            "First 25 frames accuracy: 0.8072\n",
            "Middle 25 frames accuracy: 0.8193\n",
            "Last 25 frames accuracy: 0.8193\n",
            "\n",
            "Predictions by Video:\n",
            "Video 1: Predicted 'A' (conf: 0.9973), True 'A' ✓\n",
            "  First frames: A (conf: 0.9973)\n",
            "  Middle frames: A (conf: 0.9973)\n",
            "  Last frames: A (conf: 0.9973)\n",
            "Video 2: Predicted 'A' (conf: 0.9975), True 'A' ✓\n",
            "  First frames: A (conf: 0.9975)\n",
            "  Middle frames: A (conf: 0.9975)\n",
            "  Last frames: A (conf: 0.9975)\n",
            "Video 3: Predicted 'A' (conf: 0.9971), True 'A' ✓\n",
            "  First frames: A (conf: 0.9971)\n",
            "  Middle frames: A (conf: 0.9971)\n",
            "  Last frames: A (conf: 0.9970)\n",
            "Video 4: Predicted 'F' (conf: 0.9491), True 'A' ✗\n",
            "  First frames: F (conf: 0.9534)\n",
            "  Middle frames: F (conf: 0.9410)\n",
            "  Last frames: F (conf: 0.9529)\n",
            "Video 5: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "  First frames: B (conf: 0.9970)\n",
            "  Middle frames: B (conf: 0.9970)\n",
            "  Last frames: B (conf: 0.9970)\n",
            "Video 6: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "  First frames: B (conf: 0.9969)\n",
            "  Middle frames: B (conf: 0.9969)\n",
            "  Last frames: B (conf: 0.9969)\n",
            "Video 7: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "  First frames: B (conf: 0.9970)\n",
            "  Middle frames: B (conf: 0.9970)\n",
            "  Last frames: B (conf: 0.9970)\n",
            "Video 8: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "  First frames: B (conf: 0.9970)\n",
            "  Middle frames: B (conf: 0.9970)\n",
            "  Last frames: B (conf: 0.9970)\n",
            "Video 9: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "  First frames: B (conf: 0.9971)\n",
            "  Middle frames: B (conf: 0.9971)\n",
            "  Last frames: B (conf: 0.9971)\n",
            "Video 10: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "  First frames: B (conf: 0.9971)\n",
            "  Middle frames: B (conf: 0.9971)\n",
            "  Last frames: B (conf: 0.9971)\n",
            "Video 11: Predicted 'O' (conf: 0.9854), True 'C' ✗\n",
            "  First frames: O (conf: 0.9852)\n",
            "  Middle frames: O (conf: 0.9850)\n",
            "  Last frames: O (conf: 0.9858)\n",
            "Video 12: Predicted 'C' (conf: 0.9848), True 'C' ✓\n",
            "  First frames: C (conf: 0.9848)\n",
            "  Middle frames: C (conf: 0.9848)\n",
            "  Last frames: C (conf: 0.9848)\n",
            "Video 13: Predicted 'C' (conf: 0.9842), True 'C' ✓\n",
            "  First frames: C (conf: 0.9842)\n",
            "  Middle frames: C (conf: 0.9842)\n",
            "  Last frames: C (conf: 0.9842)\n",
            "Video 14: Predicted 'A' (conf: 0.9956), True 'A' ✓\n",
            "  First frames: A (conf: 0.9961)\n",
            "  Middle frames: A (conf: 0.9956)\n",
            "  Last frames: A (conf: 0.9952)\n",
            "Video 15: Predicted 'A' (conf: 0.9591), True 'A' ✓\n",
            "  First frames: A (conf: 0.9653)\n",
            "  Middle frames: A (conf: 0.9655)\n",
            "  Last frames: A (conf: 0.9466)\n",
            "Video 16: Predicted 'A' (conf: 0.9972), True 'A' ✓\n",
            "  First frames: A (conf: 0.9972)\n",
            "  Middle frames: A (conf: 0.9971)\n",
            "  Last frames: A (conf: 0.9972)\n",
            "Video 17: Predicted 'R' (conf: 0.9963), True 'A' ✗\n",
            "  First frames: R (conf: 0.9964)\n",
            "  Middle frames: R (conf: 0.9963)\n",
            "  Last frames: R (conf: 0.9963)\n",
            "Video 18: Predicted 'A' (conf: 0.9972), True 'A' ✓\n",
            "  First frames: A (conf: 0.9972)\n",
            "  Middle frames: A (conf: 0.9972)\n",
            "  Last frames: A (conf: 0.9972)\n",
            "Video 19: Predicted 'B' (conf: 0.9971), True 'B' ✓\n",
            "  First frames: B (conf: 0.9971)\n",
            "  Middle frames: B (conf: 0.9971)\n",
            "  Last frames: B (conf: 0.9971)\n",
            "Video 20: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "  First frames: B (conf: 0.9970)\n",
            "  Middle frames: B (conf: 0.9970)\n",
            "  Last frames: B (conf: 0.9970)\n",
            "Video 21: Predicted 'B' (conf: 0.9969), True 'B' ✓\n",
            "  First frames: B (conf: 0.9969)\n",
            "  Middle frames: B (conf: 0.9969)\n",
            "  Last frames: B (conf: 0.9969)\n",
            "Video 22: Predicted 'B' (conf: 0.9970), True 'B' ✓\n",
            "  First frames: B (conf: 0.9970)\n",
            "  Middle frames: B (conf: 0.9970)\n",
            "  Last frames: B (conf: 0.9970)\n",
            "Video 23: Predicted 'C' (conf: 0.9839), True 'C' ✓\n",
            "  First frames: C (conf: 0.9839)\n",
            "  Middle frames: C (conf: 0.9839)\n",
            "  Last frames: C (conf: 0.9839)\n",
            "Video 24: Predicted 'C' (conf: 0.9848), True 'C' ✓\n",
            "  First frames: C (conf: 0.9848)\n",
            "  Middle frames: C (conf: 0.9848)\n",
            "  Last frames: C (conf: 0.9848)\n",
            "Video 25: Predicted 'C' (conf: 0.9845), True 'C' ✓\n",
            "  First frames: C (conf: 0.9844)\n",
            "  Middle frames: C (conf: 0.9845)\n",
            "  Last frames: C (conf: 0.9845)\n",
            "Video 26: Predicted 'C' (conf: 0.9844), True 'C' ✓\n",
            "  First frames: C (conf: 0.9844)\n",
            "  Middle frames: C (conf: 0.9844)\n",
            "  Last frames: C (conf: 0.9844)\n",
            "Video 27: Predicted 'D' (conf: 0.8991), True 'D' ✓\n",
            "  First frames: D (conf: 0.8891)\n",
            "  Middle frames: D (conf: 0.9003)\n",
            "  Last frames: D (conf: 0.9078)\n",
            "Video 28: Predicted 'D' (conf: 0.9940), True 'D' ✓\n",
            "  First frames: D (conf: 0.9940)\n",
            "  Middle frames: D (conf: 0.9940)\n",
            "  Last frames: D (conf: 0.9940)\n",
            "Video 29: Predicted 'P' (conf: 0.9832), True 'D' ✗\n",
            "  First frames: P (conf: 0.9832)\n",
            "  Middle frames: P (conf: 0.9832)\n",
            "  Last frames: P (conf: 0.9831)\n",
            "Video 30: Predicted 'D' (conf: 0.9952), True 'D' ✓\n",
            "  First frames: D (conf: 0.9952)\n",
            "  Middle frames: D (conf: 0.9952)\n",
            "  Last frames: D (conf: 0.9952)\n",
            "Video 31: Predicted 'F' (conf: 0.4890), True 'F' ✓\n",
            "  First frames: Q (conf: 0.5570)\n",
            "  Middle frames: F (conf: 0.4402)\n",
            "  Last frames: F (conf: 0.7674)\n",
            "Video 32: Predicted 'F' (conf: 0.7621), True 'F' ✓\n",
            "  First frames: F (conf: 0.7660)\n",
            "  Middle frames: F (conf: 0.7643)\n",
            "  Last frames: F (conf: 0.7562)\n",
            "Video 33: Predicted 'F' (conf: 0.9893), True 'F' ✓\n",
            "  First frames: F (conf: 0.9892)\n",
            "  Middle frames: F (conf: 0.9892)\n",
            "  Last frames: F (conf: 0.9896)\n",
            "Video 34: Predicted 'G' (conf: 0.9985), True 'G' ✓\n",
            "  First frames: G (conf: 0.9990)\n",
            "  Middle frames: G (conf: 0.9981)\n",
            "  Last frames: G (conf: 0.9986)\n",
            "Video 35: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "  First frames: G (conf: 0.9990)\n",
            "  Middle frames: G (conf: 0.9990)\n",
            "  Last frames: G (conf: 0.9990)\n",
            "Video 36: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "  First frames: G (conf: 0.9990)\n",
            "  Middle frames: G (conf: 0.9990)\n",
            "  Last frames: G (conf: 0.9990)\n",
            "Video 37: Predicted 'G' (conf: 0.9990), True 'G' ✓\n",
            "  First frames: G (conf: 0.9990)\n",
            "  Middle frames: G (conf: 0.9990)\n",
            "  Last frames: G (conf: 0.9990)\n",
            "Video 38: Predicted 'I' (conf: 0.9984), True 'I' ✓\n",
            "  First frames: I (conf: 0.9984)\n",
            "  Middle frames: I (conf: 0.9982)\n",
            "  Last frames: I (conf: 0.9985)\n",
            "Video 39: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "  First frames: I (conf: 0.9989)\n",
            "  Middle frames: I (conf: 0.9990)\n",
            "  Last frames: I (conf: 0.9990)\n",
            "Video 40: Predicted 'I' (conf: 0.9990), True 'I' ✓\n",
            "  First frames: I (conf: 0.9991)\n",
            "  Middle frames: I (conf: 0.9990)\n",
            "  Last frames: I (conf: 0.9990)\n",
            "Video 41: Predicted 'I' (conf: 0.9989), True 'I' ✓\n",
            "  First frames: I (conf: 0.9990)\n",
            "  Middle frames: I (conf: 0.9989)\n",
            "  Last frames: I (conf: 0.9989)\n",
            "Video 42: Predicted 'K' (conf: 0.9987), True 'K' ✓\n",
            "  First frames: K (conf: 0.9989)\n",
            "  Middle frames: K (conf: 0.9981)\n",
            "  Last frames: K (conf: 0.9989)\n",
            "Video 43: Predicted 'K' (conf: 0.9987), True 'K' ✓\n",
            "  First frames: K (conf: 0.9987)\n",
            "  Middle frames: K (conf: 0.9987)\n",
            "  Last frames: K (conf: 0.9987)\n",
            "Video 44: Predicted 'K' (conf: 0.9989), True 'K' ✓\n",
            "  First frames: K (conf: 0.9988)\n",
            "  Middle frames: K (conf: 0.9988)\n",
            "  Last frames: K (conf: 0.9991)\n",
            "Video 45: Predicted 'K' (conf: 0.9988), True 'K' ✓\n",
            "  First frames: K (conf: 0.9988)\n",
            "  Middle frames: K (conf: 0.9988)\n",
            "  Last frames: K (conf: 0.9988)\n",
            "Video 46: Predicted 'L' (conf: 0.9959), True 'L' ✓\n",
            "  First frames: L (conf: 0.9959)\n",
            "  Middle frames: L (conf: 0.9959)\n",
            "  Last frames: L (conf: 0.9959)\n",
            "Video 47: Predicted 'L' (conf: 0.9960), True 'L' ✓\n",
            "  First frames: L (conf: 0.9960)\n",
            "  Middle frames: L (conf: 0.9960)\n",
            "  Last frames: L (conf: 0.9960)\n",
            "Video 48: Predicted 'K' (conf: 0.9988), True 'L' ✗\n",
            "  First frames: K (conf: 0.9988)\n",
            "  Middle frames: K (conf: 0.9988)\n",
            "  Last frames: K (conf: 0.9987)\n",
            "Video 49: Predicted 'L' (conf: 0.9961), True 'L' ✓\n",
            "  First frames: L (conf: 0.9961)\n",
            "  Middle frames: L (conf: 0.9961)\n",
            "  Last frames: L (conf: 0.9961)\n",
            "Video 50: Predicted 'L' (conf: 0.9958), True 'L' ✓\n",
            "  First frames: L (conf: 0.9958)\n",
            "  Middle frames: L (conf: 0.9958)\n",
            "  Last frames: L (conf: 0.9958)\n",
            "Video 51: Predicted 'M' (conf: 0.9941), True 'M' ✓\n",
            "  First frames: M (conf: 0.9942)\n",
            "  Middle frames: M (conf: 0.9941)\n",
            "  Last frames: M (conf: 0.9941)\n",
            "Video 52: Predicted 'M' (conf: 0.9892), True 'M' ✓\n",
            "  First frames: M (conf: 0.9892)\n",
            "  Middle frames: M (conf: 0.9894)\n",
            "  Last frames: M (conf: 0.9891)\n",
            "Video 53: Predicted 'M' (conf: 0.9862), True 'M' ✓\n",
            "  First frames: M (conf: 0.9869)\n",
            "  Middle frames: M (conf: 0.9859)\n",
            "  Last frames: M (conf: 0.9858)\n",
            "Video 54: Predicted 'M' (conf: 0.9942), True 'N' ✗\n",
            "  First frames: M (conf: 0.9942)\n",
            "  Middle frames: M (conf: 0.9943)\n",
            "  Last frames: M (conf: 0.9942)\n",
            "Video 55: Predicted 'N' (conf: 0.9844), True 'N' ✓\n",
            "  First frames: N (conf: 0.9845)\n",
            "  Middle frames: N (conf: 0.9845)\n",
            "  Last frames: N (conf: 0.9843)\n",
            "Video 56: Predicted 'N' (conf: 0.9075), True 'N' ✓\n",
            "  First frames: N (conf: 0.9508)\n",
            "  Middle frames: N (conf: 0.8160)\n",
            "  Last frames: N (conf: 0.9555)\n",
            "Video 57: Predicted 'N' (conf: 0.9780), True 'N' ✓\n",
            "  First frames: N (conf: 0.9792)\n",
            "  Middle frames: N (conf: 0.9776)\n",
            "  Last frames: N (conf: 0.9773)\n",
            "Video 58: Predicted 'M' (conf: 0.6959), True 'N' ✗\n",
            "  First frames: M (conf: 0.6739)\n",
            "  Middle frames: M (conf: 0.6801)\n",
            "  Last frames: M (conf: 0.7338)\n",
            "Video 59: Predicted 'O' (conf: 0.9881), True 'O' ✓\n",
            "  First frames: O (conf: 0.9881)\n",
            "  Middle frames: O (conf: 0.9881)\n",
            "  Last frames: O (conf: 0.9881)\n",
            "Video 60: Predicted 'O' (conf: 0.9879), True 'O' ✓\n",
            "  First frames: O (conf: 0.9880)\n",
            "  Middle frames: O (conf: 0.9880)\n",
            "  Last frames: O (conf: 0.9879)\n",
            "Video 61: Predicted 'O' (conf: 0.9884), True 'O' ✓\n",
            "  First frames: O (conf: 0.9884)\n",
            "  Middle frames: O (conf: 0.9883)\n",
            "  Last frames: O (conf: 0.9884)\n",
            "Video 62: Predicted 'O' (conf: 0.9880), True 'O' ✓\n",
            "  First frames: O (conf: 0.9881)\n",
            "  Middle frames: O (conf: 0.9881)\n",
            "  Last frames: O (conf: 0.9880)\n",
            "Video 63: Predicted 'P' (conf: 0.9780), True 'P' ✓\n",
            "  First frames: P (conf: 0.9675)\n",
            "  Middle frames: P (conf: 0.9828)\n",
            "  Last frames: P (conf: 0.9838)\n",
            "Video 64: Predicted 'P' (conf: 0.9844), True 'P' ✓\n",
            "  First frames: P (conf: 0.9843)\n",
            "  Middle frames: P (conf: 0.9844)\n",
            "  Last frames: P (conf: 0.9845)\n",
            "Video 65: Predicted 'P' (conf: 0.9836), True 'P' ✓\n",
            "  First frames: P (conf: 0.9835)\n",
            "  Middle frames: P (conf: 0.9835)\n",
            "  Last frames: P (conf: 0.9837)\n",
            "Video 66: Predicted 'P' (conf: 0.9838), True 'P' ✓\n",
            "  First frames: P (conf: 0.9835)\n",
            "  Middle frames: P (conf: 0.9839)\n",
            "  Last frames: P (conf: 0.9839)\n",
            "Video 67: Predicted 'N' (conf: 0.4760), True 'Q' ✗\n",
            "  First frames: N (conf: 0.5205)\n",
            "  Middle frames: N (conf: 0.6039)\n",
            "  Last frames: T (conf: 0.3472)\n",
            "Video 68: Predicted 'N' (conf: 0.9843), True 'Q' ✗\n",
            "  First frames: N (conf: 0.9844)\n",
            "  Middle frames: N (conf: 0.9848)\n",
            "  Last frames: N (conf: 0.9835)\n",
            "Video 69: Predicted 'R' (conf: 0.9345), True 'Q' ✗\n",
            "  First frames: R (conf: 0.9291)\n",
            "  Middle frames: R (conf: 0.9130)\n",
            "  Last frames: R (conf: 0.9614)\n",
            "Video 70: Predicted 'Q' (conf: 0.9913), True 'Q' ✓\n",
            "  First frames: Q (conf: 0.9913)\n",
            "  Middle frames: Q (conf: 0.9913)\n",
            "  Last frames: Q (conf: 0.9913)\n",
            "Video 71: Predicted 'R' (conf: 0.9507), True 'R' ✓\n",
            "  First frames: R (conf: 0.9839)\n",
            "  Middle frames: R (conf: 0.9273)\n",
            "  Last frames: R (conf: 0.9408)\n",
            "Video 72: Predicted 'R' (conf: 0.9965), True 'R' ✓\n",
            "  First frames: R (conf: 0.9964)\n",
            "  Middle frames: R (conf: 0.9966)\n",
            "  Last frames: R (conf: 0.9965)\n",
            "Video 73: Predicted 'W' (conf: 0.4140), True 'R' ✗\n",
            "  First frames: V (conf: 0.5119)\n",
            "  Middle frames: W (conf: 0.8908)\n",
            "  Last frames: R (conf: 0.9968)\n",
            "Video 74: Predicted 'S' (conf: 0.9994), True 'S' ✓\n",
            "  First frames: S (conf: 0.9994)\n",
            "  Middle frames: S (conf: 0.9994)\n",
            "  Last frames: S (conf: 0.9993)\n",
            "Video 75: Predicted 'H' (conf: 0.9894), True 'S' ✗\n",
            "  First frames: H (conf: 0.9955)\n",
            "  Middle frames: H (conf: 0.9877)\n",
            "  Last frames: H (conf: 0.9850)\n",
            "Video 76: Predicted 'S' (conf: 0.9993), True 'S' ✓\n",
            "  First frames: S (conf: 0.9993)\n",
            "  Middle frames: S (conf: 0.9993)\n",
            "  Last frames: S (conf: 0.9993)\n",
            "Video 77: Predicted 'S' (conf: 0.9991), True 'S' ✓\n",
            "  First frames: S (conf: 0.9991)\n",
            "  Middle frames: S (conf: 0.9991)\n",
            "  Last frames: S (conf: 0.9992)\n",
            "Video 78: Predicted 'K' (conf: 0.9984), True 'T' ✗\n",
            "  First frames: K (conf: 0.9984)\n",
            "  Middle frames: K (conf: 0.9984)\n",
            "  Last frames: K (conf: 0.9985)\n",
            "Video 79: Predicted 'P' (conf: 0.9316), True 'T' ✗\n",
            "  First frames: P (conf: 0.9176)\n",
            "  Middle frames: P (conf: 0.9192)\n",
            "  Last frames: P (conf: 0.9580)\n",
            "Video 80: Predicted 'K' (conf: 0.7826), True 'T' ✗\n",
            "  First frames: K (conf: 0.9123)\n",
            "  Middle frames: K (conf: 0.7781)\n",
            "  Last frames: K (conf: 0.6576)\n",
            "Video 81: Predicted 'U' (conf: 0.9966), True 'U' ✓\n",
            "  First frames: U (conf: 0.9966)\n",
            "  Middle frames: U (conf: 0.9966)\n",
            "  Last frames: U (conf: 0.9965)\n",
            "Video 82: Predicted 'U' (conf: 0.9965), True 'U' ✓\n",
            "  First frames: U (conf: 0.9964)\n",
            "  Middle frames: U (conf: 0.9965)\n",
            "  Last frames: U (conf: 0.9965)\n",
            "Video 83: Predicted 'A' (conf: nan), True 'U' ✗\n",
            "  First frames: U (conf: 0.9965)\n",
            "  Middle frames: U (conf: 0.9966)\n",
            "  Last frames: A (conf: nan)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMAxjf7P-i-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}